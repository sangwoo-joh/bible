<!DOCTYPE html>
<html lang="en" class="no-js">
 <head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.55.6" />
<META NAME="ROBOTS" CONTENT="INDEX, FOLLOW">
<link rel="alternate" type="application/rss&#43;xml" href="/docs/index.xml">
<link rel="shortcut icon" href="/book/assets/favicons/favicon.ico" >
<link rel="apple-touch-icon" href="/book/assets/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="icon" type="image/png" href="/book/assets/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/book/assets/favicons/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/book/assets/favicons/android-icon-36x36.png" sizes="36x36">
<link rel="icon" type="image/png" href="/book/assets/favicons/android-icon-48x48.png" sizes="48x48">
<link rel="icon" type="image/png" href="/book/assets/favicons/android-icon-72x72.png" sizes="72x72">
<link rel="icon" type="image/png" href="/book/assets/favicons/android-icon-96x196.png" sizes="96x196">
<link rel="icon" type="image/png" href="/book/assets/favicons/android-icon-144x144.png" sizes="144x144">
<link rel="icon" type="image/png" href="/book/assets/favicons/android-icon-192x192.png"sizes="192x192">
<title>Search</title>
<meta property="og:title" content="Search" />
<meta property="og:description" content="Engineering Book" />
<meta property="og:type" content="website" />
<meta property="og:url" content="" />
<meta property="og:site_name" content="" />
<meta itemprop="name" content="Search">
<meta itemprop="description" content="Engineering Book">
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Search"/>
<meta name="twitter:description" content="Engineering Book"/>
<link rel="stylesheet" href="/book/assets/css/main.css">
<link rel="stylesheet" href="/book/assets/css/palette.css">
<script
  src="/book/assets/js/jquery-3.3.1/jquery-3.3.1.min.js"
  integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8= sha256-T+aPohYXbm0fRYDpJLr+zJ9RmYTswGsahAoIsNiMld4="
  crossorigin="anonymous"></script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'G-63ZZVFHP73', 'auto');
	ga('send', 'pageview');
}
</script>
 <body class="td-section">
  <header>
 <nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar">
    <a class="navbar-brand" href="/book/">
      <span class="navbar-logo"></span>
      <img src="/book/assets/img/logo.png" width="50">
      <span class="text-uppercase font-weight-bold">Book</span>
	  </a>
	 <div class="td-navbar-nav-scroll ml-md-auto" id="main_navbar">
		 <ul class="navbar-nav mt-2 mt-lg-0">
			 <li class="nav-item mr-4 mb-2 mb-lg-0">
		 </ul>
	 </div>
	 <div class="navbar-nav d-none d-lg-block">
      <input type="search" class="form-control td-search-input" placeholder="&#xf002 Search this site…" aria-label="Search this site…" autocomplete="off">
   </div>
	 <div class="navbar-nav d-none d-lg-block">
      <a class="gh-source" data-gh-source="github" href="https://github.com/sangwoo-joh/book" title="Go to repository" data-md-state="done">
       <div class="gh-source__repository">
          <i class="fab fa fa-github fa-2x" style='padding-right:20px; float:left; margin-top:5px'></i>
          sangwoo-joh/book
         <ul class="gh-source__facts"><li class="gh-source__fact" id='stars'><li id="forks" class="gh-source__fact"></ul></div></a>
   </div>
   </div>
 </nav>
</header>
<script>
 $(document).ready(function() {
   var url = "https://api.github.com/search/repositories?q=sangwoo-joh/book";
   fetch(url, {
     headers: {"Accept":"application/vnd.github.preview"}
   }).then(function(e) {
     return e.json()
   }).then(function(r) {
     console.log(r.items[0])
     stars = r.items[0]['stargazers_count']
     forks = r.items[0]['forks_count']
     $('#stars').text(stars + " Stars")
     $('#forks').text(forks + " Forks")
   });
 });
</script>
   <div class="container-fluid td-outer">
     <div class="td-main">
       <div class="row flex-xl-nowrap">
         <div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none">
         <div id="td-sidebar-menu" class="td-sidebar__inner">
  <form class="td-sidebar__search d-flex align-items-center">
    <input type="search" class="form-control td-search-input" placeholder="&#xf002 Search this site…" aria-label="Search this site…" autocomplete="off">
      <button class="btn btn-link td-sidebar__toggle d-md-none p-0 ml-3 fas fa-bars" type="button" data-toggle="collapse" data-target="#td-section-nav" aria-controls="td-docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
      </button>
  </form>  
 <nav class="collapse td-sidebar-nav pt-2 pl-4" id="td-section-nav">
     <ul class="td-sidebar-nav__section pr-md-3">
       <li class="td-sidebar-nav__section-title">
          <a  href="/book//" class="align-left pl-0 pr-2 active td-sidebar-link td-sidebar-link__section">Book</a>
     </ul>
     <ul class="td-sidebar-nav__section pr-md-3">
       <li class="td-sidebar-nav__section-title">
          <a  href="/book/ps" class="align-left pl-0 pr-2 active td-sidebar-link td-sidebar-link__section">Problem Solving</a>
         <ul>
           <li class="collapse show" id="problem-solving">
             <ul class="td-sidebar-nav__section pr-md-3">
                 <li class="td-sidebar-nav__section-title">
                    <a href="
                                /book/ps/theory
                             " 
                       class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section ">Theory
                    </a>
                 <li class="td-sidebar-nav__section-title">
                    <a href="
                                /book/ps/leetcode
                             " 
                       class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section ">Leetcode
                    </a>
                 <li class="td-sidebar-nav__section-title">
                    <a href="
                                /book/ps/cpp
                             " 
                       class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section ">C++
                    </a>
             </ul>
         </ul>
     </ul>
     <ul class="td-sidebar-nav__section pr-md-3">
       <li class="td-sidebar-nav__section-title">
          <a  href="/book/wip" class="align-left pl-0 pr-2 active td-sidebar-link td-sidebar-link__section">Work in Progress</a>
     </ul>
 </nav>
</div>
         </div>
         <div class="d-none d-xl-block col-xl-2 td-toc d-print-none">
             <div class="td-page-meta ml-2 pb-1 pt-2 mb-0">
                  <a href="https://github.com/sangwoo-joh/book/edit/master/pages/search.html" target="_blank"><i class="fa fa-edit fa-fw"></i> Edit this page</a>
             </div>
             <nav id="TableOfContents"><ul>
             <li><ul id="TOC">
             </ul>
             </ul></nav>
         </div>
         <main class="col-12 col-md-9 col-xl-8 pl-md-5" role="main">
           <nav aria-label="breadcrumb" class="d-none d-md-block d-print-none">
	     <ol class="breadcrumb spb-1">
                   <li class="breadcrumb-item active" aria-current="page">
                      <a href="/book/search/">Search</a>
	     </ol>
          </nav>
          <div class="td-content">        
	      <input class="form-control td-search-input" type="search" name="q" id="search-input" placeholder="&#xf002 Search this site…"  style="margin-top:5px" autofocus>
<i style="color:white; margin-right:8px; margin-left:5px" class="fa fa-search"></i>
<p><span id="search-process">Loading</span> results <span id="search-query-container" style="display: none;">for "<strong id="search-query"></strong>"</span></p>
<ul id="search-results"></ul>
<script>
	window.data = {
					"wip-monadic-parser-combinators-01-intro": {
						"id": "wip-monadic-parser-combinators-01-intro",
						"title": "1. Introduction",
						"version": "all",
						"categories": "",
						"url": " /wip/monadic-parser-combinators/01-intro/",
						"content": "1. 소개\n\n함수형 프로그래밍에서 재귀 하향식 파서를 만드는 대중적인 방법은\n 파서를 함수로 모델링하고, 고차 함수(또는 컴비네이터)를 정의해서\n 시퀀싱, 선택, 반복을 제공하는 문법을 구성하는 것이다. 기본 아이디어는\n 최소 Burge의 “재귀적인 프로그래밍 기술(1975)”에서 찾아야 하고, Wadler\n (1985), Hutton (1992), Fokker (1995) 그 외 많은 이들에 의해 저술된\n 함수형 프로그래밍에 의해 유명해졌다. 컴비네이터는 함수형 파서를\n 만드는 빠르고 쉬운 방법을 제공한다. 게다가, 이 방법은 다른 함수형\n 파서 생성기, 예를 들어 Ratatosk (Mogensen, 1993)과 Happy (Gill &amp;\n Marlow, 1995)보다 좋다.\n\n파서가 모나드의 한 인스턴스라는 것은 일찍이 알려졌는데, 모나드란\n 수학에서 수많은 계산 문제를 해결하는데 유용한 것으로 증명된 대수적\n 구조이다. 수학적 관점에서 흥미로울 뿐만 아니라, 파서의 모나드적\n 천성을 인식하는 일은 실질적인 이득이 있다. 예를 들어, 파서를 만들 때\n 모나드식 시퀀싱 컴비네이터를 이용하면 중첩된 이전 작업 결과의 튜플을\n 다루는 지저분한 작업을 피할 수 있다 (바인드). 게다가, 모나드\n 컴프리헨션 표기를 이용하면 파서를 더욱 컴팩트하게 만들 수 있고 읽기\n 쉬워진다.\n\n모나드식 접근을 더 취하면, 파서의 모나드는 두 개의 더 간단한 모나드를\n 통해 모듈 방식으로 표현할 수 있다. 이를 통한 즉각적인 이득은 기본적인\n 파서 컴비네이터가 더 이상 명시적으로 정의될 필요가 없다는\n 것이다. 대신, 이들은 기본 모나드 m으로부터 m을 파라미터화 한 다른\n 모나드를 리프팅해서 모나드 연산을 만드는 과정에서 자동으로 하나의\n 특수한 경우가 된다. 이는 또한 우리가 기본 모나드를 수정해서 (예를\n 들어 파서를 제한해서 최대 하나의 결과만 내게 하는) 파서의 천성을\n 바꾸면 이 수정된 파서 모나드를 위한 새로운 컴비네이터 역시 구성을\n 리프팅함으로써 자동으로 만들어진다는 뜻이다.\n\n이 글의 목적은 함수형 파서를 만들기 위한 모나드식 접근을 단계 별로\n 설명하기 위한 튜토리얼을 제공하기 위함이며, 모나드를 적극 활용했을\n 때의 장점을 설명하기도 한다. 대부분의 내용은 이미 알려진\n 것들이다. 기여점은 튜토리얼을 제공한다는 점이다. 렉서를 따로 두지\n 않고 렉싱을 다루는 새로운 컴비네이터를 소개하고, 모나드의 사용법에\n 영향을 받아 오프사이드 규칙을 구현하는 새로운 접근도 소개한다."
					}
					,
					"wip-monadic-parser-combinators-02-combinator-parsers": {
						"id": "wip-monadic-parser-combinators-02-combinator-parsers",
						"title": "2. Combinator parsers",
						"version": "all",
						"categories": "",
						"url": " /wip/monadic-parser-combinators/02-combinator-parsers/",
						"content": "2. 컴비네이터 파서\n먼저 옛 현인들의 컴비네이터 파싱에 대한 기본 아이디어를 리뷰하는\n 것부터 시작하자. 구체적으로는 일단 파서와 세 개의 원시 파서, 더 큰\n 파서를 만들기 위한 두 개의 원시 컴비네이터에 대한 타입부터 정의한다.\n\n2.1. 파서의 타입\n먼저 “파서”란 문자열을 입력으로 받아서 어떤 종류의 트리를 결과로\n 내놓는 함수로 생각하는 것부터 시작하자. 트리는 문자열의 문법적 구조를\n 명시적으로 드러낸다.\n\ntype parser = string -&gt; tree\n\n\n첫 번째 아이디어는 바로 파서가 입력 문자열을 전부 소모(consume)하지\n 않을 수도 있다는 것이다. 그러므로, 결과 트리만 리턴하기 보다는 입력\n 문자열에서 아직 소모되지 않은 접두사 부분을 같이 리턴할 수\n 있다. 따라서 파서의 타입은 다음과 같다.\n\ntype parser = string -&gt; (string * tree)\n\n\n두 번째 아이디어는 바로 파서가 어떤 입력 문자열에 대해서는 실패할\n 수도 있다는 것이다. 이럴 때 런타임 에러를 던지는 것보다는, 파서가\n 어느 부분에서 왜 실패했는지를 알려주면 디버깅에 유용할\n 것이다. Result 타입을 이용하면 좋을 것 같다.\n\ntype parser = string -&gt; string * (tree, string) result\n\n\n명시적인 실패 표현을 가지며 입력 문자열에서 소모되지 않은 부분을\n 리턴하는 일은 작은 파서로부터 더 큰 파서를 만들기 위한 컴비네이터를\n 정의할 수 있게 해준다.\n\n서로 다른 파서는 서로 다른 종류의 트리를 리턴하기 마련인데, 따라서\n 구체적인 트리의 타입을 추상화해서 파서의 타입을 파라미터화 하는 것이\n 좋다.\n\ntype 'a parser = string -&gt; string * ('a * string) result\n\n\n입력을 좀더 세분화해서 “어디까지”를 같이 기록하면 좋을 것 같다.\n\ntype input =\n  { text : string\n  ; pos : int\n  }\n\nlet make_input (s: string) : input = { text = s; pos = 0 }\n\n\n마지막으로, 우리는 파서가 항상 클로저를 갖고 있길 원한다. 따라서\n 최종적인 우리의 파서 타입은 다음과 같다.\n\ntype 'a parser =\n  { run : input -&gt; input * ('a, string) result\n  }\n\n\n2.2. 원시(Primitive) 파서\n컴비네이터 파싱의 기본 구성 요소인 네 개의 원시 파서를 볼 것이다.\n\n첫 번째 파서는 return v로 입력 문자열을 아무것도 소모하지 않고\n 성공하고 하나의 결과 v를 리턴한다.\n\nlet return (v: 'a) : 'a parser = { run = fun input -&gt; input, Ok v }\n\n\n두 번째 파서는 항상 실패하는 fail이다. 디버깅을 위한 에러 메시지를\n 함께 받는다.\n\nlet fail (err: string) : 'a parser = { run = fun input -&gt; input, Error err }\n\n\n세 번째 프리미티브는 any_char으로, 입력 문자열에 대해서 첫 번째\n 글자를 항상 소모하거나, 문자열이 비어있으면 실패하는 함수이다. 우리의\n 입력 타입인 input을 좀더 손쉽게 다루기 위해서 먼저 입력에서 일부만\n 소모하는 함수 consume_input을 만들자. consume_input input pos\n len은 주어진 입력 input의 text의 pos부터 len만큼의 문자를\n 소모하고 남은 입력을 리턴한다.\n\nlet consume_input (input: input) (pos: int) (len: int) : input =\n  { text = String.sub (input.text) pos len\n  ; pos = input.pos + pos\n  }\n\n\n이를 이용해 any_char를 구현할 수 있다.\n\nlet any_char : char parser = {\n  run = fun input -&gt;\n    let n = String.length input.text in\n    try\n      consume_input 1 (n - 1) input, Ok (String.get input.text 0)\n    with Invalid_argument _ -&gt; input, Error \"expected any character\"\n}\n\n\n마지막으로, 입력을 직접 소모하지 않고 글자를 하나만 살펴보는 이른바\n 룩어헤드(Lookahead) 파서인 peek_char가 있다. any_char와는 달리\n 조건부 파싱에 쓰일 수 있다.\n\nlet peek_char : char parser = {\n  run = fun input -&gt;\n    try\n      input, Ok (String.get input.text 0)\n    with Invalid_argument _ -&gt; input, Error \"empty input\"\n}\n\n\n2.3. 파서 컴비네이터\n앞서 정의한 원시 파서들은 그 자체로는 그다지 쓸모있지는\n 않다. 여기서는 더 유용한 파서를 만들기 위해서 이 파서를 어떻게 이어\n 붙일 수 있는지(glue)를 살펴본다. 특히, 고차 함수(=컴비네이터)를\n 이용해서 코드를 깔끔하고 읽기 쉽게 만들 수 있다. 함수 적용과 유사한\n 시퀀싱(sequencing; 여러 개의 함수를 연달아 적용) 컴비네이터,\n 선택(choice; 여러 개의 함수 중 성공한 것을 적용) 컴비네이터, 앞\n 쪽을 버리는 컴비네이터, 뒷 쪽을 버리는 컴비네이터 등을 살펴볼\n 것이다. 이렇게 정의된 컴비네이터들은 실제 BNF 문법의 구조와 거의\n 유사한 구조로 파서를 합치는 것을 도와준다.\n\n모나드 방식이 아닌 초창기의 컴비네이터 파싱에서, 파서의 시퀀싱 연산은\n 보통 다음 타입을 가졌었다:\n\nlet seq : 'a parser -&gt; 'b parser -&gt; ('a * 'b) parser\n\n\n즉, 두 파서를 번갈아 적용해서 두 파서의 결과를 튜플로 묶는\n 연산이다. 얼핏 보기에 seq 컴비네이터는 자연스러운 합성 연산으로\n 보인다. 하지만 실제로는 seq을 계속 사용하다 보면 그 결과로 엄청나게\n 중첩된 튜플을 갖게 되는데, 이를 다루는 것은 굉장히 지저분한 일이다.\n\n중첩된 튜플 문제는 모나드식 시퀀싱 컴비네이터를 적용해서 피할 수\n 있다. 흔히 바인드(bind) 연산으로 알려진 것으로, 한 파서의 결과 값을\n 처리해서 파서들을 시퀀싱하여 합치는 방식이다.\n\nlet bind (p: 'a parser) (f: 'a -&gt; 'b parser) : 'b parser =\n  { run = fun input -&gt;\n      match p.run input with\n      | input', Ok x -&gt; (f x).run input'\n      | input', Error err -&gt; input', Error err\n  }\n\n\nbind의 정의는 다음과 같이 이해할 수 있다. 먼저, 파서 p를 입력\n 문자열에 적용해서 결과로 소모되지 않은 입력과 결과 값을\n 가져온다. 만약 실패했다면 (match의 Error err 케이스), 실패를\n 그대로 리턴한다. 성공했다면 'a 타입의 값을 얻을텐데 (match의 Ok\n x 케이스), f가 'a 타입의 값을 받아 'b 타입의 파서를 리턴하는\n 함수이므로 이제 x에 f를 적용해서 새로운 파서를 만들 수 있다. 이때\n 남은 입력에 대해서 적용해야 함을 잊지말자.\n\n참고로 bind 컴비네이터는 bind 라는 함수 그 자체로 호출되기 보다는\n 주로 다음과 같이 중위 연산자로 재정의 되어 쓰이는 것이 일반적이다.\n\nlet (&gt;&gt;=) = bind\n\n\nbind 컴비네이터는 결과의 중첩된 튜플 문제를 피하게 해준다. 왜냐하면\n 첫 번째 파서의 결과가 나중에 처리될 결과와 튜플로 묶이지 않고 곧바로\n 두 번째 파서에 의해서 처리될 수 있기 때문이다.\n\nbind 컴비네이터 (중위 연산자)를 이용한 아주 전형적인 예시를 하나\n 살펴보자. 두 파서를 튜플로 묶는 pair를 bind로 구현하면 다음과\n 같다.\n\nlet pair (p: 'a parser) (q: 'b parser) : ('a * 'b) parser =\n  p &gt;&gt;= fun x -&gt;\n  q &gt;&gt;= fun y -&gt;\n  return (x, y)\n\n\n이걸 해석하면 이렇다. 우리는 파서 p와 파서 q를 합쳐서 다음과 같은\n 동작을 하는 파서를 만들 것이다: 먼저 파서 p를 적용한다. 성공한\n 경우에는 결과 값 x를 사용할 수 있다(fun x -&gt; ..).  그 다음 파서\n q를 나머지 입력에 대해서 적용한다. 역시 성공한 경우 결과 값 y를\n 곧바로 사용할 수 있다(fun y -&gt; ..). 최종적으로 두 결과를 튜플로\n 리턴하는 파서를 리턴한다(return (x, y)). p, q 둘 중 어느\n 파서든 파싱에 실패할 경우 곧바로 해당 에러를 리턴한다. 모나드식 접근\n 덕분에 코드가 아름답고 이해가 잘 된다.\n\nbind 컴비네이터를 이용하면 간단하지만 유용한 파서들을 정의할 수\n 있다. 예를 들어, any_char 파서는 하나의 글자를 무조건적으로\n 파싱했는데, 실제 상황에서는 보통 “특정 글자”에만 관심있기\n 마련이다. 따라서 룩어헤드를 위한 peek_char와 any_char를 이용해서\n 새로운 컴비네이터 satisfy를 만들 수 있다. 이 컴비네이터는 조건\n 함수(predicate)를 받아서 해당 조건을 만족하는 글자만 파싱하고 그렇지\n 않으면 실패한다.\n\nlet satisfy (f: char -&gt; bool) : char parser =\n  peek_char &gt;&gt;= fun x -&gt; if f x then any_char else fail \"Predicate not satisfied.\"\n\n\n이제 satisfy를 이용해서 특정 글자, 숫자, 소문자, 대문자 등을 파싱할\n 수 있다:\n\nlet char (c: char) : char parser = satisfy (fun x -&gt; x = c)\n\nlet digit : char parser = satisfy (fun x -&gt; '0' &lt;= x &amp;&amp; x &lt;= '9')\n\nlet lower : char parser = satisfy (fun x -&gt; 'a' &lt;= x &amp;&amp; x &lt;= 'z')\n\nlet upper : char parser = satisfy (fun x -&gt; 'A' &lt;= x &amp;&amp; x &lt;= 'Z')\n\n\n예를 들어 upper 파서를 입력 문자열 \"Hello\"에 적용하면 다음과 같은\n 결과를 리턴하며 성공할 것이다:\n\nupper.run (make_input \"Hello\") ;;\n- : input * (char, string) result = ({text = \"ello\"; pos = 1}, Ok 'H')\n\n\n즉 첫글자 대문자 H를 성공적으로 파싱한 결과 Ok 'H'와, 입력\n 문자열에서 아직 소모되지 않은 나머지 부분에 대한 정보를 잘 갖고 있다.\n\n만약 digit 파서를 입력 문자열 \"Hello\"에 적용한다면, 파싱에\n 실패하게 되고 다음과 같이 입력 문자열을 하나도 소모하지 않는다.\n\ndigit.run (make_input \"Hello\") ;;\n- : input * (char, string) result =\n({text = \"Hello\"; pos = 0}, Error \"predicate not satisfy\")\n\n\n이제 위에서 만든 파서를 가지고 더 강력한 파서를 만들 수 있는\n 선택(choice) 컴비네이터를 살펴보자. 예를 들어, 우리는 소문자 파서\n lower와 대문자 파서 upper 중 어느 것을 만족해도 상관없는 글자를\n 파싱하는 letter 파서를 정의할 수 있다. 이를 위해서, 우리는 다음과\n 같은 선택 컴비네이터가 필요하다.\n\nlet choice (p1: 'a parser) (p2: 'a parser) : 'a parser =\n  { run =\n      fun input -&gt;\n        let input', result = p1.run input in\n        match result with\n        | Ok x -&gt; input', Ok x\n        | Error err -&gt; p2.run input\n  }\n\n\n즉, choice 컴비네이터는 먼저 첫 번째 파서를 입력 문자열에\n 적용해보고 성공한 경우 남은 입력과 그 결과를 리턴한다. 실패한 경우 두\n 번째 파서를 마저 적용해본다. 둘 중 어느 것이든 만족하면 그만인\n 것이다. 참고로 선택 컴비네이터는 파서가 실패했을 때 뭔가를 더\n 해야하므로 bind 컴비네이터로는 구현할 수 없다.\n\n보통 choice 컴비네이터도 다음과 같이 중위 연산자로 정의해서 쓰는\n 것이 편리하다.\n\nlet (&lt;|&gt;) = choice\n\n\n그러면 우리는 다음과 같이 대/소문자 글자를 파싱하는 파서 letter와,\n 알파벳과 숫자를 파싱하는 파서 alphanum을 정의할 수 있다.\n\nlet letter = lower &lt;|&gt; upper\n\nlet alphanum = letter &lt;|&gt; digit\n\n\n마지막으로 조건을 만족하는 단어를 파싱하는 파서를 만들어보자. 크게\n 두 종류의 컴비네이터를 사용해볼 수 있는데,\n\n  조건(predicate)을 만족하는 동안 계속 파싱하는 컴비네이터,\n  파서가 파싱에 성공하는 동안 계속 파싱하는 컴비네이터,\n\n\n두 가지를 모두 살펴볼 것이다.\n\n먼저 조건을 만족하는 동안 계속 파싱하는 컴비네이터 take_while은\n satisfy와 유사하다.\n\nlet take_while (f: char -&gt; bool) : string parser =\n  { run =\n      fun input -&gt;\n        let n = String.length input.text in\n        let i = ref 0 in\n        while !i &lt; n &amp;&amp; String.get input.text !i |&gt; f do\n          incr i\n        done ;\n        consume_input !i (n - !i) input, Ok (String.sub input.text 0 !i)\n  }\n\n\n문자 그대로 주어진 조건 f를 만족하는 동안 계속 입력 문자열을\n 소모하여 최종 파싱 결과를 리턴한다. 이 컴비네이터를 이용해서 단어를\n 파싱하는 파서를 만들면 다음과 같다.\n\nlet word : string parser = take_while (fun x -&gt; ('a' &lt;= x &amp;&amp; x &lt;= 'z') || ('A' &lt;= x &amp;&amp; x &lt;= 'Z') || ('0' &lt;= x &amp;&amp; x &lt;= '9'))\n\n\n즉, 앞의 lower, upper, digit의 조건식으로 들어갔던 함수를\n 합쳐서 전달해주면 된다.\n\n두 번째 방법은 letter, upper, digit과 같은 미리 만들어둔 파서를\n 조합할 수 있는 방식이다. 먼저 마찬가지로 파서가 파싱 가능한 만큼\n 파싱하고 그 결과를 리스트(어떤 값일지 모르기 때문에 곧바로 문자열로\n 바꾸기는 어렵다)로 모아주는 컴비네이터 many를 정의하자.\n\nlet many (p : 'a parser) : 'a list parser =\n  { run =\n      fun input -&gt;\n        let acc = ref [] in\n        let rec loop input =\n          let input', result = p.run input in\n          match result with\n          | Ok x -&gt;\n            acc := x :: !acc ;\n            loop input'\n          | Error _ -&gt; input\n        in\n        let input' = loop input in\n        input', Ok (List.rev !acc)\n  }\n\n\n입력으로 받은 파서 p를 실패할 때까지 계속 적용하면서 결과를\n 리스트에 쌓아뒀다가 최종적으로 파서가 파싱한 값의 리스트를 돌려주는\n 컴비네이터이다. 이 친구를 이용해서 단어 파서를 만들면 다음과 같다.\n\nlet string : string parser =\n  many (lower &lt;|&gt; upper &lt;|&gt; digit) &gt;&gt;=\n  fun chars -&gt;\n    let s = String.of_seq (List.to_seq chars) in\n    return s\n\n\n즉, lower 또는 upper 또는 digit 파서를 이용해서 입력을 계속\n 파싱하여 결과를 리스트에 모아두고, 최종적으로 이 (글자의) 리스트를\n 문자열로 합쳐서 돌려주는 파서다.\n\n그 외에 유용한 컴비네이터로는 앞쪽의 결과를 버리는 컴비네이터 *&gt;가\n 있다. 예를 들어 문법에서 공백이나 중괄호를 무시하고 싶을 때 사용할 수\n 있다. 이 친구는 bind를 이용해서 깔끔하게 구현 가능하다.\n\nlet ( *&gt; ) (p1: 'a parser) (p2: 'b parser) : 'b parser = p1 &gt;&gt;= fun _ -&gt; p2\n\n\n즉 첫 번째 파서의 결과 값은 버리고, 남은 입력만을 취하는 것이다."
					}
					,
					"wip-practical-statistics-1-exploratory-data-analysis": {
						"id": "wip-practical-statistics-1-exploratory-data-analysis",
						"title": "1. Exploratory Data Analysis",
						"version": "all",
						"categories": "",
						"url": " /wip/practical-statistics/1-exploratory-data-analysis/",
						"content": "EDA\n\n  추론(Inference): 적은 표본(샘플)을 가지고 더 큰 모집단 에 대한 결론 을\n    도출하기 위한 일련의 복잡한 과정\n    \n      표본과 샘플, 표본추출과 샘플링, 모형과 모델, 임의와 랜덤 등은 혼용함\n    \n  \n\n정형화된 데이터의 요소\n왜 데이터를 구분할까?\n\n  그래프를 그리거나 모델을 피팅하는 등의 통계분석을 수행하는 방식을 결정하는데\n    큰 도움을 준다.\n  범주형 데이터라는 결국 enum 이다.\n\n수치형 데이터\n말 그대로 숫자로 표현된다.\n\n  데이터설명예시\n  연속형 데이터어떤 범위 안에서 어떤 값이든 가질 수 있는 데이터로, 구간형 또는 실수형 이라고도 한다.속도, 지속시간 등\n  이산형 데이터셀 수 있는 값을 갖는 데이터횟수, 사건의 발생 빈도 등\n\n범주형 데이터\n카테고리로 나눌 수 있는 데이터로, 제품 종류나 도시 이름 같이 어떤 범위 안에서의\n  이산형 데이터로 볼 수도 있다.\n\n  데이터설명예시\n  이진 데이터둘 중 하나참/거짓, 예/아니오 등\n  순서형 데이터범위 안에서 서로 order가 정의되는 데이터평점 등\n\n테이블 데이터\n\n  용어설명유의어\n  데이터 프레임스프레드시트와 같은 테이블 형태의 데이터-\n  피쳐 (Feature)테이블의 각 열특징, 속성(Attribute), 입력, 예측 변수(Predictor), 변수\n  결과 (Outcome)프로젝트의 목표. 결과를 예측 하기 위해서 피쳐를 사용한다.종속변수, 응답, 목표, 출력\n  레코드 (Record)테이블의 각 행기록값, 사건(Case), 사례, 예제(Example), 관측값, 패턴, 샘플\n\n\n  통계: 응답변수 (또는 종속변수)를 예측하는 모델에서 예측변수 를 사용한다\n  데이터 과학: 목표 를 예측하는데 피쳐 를 사용한다\n\n위치 추정\n데이터가 주어졌을 때 데이터를 살펴보는 가장 기초적인 단계는 각 피쳐(변수)의\n  &#8220;대표값(Typical Value)&#8221;을 구해서 -&gt; 대부분의 값 이 어디쯤에 위치하는지를\n  추정해본다.\n\n  용어설명유의어\n  평균 (Mean)-Average\n  가중평균(Weighted Mean)가중치를 곱한 값의 총합을 가중치의 총합으로 나눈 값\n  중간값 (Median)-50번째 백분위수 (Percentile)\n  백분위수전체 데이터의 P%를 아래에 두는 값분위수(Quantile)\n  절사평균 (Trimmed Mean)정해진 개수의 극단값을 제외한 나머지 값들의 평균절단평균 (Truncated Mean)\n  로버스트(Robust)극단값들에 민감하지 않은 상태저항성 (Resistant)\n  특잇값 (Outlier)대부분의 값과 매우 다른 데이터 값극단값(Extreme Value)\n\n\n  통계: 데이터로부터 계산된 값들에 보통 추정값(estimate) 이라고 부른다. &#8211;&gt;\n    불확실성을 이해하기 위한 학문이다. 그래서 추정 한다.\n  데이터 과학: 데이터로부터 계산된 값을 측정 지표(metric) 라고 부른다. &#8211;&gt;\n    구체적인 비즈니스 또는 조직의 목표치에 관심을 둔다. 그래서 측정 한다.\n\n가중평균\n\n  어떤 값이 다른 값에 비해 큰 변화량 을 가질 때, 이를 작은 가중치를 둬서 영향을\n    줄일 수 있다. 예를 들면, 여러 개의 센서 중 특정 센서의 정확도가 떨어지면 이\n    센서에는 가중치를 낮게 준다.\n  데이터를 수집할 때 우리가 관심있는 서로 다른 대조군에 대해서 정확히 같은\n    비율을 맞추기란 불가능에 가깝다. 이를 보정하기 위해서 데이터가 부족한 소수\n    그룹에 더 높은 가중치를 적용할 수도 있다.\n\n로버스트한 추정\n\n  많은 경우 데이터에 매우 민감한 평균보다는 중간값이 위치 추정에 더 유리하다.\n    예를 들어 가계소득 등. 왜냐하면 결과를 왜곡할 수도 있는 특잇값(극단값) 의\n    영향을 받지 않으므로 로버스트 하다고 여겨진다.\n  절사평균도 괜찮다. 예를 들어 상하위 10%를 잘라내는 방법은 데이터가 너무\n    적지만 않다면 특잇값으로부터 데이터를 보호할 수 있다. 이는 평균과 중간값의\n    절충안이라고 볼 수도 있다.\n\nimport pandas as pd\nimport scipy\nimport numpy as np\nimport wquantiles\n\n# load data - check out https://github.com/gedeck/practical-statistics-for-data-scientists/tree/master/data\nstate = pd.read_csv(&#39;state.csv&#39;)\n\n# 평균, 절사평균(10%), 중간값\nstate[&#39;Population&#39;].mean()\nscipy.stats.trim_mean(state[&#39;Population&#39;], 0.1)\nstate[&#39;Population&#39;].median()\n\n# 미국 전체의 평균 살인율 계산 - 인구를 가중치로\nnp.average(state[&#39;Murder.Rate&#39;], weights=state[&#39;Population&#39;])\n# 가중 중간값 - wquantiles 패키지\nwquantiles.median(state[&#39;Murder.Rate&#39;], weights=state[&#39;Population&#39;])\n\n변이 추정\n변이(Variability)는 데이터 값들이 얼마나 밀집 혹은 퍼져 있는지를 나타내는\n  산포도(Dispersion) 를 나타낸다.\n변이를 측정하고, 줄이고, 변이와 랜덤값을 구분하고, 변이의 다양한 요인들을\n  살펴보고, 변이가 상황에서 어떻게 결정을 내리는지 등 통계의 핵심이다.\n\n  용어설명유의어\n  편차 (Deviation)관측값과 위치 추정값 사이의 차이오차, 잔차(Residual)\n  분산 (Variance)평균과 편차의 제곱의 합을 (n-1)로 나눈 값평균제곱오차\n  표준편차 (Standard Deviation)분산의 제곱근\n  평균절대편차 (Mean Absolute Deviation)평균과 편차의 절대값의 평균L1 노름, 맨해튼 노름\n  중간값의 중위절대편차(MAD; Median Absolute Deviation from the median)중간값과의 편차의 절대값의 중간값\n  범위최대값 - 최소값\n  순서통계량 (Order Statistics)최소~최대로 정렬된 데이터 값에 따른 계량형순위\n  백분위수 (Percentile)어떤 값들의 P 퍼센트가 이 값 이하의 값을 갖고, (100 - P) 퍼센트가 이 값 이상을 갖도록 하는 값분위수\n  사분위범위 (IQR; InterQuantile Range)75번째 백분위수와 25번째 백분위수의 차이"
					}
					,
					"wip-practical-statistics-2-data-and-sampling-distributions": {
						"id": "wip-practical-statistics-2-data-and-sampling-distributions",
						"title": "2. Data and Sampling Distributions",
						"version": "all",
						"categories": "",
						"url": " /wip/practical-statistics/2-data-and-sampling-distributions/",
						"content": "Data and Sampling Distributions"
					}
					,
					"wip-practical-statistics-3-statistical-experiments-and-significance-testing": {
						"id": "wip-practical-statistics-3-statistical-experiments-and-significance-testing",
						"title": "3. Statistical Experiments and Significance Testing",
						"version": "all",
						"categories": "",
						"url": " /wip/practical-statistics/3-statistical-experiments-and-significance-testing/",
						"content": "Statistical Experiments and Significance Testing"
					}
					,
					"ps-leetcode-3sum": {
						"id": "ps-leetcode-3sum",
						"title": "3Sum",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/3sum/",
						"content": "3Sum\n\n정수 배열이 주어졌을 때, nums[i] + nums[j] + nums[k] == 0이 되는\n 모든 정수 세 쌍의 집합을 구하자. 이때, i != j &amp;&amp; i != k &amp;&amp; j != k를\n 만족해야 한다.\n\n정답 배열은 중복되는 수를 담으면 안된다.\n\n배열의 길이는 0~3,000 사이이고 배열의 값은 -100,000~100,000 사이이다.\n\n투 포인터\n\n두 수의 합은 해시 셋으로 금방 풀렸다. 세 수의 합은 어떻게 할 수\n 있을까? Brute Force를 생각해보면 O(N^3)의 솔루션을 떠올릴 수\n 있겠지만, 배열 최대 크기가 3000이라서 시간 초과가 날 것이다. N^3보다\n 작은 솔루션은 없을까?\n\nTwo Sum II의 접근을\n 활용해야 한다: 배열이 정렬되어 있을 때, 투 포인터를 이용해 합이\n 원하는 값보다 작으면 더 작은 값의 포인터를 더 큰 값을 갖도록\n 이동하였고, 합이 더 크다면 더 큰 값의 포인터를 더 작은 값을 갖도록\n 이동하였다. 세 수의 합을 구하려면, 정수 하나는 배열 전체를 루프하도록\n 하면서, 다른 두 정수는 투 포인터를 이용해서 O(N)만에 구하도록 한다면,\n 총 복잡도 O(N^2)을 얻을 수 있을 것 같다. 그리고 이때 문제의 조건에\n 따라 (1) 세 정수의 인덱스는 유니크해야 하고 (2) 세 정수의\n 각각의 값도 유니크해야 한다.\n\n입력으로 들어오는 수가 정렬되어 있다는 말이 없기 때문에, 투 포인터를\n 사용하려면 정렬을 해야한다. 여기에 O(NlogN)의 복잡도가 소요되긴\n 하지만, 실제로 루프를 O(N^2)만큼 돌아야 하므로 이 부분은 괜찮다.\n\n이 아이디어를 구현해보자.\n\ndef threeSum(nums):\n    answer = []\n    nums = sorted(nums)\n    n = len(nums)\n    for i in range(n-2):\n        left, right = i + 1, n - 1\n        while left &lt; right:\n            s = nums[i] + nums[left] + nums[right]\n            if s == 0:\n                answer.append((nums[i], nums[left], nums[right]))\n                left += 1\n                right -= 1\n            elif s &gt; 0:\n                right -= 1\n            else:\n                left += 1\n    return set(answer)\n\n\n\n  i &lt; left &lt; right인 세 인덱스를 잘 고르려고 한다. 따라서, i는\nn-3까지 가능하므로 range(n-2)까지 루프를 돈다. 이렇게 i를\n일단 고른다.\n  left는 i 다음부터, right는 항상 마지막 수부터\n검사한다. 그리고 left, right를 가지고 투 포인터로 범위를\n좁혀가며 합이 0이 될 때 정답에 추가한다.\n  정답의 정수 튜플은 중복되면 안되기 때문에, 최종적으로 set()\n연산으로 중복을 없앤다. 이때 튜플은 항상 (i, left, right) 순으로\n넣어야 올바르게 중복을 제거할 수 있다.\n\n\n이렇게하면 대략 2초정도 걸리는 솔루션이 나온다. 더 빠르게 할 수 있는\n 방법은 없을까?\n\nSmall Optimization - 빨리감기\n\n위의 솔루션에서 시간을 꽤 잡아먹는 부분은, 중복되는 튜플을 무지성으로\n 다 answer에 집어넣고 마지막에 이를 해싱해서 중복을 제거하는\n 부분이다. 이 부분을 더 똑똑하게 해보자.\n\n일단 떠올리기 쉬운 부분은 투 포인터를 진행하는 부분이다. 우리가\n 원하는 합이 되었을 때 (s == 0), 두 포인터를 한 칸씩만 움직이고\n 있는데, 배열이 정렬되어 있기 때문에, 이 조건을 만족하는 동안 left와\n right의 값이 같으면 전부 스킵해도 된다. 따라서 다음과 같이 바꿀 수\n 있다.\n\ndef threeSum(nums):\n    answer = []\n    nums = sorted(nums)\n    n = len(nums)\n    for i in range(n-2):\n        left, right = i + 1, n - 1\n        while left &lt; right:\n            s = nums[i] + nums[left] + nums[right]\n            if s == 0:\n                answer.append((nums[i], nums[left], nums[right]))\n                while left &lt; right and nums[left] == nums[left+1]:\n                    left += 1\n                while left &lt; right and nums[right-1] == nums[right]:\n                    right -= 1\n                left += 1\n                right -= 1\n            elif s &gt; 0:\n                right -= 1\n            else:\n                left += 1\n    return set(answer)\n\n\nleft는 왼쪽에서 오른쪽 방향으로 진행하기 때문에 left와 left +\n 1의 값이 같으면 싹 땡긴다. right는 반대로 오른쪽에서 왼쪽으로\n 진행하기 때문에 right - 1과 right의 값이 같으면 싹 땡긴다. 이렇게\n 두 개의 반복문으로 빨리감기를 진행하고 나면, 그 위치는 합 조건을\n 만족하는 같은 값을 가진 left, right 의 마지막 부분에 위치하게\n 되고, 최종적으로 그 다음 탐색을 위해서 한 칸씩 더 이동해주면 된다.\n\n이렇게하고 마지막의 set() 연산을 풀면 답을 얻을 수 있지 않을까?\n 놀랍게도 다음 반례를 발견하게 된다.\n\nInput: [-1,0,1,2,-1,-4]\nExpected: [[-1,-1,2], [-1,0,1]]\nOutput: [[-1,-1,2], [-1,0,1], [-1,0,1]]\n\n\n중복을 다 제거한줄 알았는데 중복이 나왔다. 어디서 놓친 것일까? 위의\n 입력을 하나씩 따라가보자. 먼저 입력을 정렬하면 [-4,-1,-1,0,1,2]를\n 얻는다. i = 1일 때의 상황을 살펴보자. (left, right) = (2, 5)에서\n (-1, -1, 2)의 해답 하나를 얻는다. 그 다음 left는 같은 -1을 가진\n 3을 거쳐 4가 되고, right는 4가 되어 (-1, 0, 1)의 해답을\n 얻는다. 여기까진 좋다. 그런데 그 다음 i = 2가 되었을 때, (left,\n right) = (3, 4)에서 똑같은 해답인 (-1, 0, 1)을 얻게 된다!\n\n앞서 우리는 두 개의 포인터, left와 right에서만 중복을 스킵했지,\n i에 대해서는 중복을 스킵하지 않은 것이 문제다. 그럼 무엇을\n 해야할까? i는 left와 마찬가지로 왼쪽에서 오른쪽으로 진행하기\n 때문에, nums[i] == nums[i+1]일 때 다 스킵하면 되지 않을까? 위의\n 예시를 생각해보자. i = 1일 때, i+1과 같기 때문에 이를 스킵하고 i\n = 2로 곧장 넘어가버린다. 그런데 우리는 위에서 i = 1 일 때 정답\n 튜플 (-1, -1, 2)를 구한 것을 보았다. 따라서 정답을 하나 놓친\n 것이다. 그러므로, i를 스킵할 때에는 일단 i에 대해서 먼저 투\n 포인터로 가능한 공간을 전부 탐색해본 뒤에, 그 다음 또 같은 값을\n 만났을 때 이를 스킵해야 하는 것이다. 따라서, nums[i-1] == nums[i]일\n 때 스킵해야 한다.\n\n이 최적화를 다 적용한 코드는 다음과 같다.\n\ndef threeSum(nums):\n    answer = []\n    nums = sorted(nums)\n    n = len(nums)\n    for i in range(n-2):\n        if i &gt; 0 and nums[i-1] == nums[i]:\n            continue\n        left, right = i + 1, n - 1\n        while left &lt; right:\n            s = nums[i] + nums[left] + nums[right]\n            if s == 0:\n                answer.append((nums[i], nums[left], nums[right]))\n                while left &lt; right and nums[left] == nums[left+1]:\n                    left += 1\n                while left &lt; right and nums[right-1] == nums[right]:\n                    right -= 1\n                left += 1\n                right -= 1\n            elif s &gt; 0:\n                right -= 1\n            else:\n                left += 1\n    return answer\n\n\n투 포인터에서의 빨리감기와 i의 빨리감기를 모두 적용하였기 때문에,\n 마지막의 해싱 연산은 더 이상 필요하지 않다. 이렇게 1초 미만의\n 솔루션을 얻을 수 있다."
					}
					,
					"wip-practical-statistics-4-regression-and-prediction": {
						"id": "wip-practical-statistics-4-regression-and-prediction",
						"title": "4. Regression and Prediction",
						"version": "all",
						"categories": "",
						"url": " /wip/practical-statistics/4-regression-and-prediction/",
						"content": "Regression and Prediction"
					}
					,
					"404-html": {
						"id": "404-html",
						"title": "",
						"version": "all",
						"categories": "",
						"url": " /404.html",
						"content": "Page Not Found\n\nUnfortunately we were unable to find the page you requested. It could be the page doesn’t exist or only exists for a specific version of these documents so please use the search feature to see if you are able to locate the information you were after."
					}
					,
					"wip-practical-statistics-5-classification": {
						"id": "wip-practical-statistics-5-classification",
						"title": "5. Classification",
						"version": "all",
						"categories": "",
						"url": " /wip/practical-statistics/5-classification/",
						"content": "Classification"
					}
					,
					"wip-practical-statistics-6-statistical-machine-learning": {
						"id": "wip-practical-statistics-6-statistical-machine-learning",
						"title": "6. Statistical Machine Learning",
						"version": "all",
						"categories": "",
						"url": " /wip/practical-statistics/6-statistical-machine-learning/",
						"content": "Statistical Machine Learning"
					}
					,
					"wip-practical-statistics-7-unsupervised-learning": {
						"id": "wip-practical-statistics-7-unsupervised-learning",
						"title": "7. Unsupervised Learning",
						"version": "all",
						"categories": "",
						"url": " /wip/practical-statistics/7-unsupervised-learning/",
						"content": "Unsupervised Learning"
					}
					,
					"wip-a-unified-approach-to-global-program-optimization": {
						"id": "wip-a-unified-approach-to-global-program-optimization",
						"title": "A Unified Approach to Global Program Optimization",
						"version": "all",
						"categories": "",
						"url": " /wip/a-unified-approach-to-global-program-optimization/",
						"content": "A Unified Approach to Global Program Optimization\n\nby Gray\n A. Kildall,\n 1972\n\nAbstract\n\nA technique is presented for global analysis of program structure in\n order to perform compile time optimization of object code generated\n for expressions. The global expression optimization presented\n includes constant propagation, common subexpression elimination,\n elimination of redundant register load operations, and live\n expression analysis. A general purpose program flow analysis\n algorithm is developed which depends upon the existence of an\n “optimizing function.” The algorithm is defined formally using a\n directed graph model of program flow structure, and is shown to be\n correct. Several optimizing functions are defined which, when used in\n conjunction with the flow analysis algorithm, provide the various\n forms of code optimization. The flow analysis algorithm is\n sufficiently general that additional functions can easily be defined\n for other forms of global code optimization.\n\nIntroduction\n\nA number of techniques have evolved for the compile-time analysis of\n program structure in order to locate redundant computations, perform\n constant computations, and reduce the number of store-load sequences\n between memory and high-speed registers. Some of these techniques\n provide analysis of only straight-line sequences of instructions,\n while others take the program branching structure into account. The\n purpose here is to describe a single program flow analysis algorithm\n which extends all of these straight-line optimizing techniques to\n include branching structure. The algorithm is presented formally and\n is shown to be correct. Implementation of the flow analysis algorithm\n in a practical compiler is also discussed.\n\nThe methods used here are motivated in the section which follows.\n\nA Global Analysis Algorithm\n\nBased upon these observations, it is possible to informally state a\n global analysis algorithm.\n\n\n  Start with an entry node in the program graph, along with a given\nentry pool corresponding to this entry node. Normally, there is\nonly one entry node, and the entry pool is empty.\n  Process the entry node, and produce optimizing information which\nis sent to all immediate successors of the entry node.\n  Intersect the incoming optimizing pools with that already\nestablished at the successor nodes (if this is the first time the\nnode is encountered, assume the incoming pool as the first\napproximation and continue processing).\n  Considering each successor node, if the amount of optimizing\ninformation is reduced by this intersection (or if the node has\nbeen encountered for the first time) then process the successor in\nthe same manner as the initial entry node (the order in which the\nsuccessor nodes are processed is unimportant).\n\n\nIn order to generalize the above notions, it is useful to define an\n “optimizing function” f which maps an “input” pool, along with a\n particular node, to a new “output” pool. Given a particular set of\n propagated constants, for example, it is possible to examine the\n operation at a particular node and determine the set of propagated\n constants which can be assumed after the node is executed. In the\n case of constant propagation, the function can be informally stated\n as follows. Let V be a set of variables, let C be a set of\n constants, and let N be the set of nodes in the graph being\n analyzed. The set \\(U = V \\times C\\) represents ordered pairs which\n may appear in any constant pool. In fact, all constant pools are\n elements of the power set of U (i.e., the set of all subsets of\n U), denoted by \\(\\mathcal{P}(U)\\). Thus, \\(f: N \\times\n \\mathcal{P}(U) \\mapsto \\mathcal{P}(U)\\), where \\((v, c) \\in f(N, P)\\)\n\n\n  \\((v, c) \\in P\\) and the operation at node N does not assign a\nnew value to the variable v, or\n  the operation at node N assigns an expression to the variable\nv, and the expression evaluates to the constant c, based upon\nthe constans in P."
					}
					,
					"wip-algebraic-effects-and-handlers": {
						"id": "wip-algebraic-effects-and-handlers",
						"title": "An Introduction to Algebraic Effects and Handlers",
						"version": "all",
						"categories": "",
						"url": " /wip/algebraic-effects-and-handlers/",
						"content": "An Introduction to Algebraic Effects and Handlers\n\n대수적 효과(Algebraic effects)는 순수하지 않은(impure) 동작이 가변\n 저장 연산인 get과 set, 인터랙티브 입출력 연산인 read와 print,\n 또는 예외 처리 연산인 raise와 같은 일련의 연산에서 발생한다는\n 전제에 기반한 계산 효과에 대한 접근 방식입니다. 이는 자연스럽게 예외\n 처리 뿐만 아니라 모든 다른 효과를 위한 핸들러를 필요로 하는데, 다른\n 무엇보다도 스트림 재지정(redirection), 백트래킹, 협력적 멀티 쓰레딩,\n 그리고 구분된 컨티뉴에이션을 캡쳐할 수 있는 새로운 개념을 떠올리게\n 합니다.\n\n대수적 효과나 핸들러에 관심이 있어하지만 무엇부터 시작해야하는지\n 모르는 사람들이 많습니다. 이 튜토리얼이 그걸 제공했으면\n 좋겠습니다. 대수적 효과와 핸들러를 이용해서 어떻게 프로그램을 짜는지,\n 어떻게 모델링하는지, 어떻게 이해해야 하는지를 살펴봅니다.\n\n1. 언어\n\n핸들러를 살펴보기 전에 일단 쓸 언어를 먼저 정합시다. 효과를 다룰 때\n 평가의 순서는 중요하기 때문에, 우리는 언어의 터미널을 불변의\n 값(values)과 잠재적으로 효과가 있는 계산(computations)으로\n 나누어서 고운 값 호출(fine-grained call-by-value) 접근을 따를\n 것입니다. 몇 가지 언급해야 하는 것들이 있습니다:\n\nvalue v := x                                                  variable\n          | true | false                                      boolean constans\n          | fun x -&gt; c                                        function\n          | h                                                 handler\nhandler h := handler { return x -&gt; cr,                       (optional) return clause\n             op1(x; k) -&gt; c1, ..., opn(x; k) -&gt; cn }      operation clauses\ncomputation c := return v                                     return\n               | op(v; y.c)                                   operation call\n               | do x &lt;- c1 in c2                             sequencing\n               | if v then c1 else c2                         conditional\n               | v1 v2                                        application\n               | with v handle c                              handling\n\n\n연속 계산\n연속 계산 (sequencing) do x &lt;- c1 in c2는 먼저 c1을 평가하고, 그\n 결과로 값이 리턴되면, x에 그 값을 묶은(bind) 다음 c2를\n 평가합니다. 만약 c2에 x가 나타나지 않으면, 문법을 c1; c2와 같이\n 요약해서 연속적인 계산을 표현할 수 있습니다.\n\n연산 호출\nop(v; y.c) 호출은 매개변수 값 v(예를 들면 읽을 메모리 주소)를\n 연산 op에 전달하고, op가 효과를 수행(perform) 하고, 그 결과\n 값(예를 들면 메모리 주소의 내용물)이 y에 묶이고(bound),\n 컨티뉴에이션(continuation)이라고 불리는 c의 평가를\n 재개합니다. 하지만, 주변의 핸들러가 이 동작을 덮어쓸 수 (override)\n 있음을 주의합시다.\n\n제네릭 효과"
					}
					,
					"ps-leetcode-alien-dictionary": {
						"id": "ps-leetcode-alien-dictionary",
						"title": "Alien Dictionary",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/alien-dictionary/",
						"content": "Alien Dictionary\n전형적인 위상 정렬 문제이다. 단어 순서대로 글자를 비교해가면서, 같은 글자이면\n  얻을 수 있는 정보가 없지만, 서로 다른 글자인 경우 두 글자 사이에\n  lexicographical order가 있다는 사실을 딱 한 번 알 수 있다. 즉, 한 단어에서\n  하나의 글자 order를 발견했다면 그 이후는 정확한 order를 알 수 없기 때문에 뒤는\n  버려야 한다.\n위상 정렬에 관한 내용은 Topological Sort 에 정리해 뒀다. 두 가지 방법이 있는데\n  하나는 들어오는 엣지 (in-degree edge) 수를 이용한 방법이고 다른 하나는 DFS를\n  이용하는 방법이다. 두 방법 모두 공통적으로 다음 두 가지 정보가 필요하다:\n\n  엣지 정보\n  중복없는 모든 노드의 정보 (엣지로 이어지지 않은 노드도 필요)\n\n따라서 두 방법 모두 그래프를 만드는 과정이 필요하다.\n단어로 그래프 만들기\n모든 단어는 사전식(lexicographically) 정렬되어 있으므로, 순서대로 i, i+1 번 째\n  단어 두 개를 선택한 경우 다음이 성립한다:\n\n  단어 i 와 i+1 각 글자 중에서 처음으로 다른 두 글자 가 사전식 순서를 말해준다.\n    이후에 나오는 모든 글자에 대해서는 어떤 순서도 말할 수 없다.\n  만약 단어 i 의 길이가 i+1 보다 더 길면서 i 의 길이 만큼의 글자가 모두 같다면,\n    사전식 정렬이 아니므로 아무것도 알 수 없다. 코너 케이스이므로 손쉽게 에러를\n    리턴한다.\n\ndef build_graph(words: List[str]) -&gt; Dict[str, Set[str]], Set[str], Counter:\n    &quot;&quot;&quot;\n    Build graph from lexicographically sorted word list.\n    Returns edges and (unique) nodes tuple.\n    &quot;&quot;&quot;\n    nodes = set([char for word in words for char in word])\n    edges = defaultdict(set)\n    indegree = Counter({char: 0 for char in nodes})\n\n    for w1, w2 in zip(words, words[1:]):\n        for c1, c2 in zip(w1, w2):\n            if c1 != c2 and c1 not in edges:\n                edges[c1].add(c2)\n                indegree[c2] += 1\n                break\n        else:\n            if len(w1) &gt; len(w2):\n                raise ValueError\n    return edges, nodes, indegree\n\n\n  여기서 노드는 단어가 아니라 글자 이므로 문자열의 리스트를 풀어서 중복을 없애야\n    한다. 엣지로 연결되지 않은 노드가 있을 수 있으므로 노드 정보가 필요하다.\n  처음으로 글자가 다른 부분을 발견하면 엣지 정보를 업데이트하고 break 하는 것을\n    눈여겨 보자. 이후의 글자에 대해서는 어떤 정보도 얻을 수 없다.\n  파이썬의 for ... else 구문은 for 반복문에서 break 로 빠져나가지 않으면 else\n    브랜치의 구문이 실행된다. 이를 이용하면 두 글자 w1 과 w2 를 (같은 길이만큼)\n    비교했는데 서로 다른 글자가 없는 경우를 알 수 있다. 이때, 앞의 단어의 길이가\n    더 길면 사전식 정렬이 아니므로 불가능하기 때문에 에러를 던진다.\n\n이제 위의 함수를 이용해서 두 가지 방법으로 위상 정렬을 구현할 수 있다.\nIn-degree 엣지를 이용한 위상 정렬\n먼저 in-degree 정보를 이용할 수 있다. 어떤 노드의 in-degree가 0이면 그 친구부터\n  사전식 순서를 만들어 나갈 수 있다. 일종의 BFS를 하면서 연결된 in-degree들을\n  하나씩 지워가면 된다. 이때 주의할 코너 케이스는 만들어낸 정답의 길이가 노드\n  수보다 적은 경우인데, 바로 싸이클이 있는 경우이다. 싸이클이 있으면 두 노드의\n  in-degree가 모두 1이므로 큐의 초기화에 들어가지 못해서 탐색되지 못한다. 이\n  경우만 주의하면 된다.\ndef alienOrder(words: List[str]) -&gt; str:\n    try:\n        edges, nodes, indegree = build_graph(words)\n    except ValueError:\n        return &quot;&quot;\n    order = []\n    q = deque([c for c in indegree if indegree[c] == 0])\n    while q:\n        node = q.popleft()\n        order.append(node)\n        for neighbor in edges[node]:\n            indegree[neighbor] -= 1\n            if indegree[neighbor] == 0:\n                q.append(neighbor)\n\n    if len(order) &lt; len(nodes):\n        return &quot;&quot;\n\n    return &quot;&quot;.join(order)\n\nDFS를 이용한 위상 정렬\nDFS를 이용한 방법은 방문 중 정보와 방문 완료 정보를 유지하면서 사전식 순서의\n  마지막 부터 쌓은 후 마지막에 뒤집는 방식이다. 방문 중 인 노드에 또 방문한다는\n  것은 그래프에 싸이클이 있다는 의미이므로 역시 사전식 순서가 불가능한 경우이다.\ndef alienOrder(words: List[str]) -&gt; str:\n    try:\n        edges, nodes, _indegree = build_graph(words)\n    except ValueError:\n        return &quot;&quot;\n\n    order = []\n    visiting, visited = set(), set()\n    def dfs(node):\n        if node in visited:\n            return\n        visiting.add(node)\n        for neighbor in edges[node]:\n            if neighbor in visiting:\n                raise ValueError(&quot;Cycle&quot;)\n            if neighbor not in visited:\n                dfs(neighbor)\n        visiting.remove(node)\n        visited.add(node)\n        order.append(node)\n\n    try:\n        for node in nodes:\n            dfs(node)\n    except ValueError:\n        return &quot;&quot;\n\n    return &quot;&quot;.join(reversed(order))"
					}
					,
					"ps-leetcode-as-far-from-land-as-possible": {
						"id": "ps-leetcode-as-far-from-land-as-possible",
						"title": "As Far From Land As Possible",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/as-far-from-land-as-possible/",
						"content": "As Far From Land As Possible\n\n  맨하탄 거리를 재야한다.\n  이른바 &#8220;멀티 소스 BFS&#8221;를 수행해야 한다. 각 턴마다 같은 턴에 있는 노드들을 한\n    칸씩 움직인다고 생각하면 된다.\n  일단 땅을 전부 초기 큐에 넣은 다음에 물로 갈 수 있는 친구들만 계속 움직인다.\ndef maxDistance(grid: List[List[int]]) -&gt; int:\n    q, visited, n = deque(), set(), len(grid)\n    for y in range(n):\n        for x in range(n):\n            if grid[y][x] == 1:\n                # initialize all lands\n                q.append((y, x))\n                visited.add((y, x))\n    farthest = -1\n    while q:\n        turns = len(q)  # exhaust all current position\n        while turns:\n            turns -= 1\n            y, x = q.popleft()\n            for ny, nx in ((y+1, x), (y-1, x), (y, x+1), (y, x-1)):\n                if not (0 &lt;= ny &lt; n) or not (0 &lt;= nx &lt; n):\n                    continue\n                if (ny, nx) in visited or grid[ny][nx] != 0:\n                    continue\n                # now (ny, nx) is reachable water\n                q.append((ny, nx))\n                visited.add((ny, nx))\n        farthest += 1\n    return farthest if farthest else -1"
					}
					,
					"ps-boj-backtracking": {
						"id": "ps-boj-backtracking",
						"title": "Backtracking (WIP)",
						"version": "all",
						"categories": "",
						"url": " /ps/boj/backtracking/",
						"content": "백트래킹\n백트래킹 문제는 대충 개념을 이해한채로 막상 문제를 풀려고 그러면\n 난이도가 상당하다. 실수하기도 쉽고, 재귀로 코드를 짜야하는 특성 상\n 실수한 부분을 찾아내기도 정말 어렵다. 그러므로 많은 연습이 필요하다.\n\n한편으로는 응용 문제가 그렇게 많지 않기 때문에 (정말?) 예제를 꼼꼼히\n 풀고 기본적인 코드의 형태를 익혀두면 그럭저럭 할만 하다.\n\n15649번: N과 M (1)"
					}
					,
					"ps-theory-backtracking": {
						"id": "ps-theory-backtracking",
						"title": "Backtracking",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/backtracking/",
						"content": "백트래킹\n\n백트리킹이란 CSP(Constraint Satisfaction Problem)이라고 불리는\n 제약조건만족문제를 풀기위한 일반적인 방법론을 말한다. 주로 정답의\n 후보를 점진적으로 만들다가 후보가 정답이 아니라는 것을 알면 그걸\n 버리고 이전으로 돌아가서 다시 후보를 만들어 가는 과정이다.\n\n개념적으로는 (탐색 공간의) 트리 탐색 과정과 유사하다. 루트\n 노드에서부터 시작해서 리프 노드에 있는 정답 후보를 탐색한다. 중간에\n 있는 노드는 부분적인 정답 후보이고 최종 정답이 될 가능성이\n 있다. 각각의 노드에서는 노드의 자식 노드를 하나씩 골라서 정답으로 한\n 단계씩 나아갈 수 있다. 어떤 노드가 절대로 정답이 안될 거라고\n 판단되면, 지금 노드를 버리고 뒤로 돌아가서(backtrack), 즉 부모\n 노드로 올라가서 다른 가능성을 찾아본다. 이런 특징 때문에 백트래킹은\n 완전탐색(Brute Force)보다 훨씬 빠르게 동작한다.\n\n템플릿\n\n백트래킹 문제의 알고리즘은 대부분 어떤 패턴을 갖고 있다.\n\ndef backtrack(candidate):\n    if find_solution(candidate):\n        output(candidate)\n        return\n\n    # iterate all possible candidates\n    for next_candidate in list_of_candidates:\n        if is_valid(next_candidate):\n            # try this partial candidate solution\n            place(next_candidate)\n            # given the candidate, explore further\n            backtrack(next_candidate)\n            # backtrack\n            remove(next_candidate)\n\n\n\n  전체적으로 후보군을 만드는 일은 두 레벨로 진행된다. 먼저 함수는\n재귀적으로 구현된다. 각 재귀 함수 호출에서 함수는 최종 정답으로 한\n단계씩 진행한다. 두 번째로, 재귀 안에서는 모든 후보군을 탐색하는\n반복을 통해 최종 정답으로 나아가고 있다.\n  백트래킹은 재귀 안의 반복 레벨에서 나타난다.\n  완전탐색과는 다르게, 백트래킹에서는 지금까지 만들어낸 부분 정답\n후보가 탐색할 가치가 있는지를 확인할 수 있다(코드의\nis_valid(next_candidate)). 이를 통해 탐색 공간을 가지치기할 수\n있다. 이는 제약조건이라고도 하는데, 예를 들면 N-퀸 문제에서 퀸이 갈\n수 있는 좌표값이 있다.\n  두 개의 대칭적인 함수에 주목하자. 부분 후보를 한 단계 진행시키는\n결정을 하는 place(candidate)과, 이 결정을 취소하는\nremove(candidate)이다."
					}
					,
					"ps-leetcode-basic-calculator": {
						"id": "ps-leetcode-basic-calculator",
						"title": "Basic Calculators",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/basic-calculator/",
						"content": "Basic Calculators\n\n  Basic Calculator\n  Basic Calculator II\n  Basic Calculator III\n\n\n수식을 표현하는 문자열을 평가하고 그 결과 값을 구하는 문제들이다.\n\n정수 나눗셈은 버림하여 정수로 계산한다.\n\n모든 수식이 유효한 수식이라고 가정해도 된다. 수식을 계산하는 과정에서\n 생기는 모든 중간 결과와 최종 결과 값은 32비트 정수 범위 안에 포함됨이\n 보장된다.\n\n문자열 수식을 곧바로 평가할 수 있는 파이썬의 eval()같은거 쓰지말고\n 정정당당하게 계산하자.\n\n역폴란드 표기법, 또는 후위 표기법 - Reverse Polish Notation, or Postifx Notation\n\nBasic Calculator 문제들은 모두 하나의 궁극적인 솔루션이\n 존재한다. 중위 표기법으로 들어오는 수식을 역폴란드\n 표기법으로\n 바꾼 후에 스택 머신을 통해 계산하는 것이다.\n\n중위 표기법은 사람이 쓰고 이해하기에는 직관적이고 편리하지만,\n 기계적으로 처리하기에는 모호한 부분이 많다.\n\n  1 + 2 * 3과 같은 수식은 (1 + 2) * 3 또는 1 + (2 * 3)으로\n해석될 수 있는 모호함이 있다. 이를 해결하기 위해서 괄호나 연산자\n우선순위가 도입되지만, 기계적으로 처리하기 귀찮다.\n  반면 RPN으로는 위의 첫 번째 수식은 1 2 + 3 *으로, 두 번째 수식은\n1 2 3 * +으로 표기되기 때문에 모호함이 없다.\n  또한 RPN은 스택 머신을 통해 평가하기가 매우 쉽다. RPN 토큰을\n훑으면서 숫자(피연산자)는 스택에 넣는다. 연산자를 만나면 스택에서\n피연산자를 꺼내서 계산(평가)한 후 다시 스택에 넣으면 된다. 모든\n수식을 다 훑고 나면 스택에 있는 값이 바로 계산 결과가 된다. 참고로\n많은 가상 머신들이 스택 머신 모델을 사용하고 있다.\n\n\n그래서, 일단 수식이 RPN으로 들어왔다고 가정하면, 이 수식을 평가하는\n 함수는 매우 자명하다.\n\ndef eval_(rpn):\n    stack = []\n    for tok in rpn:\n        if isinstance(tok, int):\n            stack.append(tok)\n        elif tok in binary_operators:\n            x2 = stack.pop()\n            x1 = stack.pop()\n            y = binary_operator[tok](x1, x2)\n            stack.append(y)\n        elif tok in unary_operators:\n            x = stack.pop()\n            y = unary_operator[tok](x)\n            stack.append(x)\n    return stack.pop()\n\n\n  이항 연산과 단항 연산을 구분하고 있는 점을 눈여겨보자. 단항 연산의\n예는 -가 있다. 다만, - 토큰만으로는 이항 연산 -와 단항 연산\n-를 구분하기 힘들기 때문에, 전처리(파싱) 단계에서 이 둘을\n구분하도록 하는 것이 좋다.\n  이항 연산의 경우, 피연산자의 순서에 주목하자. 스택(메모리)은\nFILO이므로 꺼내는 순서의 역순으로 함수에 넘겨줘야 한다. +나 *는\n교환법칙(Commutative Law)가 성립하기 때문에 상관없지만, -와 /는\n교환법칙이 성립하지 않기 때문에 이 순서를 틀리면 결과가 어그러진다.\n\n\n\n\n이렇게 RPN을 가정한 평가 함수를 만들고 나면, 남은 작업은 입력으로\n 들어온 중위 표기법 수식을 후위 표기법으로 바꾸는 것 뿐이다. 킹갓\n 다익스트라님께서 이미 알고리즘을 만들고 증명해두셨으니 우리는 이걸\n 가져다 쓰면 된다. 바로 차량기지 알고리즘(Shunting yard\n algorithm)이다. 알고리즘이\n 동작하는 (중간에 연산자를 넣어뒀다가 다시 꺼내는) 방식이 차량 기지가\n 동작하는 방식을 닮아서 이름붙여졌다고 한다.\n\n위키 문서의 방법을 거의 그대로 가져다 코드로 쓰면 된다. 여기서는\n 함수가 따로 없으므로 사칙연산과 괄호만 수도 코드로 가져왔다. 참고로,\n 이렇게 뭔가 순서를 뒤집거나 하는 데에는 항상 스택이 필수로 쓰인다.\n\n입력: 중위 표기법 수식의 토큰 리스트\n중간 데이터: 연산자 스택\n출력: 후귀 표기법 수식 큐\n\nwhile 토큰이 아직 남아있는 동안:\n    토큰을 읽는다.\n    match 토큰 with\n    | 숫자 -&gt; 출력 큐에 넣는다.\n    | 연산자 o1 -&gt;\n        while (연산자 스택 꼭대기에 여는 괄호가 아닌 연산자 o2가 있고\n            &amp;&amp; o2가 o1보다 우선순위가 높거나\n            || 둘의 우선순위가 같고 o1이 왼쪽 결합인 동안):\n            연산자 스택에서 o2를 팝해서 출력 큐에 넣는다.\n        o1을 연산자 스택에 넣는다.\n    | 여는 괄호 -&gt; 연산자 스택에 넣는다.\n    | 닫는 괄호 -&gt;\n        while 연산자 스택의 꼭대기가 여는 괄호가 아닌 동안:\n            연산자 스택에서 연산자를 팝해서 출력 큐에 넣는다.\n        여는 괄호를 팝해서 버린다.\n\nwhile 연산자 스택에 연산자가 남아 있는 동안:\n    연산자를 팝해서 출력 큐에 넣는다.\n\n\n전체적인 알고리즘의 모습은 이것과 동일하다. 즉, 토큰을 읽어서, 토큰의\n 종류에 따라 연산자 스택을 적절히 이용해서 우선순위에 맞게 후위\n 표기법으로 바꾼다.\n\n여기서 위키에서 다루지 않는 내용이 바로 단항 연산자의\n 경우이다. 예를 들어, - 3 + 5는 후위 표기법으로 바꾸면 3 - 5 +가\n 되는데, 이는 -가 단항 연산자이기 때문이다. 그럼 단항 연산자는\n 어떻게 처리하면 될까? 먼저 어떤 경우에 단항 연산자인지를 생각해보면\n 다음 세 가지 케이스밖에 없다는 것을 알 수 있다.\n\n  중위 표기법 토큰 스트림의 가장 처음에 나온다. e.g. -1\n  다른 연산자 바로 다음에 나온다. e.g. 1 + -1\n  여는 괄호 바로 다음에 나온다. e.g. (-1)\n\n\n그럼 단항 연산자 일때는 어떻게 하면 될까? 그냥 바로 연산자 스택에\n 넣으면 된다. 예를 들어, 1의 경우는 -가 스택에 들어가고, 1이 큐에\n 쌓이고, 그 후 마지막 while 루프에서 스택에 있는 단항 연산자가 큐에\n 들어가 정상적인 1 - 가 된다. 3의 경우도 자명하다.\n\n2의 경우는 두 가지 더 고려해야 할 것이 있는데, (1) 단항 연산자와 이항\n 연산자를 구분해야하고 (2) 두 연산자의 우선순위를 비교해야 한다. 단항\n 연산자의 우선순위는 어떻게 될까? 자연스럽게, 우리는 단항 연산자의\n 우선순위가 더 높음을 안다. 따라서 (2)는 해결된다. (1)을 위해서, 위의\n 세 가지 케이스일 때, 연산자 스택에 그냥 -를 넣으면 안되고 이것이\n 단항 연산자임을 알리기 위한 특별한 토큰을 넣어야 한다. 여기서는\n u-로 표기하겠다. 이러면 (1)과 (2)는 해결된다. 그러면 계속해서 2의\n 경우를 살펴보자. 루프를 몇 번 거치고 나면 출력 큐는 1 1이고\n 스택에는 [+, u-]가 들어간다. 그러면 마지막 while 루프를 통해 1 1\n u- +가 되고 이는 우리가 원하는 올바른 후위 표기법이다.\n\n이 아이디어를 코드로 구현해서 중위 표기법 수식을 파싱하여 RPN 수식의\n 리스트로 돌려주는 함수를 작성하면 다음과 같다.\n\ndef parse(infix_exp):\n    binary_operators = ['+', '-', '*', '/']\n    precedences = {\n        '+': 1, '-': 1,\n        '*': 2, '/': 2,\n        'u-': 3,\n    }\n    rpn, opstack = [], []\n    lexer = re.compile(r\"[-+*/()]|\\d+\")\n    tokens = lexer.findall(infix_exp)\n    for idx, tok in enumerate(tokens):\n        if tok.isdigit():\n            rpn.append(int(tok))\n            continue\n\n        if tok == '-' and (idx == 0 or tokens[idx-1] in binary_operators + ['(']):\n            opstack.append('u-')\n        elif tok in binary_operators:\n            while opstack and opstack[-1] != '(' and precedences[opstack[-1]] &gt;= precedences[tok]:\n                rpn.append(opstack.pop())\n            opstack.append(tok)\n        elif tok == '(':\n            opstack.append(tok)\n        else: # tok == ')'\n            while opstack:\n                top = opstack.pop()\n                if top == '(':\n                    break\n                rpn.append(top)\n    while opstack:\n        rpn.append(opstack.pop())\n    return rpn\n\n\n\n  입력이 문자열이기 때문에 이를 토큰으로 쪼개기 위해서 파이썬의\nre를 이용해 정규식으로 쪼개었다. 정규식 사용법은\n여기를 참조하자.\n  단항 연산자의 처리를 위해서 토큰의 인덱스가 필요하다.\n\n\n\n\n이렇게 두 가지를 얻었다:\n\n  중위 표기법 수식 문자열을 후위 표기법 토큰 리스트로 변환하는 함수\nparse\n  후위 표기법 토큰 리스트를 평가하고 결과 값을 계산하는 함수 eval_\n\n\n그러면, 모든 Basic Calculator 문제는 다음 두 줄로 풀린다:\n\ndef calculate(s):\n    rpn = parse(s)\n    return eval_(rpn)"
					}
					,
					"ps-leetcode-best-time-to-buy-and-sell-stock": {
						"id": "ps-leetcode-best-time-to-buy-and-sell-stock",
						"title": "Best Time to Buy and Sell Stock",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/best-time-to-buy-and-sell-stock/",
						"content": "Best Time to Buy and Sell Stock\n\n주식 가격 리스트 prices가 주어진다. i 번째 날의 주식 가격이\n 적혀있다.\n\n수익을 최대한으로 내기 위해서 주식을 살 날짜 하나와 그 날짜 이후에\n 주식을 팔 날짜 하나를 고르고 싶다. 이때 가능한 최대의 수익을\n 구해보자. 수익을 아예 못내는 경우는 0을 리턴한다.\n\n접근\n\n  배열을 순차적으로(날짜 순으로) 훑어감\n  항상 판매는 구매 날짜 이후에 가능하므로, 다음 상태를 유지:\n    \n      지금까지 구매했던 최소 가격\n      지금까지 가능했던 최대 수익\n    \n  \n  날짜를 진행할 때마다 “현재 날짜에 가능한 수익”을 계산할 수 있음:\n지금 날짜의 가격 - 지금까지 구매했던 최소 가격. 이를 매번\n최대치로 업데이트\n  초기 값에 주의\n    \n      0일에 가능한 최소 가격은 무한대\n      0일에 가능한 최대 수익은 0\n    \n  \n\n\ndef max_profit(prices):\n    min_price_so_far = float('inf')\n    max_profit_so_far = 0\n    for p in prices:\n        min_price_so_far = min(min_price_so_far, p)\n        max_profit_so_far = max(max_profit_so_far, p - min_price_so_far)\n    return max_profit_so_far"
					}
					,
					"ps-boj-bfs": {
						"id": "ps-boj-bfs",
						"title": "Breadth First Search",
						"version": "all",
						"categories": "",
						"url": " /ps/boj/bfs/",
						"content": "BFS\nDeque\n파이썬에는 collections 패키지 안에 deque가 있으므로 다음\n 인터페이스를 숙지해야 한다.\n\n  deque(): 생성자\n  deque.append(x): 끝\n  deque.appendleft(x): 앞\n  deque.pop(): 끝\n  deque.popleft(): 앞\n\n\n따라서, “큐”의 Functionality를 얻으려면 append()와 popleft()를\n 써야한다. pop()을 써버리면 스택과 다름없다.\n\n연관 키워드\n길 찾기, 최소 경로 찾기,\n\n정석\n\n  큐, 집합 초기화\n  시작 지점을 하나 잡아서, 큐와 집합에 둘다 넣는다.\n  큐가 빌 때까지 다음을 반복한다:\n    \n      앞에서 하나 pop 한다.\n      pop한 원소에서 갈 수 있는 다음 지점을 전부 훑어본다.\n      다음 지점이 집합에 없으면 (즉, 방문하지 않았으면), 큐와\n집합에 둘다 넣는다.\n    \n  \n\n\nBFS에서 주의해야 할 부분은 루프 안에서 큐에 다음 지점을 넣기 전에\n 방문 체크를 해야한다는 점이다. 꺼내서 방문 체크 해도 말은 되지만\n 이러면 시간 복잡도가 터진다.\n\n1926번: 그림\n\nimport sys\nfrom collections import deque\nline = sys.stdin.readline\n\nn, m = map(int, line().rstrip().split())\ngraph = []\nfor _ in range(n):\n    graph.append(line().rstrip().split())\n\nvisited, max_area, total_count = set(), 0, 0\ndef bfs(y, x):\n    q = deque()\n    visited.add((y, x))\n    q.append((y, x))\n    area = 1\n    while q:\n        y, x = q.popleft()\n        for ny, nx in ((y+1, x), (y-1, x), (y, x+1), (y, x-1)):\n            if 0 &lt;= ny &lt; n and 0 &lt;= nx &lt; m and graph[ny][nx] == '1' and (ny, nx) not in visited:\n                visited.add((ny, nx))\n                q.append((ny, nx))\n                area += 1\n    return area\n\n# check all\nfor y in range(n):\n    for x in range(m):\n        if graph[y][x] == '1' and (y, x) not in visited:\n            total_count += 1\n            max_area = max(max_area, bfs(y, x))\n\nprint(total_count)\nprint(max_area)\n\n\n위의 클래식을 잘 고려해서 bfs를 짜면 된다. 파이써닉하게 짠 부분은 (1)\n 방문 체크할 때 내장 해쉬셋과 내장 튜플을 곧바로 이용한 점, (2) 다음\n 지점을 구할 때 상하좌우 다음 좌표를 곧바로 튜플로 계산한 것, 그리고\n (3) 다음 지점의 바운드 체크를 할 때 체인 비교 연산자를 쓴 것이다.\n\n한 그림의 어느 지점에서 시작하던지 간에 bfs가 호출되고 나면 그\n 그림의 모든 좌표를 방문하게 되므로 처음 방문할 때 total_count를\n 늘리면 된다.\n\n그림의 크기는 bfs에서 큐에 넣을 때마다, 혹은 방문했다고 기록할\n 때마다 크기가 1씩 증가하므로 이 사실을 이용해서 계속 누적해 나아가면\n 된다.\n\n2178번: 미로 탐색\n\nimport sys\nfrom collections import deque\n\nn, m = map(int, sys.stdin.readline().rstrip().split())\nboard = []\nfor _ in range(n):\n    board.append(sys.stdin.readline().rstrip())\n\npath = [[0 for _ in range(m)] for _ in range(n)]\nq = deque()\n\nq.append((0, 0))\npath[0][0] = 1\n\nwhile q:\n    cy, cx = q.popleft()\n    for y, x in ((cy+1, cx), (cy-1, cx), (cy, cx+1), (cy, cx-1)):\n        if y &lt; 0 or y &gt;= n or x &lt; 0 or x &gt;= m:\n            continue\n        if board[y][x] == '0' or path[y][x] != 0:\n            continue\n        path[y][x] = path[cy][cx] + 1\n        q.append((y, x))\n\nprint(path[n-1][m-1])\n\n\n최단 경로를 구할 때 BFS를 활용할 수 있다. 방문 체크를 집합으로 하지\n 않고, 원래의 맵과 똑같은 사이즈의 맵을 만든 뒤 여기에 경로를 기록하면\n 된다. 이런 문제에서는 보통 시작점은 주어지기 때문에, 이 경로 맵에는\n 시작점으로부터 해당 위치까지의 경로를 계속 기록하면 된다. 그러면\n BFS의 특성 상 경로 맵을 다 채우고 나면 시작점으로부터 모든 점까지의\n 최단 경로를 알 수 있다.\n\n이를 위해서 path를 만들 때, 파이썬에서는 위와 같이 range를\n 이용해서 만들어줘야 한다. 그냥 곱 연산으로 [[0] * m] * n 처럼\n 만들면, 처음 m 만큼은 깊은 복사가 일어나지만 이후 이 리스트를\n n만큼 곱할 때에는 얕은 복사가 일어나기 때문에 제대로 된 경로를\n 계산하지 못한다.\n\n이 점만 주의하면 나머지는 Trivial 하다.\n\n7576번: 토마토\n\nimport sys\nfrom collections import deque\nload = lambda: sys.stdin.readline().rstrip().split()\nn, m = map(int, load())\nbox = []\nfor _ in range(m):\n    box.append(load())\n\nripes, total = 0, 0\npath = [[-1 for _ in range(n)] for _ in range(m)]\nq = deque()\n\nfor y in range(m):\n    for x in range(n):\n        if box[y][x] != '-1':\n            total += 1\n        if box[y][x] == '1':\n            ripes += 1\n            q.append((y, x))\n            path[y][x] = 0\n\nwhile q:\n    y, x = q.popleft()\n    for ny, nx in ((y+1,x), (y-1,x), (y,x+1), (y,x-1)):\n        if 0 &lt;= ny &lt; m and 0 &lt;= nx &lt; n and box[ny][nx] == '0' and path[ny][nx] == -1:\n            q.append((ny, nx))\n            path[ny][nx] = path[y][x] + 1\n            ripes += 1\n\nif ripes != total:\n    print(-1)\nelse:\n    elapsed = 0\n    for p in path:\n        elapsed = max(elapsed, max(p))\n    print(elapsed)\n\n\n문제를 잘 읽어보면 BFS로 시뮬레이션 할 수 있음을 알 수 있다. 익은\n 토마토부터 시작해서 모든 경로의 최단 거리를 구하고 그 중 가장 큰 값이\n 답이다. 마찬가지로 시작점이 여러 개일 수 있는데, 이것도 미리 구해서\n 큐에 넣어두면 된다.\n\n주의해야 할 한 가지는, 익지 않는 토마토 체크(일종의 Reachability\n 체크)를 따로 해줘야 한다는 점이다. 여기서는 그냥 손쉽게 전체 토마토\n 개수랑 익은 토마토 개수를 구해서 비교했다.\n\n4179번: 불!\n지훈이가 옮겨다닐 때 불을 끌 수 없다는 강력한 제약 조건 덕분에 BFS 두\n 번 돌려서 풀 수 있는 문제다. 즉, 시작 지점이 두 개인 BFS이면서 동시에\n 서로 영향을 주지 않는다.\n\nimport sys\nfrom collections import deque\nload = lambda: sys.stdin.readline().rstrip()\nr, c = map(int, load().split())\nlabyrinth = []\nfor _ in range(r):\n    labyrinth.append(load())\n\nfire_q = deque()\nfire_map = [[-1 for _ in range(c)] for _ in range(r)]\njihun_q = deque()\njihun_run = [[-1 for _ in range(c)] for _ in range(r)]\n\n# 일단 불과 지훈이를 찾아야 한다.\nfor y in range(r):\n    for x in range(c):\n        if labyrinth[y][x] == 'J':\n            jihun_q.append((y, x))\n            jihun_run[y][x] = 0\n        elif labyrinth[y][x] == 'F':\n            fire_q.append((y, x))\n            fire_map[y][x] = 0\n\n# 먼저 불을 시뮬레이션 한다.\nwhile fire_q:\n    y, x = fire_q.popleft()\n    for ny, nx in ((y+1,x), (y-1,x), (y,x+1), (y,x-1)):\n        if 0 &lt;= ny &lt; r and 0 &lt;= nx &lt; c and labyrinth[ny][nx] != '#' and fire_map[ny][nx] == -1:\n            fire_q.append((ny, nx))\n            fire_map[ny][nx] = fire_map[y][x] + 1\n\n# 지훈이를 달리게 하면서 시간을 기록한다.\nescaped_time = None\nwhile jihun_q:\n    y, x = jihun_q.popleft()\n    this_turn = jihun_run[y][x] + 1\n    for ny, nx in ((y+1,x), (y-1,x), (y,x+1), (y,x-1)):\n        if ny &lt; 0 or ny &gt;= r or nx &lt; 0 or nx &gt;= c:\n            # 범위 밖으로 빠져나온 건 탈출에 성공했다는 얘기다.\n            escaped_time = this_turn\n            break\n        if labyrinth[ny][nx] == '#' or jihun_run[ny][nx] != -1:\n            # 갈 수 없는 길이거나, 이미 더 빨리 올 수 있으면 다음으로\n            continue\n        if fire_map[ny][nx] == -1 or this_turn &lt; fire_map[ny][nx]:\n            # case 1: 불이 아예 못오거나\n            # case 2: 이번 턴에 불 보다 빨리 갈 수 있어야 갈 수 있다.\n            jihun_run[ny][nx] = this_turn\n            jihun_q.append((ny, nx))\n    if escaped_time:\n        break\n\nprint(escaped_time if escaped_time else \"IMPOSSIBLE\")\n\n\n따라서, 먼저 불을 BFS로 시뮬레이션해서 불이 퍼져나가는 시간을 전부\n 기록한 다음, 지훈이를 조심스럽게 달리게 하면 된다. 불을 퍼뜨리는 것은\n 일반적인 BFS라서 그냥 하면 되고, 지훈이는 다음 턴에 달릴 때 다음과\n 같은 조건을 살펴봐야 한다.\n\n  탈출 성공: 미로 범위 바깥으로 나가게 되면 탈출 성공이다.\n  탈출 시간: 지훈이가 BFS로 옮겨다니는 시간을 기록해뒀다면,\n빠져나가는 순간의 시간은 직전 위치의 시간 + 1이다.\n  옮겨갈 수 있는 위치: 불이 아예 못오는 경우도 고려해야 한다. 불과\n지훈이가 벽으로 분리되어 있는 경우가 해당한다.\n\n\n1697번: 숨바꼭질\n이게 BFS인가? 싶은데 문제를 잘 읽어보면 결국 시뮬레이션으로 최단\n 거리를 구하는 문제로 환원할 수 있어서 BFS를 적용해볼 수 있다.\n\nimport sys\nfrom collections import deque\nn, k = map(int, sys.stdin.readline().rstrip().split())\n\ndef bfs(n, k):\n    if n == k:\n        return 0\n    q = deque()\n    q.append(n)\n    time = {n: 0}\n\n    while q:\n        now = q.popleft()\n        for after in (now+1, now-1, 2*now):\n            if after &lt; 0 or after &gt; 100000:\n                continue\n            if after == k:\n                return time[now] + 1\n            if after in time:\n                continue\n            time[after] = time[now] + 1\n            q.append(after)\n\nprint(bfs(n,k))\n\n\n\n  코너 케이스 하나를 잘 고려해야 한다. 시작부터 수빈이랑 동생이 같은\n지점에 있으면 0초만에 찾을 수 있다.\n  움직일 수 있는 범위가 0과 100000 사이인데, 수빈이가 이 범위를\n벗어나도록 움직이면 최단 시간 안에 동생을 찾을 수 없으므로 제외해야\n한다. 그리고 이렇게 제외를 해야 수빈이가 움직이는 시간에 대한\n기록을 덜 해서 메모리 초과가 나지 않는다."
					}
					,
					"ps-theory-bfs": {
						"id": "ps-theory-bfs",
						"title": "Breadth First Search",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/bfs/",
						"content": "BFS\nBFS 알고리즘의 결과로 얻어지는 경로는 시작 노드로부터 가장 가까운 거리에 있는 노드, 즉 엣지 수가 가장 적은 경로를 갖는 노드이다.\n알고리즘의 복잡도는 \\(O(n+m)\\) 이고 n은 노드의 수, m은 엣지의 수 이다.\n\n알고리즘\n웨이트가 없는 그래프와 시작 노드를 입력으로 받는다. 입력 그래프의 방향성(무향/유향)은 상관없다.\n알고리즘을 불이 뻗어나가는 것으로 이해할 수 있다. 0번째 단계에서 시작 노드 s에 불이 붙는다. 이후 각각의 단계에서 각 노드와 인접한 노드에 불이 붙는다. 이러한 반복에 의해서 “불의 고리”가 넓게 퍼져 나간다.\n\n구현\nfrom collections import deque\n\ndef bfs(graph: List[List[int]], source: int, n: int):\n    q = deque()\n    visited = set()\n    dist, parent = [0] * n, [0] * n\n\n    q.append(source)\n    visited.add(source)\n    parent[source] = -1\n    while q:\n        node = q.popleft()\n        for neighbor in graph[node]:\n            if neighbor in visited:\n                continue\n            visited.add(neighbor)\n            q.append(neighbor)\n            dist[node] = dist[neighbor] + 1\n            parent[neighbor] = node\n\n\n\n\n  큐가 빌 때까지 반복한다. 따라서, 큐의 초기 상태는 시작 노드 source가 들어있어야 한다.\n  큐에서 꺼낸 노드는 항상 방문이 완료된 상태, 즉 visited 집합에 들어 있는 노드임이 불변식(invariant)이다.\n  각 단계에서 인접한 노드의 방문 여부를 먼저 확인한다. 아직 방문하지 않았다면, 방문 표시를 하고 큐에 넣어야 한다. 그래야 탐색 공간이 터지지 않는다.\n  각 단계에서 인접한 노드를 방문할 때, 방문을 완료한 이전 노드의 정보를 이용해서 (1) 이때까지 (시작 노드로부터) 거쳐온 거리와 해당 노드의 바로 직전 노드(부모) 정보를 기록할 수 있다. 이 정보를 이용하면 다음과 같이 최단 경로를 알아낼 수 있다.\n\n\ndef shortest_path(source: int, parent: List[int]) -&gt; List[int]:\n    path = []\n    node = source\n    while node != -1:\n        path.append(node)\n        node = parent[node]\n\n    return reversed(path)\n\n\n그래프가 아닌 좌표 평면 상의 최단 경로를 구하는 데에도 적용할 수 있다.\n\ndef bfs(graph, starting, visited):\n    m, n = len(graph), len(graph[0])\n    visited.add(starting)\n    q = deque()\n    q.append((0, starting))  # carry with step\n\n    while q:\n        step, (y, x) = q.popleft()\n\n        # check arrival here!\n        if has_arrived(y, x):\n            return step\n\n        # populate next states\n        for ny, nx in ((y+1, x), (y-1, x), (y, x+1), (y, x-1)):\n            # check range\n            if ny &lt; 0 or nx &lt; 0 or ny &gt;= m or nx &gt;= n:\n                continue\n            # or check arrival here, with step + 1\n            if has_arrived(ny, nx):\n                return step + 1\n\n          # check reachability\n            if (ny, nx) not in visited and reachable(graph[ny][nx]):\n                visited.add((ny, nx))\n                q.append((step + 1, (ny, nx)))  # carry with step\n\n\n최단 거리를 구할 때 주의해야 할 점은 딱 한 가지다. 도착 여부 체크 has_arrived()를 언제 하느냐에 따라서 정답이 되는 거리가 step인지 step + 1인지이다. 즉, 큐에서 방금 꺼낸 위치는 방문을 완료한 위치이기 때문에 꺼내자마자 도착 여부를 체크를 하면 step이고, 다음 위치를 계산하는 시점에 도착 여부를 확인하면 step + 1이 거리가 된다. 아마 다음 위치를 계산하는 시점에서 확인하면 상태를 조금이라도 덜 탐색하기 때문에 (큐에 넣고 빼는 과정이 없음) 시간 및 공간적으로 조금이라도 더 낫겠지만 전체 복잡도에서는 차이가 없을 것이므로 적당히 취향 껏 하면 된다.\n\nBFS의 응용\n\n  웨이트가 없는 그래프에서 시작 노드로부터 다른 모든 노드로의 최단 경로 찾기.\n  무향 그래프에서 \\(O(n+m)\\) 복잡도로 모든 연결 요소(connected component) 찾기: 이걸 하려면 BFS를 각각의 노드에 대해서 모두 수행해야 하는데, 이때 이전의 수행에서 방문된 노드들은 제외한다. 그러면 각각의 노드로부터 일반적인 BFS를 수행하게 되지만, 새로운 연결 요소를 만나더라도 visited 집합을 초기화하지 않기 때문에 전체 수행 시간은 그대로 \\(O(n+m)\\)이 된다. 이렇게 방문 집합을 유지하면서 BFS를 여러 번 수행하는 것을 연속 BFS (a series of BFSes)라고 한다.\n  어떤 문제나 게임에서 최소한의 턴(움직임)으로 해결할 수 있는 해법 찾기: 게임의 각 상태를 그래프의 노드로 표현하고 하나의 상태에서 다른 상태로 바뀌는 것을 그래프의 엣지로 표현하면 된다.\n  웨이트가 0 또는 1만 있는 그래프에서 최단 경로 찾기: 일반적인 BFS에 아주 약간의 수정을 가하면 된다. visited 집합을 유지하지 않고, 대신 노드까지의 거리가 현재 계산한 거리보다 짧은지를 체크한 후 현재 엣지의 웨이트가 0이라면 큐의 앞쪽에 넣고 아니면 큐의 뒷쪽에 넣는다. 이러한 방법을 0-1 BFS 라고 한다.\n  웨이트가 없는 유향 그래프에서 가장 짧은 싸이클 찾기: 각각의 노드에서 BFS를 시작한다. 시작 노드로 다시 되돌아 오는 순간 우리는 시작 노드로부터 가장 짧은 싸이클을 찾은 것이다. 이 시점에서 BFS를 멈추가 그 다음 노드에 대해서 새로운 BFS를 시작하면 된다. 그리고 이렇게 찾은 모든 싸이클 중에서 가장 짧은 것을 고르면 된다.\n  주어진 노드 쌍 (a, b) 사이의 어떤 최단 경로에 있는 모든 노드 구하기. 이걸 하려면 BFS를 두 번 하면 된다. 먼저 a에서 b로 한번 한다. \\(d_{a}[]\\)를 첫 번째 (a로부터의) BFS를 통해 얻은 최단 거리 배열이라고 하자. 그 다음 b에서 a로 한다. 두 번째 (b로부터의) BFS를 통해 얻은 최단 거리 배열을 \\(d_{b}[]\\)라고 하자. 그러면 각각의 노드 x에 대해서 해당 노드가 a와 b 사이의 최단 경로에 있는지를 쉽게 확인할 수 있다: \\(d_{a}[x] + d_{b}[x] = d_{a}[b]\\).\n  주어진 노드 쌍 (a, b) 사이의 어떤 최단 경로에 있는 모든 엣지 구하기. 이걸 하려면 BFS를 a -&gt; b, b -&gt; a 방향으로 두 번 수행해서 각 시작 노드로부터의 최단 거리 배열 \\(d_{a}[]\\)와 \\(d_{b}[]\\)를 구한 다음, 모든 엣지 (x, y)에 대해서 다음 조건을 확인하면 된다: \\(d_{a}[x] + 1 + d_{b}[y] = d_{a}[b]\\).\n  웨이트가 없는 그래프에서 시작 노드 s로부터 목표 노드 t까지의 짝수 거리를 갖는 최단 경로 찾기: 이걸 하려면 보조 그래프부터 만들어야 한다. 현재 노드를 v, 현재 패리티(즉 홀짝성) 0 또는 1을 담은 변수를 c라고 하면, (v, c) 상태를 노드로 하는 새로운 그래프를 만들자. 그러면 원래 그래프의 어떤 엣지 (x, y)는 이 새로운 그래프에서 두 개의 엣지 ((x, 0), (y, 1))과 ((x, 1), (y, 0))을 갖게 된다. 그러면 이제 우리는 시작 노드 (s, 0)에서 목표 노드 (t, 0)까지의 최단 경로를 구하면 된다."
					}
					,
					"ps-theory-binary-search": {
						"id": "ps-theory-binary-search",
						"title": "Binary Search",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/binary-search/",
						"content": "Binary Search\n\nBinary Search in Rotated Sorted Array\n\n정렬된 리스트(배열)에서 k (0 &lt;= k &lt; len(arr)) 번째 인덱스를\n 기준으로 회전을 시킨 경우, 어디서 회전되었는지를 찾고 (피벗) 이 값을\n 이용해서 이분탐색을 하면 O(log N) 만에 찾을 수 있다.\n\n참고로, 피벗을 찾은 다음 sorted_arr = arr[pivot:] + arr[:pivot]\n 이렇게 정렬된 리스트를 복구해서 검색해도 말은 되지만, 복사 연산자\n 때문에 O(N)을 한번 겪게 되어서 사이즈가 커지면 느려진다. 작으면\n 별로 문제 안됨.\n\ndef search_from_rotated(nums, tofind):\n    # 1. find pivot index (the smallest value)\n    low = 0\n    high = len(nums) - 1  # this is tricky - high is an index here\n\n    while low &lt; high:\n        mid = low + (high - low) // 2  # same as (low + high) // 2, but avoid overflow\n        if nums[mid] &gt; nums[high]:\n            # rotated in somewhere mid..high\n            low = mid + 1\n        else:\n            # rotated in somewhere low..mid\n            high = mid\n\n    pivot = low  # the index of the smallest value\n\n    # 2. now, binary search with this info\n    low = 0\n    high = len(nums)  # here, the range is half open: [low, high)\n\n    # find correct range\n    if nums[pivot] &lt;= tofind &lt;= nums[high-1]:\n        # tofind is somewhere pivot..high\n        low = pivot\n    else:\n        # tofind is somewhere low..pivot\n        high = pivot\n\n    while low &lt; high:\n        mid = low + (high - low) // 2\n        if nums[mid] == tofind:\n            return mid\n        if tofind &gt; nums[mid]:\n            low = mid + 1\n        else:\n            high = mid\n\n    return -1\n\n\n\n  처음에 피벗 인덱스를 찾을 때는 high 역시 인덱스로\n쓰였다. high를 half-open 으로 둬볼려고 했는데, 1씩 빼거나\n더해줘야 되서 코드가 더 복잡해져서 그냥 저렇게 하는게 깔끔하다.\n  피벗을 찾은 이후에는 위 코드처럼 직접 이분 탐색을 구현해도 되고\n(여기서는 half-open 으로 구현), 아니면 아래와 같이 bisect를\n활용해도 된다.\n\n\n    ... # search pivot\n    # find Lower Bound to find equal value\n    bi = bisect.bisect_left(nums, tofind, low, high)\n    if bi &lt; len(nums) and nums[bi] == tofind:\n        return bi\n    else:\n        return -1\n\n\n\n\n  bisect 를 활용할 때에는 Lower Bound를 찾는게 편한데, 왜냐하면\n위에서 설명했듯이, 찾고자 하는 값 보다 “크거나 같은 값”이 처음\n나오는 위치를 찾아주기 때문이다. 그래서 bisect_left 리턴 값을\n곧바로 인덱스로 쓸 수 있다. 만약 Upper Bound로 찾았다면, 이는 “큰\n값”이 처음으로 나오는 위치 이므로, bisect_right (또는 그냥\nbisect) 리턴 값에서 1을 빼줘야 정확한 인덱스가 된다.\n  추가로, bisect는 “값을 적절하게 삽입할 위치”를 찾아주기 때문에,\n실제로 리턴한 인덱스에 정말 찾고자 하는 값이 있는지 한번 더\n확인해야 한다."
					}
					,
					"ps-leetcode-binary-tree-cameras": {
						"id": "ps-leetcode-binary-tree-cameras",
						"title": "Binary Tree Cameras",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/binary-tree-cameras/",
						"content": "Binary Tree Cameras\n\n이진 트리의 루트 노드가 주어진다. 트리의 노드에 카메라를 설치해서\n 노드 자신과 부모, 그리고 자식 노드를 관찰하려고 한다.\n\n트리의 모든 노드를 관찰하기 위해서 필요한 최소 카메라의 수를 구하자.\n\n노드 수는 최대 1,000 이고 모든 노드의 값은 0이다.\n\n예를 들어 아래와 같은 트리는, 카메라를 1개만 설치하면 모든 노드를 다\n 관찰할 수 있다.\n\n\n\n음..?\n\n이걸 무슨 알고리즘이라고 불러야될지 모르겠다. 솔루션에는 DP라고\n 나와있는데 DP가 아니어도 풀 수 있는 것 같고, 그리디도 아닌것 같고..\n\n트리를 리프 노드부터 훑어서 루트 노드까지 올라올 때, 각 노드가 가질\n 수 있는 상태는 총 세 가지이다:\n\n  카메라가 설치됨\n  카메라가 설치되지 않았지만, 인접한 노드에 의해서 관찰됨\n  카메라가 설치되지도 않았고 인접한 노드에도 없어서 관찰도 안됨\n\n\n그러면 자식 노드의 상태에 따라서, 지금 노드의 상태를 알 수 있고, 이때\n 카메라를 설치해야 하는 노드도 알 수 있다. 즉,\n\n  null 노드는 2번 상태라고 볼 수 있다. null이기 때문에 카메라를\n설치할 수는 없지만, null이라서 특별히 관찰하지 않아도 관찰되고 있기\n때문이다.\n  현재 노드의 자식 노드에 따라서 현재 노드의 상태가 나눠진다. 즉,\n    \n      자식 노드 중 하나라도 카메라도 없고 관찰되고 있지도 않으면, 지금\n노드에 카메라를 설치해야 한다.\n      자식 노드 중 하나라도 카메라가 있다면, 지금 노드는 관찰되고 있는\n상태이다.\n      위의 두 경우가 아니라면 카메라도 없고 관찰되고 있지도 않은\n상태이다.\n    \n  \n\n\n이 중 카메라를 설치해야 하는 경우에 카메라 개수를 늘리면 된다.\n\n다만, 이때 한 가지 코너 케이스가 있는데, 바로 루트 노드에 카메라도\n 없고 관찰되지도 않는 경우이다. 이때는 추가적으로 루트 노드에 카메라를\n 설치해줘야 한다. 예를 들어, 루트 노드 하나만 있는 경우이거나, 혹은\n 아래와 같이 Skewed Tree일 때 이런 케이스가 생긴다:\n\n^  O -------------&gt; not monitored ! -&gt; need to install camera\n|   \\\n|    O -----------&gt; monitored\n|     \\\n|      O  --------&gt; camera\n|       \\\n|        O    ----&gt; not monitored\n|\nsee upward\n\n\n따라서 아래와 같이 구현할 수 있다.\n\ndef minCameraCover(root):\n    CAMERA = 0\n    MONITORED = 1\n    NOT_MONITORED = 2\n\n    camera_count = 0\n    def dfs(node):\n        nonlocal camera_count\n        if not node:\n            return MONITORED\n\n        left, right = dfs(node.left), dfs(node.right)\n        if NOT_MONITORED in (left, right):\n            camera_count += 1\n            return CAMERA\n        elif CAMERA in (left, right):\n            return MONITORED\n        return NOT_MONITORED\n\n    if dfs(root) == NOT_MONITORED:\n        # corner case\n        camera_count += 1\n    return camera_count"
					}
					,
					"ps-leetcode-binary-tree-level-order-traversal": {
						"id": "ps-leetcode-binary-tree-level-order-traversal",
						"title": "Binary Tree Level Order Traversal",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/binary-tree-level-order-traversal/",
						"content": "Binary Tree Level Order Traversal\n\n바이너리 트리의 루트 노드가 주어졌을 때, 트리를 레벨 순서로 순회한\n 결과를 리턴하자. 레벨 순 순회란 왼쪽에서 오른쪽으로, 레벨(깊이)\n 순서로 순회하는 것이다. 결과는 리스트로, 같은 레벨에 있는 값은\n 왼쪽에서 오른쪽 순으로 들어가있도록 한다.\n\n예를 들어 다음과 같은 트리가 있다면,\n\n\n\n레벨 순서로 순회한 결과는 [[3], [9, 20], [15, 7]]이 된다.\n\n노드의 개수는 0~2,000 이고 노드의 값은 -1,000~1,000이다.\n\n재귀\n\n모든 트리의 순회는 루트로부터 시작할 수 밖에 없기 때문에, 레벨은 결국\n 루트에서 0으로 시작해서 아래로 내려갈 때마다 1씩 증가하는 정수\n 값이라고 생각해도 무방하다.\n\n같은 레벨일 때에는 왼쪽을 먼저 방문하면 된다.\n\n순회 결과는 방문한 순서대로 결과를 같은 레벨의 리스트에 추가해야\n 하므로, 레벨 -&gt; 방문 목록을 기록하는 자료구조가 있으면 충분할 것\n 같다. 여기서는 파이썬의 딕셔너리, 그 중에서도 defaultdict를\n 활용하면 첫 방문 시에 null check를 피할 수 있다.\n\nfrom collections import defaultdict\ndef levelOrder(root):\n    traversal = defaultdict(list)\n    def levelorder(node, level):\n        if node is None:\n            return\n        nonlocal traversal\n        traversal[level].append(node.val)\n        levelorder(node.left, level+1)\n        levelorder(node.right, level+1)\n\n    levelorder(root, 0)\n    return traversal.values()\n\n\n\n  방문 결과를 defaultdict에 쌓는다. 쌓을 곳은 level을 인덱스로\n접근한 리스트이다.\n  방문이 다 끝나고 나면 결과는 딕셔너리 형태로 저장되어 있는데,\nvalues() 함수를 이용하면 키 값이 아닌 값들을 묶어서 리스트로\n반환할 수 있다.\n\n\nvalues()에 대해 좀더 정확한 설명을 하자면 이렇다. 일단 values()는\n 정확하게는 리스트를 리턴하는 게 아니라 view 객체를\n 리턴한다. view\n 객체는 엔트리의 동적인 뷰를 제공해줘서 원본 딕셔너리가 업데이트되면\n 뷰에도 즉각 반영된다. 그 외에는 다 같아서 이건 문제 푸는데 크게\n 상관없다.\n\n중요한 것은 values() 결과 리스트에 들어가있는 원소의 순서인데,\n 파이썬 3.7부터는 딕셔너리에 삽입한 순서를 보장한다. 원래는 3.6\n CPython의 구현 디테일이었는데 3.7부터 표준에 반영된 것 같다.\n\n\n  Dictionaries preserve insertion order. Note that updating a key does\nnot affect the order. Keys added after deletion are inserted at the\nend.\n\n\n\n  Changed in version 3.7: Dictionary order is guaranteed to be\ninsertion order. This behavior was an implementation detail of\nCPython from 3.6.\n\n\n즉, 문제에서 레벨 순으로 트리를 방문한다는 것은 곧 레벨의\n 오름차순으로 방문하는 것과 같기 때문에, 딕셔너리가 내부적으로는 해시\n 테이블이지만 결국 레벨의 오름차순 방문이 보장되어 values()를\n 사용해도 무방한 것이다. 만약 순서가 보장되지 않는다면 먼저\n items()를 가져와서 (key, value) 쌍의 리스트를 만들고, key를\n 기준으로 정렬하는 과정을 반드시 거쳐야 한다.\n\nQueue\n\n트리의 레벨 오더 순회는 본질적으로는 루트로부터 시작한 BFS와\n 같다. 따라서 큐를 이용한 BFS로도 구현할 수 있다. 다만 여전히 레벨에서\n 방문한 목록은 기록해야 하기 때문에 defaultdict에 저장하는 것은\n 필요하다.\n\nfrom collections import deque, defaultdict\ndef levelOrder(root):\n    traversal = defaultdict(list)\n    q = deque()\n    q.append((0, root))\n    while q:\n        lv, node = q.popleft()\n        if node is None:\n            continue\n        traversal[lv].append(node.val)\n        q.append((lv+1, node.left))\n        q.append((lv+1, node.right))\n    return traversal.values()\n\n\n\n  큐에 노드를 곧바로 집어넣는 것이 아니라 (레벨, 노드) 정보를\n넣는다. 그러면 (1) 레벨 오더 순회가 보장되면서 (2) 현재 레벨을 같이\n알 수 있다."
					}
					,
					"ps-leetcode-binary-tree-maximum-path-sum": {
						"id": "ps-leetcode-binary-tree-maximum-path-sum",
						"title": "Binary Tree - Maximum Path Sum",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/binary-tree-maximum-path-sum/",
						"content": "Binary Tree - Maximum Path Sum\n\n바이너리 트리 안의 경로란 인접한 두 노드 사이에 엣지가 있는\n 노드의 시퀀스를 말한다. 노드는 최대 한번 그 시퀀스에 나타날 수\n 있다. 경로가 꼭 루트를 지날 필요는 없다는 것을 알아두자.\n\n경로 합이란 어떤 경로에 있는 모든 노드의 값의 합을 뜻한다.\n\n바이너리 트리의 루트 노드가 주어졌을 때, 비어있지 않은 경로\n 중에서 경로 합의 최대 값을 구하자.\n\n노드 개수의 범위는 \\(1 \\sim 3 \\times 10^4\\) 이고 값은 -1,000~1,000\n 사이이다.\n\n풀이\n\n하드 문제 다운 난이도이다. 일단 트리이긴 하지만 경로를 고려해야\n 하고, 또 노드의 값이 음수가 될 수 있기 때문에 까다롭다.\n\n몇 가지 기본적인 관찰을 해보자.\n\n  노드에 서브트리가 없을 때에는 노드의 값 그 자체가 된다.\n  트리으 노드가 전부 음수이면, 노드 중 가장 큰 값이 곧바로 답이\n된다. 노드를 하나라도 더 골라서 경로를 만들면 음수가 더해져서 계속\n작아지기 때문이다.\n  음수가 가능하기 때문에, 어떤 노드의 왼쪽과 오른쪽 서브트리를 볼 때,\n이득만을 따져야 한다. 즉, 어떤 서브트리의 노드 값을 다 더해서\n오히려 마이너스가 될 수 있기 때문에, 아예 안따지는 경우(즉, 0)와\n비교해야 한다.\n  현재 노드를 루트 노드로 포함하는 경로에서 가능한 이득을\n따질 때에는 결국 세 가지를 다 따져야 한다: (1) 현재 노드만 따졌을\n때, (2) 왼쪽 서브트리의 이득, (3) 오른쪽 서브트리의 이득. 이 값이\n이전 최대 값보다 크면 업데이트 해야 한다.\n  현재 노드를 포함하는 경로를 생각한다면, 양쪽 서브트리의 이득 중\n더 큰 값만을 더해야 한다. 왜냐하면 경로이기 때문에, 양쪽\n서브트리를 다 포함할 수는 없다.\n\n\ndef maxPathSum(root):\n    maxsum = float('-inf')\n\n    def max_gain_include_path(node):\n        \"\"\"\n        Returns max profit with the node as root\n        \"\"\"\n        if node is None:\n            return 0\n\n        left_profit = max(max_gain_include_path(node.left), 0)\n        right_profit = max(max_gain_include_path(node.right), 0)\n        profit = node.val + left_profit + right_profit\n        nonlocal maxsum\n        maxsum = max(maxsum, profit)\n\n        return node.val + max(left_profit , right_profit)\n\n    max_gain_include_path(root)\n    return maxsum\n\n\n설명에 비해서 코드는 꽤 짧은 편이다. 결국 위에서 설명한 걸 그대로\n 적은 것인데,\n\n  left_profit과 right_profit은 현재 노드의 양쪽 서브트리안의\n경로에서 얻을 수 있는 최대한의 이득을 계산한 뒤에, 이 값과 0 중 더\n큰 값을 취해서 음수인 경우를 처리한다.\n  profit은 현재 노드를 루트 노드로 포함한 경로에서 가능한\n이득을 따진다. 즉, 현재 노드의 부모 노드를 타고 올라가는 경로는\n여기서 고려되지 않는다. 그리고 이 값을 maxsum에 업데이트 한다.\n  리턴 값은 현재 노드를 포함하는 경로에서 가능한 이득을\n리턴한다. 즉, 현재 노드의 부모 노드를 타고 올라가는 경로를\n고려한다. 이때에는 경로의 정의에 따라 왼쪽과 오른쪽 중 하나의\n서브트리만을 택할 수 있기 때문에, 둘 중 더 큰 값을 더한다.\n  maxsum을 한번만 업데이트해도 되는 이유는, 베이스 케이스에서\n노드가 null이면 0을 리턴하기 때문이다. 덕분에 리턴 값을 한번 더\nmaxsum과 비교해서 업데이트하지 않아도 재귀 호출 어딘가에서\n처리된다.\n  최종적으로 구한 값은 maxsum에 저장되므로 이 값을\n리턴한다. max_gain_include_path는 현재 노드의 부모 노드를 타고\n올라가는 경로를 고려했을 때 최대 값을 리턴하는 함수이므로, 이\n값을 리턴하면 안된다."
					}
					,
					"ps-theory-bisect": {
						"id": "ps-theory-bisect",
						"title": "Upper Bound and Lower Bound",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/bisect/",
						"content": "Upper Bound and Lower Bound\nMathematical Definition\nUpper Bound와 Lower Bound의 수학적인 정의는 다음과 같다. 어떤 순서\n 있는 집합(구체적으로는 Preorder, 즉 reflexive + transitive 한\n 순서이고, 보통은 &lt;= 라고 이해하면 된다)의 부분 집합 S에 대해서,\n\n  S의 Upper Bound: S의 모든 원소보다 크거나 같은 원소 K\n  S의 Lower Bound: S의 모든 원소보다 작거나 같은 원소 K\n\n\n이때 각 Bound인 K는 S안에 있을수도, 아니면 S 바깥 즉 Preorder 집합\n 어딘가에 있을수도 있다. 예를 들어 정수 집합의 부분 집합인 S = {5, 8,\n 42, 34, 13943}에 대해서, Lower Bound는 5, 4 등이 될 수 있고\n Upper Bound는 13943, 999999 등이 될 수 있다. (여기서 알 수 있는\n 사실 한 가지는 모든 자연수의 부분 집합은 최소 하나의 Lower Bound인\n 0을 갖는다는 것이다)\n\n아무튼, 이처럼 원래 Upper Bound와 Lower Bound의 정의는, 어떤 집합의\n 부분 집합을 기준으로 생각하는 것이다.\n\nC++ Standard Library\nC++에는 std::lower_bound와 std::upper_bound라는 함수가 있는데,\n 이는 다음으로 설명 가능하다1:\n\n\n\n\n\n즉, 정렬된 배열 또는 리스트가 있고 어떤 값 x 를 기준으로 x가\n 구간(range)을 형성하는 경우에 std::upper_bound와\n std::lower_bound는 다음과 같다.\n\n  std::upper_bound: x보다 큰 값이 처음으로 나오는 위치\n  std::lower_bound: x보다 크거나 같은 값이 처음으로 나오는\n위치\n\n\n뭔가 앞의 수학적 정의랑 비슷하면서도 다르다.  앞서 말했듯 수학적\n 정의는 어떤 집합의 부분 집합이 기준이었다. 이 기준을 구현에서\n 다음과 같이 생각해보면:\n\n  어떤 집합: 정렬된 배열 (또는 배열의 정렬된 일부 구간)\n  부분 집합: 찾고자 하는 값 x로 형성된 구간\n\n\n이 관점에서 생각해 보면 std::lower_bound와 std::upper_bound가\n 하는 일은 수학적 정의와 관련이 있다. 한마디로 x가 형성하는 구간을\n 찾는 것이다. x가 형성하는 구간이 대상 배열 안에 존재한다면 수학적\n 의미의 (Greatest) Lower Bound와 (Least) Upper Bound 모두 x가\n 된다. 우리가 궁금한 것은 배열에서의 이 구간(인덱스)에 대한 정보이고,\n CS의 전통적인 Half-Closed Interval2을 따라 x 구간의 범위\n [lower_bound, upper_bound)의 시작점과 끝점을 찾아주는 함수가 바로\n std::lower_bound와 std::upper_bound인 것이다.\n\n따라서, 이 정의를 활용하면 Upper Bound에는 x 보다 크거나 같은\n 값을 넣을 수 있고, Lower Bound에는 x 보다 작거나 같은 값을 넣을\n 수 있다. 좀더 쉽게 설명하면, 정렬된 배열에 x를 삽입하고 싶을 때,\n 정렬 순서를 유지한채로 넣을 수 있는 가장 첫 번째 위치가 Lower\n Bound이고 가장 마지막 위치가 Upper Bound 이다. 이때 삽입이란 해당\n 인덱스에 x를 넣고 원래 인덱스부터 나머지를 한칸씩 쭉 뒤로\n 밀어버리는 연산을 뜻한다.\n\n참고로 파이썬에는 bisect라는 패키지가 있어서 곧바로 적용해볼 수\n 있다. std::lower_bound는 bisect.bisect_left와,\n std::upper_bound는 bisect.bisect_right 또는 bisect.bisect와\n 대응된다. 이때,\n\n  Upper Bound를 ub(index)라고 한다면, arr[:ub] &lt;= x &lt; arr[ub:] 를\n만족한다.\n  Lower Bound를 lb(index)라고 한다면, arr[:lb] &lt; x &lt;= arr[lb:] 를\n만족한다.\n\n\nBisection\n\ndef bisect_right(arr, x, low=0, high=None):\n    \"\"\"\n    The return value idx is such that all element in arr[:idx] have elt &lt;= x,\n    and all elt in arr[idx:] have x &lt; elt.\n    So if x already appears in the list, arr.insert(x) will insert just after the rightmost\n    x already there.\n    \"\"\"\n\n    if low &lt; 0:\n        raise ValueError('low must be positive')\n\n    if high is None:\n        high = len(arr)\n\n    # [low, high)\n    while low &lt; high:\n        mid = (low + high) // 2\n\n        if x &lt; arr[mid]:\n            high = mid\n        else:\n            low = mid + 1\n    return low\n\n\n\ndef bisect_left(arr, x, low=0, high=None):\n    \"\"\"\n    Return the index where to insert item x in a list arr, assuming arr is sorted.\n\n    The return value idx is such that all element in arr[:idx] have elt &lt; x,\n    and all elt in arr[idx:] have x &lt;= elt.\n    So if x already appears in the list, arr.insert(x) will insert just after the leftmost\n    x already there.\n    \"\"\"\n\n    if low &lt; 0:\n        raise ValueError('low must be positive')\n\n    if high is None:\n        high = len(arr)\n\n    # [low, high)\n    while low &lt; high:\n        mid = (low + high) // 2\n\n        if x &lt;= arr[mid]:\n            high = mid\n        else:\n            low = mid + 1\n    return low\n\n\n\n\n\n  \n    \n      출처 &#8617;\n    \n    \n      참고 &#8617;"
					}
					,
					"ps-theory-bitwise": {
						"id": "ps-theory-bitwise",
						"title": "Bitwise Property",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/bitwise/",
						"content": "Bitwise Property\n\n  비스마스크 연산은 O(1) 구현이 많아서 적절히 사용하면 훨씬 빠르다.\n  특히 집합 연산의 경우 반복문 없이 곧바로 가능한 경우가 많아서 코드가\n    짧아진다.\n  같은 데이터를 더 적은 메모리에 표현 가능하다. 따라서 더 많은 데이터를 미리\n    계산해둘 수 있고, 캐시 효율도 좋아지며, 더 빨라질 수 있다.\n  XOR 연산은 &lt;&gt; 와 동치. 즉, 두 비트가 다르면 참을 반환한다.\n  비트마스크 연산자 우선순위는 가장 낮기 때문에, 중첩된 연산 식에 쓰일 때에는\n    항상 괄호를 쳐주자.\n  C++에서 1은 부호있는 32비트 상수 로 취급되므로, 부호없는 64비트 1을 쓰고\n    싶다면 항상 =1ull=의 형태로 쓰자.\n  32비트 또는 64비트 전체 비트를 쓰고 싶다면 항상 부호없는(unsigned) 정수를\n    쓰자. 음수를 잘못 쉬프트 하면 1이 채워질 수 있다.\n\n응용\n2의 제곱수 판별 (1)\n2의 보수 표현에서 다음 등식이 성립한다: -x = ~x + 1\n예를 들어 x = 7 인 경우를 살펴보면 다음과 같다.\nx = 7;\n0 0 0 0 0 1 1 1  // x\n1 1 1 1 1 0 0 0  // ~x\n1 1 1 1 1 0 0 1  // ~x + 1 == -x\n\n직접 x + (~x + 1) 을 계산해보면 전부 0이 된다는 것을 알 수 있다. 즉, 2의 보수\n  표현에서 -x = ~x + 1 이다.\n이제 이 성질을 가지고 다음과 같이 x 의 가장 오른쪽에 있는 1인 비트 의 위치를\n  알아낼 수 있다.\nx = 7;\n0 0 0 0 0 1 1 1  // x\n1 1 1 1 1 0 0 1  // -x\n0 0 0 0 0 0 0 1  // x &amp; -x\n\nx = 6;\n0 0 0 0 0 1 1 0  // x\n1 1 1 1 1 0 1 0  // -x\n0 0 0 0 0 0 1 0  // x &amp; -x\n\n즉, 두 수를 AND 연산으로 묶으면 가장 오른쪽에 있는 1인 비트 하나만 남기고 다\n  Unset 된다.\nx 가 2의 제곱수인 경우에 어떻게 되는지 보자.\nx = 16;\n0 0 0 1 0 0 0 0  // x\n1 1 1 1 0 0 0 0  // -x\n0 0 0 1 0 0 0 0  // x &amp; -x\n\nx 가 2의 제곱수인 경우 (즉 x = 2**x 꼴) 위와 같이 x &amp; -x = x 가 됨을 알 수 있다.\n2의 제곱수 판별 (2)\n첫 번째 방법이 가장 오른쪽에 있는 1인 비트만 남기는 방법이었다면, 이와 반대로\n  가장 오른쪽에 있는 1인 비트를 딱 하나만 지워버리는 방법도 있다.\n먼저 x 와 x - 1 의 비트 표현을 살펴보자.\nx = 7;\n0 0 0 0 0 1 1 1  // x\n0 0 0 0 0 1 1 0  // x - 1\n0 0 0 0 0 1 1 0  // x &amp; (x - 1)\n\nx = 16;\n0 0 0 1 0 0 0 0  // x\n0 0 0 0 1 1 1 1  // x - 1\n0 0 0 0 0 0 0 0  // x &amp; (x - 1)\n\n즉, x 가 2의 제곱수라면 x &amp; (x - 1) = 0 이 됨을 알 수 있다.\n4의 제곱수 판별\n그러면 문제를 조금 비틀어서, 어떤 수가 4의 제곱수, 즉 &#92;( x = 4^n &#92;) 꼴로\n  표현되는 수는 어떻게 판별할 수 있을까?\n일단 4의 제곱수는 2의 제곱수이므로 위의 방법을 써서 올바른 1비트의 위치를 갖는지\n  확인할 수 있다.\n4의 제곱수의 경우 2의 제곱수와 거의 비슷하지만 한 자리씩 건너 뛰게 된다. 즉 b1,\n  b100, b10000 과 같은 형태를 지니게 된다. 만약 문제의 조건에 따라 값의 범위가\n  32비트 정수 이내라면, 이 모든 가능한 경우를 하나로 합치면 b010101010101...0101\n  꼴이 되고 이를 16진수로 좀더 쉽게 표현하면 0xaaaaaaaa 이 된다. 따라서 아래와\n  같이 판별할 수 있다.\nbool isPowerOfFour(int n) {\n  if (n &lt;= 0) return false;\n  unsigned long long x = n;\n  return ((x &amp; (x - 1)) == 0 &amp;&amp; (x &amp; 0xaaaaaaaa) == 0);\n}\n\n집합 표현하기\nN개의 비트를 가지고 집합을 표현할 수 있다. i번째 원소가 집합에 속해있는지 여부는\n  i번째 비트가 0인지 1인지 여부로 표현한다. 정수는 32비트 또는 64비트 크기 이므로\n  N이 이 범위에 속할 때에만 가능하다.\n구체적인 예시를 위해 N = 20이라고 하자. 즉 0부터 19까지 총 20개의 원소가\n  가능하다.\n다 켠 경우\nN개의 원소를 다 선택한 경우를 상수로 미리 선언해두자. 일일이 1을 채워넣은\n  바이너리 수식을 써줘도 되지만 간단히 다음과 같이 1을 N만큼 쉬프트한 다음 1을\n  빼줘도 된다. 괄호 치는거 꼭 잊지말자.\nconst int full = 0b0000&#39;0000&#39;0000&#39;1111&#39;1111&#39;1111&#39;1111&#39;1111; // 20 1s\n// or\nconst int full = (1 &lt;&lt; 20) - 1;\n\n원소 추가\npicked = picked | (1 &lt;&lt; i);\n\n1을 왼쪽으로 i만큼 시프트하면 i번째 비트만 1인 정수가 되고 이 결과를 이때까지\n  선택한 picked 에 OR로 합치면 항상 이 원소가 추가되게 된다.\n원소 포함 여부 확인 (membership)\nif (picked &amp; (1 &lt;&lt; i)) {\n  // i-th element is contained ...\n}\n\n역시 i번째 비트만 1인 정수를 이때까지 선택한 picked 와 AND 연산을 하면 i번째\n  원소의 포함 여부를 알 수 있다.\n원소 삭제\n삭제가 좀 트리키하다. i번째 원소를 삭제한다는 것은 i번째 원소의 비트를 끄고,\n  나머지 비트 는 다 살려둬야 한다. i번째 원소는 항상 0으로, 나머지 원소는 항상 1로\n  만드는 것이다.\npicked = picked &amp; ~(1 &lt;&lt; i);\n\ni번째 비트만 꺼지고 나머지 비트는 전부 켜진 정수를 picked 와 AND 연산하면 우리가\n  원하는 것을 달성할 수 있다.\n원소 토글\ni번째 비트가 켜져있다면 끄고, 꺼져있다면 켜는 연산인 토글 연산이 종종 유용하다.\n  XOR 연산이 정확히 이것을 해준다.\npicked = picked ^ (1 &lt;&lt; i);\n\n집합 연산\nint added = a | b;         // 합집합\nint intersection = a &amp; b;  // 교집합\nint removed = a &amp; ~b;      // a에서 b를 뺀 차집합\nint toggled = a ^ b;       // a와 b 중 한 쪽에만 포함된 집합 (여집합)\n\n집합 크기\n집합의 크기 (Cardinality)를 쉽게 구하는 방법은 딱히 없다. 그냥 일일이 비트를\n  확인해서 켜진 개수를 세야한다.\nint cardinality(int a) {\n  if (a == 0) return 0;\n  return (a % 2) + cardinality(a / 2);\n}\n\n모듈러 연산과 나누기 연산은 비싸니까 어떻게 비트로 좀 쪼개면 다음과 같다.\nint cardinality(int a) {\n  if (a == 0) return 0;\n  return (a &amp; 1) + cardinality(a &gt;&gt; 1);\n}\n\n더 최적화할 수 있는 방법이 많지만 굉장히 어렵다고 한다.\n다행히도 컴파일러가 몇몇 비트 연산과 관련된 내장 함수를 제공한다.\nint card = __builtin_popcount(picked);  // gcc/g++\nint card = __popcnt(picked);            // Visual C++\n\n최소 원소 찾기 (최하위 비트 찾기)\n최하위 비트부터 원소 순서가 매겨진다고 할 때, 처음으로 켜진 최하위 비트만\n  구하려면 다음과 같이 하면 된다.\nint firstPick = picked &amp; -picked;\n\n이건 앞의 2의 제곱수 판별 (1) 방법과 같다. 즉, 가장 오른쪽(최하위) 1만 남기고\n  나머지는 다 삭제하는 연산과 같다.\n최소 원소 지우기 (최하위 비트 지우기)\n최하위 1인 비트만 없애는 연산이 종종 필요한데, 이는 위의 2의 제곱수 판별 (2)의\n  방법과 같다.\npicked = picked &amp; (picked - 1);\n\n모든 부분 집합 순회하기\n모든 원소가 아니라 부분 집합 을 순회하는 방법이다. 예를 들어 picked 가 {1, 2, 4}\n  라면 {1}, {2}, {4}, {1, 2}, {1, 4}, {2, 4}, {1, 2, 4} 를 순회하는 방법이다.\nfor (int subset = picked; subset; subset = ((subset - 1) &amp; picked)) {\n  ...\n}\n\nsubset 은 전체 집합 picked 에서 시작해서 아무것도 선택되지 않은 공집합(즉 0)이\n  될 때까지 반복한다. subset - 1 을 하면 (1) 켜져 있던 최하위 비트는 꺼지고 (2)\n  꺼진 최하위 비트의 모든 하위 비트는 켜지게 된다. 예를 들어 001001000 에서 1을\n  빼면 001000111 이 된다. (subset - 1) &amp; picked 는 이 값과 원래 집합의 교집합 을\n  구하는 것과 동일한 의미이고, 이는 곧 (subset - 1) 을 통해 켜진 비트들 중 picked\n  에 속하지 않는 원소들은 모두 제거되는 것과 동일하다. 따라서 이 연산을 반복하면\n  picked 의 모든 부분 집합을 방문하게 된다.\n우선순위 큐\n특정한 제약 조건이 있는 경우에 O(1)의 우선순위 큐를 만들 수 있다.\n\n  우선순위의 범위가 정해져 있는 경우. (예: 1부터 140 사이의 정수)\n  우선순위가 같은 원소에 대해서는 순서가 상관없는 경우.\n\n이런 경우에 우선순위를 비트 연산으로 O(1) 만에 구할 수 있다.\n좀더 구체적으로 우선순위가 1부터 140 사이의 정수라고 하자. 각 우선순위마다\n  원소를 담을 큐 140개(같은 우선순위에 대해서는 순서 상관 없음)를 만들고 , 각 큐에\n  원소가 있는지 여부를 비트마스크로 표현할 수 있다. 140개의 불린 값을 64비트 정수\n  세 개에 저장하면, 앞서 살펴본 최하위 비트를 찾는 연산을 통해 모든 큐를 뒤질 필요\n  없이 가장 우선순위가 높은 원소가 어디 있는지 바로 찾을 수 있다.\n참고로 이런 방식의 우선순위 큐가 리눅스 커널의 프로세스 관리를 위해 구현되어\n  사용된 적이 있다."
					}
					,
					"wip-multicore-ocaml-bounding-data-races-in-space-and-time": {
						"id": "wip-multicore-ocaml-bounding-data-races-in-space-and-time",
						"title": "Bounding Data Races in Space and Time",
						"version": "all",
						"categories": "",
						"url": " /wip/multicore-ocaml/bounding-data-races-in-space-and-time/",
						"content": "1. Introduction\n\n현대 CPU와 컴파일러는 프로그램을 공격적으로 최적화한다. 이런 최적화는\n 순차적인 프로그램(sequential programs)을 빠르게 만들지만, 병렬\n 프로그램(parallel program)에서는 놀라운 행동을 관찰하게 만든다. 이런\n 최적화에서 득을 보기 위해서, C++나 자바같은 메인스트림 언어들은\n 프로그램이 관찰할 수도 있는 이러한 느슨한 행동(relaxted\n behaviour)을 명세하는 복잡한 메모리 모델을 채택하고 있다. 하지만,\n 이런 모델은 곧바로 프로그램을 작성하기 어렵다.\n\n이런 모델이 프로그래머에게 제공하는 기본적인 추론 도구는 데이터 경쟁\n 없음 정리(data-race-freedom theorems; DRF)이다. 프로그래머는\n 비원자적 변수에 동시에 접근하는 (동시에 읽는 것은 제외됨) 데이터\n 경쟁(data races)을 피하기 위해서 쓰레드 사이의 동기화에 쓰이는 모든\n 변수를 원자적(atomic)이라고 표시해야 한다. 대신, DRF 정리는 어떤\n 느슨한 행동도 관찰할 수 없음을 보장해준다. 정리하면, DRF 프로그램은\n 순차적인 의미(sequential semantics)를 갖는다.\n\n프로그램이 데이터 경쟁에서 자유롭지 못할 때, 그런 모델은 프로그램의\n 행동에 대해서 아주 적은 보장을 해주거나 아니면 아무것도 보장해주지\n 않는다. 이것은 언어의 구성 요소를 잘못 사용하면 보통 정의되지 않은\n 행동(undefined behaviour)을 초래하는 불안전한 언어(unsafe\n languages)를 설명하는데 잘 맞는다. 즉, 데이터 경쟁 역시 하나의\n 오사용으로 보면, 이것은 꽤 자연스럽다. 반면에, 안전한 언어는 버그가\n 있는 프로그램일지라도 잘 정의된 의미(well-defined semantics)를\n 제공하기 위해 최선을 다한다. 이런 의미는 합성적(compositional)일\n 것으로 기대되는데, 그래야 프로그램이 그 프로그램의 구성 요소 중\n 일부가 버그를 갖고 있어도 부분을 이해함으로써 전체를 이해할 수 있기\n 때문이다.\n\n데이터 경쟁에 약한 의미(weak semantics)가 주어지는 것은 이런 합성적\n 성질을 위태롭게 만든다. 안전한 언어에서는, 만약 f()이 올바른 정답을\n 리턴하더라도 f() + g()가 틀린 답을 리턴한다면, g에 버그가 있다고\n 결론지을 수 있다. 데이터 경쟁에 대한 약한 의미는 이런 성질을 위태롭게\n 하는데, g가 올바르더라도 f 안의 데이터 경쟁에 의해서 틀린 답을\n 내놓을 수도 있기 때문이다.\n\n이 연구에서는 메모리를 공유하는 병렬 프로그램(shared-memory parallel\n programs)에 대한 새로운 의미를 제안하여, 데이터 경쟁이 있음에도\n 강력한 의미를 보장하게 해준다.\n\n  먼저 지역적 DRF(local DRF) 성질을 도입하여, 데이터 경쟁이\n존재하는 상황에서도 동시성 프로그램에 대한 합성적인 추론을\n가능하게 해준다.\n  간단한 small-step operational semantics와 함께 메모리 모델을\n제안하고, 이 모델이 지역적 DRF를 가지고 있음을 증명하고, 동등한\naxiomatic model을 제안한다.\n  이 메모리 모델이 많은 일반적인 컴파일러 최적화를 지원하며, x86과\nARMv8 아키텍쳐 모두에서 안전한 compilation scheme을 제공한다는\n것을 보이고, OCaml에서의 효율성의 증거를 보인다.\n\n\n2. Reasoning beyond data-race freedom\n먼저 전역적 DRF(global DRF) 성질인:\n\n\n  데이터 경쟁에서 자유로운 프로그램은 순차적인 의미를 갖는다.\n\n\n에서, 더 강한 지역적 DRF 성질인:\n\n\n  프로그램의 데이터 경쟁이 없는 모든 부분은 순차적인 의미를 갖는다.\n\n\n를 제안한다.\n\n전역적 DRF와 지역적 DRF의 차이점을 설명하기 위해서, 순차적인\n 프로그램과 지역적 DRF가 없어서 예상치못한 결과를 뱉는 멀티 쓰레드\n 프로그램 몇 가지를 소개할 것이다.\n\n2.1. Bounding data races in space\n지역적 DRF로 가기 위한 첫 번째 단계는 데이터 경쟁이 영향을 미치는\n 공간을 제한해서(bounding data races in space), 하나의 변수에 대한\n 데이터 경쟁이 다른 변수에 접근하는데 영향을 미치지 않도록 보장하는\n 것이다.\n\nC++ 메모리 모델은 데이터 경쟁에서 자유로운 프로그램에 대해서만 의미를\n 주기 때문에, 원칙적으로 C++ 메모리 모델은 이런 성질을 갖지\n 않는다. 하지만, 어떻게 타당한 구현에서 이런 성질을 갖는 것이\n 실패하는지는 분명하지 않기 때문에, 예시를 들고 왔다.\n\nExample 1.\n\nb = a + 10\n\n\n\n  가정: a나 b에 다른 쓰레드가 접근하지 않는다.\n  예상 결과: b = a + 10\n  가능한 결과: b != a + 10 (C++)\n\n\n설명\n다음과 같은 멀티 쓰레드 프로그램을 생각해보자. c는 비원자적인 전역\n 변수이다.\n\nc = a + 10;                         ||\n...  some computation ...           ||  c = 1;\nb = a + 10;                         ||\n\n\n여기서 … 부분의 계산이 순수, 즉 사이드 이펙트가 없다고\n 하자. 컴파일러는 a가 두 번 읽히는 사이에 a가 수정되지 않는다는\n 것을 알고, a + 10을 굳이 두 번 계산할 필요가 없다는 것을 알고 첫\n 번째 쓰레드를 다음과 같이 최적화할 수 있다:\n\nt = a + 10 ;\nc = t;\n... some computation ...\nb = t;\n\n\n… 부분의 계산에서 레지스터가 부족하다면 a + 10의 결과를 저장해둔\n 임시 변수 t가 레지스터에서 방출될 수 있다. t의 결과는 c에\n 저장되기 때문에, 똑똑한 레지스터 할당자(register allocator)는 새로운\n 스택 슬롯을 할당하기 보다는 t를 c로 재활용할 수 있다1:\n\nt = a + 10;                         ||\nc = t;                              ||\n...  some computation ...           ||  c = 1;\nb = c;                              ||\n\n\n하지만, 이렇게 최적화된 프로그램에서는, c = a + 10과 c = 1 사이에\n 데이터 경쟁이 생기고 c가 이상한 값을 가질 수 있다. 프로그래머의\n 관점으로는, a에 동시 쓰기(concurrent write)가 없었는데도 불구하고\n 같은 a에서 두 번 읽었는데 서로 다른 값을 관찰하게 된다! 실제로, 두\n 쓰레드가 c에 동시에쓰는 것이 유일한 데이터 경쟁이고, 첫 번째\n 쓰레드(의 원본 코드)에서는 c를 읽지 않았다.\n\n변수 하나에 대한 데이터 경쟁이 다른 변수를 읽는 결과에 영향을 미치는\n 일은 컴파일러 최적화가 경쟁이 있는 C++ 프로그램에 줄 수 있는 최악의\n 영향은 아니다. Boehm의 연구에서는 다른 예시도 있지만, 이 예시 하나면\n 데이터 경쟁이 영향을 미치는 공간을 제한하는 일이 중대한 성질임을\n 보이기에 충분하며, 타당한 C++ 구현은 이 성질이 없다는 것도 알았다.\n\n2.2 Bounding data races in time\nC++와는 반대로, 자바 메모리 모델은 데이터 경쟁이 있더라도 허용되는\n 행동을 제한한다. 특히, 변수를 읽어서 리턴하는 값은 반드시 같은 변수에\n 쓰여진 무언가여야 하는데, 덕분에 데이터 경쟁이 영향을 미치는 공간이\n 제한된다.\n\n하지만, 자바의 데이터 경쟁이 영향을 미치는 시간은 제한되어 있지\n 않다(not bounded in time): 아래의 예시와 같이, 과거에 발생한 데이터\n 경쟁이 이후의 접근에 영향을 줘서 비순차적인 행동을 가지도록 할 수\n 있다. 어떤 두 개의 접근이 동시에 발생(happen concurrently)한다는\n 것은, 메모리 모델에 의해 정의되는 순서를 사용해서 정의되는 이전에\n 발생(happens-before)을 이용해서 두 쓰레드가 서로 이전에 발생하지\n 않았다고 정의한다. 그러니까 아무런 동기화 없이 서로 다른 쓰레드에서\n 발생하는 두 개의 접근이라는 뜻이다.\n\nExample 2.\n\nb = a; c = a;\n\n\n  가정: a, b, c에 대해서 동시에 발생하는 접근이 없다.\n  예상 결과: b = c\n  가능한 결과: b != c (C++, 자바)\n\n\n설명\n다음과 같은 프로그램을 생각해보자. flag는 초기값이 false인 원자적\n 불리언 변수(자바의 volatile)이다.\n\na = 1;                              || a = 2;\nflag = true;                        || f = flag;\n                                    || b = a;\n                                    || c = a;\n\n\nf가 true가 되었다고 해보자. 그러면 flag가 volatile이기 때문에\n flag에 대한 읽고 쓰기는 서로 동기화되고, 따라서 a에 값을 쓰는\n 일(a = 1과 a = 2)은 서로 경쟁 상태에 있지만 a에서 값을 읽는 일\n 이전에 발생하게 된다.\n\n이런 상황에서, 다음과 같은 가정이 성립한다: a에서 값을 읽는 일과\n 동시에 발생하는 a, b, c에 대한 접근이 없다. 하지만, 자바는 b =\n 1, c = 2인 결과를 허용하는데, 두 개의 읽기(b = a와 c = a)가\n 서로 다른 쓰기(a = 1과 a = 2)에서 읽는 것을 서용하기\n 때문이다. 구체적으로는, 컴파일러가 c = a는 최적화하지 않고 b =\n a를 b = 2로 최적화하면 발생할 수 있다. 이런 상황은 별칭(aliasing)\n 때문에 발생할 수 있는데, 만약 첫 번째 읽기 b = a만 a = 2로 쓰여진\n 곳과 같은 위치라는 것을 정적으로 알는 경우에 그렇다. 자바 8과 9\n 버전에서 이 행동을 초래하는 구체적인 예시는 부록의 기술 보고서에\n 있음.\n\n따라서, 자바의 데이터 경쟁은 시간에 얽매이지(bounded in time)\n 않는데, 메모리 모델이 과거에 일어난 데이터 경쟁으로 인해서 일관되지\n 않은 값을 리턴하는 것을 읽는 것을 허용하기 때문이다. 놀랍게도, 이런\n 비순차적인 행동은 미래의 데이터 경쟁 때문에 나타나기도 하는데, 다음\n 예시를 보자.\n\nExample 3.\nclass C { int x; } 라는 정의가 이전에 있다고 가정하자.\n\nC c = new C(); c.x = 42; a = c.x;\n\n\n  가정: a에 다른 접근은 없다.\n  예상 결과: a = 42\n  가능한 결과: a != 42 (C++, 자바)\n\n\n설명\n여기서, c는 새로 할당되었고 아직 다른 쓰레드가 참조하지 않기\n 때문에, 과거에 c.x에 데이터 경쟁이 발생할 수 없다는 것을 알 수\n 있다. 따라서, 이 코드 조각은 프로그램의 나머지 부분에 존재하는 데이터\n 경쟁과 상관없이 항상 a에 42를 쓴다고 상상할 수 있다.\n\n하지만 실제로 이 이후의 데이터 경쟁 때문에 a가 42가 아닌 다른\n 값을 갖는 것이 가능하다. 다음 코드를 보면:\n\nC c = new C();                      ||\nc.x = 42;                           ||\na = c.x;                            ||\ng = c;                              || g.x = 7;\n\n\n첫 번째 쓰레드가 c.x에서 값을 읽고 g에 값을 쓰는데, 이때 이 두\n 오브젝트의 위치가 다르기 때문에, 자바의 메모리 모델은 이 순서를\n 바꾸는 것을 허용한다. 그래서 g = c가 먼저 실행되고, 그 사이 두 번째\n 쓰레드가 g.x에 7을 쓰고, 다시 첫 번째 쓰레드가 a = c.x로 값을\n 읽게 되면, a는 42가 아니라 7이 된다.\n\n따라서, 지역적 DRF를 제공한다는 것은 곧 읽기의 순서가 나중에 있을\n 쓰기와 뒤섞이면 안된다는 것을 뜻하고, 이는 컴파일러 최적화와 느슨한\n 동작을 허용하는 (weakly-ordered) 하드웨어에서의 컴파일에 제약을 주게\n 된다. 이 제약으로 인한 성능 비용이 어느 정도인지 나중에 살펴볼\n 것이다.\n\n2.3 Global and Local DRF\n지역적 DRF 성질이란, 데이터 경쟁의 영향이 공간적으로 또 시간적으로\n 제한되는 것을 말한다. 다른 변수의 데이터 경쟁, 과거의 데이터 경쟁,\n 또는 미래의 데이터 경쟁이 어떤 변수에 접근하는 일에 영향을 주지 않는\n 것이다. 특히, 다음과 같은 직관적인 성질이 성립한다:\n\n\n  만약 같은 쓰레드가 어떤 위치 a에서 값을 두 번 읽을 때, 동시에\na에 값을 다른 쓰레드가 없다면, 두 번 읽은 값은 같은 값이다.\n\n\n섹션 3에서 operational semantics를 소개한 뒤, 섹션 4에서 메모리\n 모델에 대한 지역적 DRF 정리를 형식적으로(formally) 기술한다. 자세한\n 증명은 부록에 있다. 지역적 DRF 정리 덕분에 이전에 소개한 예시들이\n 예상되는 행동을 한다는 것을 증명할 수 있었다.\n\n표준적인 전역적 DRF 정리를 이용하면 앞의 세 가지 예시들이 프로그램\n 실행 도중의 어떤 시간에 어떤 변수에도 데이터 경쟁이 없다는 아주\n 강력한 가정 하에서만 예상되는 행동을 한다는 것을 증명할 수 있다. 반면\n 지역적 DRF는 프로그램의 다른 부분에 데이터 경쟁이 있어도 괜찮다는 더\n 일반적인 가정 하에 같은 결과를 증명할 수 있게 해준다.\n\n3. A Simple Operational Model\n\n\n\n  \n    \n      레지스터 할당 내내 메모리의 내용에 대한 정보를 유지해야 하는 노력이 필요하기 때문에, 이것은 일반적으로 구현되는 최적화는 아니지만, LLVM 최적화의 하나로 제안되었다. &#8617;"
					}
					,
					"ps-cpp-brute-force": {
						"id": "ps-cpp-brute-force",
						"title": "Brute Force",
						"version": "all",
						"categories": "",
						"url": " /ps/cpp/brute-force/",
						"content": "Brute Force\n중첩 반복문 대체하기\nn개의 원소에서 m개를 고르는 모든 조합을 찾는 알고리즘을 쌩 반복문으로 짜면 m중\n  중첩문이 된다. 하지만 다음과 같이 작업을 쪼개면 재귀로 풀 수 있다.\n\n  원소들의 총 개수(= n)\n  더 골라야 할 원소들의 개수\n  지금까지 고른 원소들의 번호\n\nvoid pick(int n, vector&lt;int&gt;&amp; picked, int to_pick) {\n  // base case: no more to pick\n  if (to_pick == 0) {\n    do_something(picked);\n    return;\n  }\n\n  int smallest = picked.empty() ? 0 : picked.back() + 1;\n  for (int next = smallest; next &lt; n; next++) {\n    picked.push_back(next);\n    pick(n, picked, to_pick - 1);\n    picked.pop_back();\n  }\n}\n\n보글 게임\nconst int dx[8] = {-1, -1, -1, 1, 1, 1, 0, 0};\nconst int dy[8] = {-1, 0, 1, -1, 0, 1, -1, 1};\n\nbool has_word(int y, int x, const string&amp; word) {\n  if (!in_range(y, x)) {\n    return false;\n  }\n  if (board[y][x] != word[0]) {\n    return false;\n  }\n  if (word.size() == 1) {\n    return true;\n  }\n\n  for (int dir = 0; dir &lt; 8; dir++) {\n    int ny = y + dy[dir], nx = x + dx[dir];\n    if (has_word(ny, nx, word.substr(1))) {\n      return true;\n    }\n  }\n  return false;\n}"
					}
					,
					"ps-leetcode-campus-bikes": {
						"id": "ps-leetcode-campus-bikes",
						"title": "Campus Bikes",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/campus-bikes/",
						"content": "Campus Bikes\n\nCampus Bikes II\n\n2차원 평면에 n명의 작업자와 m개의 자전거가 뿌려져있다. n &lt;=\n m이다.\n\n각각의 자전거는 딱 한명의 작업자에게 할당되야 한다. 이때, 작업자와\n 자전거 사이의 맨하탄 거리의 합이 최소가 되어야 한다.\n\n이렇게 자전거를 할당했을 때, 가능한 맨하탄 거리의 합의 최소값을\n 구하자.\n\n두 점 p1과 p2의 맨하탄 거리는 Manhattan(p1, p2) = |p1.x -\n p2.x| + |p1.y - p2.y|로 정의된다.\n\n\n  \n\\[1 \\leq n \\leq m \\leq 10\\]\n  \n  각 좌표는 정수이고 좌표의 범위는 0~1000\n  모든 작업자와 자전거의 위치 좌표는 유일함이 보장된다.\n\n\n탐욕법 + 백트래킹\n\n\n  각각의 작업자가 모든 자전거를 다 확인하면서, 가장 가깝고 아직\n할당되지 않은 자전거를 할당한다. 할당한 자전거를 기록한다.\n  맨하탄 거리의 합을 업데이트하고 다음 작업자를 확인하기 위해서\n재귀호출한다.\n  재귀호출이 끝나면, 즉 다음 작업자에 대한 확인이 끝나면, 해당\n작업자에게 할당했던 자전거를 원복한다.\n  만약 모든 자전거를 할당했다면, 지금까지 누적된 맨하탄 거리의 합을\n이전 최소합과 비교해서 업데이트한다.\n  자전거를 작업자한테 할당하기 전에, 지금까지 누적된 맨하탄 거리의\n합이 이미 이전 최소합을 넘겼는지를 확인하면 좋다. 이미 넘겼다면\n나머지 작업자에 대해서는 확인할 필요가 없기 때문이다.\n\n\ndef assignBikes(workers: List[List[int]], bikes: List[List[int]]) -&gt; int:\n    def dist(p1, p2):\n        return abs(p1[0] - p2[0]) + abs(p1[1] - p2[1])\n\n    n, m = len(workers), len(bikes)\n    assigned = [False] * m\n    answer = float('inf')\n\n    def assign(wi, acc):\n        nonlocal answer\n        if wi &gt;= n:\n            answer = min(answer, acc)\n            return\n\n        if acc &gt;= answer:\n            return\n\n        for bi in range(m):\n            if assigned[bi]:\n                continue\n            assigned[bi] = True\n            worker, bike = workers[wi], bikes[bi]\n            assign(wi + 1, acc + dist(worker, bike))\n            assigned[bi] = False\n\n    assign(0, 0)\n    return answer\n\n\n\n  이렇게하면 \\(O(M! / (M-N)!)\\) 라는 굉장한 시간 복잡도가 나와서\n(…) 파이썬은 타임아웃난다."
					}
					,
					"ps-leetcode-can-place-flowers": {
						"id": "ps-leetcode-can-place-flowers",
						"title": "Can Place Flowers",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/can-place-flowers/",
						"content": "Can Place Flowers\n문제 자체는 탐욕법으로 풀리는 문제인데, 코드를 깔끔 하게 정리하는 방법을 배울\n  수 있어서 기록해둔다.\n일단 인덱스를 늘려가며 꽃을 둘 수 있는 경우, 즉 양 옆에 꽃이 없는 경우를\n  찾아내어서 꽃을 직접 심는다. 이때, 왼쪽과 오른쪽 각각 코너 케이스가 있는데,\n  왼쪽의 경우는 화단의 시작점인 경우이고 오른쪽은 화단의 끝점인 경우이다. 이걸\n  특수한 케이스로 처리하려면 코드가 복잡해지는데, 에디토리얼에서 가르쳐준 다음\n  방법이 깔끔했다.\ndef canPlaceFlowers(flowerbed: List[int], n: int) -&gt; bool:\n    N = len(flowerbed)\n    possible = 0\n    for i in range(N):\n        if flowerbed[i] != 0:\n            continue\n\n        left = (i == 0) or (flowerbed[i - 1] == 0)\n        right = (i == N - 1) or (flowerbed[i + 1] == 0)\n        if left and right:\n            possible += 1\n            flowerbed[i] = 1\n    return possible &gt;= n"
					}
					,
					"ps-leetcode-candy": {
						"id": "ps-leetcode-candy",
						"title": "Candy",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/candy/",
						"content": "Candy\n\nn명의 아이들이 한 줄로 서있다. 각각의 아이에게는 평가 점수가 매겨져\n 있는데 이 정보는 ratings 배열에 들어있다.\n\n다음 조건을 만족하도록 아이에게 사탕을 주려고 한다:\n\n  각각의 아이는 최소 하나의 사탕은 받아야 한다.\n  주변의 아이보다 더 높은 평가 점수를 가진 아이는 더 많은 사탕을\n가져야 한다.\n\n\n아이들에게 나눠줄 사탕의 최소 개수를 구하자.\n\n평가 점수 배열의 크기는 \\(1 \\sim 2 \\times 10^4\\) 이고 각 평가 점수\n 범위는 \\(0 \\sim 2 \\times 10^4\\) 이다.\n\n예를 들어, ratings = [1, 0, 2]라고 하자. [2, 1, 2]로 나눠주는 것\n 최선이기 때문에 정답은 5이다.\n\n시뮬레이션 해보기\n\n배열을 가지고 뭔가 정렬을 하거나 보조 자료 구조를 쓰거나 하는 방법을\n 궁리해봤는데, 이 문제는 그런 게 아니라 일단 조건에 맞게 사탕을 잘\n 나눠주는 것이 중요한 것 같다. 시뮬레이션을 잘 해보자.\n\n먼저 주변의 아이를 확인하려면, i번째 아이에 대해서 i-1과 i+1\n 모두를 확인해야 한다. 하지만 이걸 제대로 하려면 인덱스에 대한 엣지\n 케이스를 세심히 처리해줘야 하고, 또 한 방향으로 진행할 때 이전 방향을\n 다시 봐야하기 때문에 꽤 까다롭다. 좀더 깔끔한 방법은 배열을\n 정방향으로 한번 역방향으로 한번, 총 두 번 보는 것이다.\n\n정방향으로 나눠주는 걸 먼저 생각해보자. 최소 하나는 나눠준 상태라고\n 하면, i 번째 아이의 점수가 i-1 번째 아이보다 큰 경우에는 i-1\n 번째 아이에게 나눠준 것보다 하나 더 주기만 하면 된다. 즉, 이웃한 아이\n 중 왼쪽(i-1)의 아이만 먼저 기준으로 살펴본 것이다.\n\n그럼 역방향의 경우는 어떻게 하면 될까? 정방향에서 왼쪽 아이를\n 살펴봤으니 여기서는 오른쪽 아이를 마저 살펴봐야\n 한다. 오른쪽(i+1)아이보다 지금 아이가 사탕이 더 많으면, 이전처럼\n 그냥 오른쪽 아이보다 사탕을 하나 더 주면 될까? 정방향을 살펴보면서\n 이미 왼쪽 아이를 기준으로 조건을 맞춰놨기 때문에, 오른쪽 아이보다\n 하나 더 주는 것이 오히려 덜 주는 경우가 생길 수 있다. 따라서 둘 중\n 더 많은 것을 취해야 양쪽 아이 모두보다 많은 조건을 만족할 수 있다.\n 예를 들어 점수가 [1, 3, 4, 5, 2]인 경우 정방향으로 나눠주고 나면\n [1, 2, 3, 4, 1]이 되는데, 역방향으로 나눠줄 때 무작정 i+1\n 아이보다 하나 더 줘버리면 오히려 [1, 2, 3, 2, 1]로 4번째 아이의\n 사탕 개수가 줄어들어버릴 수 있기 때문이다.\n\n이 아이디어를 구현하면 다음과 같다.\n\ndef candy(ratings):\n    n = len(ratings)\n    candies = [1] * n\n    for i in range(1, n):\n        if ratings[i] &gt; ratings[i-1]:\n            candies[i] = candies[i-1] + 1\n    for i in range(n-2, -1, -1):\n        if ratings[i] &gt; ratings[i+1]:\n            candies[i] = max(candies[i], candies[i+1] + 1)\n    return sum(candies)\n\n\n시간과 공간 복잡도 모두 O(N)이다."
					}
					,
					"ps-leetcode-check-completeness-of-a-binary-tree": {
						"id": "ps-leetcode-check-completeness-of-a-binary-tree",
						"title": "Check Completeness Of A Binary Tree",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/check-completeness-of-a-binary-tree/",
						"content": "Check Completeness Of A Binary Tree\n트리의 완전함을 어떻게 알고리즘으로 체크할 수 있을지 고민해 볼 수 있는 좋은\n  문제였다.\n잘 생각해보면 트리를 pre-order, in-order, post-order 중 하나로 순회해서는\n  완전함을 체크할 수 없다. 트리를 레벨 순으로 순회하면서 빠진 노드 가 있는지를\n  확인해야 한다. 따라서 가장 쉽게는 왼쪽 서브트리 -&gt; 오른쪽 서브트리 방향으로\n  BFS를 하면서, 바로 직전에 방문한 노드가 null 이었는지(=빠졌는지)를 체크해야\n  한다.\ndef isCompleteTree(root: Optional[TreeNode]) -&gt; bool:\n    found_none = false\n    q = deque()\n    q.append(root)\n\n    while q:\n        node = q.popleft()\n        if node is None:\n            found_none = True\n        else:\n            if found_none:\n                return False\n            q.append(node.left)\n            q.append(node.right)\n    return True"
					}
					,
					"ps-leetcode-climbing-stairs": {
						"id": "ps-leetcode-climbing-stairs",
						"title": "Climbing Stairs",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/climbing-stairs/",
						"content": "Climbing Stairs\n\n계단을 올라가려고 한다. n 개의 계단을 올라가야 꼭대기에 도착한다.\n\n각 단계에서 계단을 1개 또는 2개 씩 올라갈 수 있다. 꼭대기까지\n 올라가기 위한 방법은 총 몇 가지가 있는지 계산하자.\n\n\\(1 \\leq n \\leq 45\\) 이다.\n\n예를 들어, n = 3일 때, 총 세 가지 방법이 있다:\n\n  1 + 1 + 1\n  1 + 2\n  2 + 1\n\n\n피보나치 + 다이나믹 프로그래밍\n\nk 개의 계단을 올라가는 방법을 구하려면 다음 두 가지 방법이 있다는\n 것을 알 수 있다:\n\n  k-1 개의 계단을 올라가는 방법 + 1 (계단 1개)\n  k-2 개의 계단을 올라가는 방법 + 1 (계단 2개)\n\n\n즉, f(k)를 “k개의 계단을 올라가는 방법의 수”라고 한다면, 다음\n 점화식이 성립한다: f(k) = f(k-1) + f(k-2). 그리고 이 식은 그냥\n 피보나치 공식과 같다.\n\n따라서, 이 문제는 피보나치 수를 구하는 것과 같다. 피보나치 수는\n 다이나믹 프로그래밍의 대표적인 예시이고, n의 피보나치 수를 구하기\n 위해서 n-1부터 0(또는 1)까지의 모든 부분 문제를 계산해야\n 하므로, 탑 다운 방식의 메모이제이션이 잘 먹히는 문제이기도 하다.\n\nimport functools\ndef climbStairs(n):\n    @functools.cache\n    def fib(n):\n        if n == 1:\n            return 1\n        if n == 2:\n            return 2\n        return fib(n-1) + fib(n-2)\n    return fib(n)"
					}
					,
					"ps-leetcode-clone-graph": {
						"id": "ps-leetcode-clone-graph",
						"title": "Clone Graph",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/clone-graph/",
						"content": "Clone Graph\n\n연결 무향 그래프를 깊은 복사하자.\n\n탐색하면서 기록하기\n\n일반적인 그래프 탐색을 생각해보자. DFS든 BFS든 보통 방문 여부를\n 체크하기 위해서 visited 배열(집합)을 활용한다. 여기서는 이 visited를\n 확장해서, 노드의 방문 여부 뿐만 아니라 해당 노드의 복사 노드를\n 담고 있도록 하고, 모든 복사 노드를 연결하면 된다.\n\n혹시나 스택이 너무 커질 위험을 피하기 위해서 여기서는 BFS로\n 구현해보았다.\n\n\"\"\"\nclass Node:\n    def __init__(self, val=0, neighbors=None):\n        self.val = val\n        self.neighbors = neighbors if neighbors is not None else []\n\"\"\"\n\nfrom collections import deque\ndef cloneGraph(root):\n    if not root:\n        return None\n\n    q = deque()\n    q.append(root)\n    visited = {root: Node(root.val)}\n\n    while q:\n        node = q.popleft()\n        for neighbor in node.neighbors:\n            if neighbor not in visited:\n                visited[neighbor] = Node(neighbor.val)\n                q.append(neighbor)\n            # deep copy\n            visited[node].neighbors.append(visited[neighbor])\n\n    return visited[root]\n\n\n\n  visited를 해시 테이블로 만들고 해당 노드와 같은 값의 새로운\n노드를 담도록 한다. 생성자를 보면 알겠지만 자식 노드 없이 만들어도\n빈 리스트가 들어간다.\n  큐에서 노드를 하나씩 꺼내서 BFS를 하는 로직은 동일하다. 주의할 점은\n두 가지 인데, 하나는 아직 방문하지 않은 노드는 깊은 복사를\n해줘야 한다는 점이고, 다른 하나는 모든 복사한 자식 노드를 올바르게\n연결해줘야 한다는 점이다. 여기서 큐에서 꺼내어 방문 체크가 끝난\n노드는 항상 해시 테이블에 짝이 되는 복사 노드가 있는 것이\n보장된다는 점을 이용한다.\n\n\n참조) 파이썬의 해싱 함수\n\n참고로 파이썬에는 디폴트 해시 함수가 있는데, 모든 클래스는 object를\n 암묵적으로 상속 받기 때문에 노드 클래스에서 특별히 해시 함수를\n 지정해주지 않아도 곧바로 해시 테이블의 키로 사용할 수 있다.\n\n그리고 이 해시 함수는 다음과 같이 정의된다:\n\nclass Node:\n    def __init__(self, val=0, neighbors=None):\n        self.val = val\n        self.neighbors = neighbors if neighbors is not None else []\n\nn = Node( ... )\nhash(n) == (id(n) // 16)\n\n\n즉, 객체의 아이디 값을 16으로 나눈 값을 쓴다. 그리고 CPython에서\n 객체의 아이덴티티를 계산하는 id 함수는 객체의 메모리 주소와\n 같다. 즉, 기본 해시 함수는 메모리 주소를 쓴다고 봐도 무방하다."
					}
					,
					"ps-leetcode-coin-change": {
						"id": "ps-leetcode-coin-change",
						"title": "Coin Change",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/coin-change/",
						"content": "Coin Change\n\n서로 다른 금액을 나타내는 코인 배열 coins와 전체 돈의 양을 나타내는\n amount 정수 값이 주어진다. 이 양을 맞추기 위해서 필요한 최소한의\n 코인의 수를 구하자. 어떤 코인의 조합도 양을 맞출 수 없다면 -1을\n 리턴.\n\n각 코인은 무한개 있다고 가정해도 된다.\n\n\n  배열 크기: 1~12\n  코인 값: \\(1 \\sim 2^{31} - 1\\)\n  돈의 양: 0~10,000\n\n\n오답 노트 - 그리디 알고리즘\n탐욕법이 먹힐 것 같이 생겼지만 실제로는 반례가 있음.  coins =\n [1,3,4]이고 amount = 6일 때 그리디하게 풀면 (4, 1, 1)이 되어 3을\n 구하지만, 실제 정답은 (3, 3)의 2가 된다.\n\n따라서 그리디 쓰면 안된다.\n\nDP - 메모아이제이션\n\n  F(A) = A를 맞추기 위한 최소한의 코인 개수.\n  따라서 금액 C인 코인을 선택한다면, F(A) = F(A - C) + 1이\n성립한다.\n  코인이 몇 개인지 모르기 때문에 다음 등식이 성립: \\(F(A) =\nmin_{i=0..n-1}F(A-c_{i}) + 1\\)\n  기저 조건을 생각해보면 F(0) = 0임.\n  그외 불가능한 경우는 A가 음수인 경우\n  각 코인마다 전부 가능한 경우를 따져봐야 하고, 이걸 다시 최소값으로\n누적해야 올바른 답을 구할 수 있다.\n\n\nimport functools\ndef coinChange(coins, amount):\n    @functools.cache\n    def recurse(a):\n        if a &lt; 0:\n            return -1\n        if a == 0:\n            return 0\n\n        mincost = float('inf')\n        for coin in coins:\n            fa = recurse(a - coin)\n            if fa == -1:\n                continue\n            mincost = min(mincost, fa + 1)\n        return -1 if mincost == float('inf') else mincost\n\n    return recurse(amount)"
					}
					,
					"ps-leetcode-combination-sum": {
						"id": "ps-leetcode-combination-sum",
						"title": "Combination Sum",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/combination-sum/",
						"content": "Combination Sum\n\n중복 없는 정수 배열 candidates 와 정수 target이 주어졌을 때,\n candidates에서 고른 숫자 배열 합이 target이 되는 모든 유일한\n 조합의 목록을 구하자. 순서는 상관없다.\n\n같은 값의 원소가 무한 번 선택될 수 있다. 선택된 숫자의 빈도가\n 다를 때에만 유일한 조합으로 간주한다.\n\n\n  candidates 크기: 1~30\n  candidates 값의 범위: 2~40\n  targete: 1~500\n\n\n백트래킹\n\n  모든 조합을 구해야 하므로 정직하게 다 찾아봐야 하긴 한다.\n  하지만 애초에 불가능한 경우는 탐색할 필요가 없으므로, 적절히\n가지치기가 가능하다.\n  따라서 백트래킹으로 충분히 가능해보인다.\n  유지할 상태:\n    \n      지금 턴에서 살펴볼 원소의 인덱스\n      지금까지 조합한 배열\n      지금까지 쌓은 합 또는 target에서 빼면서 남은 값, 이건 근데\n배열을 유지할거면 매번 합을 구하는 방식으로 구해도 된다 (어차피\n문제 크기가 작음)\n    \n  \n  같은 값을 무한 번 선택할 수 있음에 주의하자. 상태에서 현재\n인덱스로부터 다음 인덱스를 살펴볼 때 항상 지금 인덱스를\n포함하도록 다음 상태를 전이하면 된다.\n  프루닝 가능한 부분: 지금까지 조합한 배열 합이 target을 넘겼을 때,\n이때는 더 이상 살펴봐도 의미없다.\n\n\ndef combinationSum(candidates, target):\n    answer = []\n    def backtrack(comb, idx, cursum):\n        if cursum == target:\n            answer.append(comb[::])\n            return\n        elif cursum &gt; target:\n            return\n\n        for i in range(idx, len(candidates)):\n            comb.append(candidates[i])\n            backtrack(comb, i, cursum + candidates[i])\n            comb.pop()\n    backtrack([], 0, 0)\n\n    return answer"
					}
					,
					"wip-multicore-ocaml-concurrency-and-parallelism": {
						"id": "wip-multicore-ocaml-concurrency-and-parallelism",
						"title": "Concurrency and Parallelism Design Notes",
						"version": "all",
						"categories": "",
						"url": " /wip/multicore-ocaml/concurrency-and-parallelism/",
						"content": "동시성(Concurrency)와 병렬성(Parallelism)\n\nOCaml이 멀티 코어를 통해 더 나은 지원을 하려 노력하는 두 가지 중요한\n 계산 방법이 있다.\n\n\n  동시성(Concurrency)은 여러 계산을 분할해서 엄격하게 순차적으로\n실행하는 되는 것이 아니라, 겹치는 시간(overlapping time)에 실행할\n수 있도록 하는 방법이다. OCaml은 하나의 힙에 대해서는 이미 Lwt나\nAsync같은 훌륭한 라이브러리들이 있다. OCaml의 Thread 모듈 역시\n동시성 계산을 표현하기 위한 훌륭한 방법이다.\n  병렬성(Parallelism)은 여러 계산을, 주로 멀티코어 머신의 여러 개의\n코어를 이용해서 동시에 실행하는 방법이다.\n\n\nOCaml에는 동시성과 병렬성을 지원하는 여러 메커니즘들이 존재한다.\n\n\n  \n    \n      시스템\n      동시성\n      병렬성\n    \n  \n  \n    \n      OCaml 4.11 Thread 모듈\n      직접적인 스타일(Direct-style)의 코드를 동시에 실행할 수 있음, pthreads 사용\n      OCaml 런타임 락으로 인해, C 쓰레드가 병렬적으로 실행되긴 하지만 최종적으로는 하나의 OCaml 쓰레드로 합쳐짐\n    \n    \n      Lwt / Async\n      모나드 스타일(monadic interface)로 코드를 짜야 함\n      싱글 쓰레드이지만 입출력을 병렬로 할 수 있음\n    \n    \n      Functory\n      map처럼 Functory 모듈 스타일로 동시성 연산을 짜야 함\n      여러 개의 런타임에서 동작하며, 분산 처리도 가능\n    \n  \n\n\n이런 방법들은 여러 개의 코어에서 병렬적으로 OCaml 코드가 실행되는\n 직접적인 스타일의 동시성을 지원하지 않는다. 멀티코어 OCaml\n 프로젝트는 이러한 한계를 해결하고 직접적인 스타일로 작성된 OCaml\n 코드가 공유 메모리 병렬성(Shared-Memory Parallelism; SMP)을\n 허용하는 것을 목표로 한다.\n\n도메인과 파이버, 이펙트\n현재 멀티코어에서 동시성과 병렬성에 대한 추상화 구현체는 두 가지가\n 있다.\n\n\n  도메인은 병렬적으로 실행되며, 자신만의 마이너 힙을 가지고\n멀티코어 마이너/메이저 GC를 관리하는데 필요한 동기화가 필요하기\n때문에 상당히\n무겁다. domainslib\n라이브러리를 사용하면 도메인을 이용해서 병렬 계산을 쉽게 할 수\n있다.\n  (이펙트를 통해 제공되는) 파이버는 유연한 동시성을 허용하는 동적\n스택을 갖고 있는 가벼운 실행 문맥이다. 파이버는 이펙트를 통해서\n만들어지고 관리된다(scheduled). 도메인끼리 컨티뉴이에션을 주고 받을\n수 있어서 멀티코어 런타임 위에서 복잡한 스케쥴링이 가능하다.\n\n\n참조\n\n  도메인은 블로킹 연산에 대해서는 블록된다. 구체적으로, 다른 계산의\n스케쥴링이 멈춘다.\n  블로킹 연산이 호출되면 도메인도 블록되기 때문에, 만약 파이버가\n블로킹 C 연산을 호출하면 해당 도메인에서 수행되는 모든 스케쥴링은\n이 연산이 끝날 때까지 블록된다.\n  멀티코어 GC는 도메인 개수가 물리적 코어의 개수보다 작거나 같을 때\n가장 잘 동작하도록 설계되었다. 런타임이 가비지 콜렉터를 관리하기\n위해 도메인마다 추가적인 상태를 갖기 때문이다. 마이너 콜렉션과\n메이저 싸이클의 끝에서 도메인들끼리 동기화가 필요하다. 그러므로,\n도메인이 시스템 (p)쓰레드와 짝지어지긴 하지만, OCaml에서는 더\n무거운 추상화로 취급된다."
					}
					,
					"ps-leetcode-construct-binary-tree-from-preorder-and-inorder-traversal": {
						"id": "ps-leetcode-construct-binary-tree-from-preorder-and-inorder-traversal",
						"title": "Construct Binary Tree from Preorder and Inorder Traversal",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/construct-binary-tree-from-preorder-and-inorder-traversal/",
						"content": "Construct Binary Tree from Preorder and Inorder Traversal\n\n어떤 바이너리 트리가 있다. 이 트리를 Inorder로 순회한 결과 배열과\n Preorder로 순회한 결과 배열이 입력으로 주어졌을 때, 이 바이너리\n 트리를 복원하고 루트 노드를 리턴하자.\n\n입력으로 들어오는 Preorder, Inorder 배열의 길이는 같고 1~3,000 사이의\n 값이다. 각각의 배열 값은 -3,000~3,000 사이의 값을 갖고 항상 유니크한\n 값을 담고 있다. Inorder에 나타난 모든 값은 Preorder에도\n 존재한다. Preorder와 Inorder는 동일한 바이너리 트리를 각각 Preorder와\n Inorder로 순회한 결과임이 보장된다.\n\n해시 테이블 해킹\n\n이거랑 유사한 문제가 그래프 클론하기인데, 이런 류의\n 문제는 주로 (1) 올바른 순서로 탐색하면서 (2) 해시 테이블에 노드를\n 직접 저장해뒀다가 꺼내 쓰는 것이 주요한 접근으로 보인다.\n\n일단 트리의 순회는 기본적으로 왼쪽 -&gt; 오른쪽이고, 루트 노드를 언제\n 방문하느냐에 따라 다음 세 가지 방법이 있다:\n\n  Pre-order: 루트 -&gt; 왼쪽 -&gt; 오른쪽\n  In-order: 왼쪽 -&gt; 루트 -&gt; 오른쪽\n  Post-order: 왼쪽 -&gt; 오른쪽 -&gt; 루트\n\n\n우리에게 주어진 것은 1과 2의 순회 결과이다. 일단 여기서 알 수 있는\n 것은 다음 두 가지이다.\n\n  Pre-order 결과의 첫번째 원소는 전체 트리의 루트 노드이다.\n  In-order 결과는 항상 루트를 중간에 탐색하므로, 만약 어떤 서브트리의\n루트 위치를 알고 있다면, 왼쪽과 오른쪽 서브트리를 알게 된다.\n\n\n이해를 위해 구체적인 예시를 살펴보자. 다음과 같은 트리가 있을 때,\n\n           3\n           |\n  +--------+--------+\n  |                 |\n  9                20\n  |                 |\n+--+--+          +--+--+\n|     |          |     |\n1     2          15    7\n\n\n입력으로 들어오는 preorder와 inorder는 다음과 같다.\n\npreorder: [3, 9, 1, 2, 20, 15, 7]\ninorder: [1, 9, 2, 3, 15, 20, 7]\n\n\n이때 관찰대로 preorder의 첫번째 인덱스 3은 전체 트리의\n 루트노드이다. 그러면 이 값의 inorder에서의 위치를 살펴보면, 3을\n 기준으로 왼쪽에 있는 모든 원소는 왼쪽 서브트리이고 오른쪽에 있는 모든\n 원소는 오른쪽 서브트리가 된다. 즉,\n\ninorder: [1, 9, 2,          3,        15, 20, 7  ]\n         |               | root  |               |\n         |  left subtree |       | right subtree |\n\n\n한 단계만 더 나아가보자. preorder의 다음 원소인 9는 3의 왼쪽\n 서브트리의 루트노드인 것을 알 수 있다. 따라서, inorder에서 3의\n 왼쪽 서브트리 부분에서 9를 찾으면, 이번에도 왼쪽 서브트리와 오른쪽\n 서브트리를 알아낼 수 있다.\n\ninorder: [1,                 9,            2     ]\n         |               | root  |               |\n         |  left subtree |       | right subtree |\n\n\n이제 실마리가 보이는 것 같다. 즉, 우리가 해야할 일은 다음과 같다.\n\n\n  먼저 노드 -&gt; Inorder의 인덱스로 가는 해시 테이블을 만든다.\n  노드는 Preorder 순으로 빌드할 것이다. 전역 인덱스 0을 만들어서\n현재 Preorder 순회의 어디인지 추적한다.\n  Preorder 순으로 노드를 만들면서 진행하는 재귀함수는 다음 일을\n한다:\n    \n      범위가 벗어났으면 None\n      범위가 적절하다면, 현재 Preorder 인덱스 위치의 값을 가져와서\n현재 서브 트리의 루트 노드를 생성하고 인덱스를 증가\n      노드의 양쪽 서브 트리를 재귀적으로 호출해서 만들건데, 이때\n범위를 적절하게 줌\n    \n  \n\n\n즉, 키 아이디어는 Inorder 순회 결과에서 루트 노드의 위치를 알면,\n 왼쪽과 오른쪽 범위를 가지고 서브 트리 정보를 알아낼 수 있다는 점을\n 이용하고, 이때 루트 노드의 정확한 위치를 Preorder를 가지고 알아내는\n 것이다.\n\n아이디어를 구현하면 다음과 같다.\n\ndef buildTree(preorder, inorder):\n    inorder_index_of = {}\n    for idx, val in enumerate(inorder):\n        inorder_index_of[val] = idx\n\n    preorder_index = 0\n    def pre_order(left, right):\n        nonlocal inorder_index_of\n        nonlocal preorder_index\n\n        if left &gt; right:\n            return None\n\n        root_value = preorder[preorder_index]\n        root = TreeNode(root_value)\n        preorder_index += 1\n\n        root.left = pre_order(left, inorder_index_of[root_value] - 1)\n        root.right = pre_order(inorder_index_of[root_value] + 1, right)\n        return root\n    return pre_order(0, len(preorder)-1)\n\n\n\n  일종의 이분 탐색이라고 봐도 되겠다. Preorder에서 루트 노드의\n인덱스를 기준으로 양 옆을 쪼개면서 트리를 구성해간다.\n  솔직히 이 문제를 시간 안에 풀 자신은 없다."
					}
					,
					"ps-leetcode-container-with-most-water": {
						"id": "ps-leetcode-container-with-most-water",
						"title": "Container with Most Water",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/container-with-most-water/",
						"content": "Container with Most Water\n\n높이가 적힌 배열 height가 들어온다. 여기에는 배열의 크기 n개\n 만큼의 수직선(세로선)의 정보가 들어있는데 i번째 수직선은 (i,\n 0)부터 (i, height[i])까지 긋는다.\n\n이 중에서 두 개의 서로 다른 수직선을 골라 X축을 이으면 물을 담을 수\n 있는 컨테이너를 그릴 수 있다. 이 중 가장 많은 물을 저장할 수 있는\n 컨테이너를 만드는 두 개의 수직선을 찾고, 그때의 물의 양을 구하자.\n\n컨테이너를 기울이면 안된다.\n\n배열의 크기는 2~100,000, 높이는 0~10,000 사이이다. 항상 최소 두 개의\n 수직선이 있음이 보장된다.\n\n투 포인터\n\n컨테이너를 기울이면 안된다는 조건에 집중하자. 즉, 두 개의 수직선\n 중에서 더 짧은 쪽이 컨테이너의 물의 양을 결정한다. 그리고, X축이\n 길수록 컨테이너가 넓어지므로 물의 양이 더 많아진다.\n\n그러므로 우리가 찾아야 하는 수직선의 조건은 다음과 같다:\n\n  두 수직선 사이가 멀수록 좋다.\n  두 수직선 중 짧은 쪽의 길이가 클수록 좋다.\n\n\n수직선 두 개를 골라야 하므로 투 포인터 기법이 가장 유력해보인다. 두\n 수직선 사이가 멀수록 좋기 때문에, 양 끝점에서 시작해서 한 칸씩\n 좁혀나가면서 최대의 수량을 구하면 된다. 이때, 둘 중 더 긴 쪽의\n 수직선은 그대로 두고, 더 짧은 쪽의 수직선을 계속해서\n 움직여나간다. 즉, 좁혀나간다. 이렇게 두 개의 포인터가 서로 끝까지\n 도달할 때까지 모든 케이스를 다 살펴보면 된다.\n\n일단 두 X좌표가 주어졌을 때 물의 양을 구하는 함수를 짜두자.\n\ndef water(x1, x2):\n    return abs(x1 - x2) * min(height[x1], hight[x2])\n\n\n그 후, 투 포인터를 유지하면서 최대 물의 양을 계속 누적해가면서 더\n 짧은 쪽의 위치를 계속 좁혀나가도록 하면 된다.\n\ndef maxArea(height):\n    maxarea = 0\n    start, end = 0, len(height) - 1\n    while start &lt; len(height) and end &gt;= 0:\n        maxarea = max(maxarea, water(start, end))\n        if height[start] &lt; height[end]:\n            start += 1\n        else:\n            end -= 1\n    return maxarea"
					}
					,
					"ps-leetcode-contains-duplicate": {
						"id": "ps-leetcode-contains-duplicate",
						"title": "Contains Duplicate",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/contains-duplicate/",
						"content": "Contains Duplicate\n\n정수 배열이 주어졌을 때, 최소 두 번 이상 나타나는 원소가 있는지를\n 확인하자.\n\n배열 크기는 1~100,000 이다.\n\n해시 셋\n\n  중복을 제거해서 전후 Cardinality를 비교하면 된다.\n\n\ndef containsDuplicate(nums):\n    return len(nums) != len(set(nums))\n\n\nContains Duplicate II\n\n역시 정수 배열이 주어지고 이번에는 정수 k도 같이 주어진다. 이때,\n 서로 다른 두 인덱스 i와 j에 대해서 nums[i] == nums[j] 이면서\n abs(i - j) &lt;= k를 만족하는 두 인덱스가 존재하는지를 확인하자.\n\n\n  정수 배열의 크기는 1 ~ 100,000\n  정수 원소 값의 범위는 \\(-10^9 \\sim 10^9\\)\n  k의 범위는 0~100,000\n\n\n해시 셋\n\n  abs(i - j) &lt;= k인 서로 다른 두 인덱스 i, j가 뜻하는 바는 결국\nk 크기의 슬라이딩 윈도우를 뜻한다.\n  중복은 역시 해시 셋으로 판단할 수 있다. k 크기의 슬라이딩\n윈도우에 포함되는 원소를 해시 셋으로 유지하면서 정방향으로 훑어\n나간다.\n    \n      원소가 해시 셋에 있다면 중복이 있다는 것이다.\n      원소가 없는데 해시 셋의 크기가 k를 넘었다면, 이때까지 살펴본\n슬라이딩 윈도우에서는 중복이 없었다는 의미이다. 다음으로 넘어가기\n위해서는 슬라이딩 윈도우를 벗어나는 지점의 원소를 빼야한다.\n    \n  \n\n\ndef containsNearbyDuplicate(nums, k):\n    window = set()\n    for i in range(len(nums)):\n        if nums[i] in window:\n            return True\n\n        window.add(nums[i])\n        if len(window) &gt; k:\n            window.remove(nums[i - k])\n    return False\n\n\nContains Duplicate III\n\n역시 정수 배열과 indexDiff (II의 k) 가 주어지고 이번에는 추가로\n valueDiff도 주어진다. 이때 다음 조건을 만족하는 서로 다른 인덱스\n 쌍이 존재하는지 확인하자.\n\n  abs(i - j) &lt;= indexDiff\n  \n    abs(nums[i] - nums[j]) &lt;= valueDiff\n  \n  배열의 크기는 2~100,000\n  값의 크기는 \\(-10^9 \\sim 10^9\\)\n  indexDiff는 1과 배열 크기 사이\n  valueDiff는 \\(0 \\sim 10^9\\)\n\n\n버킷 테이블\n\n  II의 슬라이딩 윈도우와 유사한 접근을 생각해볼 수 있는데, 이번에는\nvalueDiff 조건 즉 값의 범위도 생각해야 한다. 슬라이딩 윈도우 +\n해시 셋 접근을 하면 현재 배열의 값에 0부터 valueDiff까지를\n증가시켜 가면서 값을 체크하거나, 혹은 조금 더 똑똑하게 절반씩\n바이너리 서치를 해볼 수도 있다.\n  간단한 방법은 버킷 정렬의 아이디어를 빌려오는 것이다.\n  버킷 정렬에서 하나의 버킷은 특정 범위의 값을 담는다.\n  이 아이디어를 바탕으로, 슬라이딩 윈도우에 해당하는 버킷을\n유지하면서 버킷에는 valueDiff 범위의 값만 담도록 한다면, 다음 세\n가지 경우가 있다:\n    \n      같은 버킷 아이디가 존재: valueDiff 범위의 값이 존재함\n      현재 버킷 아이디 + 1이 존재: 해당 버킷의 값을 꺼내와서\nvalueDiff 만큼 차이나는지 확인\n      현재 버킷 아이디 - 1이 존재: 역시 버킷의 값을 꺼내와서\nvalueDiff 만큼 차이나는지 확인\n    \n  \n  슬라이딩 윈도우 사이즈 축소 조건을 확인하는 방법은 다음 두\n가지이다:\n    \n      유지하고 있는 윈도우에 해당하는 데이터의 크기가 k를 넘었는지:\nlen(window) &gt; k\n      인덱스가 k 이상인지: i &gt;= k\n      둘 중 어느것을 해도 동작한다. 첫 번째가 동작하는 이유는 중복\n체크를 먼저해서 리턴하기 때문이고, 두 번째는 일반적인 슬라이딩\n윈도우 기법이다.\n    \n  \n\n\ndef containsNearbyAlmostDuplicate(nums, indexDiff, valueDiff):\n    def bucket_id(x):\n        return x // (valueDiff + 1)\n\n    buckets = {}\n    for i in range(len(nums)):\n        x = nums[i]\n        bid = bucket_id(x)\n\n        if bid in buckets:\n            return True\n        if (bid + 1) in buckets and abs(x - buckets[bid-1]) &lt;= valueDiff:\n            return True\n        if (bid - 1) in buckets and abs(x - buckets[bid+1]) &lt;= valueDiff:\n            return True\n\n        buckets[bid] = x\n        if i &gt;= indexDiff:\n            buckets.pop(bucket_id[i - indexDiff])\n    return False"
					}
					,
					"ps-leetcode-convert-sorted-list-to-bst": {
						"id": "ps-leetcode-convert-sorted-list-to-bst",
						"title": "Convert Sorted List to Binary Search Tree",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/convert-sorted-list-to-bst/",
						"content": "Convert Sorted List to Binary Search Tree\n\n오름차순으로 정렬된 링크드 리스트의 헤드 노드가 입력으로 들어왔을\n 때, 이걸 밸런스가 맞춰진 바이너리 서치 트리로 바꾸는\n 문제이다. 여기서 밸런스는 모든 노드의 양 쪽 서브트리 높이의 차이가\n 최대 1만큼 나는 친구다.\n\nInorder Traverse\n\n트리를 순회하는 방법은 기본적으로 왼쪽 -&gt; 오른쪽이고 루트를 언제\n 방문하느냐에 따라 세 가지로 나뉜다.\n\n  전위 순회: 루트 -&gt; 왼 -&gt; 오\n  중위 순회: 왼 -&gt; 루트 -&gt; 오\n  후위 순회: 왼 -&gt; 오 -&gt; 루트\n\n\n이 중에서 중위 순회가 가장 우리의 직관과 맞닿아 있다. 특히, BST를\n 중위순회하면 정렬된 순서로 노드를 방문하게 된다. 이 성질을 이용해볼\n 수 있다.\n\n중위 순회는 결국 루트 노드를 기준으로 왼쪽 서브트리를 먼저 다 뒤지고,\n 그 다음 루트 노드를 뒤지고, 그 다음 오른쪽 서브트리를 다 뒤지는\n 것이다. 만약 (1) 트리가 균형이 맞고, (2) 트리의 노드 수를 알고\n 있다면, 다음 성질 또한 알 수 있다: 루트 노드가 항상 노드 수를 절반 씩\n 나누게 된다.\n\n마침 우리는 밸런스가 맞춰진 트리를 복원하는 것이 목표이므로, 이\n 성질을 이용해서 중위 순회를 시뮬레이션할 수 있다.\n\ndef inorder(low, high):\n    if low &gt; high:\n        return None\n    mid = (low + high) // 2\n\n    inorder(low, mid - 1)\n    # make tree node from linked list\n    # forward linked list\n    inorder(mid + 1, high)\n\n\n즉, 리스트 전체 사이즈를 먼저 구해서 low와 high를 가지고 중위\n 순회를 돌면서, 더 이상 절반으로 쪼개지지 않으면 null을 매달고, 그게\n 아니라면 링크드 리스트의 노드로부터 트리의 노드를 만들면 된다. 문제의\n 조건 덕분에 이런 시뮬레이션이 가능하다.\n\ndef sortedListToBST(head):\n    high = 0\n    node = head\n    while node:\n        high += 1\n        node = node.next\n    high -= 1\n\n    node = head\n    def inorder(low, high):\n        nonlocal node\n        if low &gt; high:\n            return None\n        mid = (low + high) // 2\n        left = inorder(low, mid - 1)\n        root = TreeNode(node.val)\n        node = node.next\n        root.left = left\n\n        root.right = inorder(mid + 1, high)\n        return root\n    return inorder(0, high)\n\n\n\n  low와 high는 모두 인덱스임에 주의하자. 따라서 high는 링크드\n리스트의 길이에서 1을 빼줘야 한다.\n  중위 순회의 방문 순서를 충실하게 지키고 있음을 눈여겨 보자. 먼저\n왼쪽 서브트리를 방문한다. 그 결과를 left에다 우선 저장해둔다. 그\n후 현재 node의 값으로부터 지금 위치의 루트 노드를 만든다. 루트\n노드의 왼쪽 서브트리를 미리 순회해둔 포인터로 설정한다. 마지막으로\n오른쪽 서브트리를 방문할 건데 이때는 곧바로 루트 노드의 오른쪽에\n박아둔다. 최종적으로 루트 노드를 리턴한다."
					}
					,
					"ps-leetcode-count-common-words-with-one-occurrence": {
						"id": "ps-leetcode-count-common-words-with-one-occurrence",
						"title": "Count Common Words with One Occurrence",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/count-common-words-with-one-occurrence/",
						"content": "Count Common Words with One Occurrence\n\n두 개의 단어 배열 words1과 words2가 입력으로 들어왔을 때, 두 배열\n 모두에서 각각 한 번씩만 등장하는 단어의 개수를 구하자.\n\n그냥..센다\n\n그냥 양쪽 단어 목록에서 단어 개수를 센 다음, 개수가 1개인 단어만\n 남겨서 교집합을 구하면 된다.\n\nfrom collections import Counter\ndef countWords(words1, words2):\n    c1, c2 = Counter(words1), Counter(words2)\n    c1set = set([c[0] for c in c1.items() if c[1] == 1])\n    c2set = set([c[0] for c in c2.items() if c[1] == 1])\n    return len(c1set &amp; c2set)\n\n\n\n  문자 그대로 단어의 개수를 각각 세고, 개수가 1개인 것만 집합으로\n모은 다음, 두 교집합의 길이를 리턴한다."
					}
					,
					"ps-leetcode-count-odd-numbers-in-an-interval-range": {
						"id": "ps-leetcode-count-odd-numbers-in-an-interval-range",
						"title": "Count Odd Numbers in an Interval Range",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/count-odd-numbers-in-an-interval-range/",
						"content": "Count Odd Numbers in an Interval Range\n\n\\(0 \\sim 10^9\\) 사이의 정수 low와 high가 주어진다. 이 두 수가\n 만드는 범위 안의 홀수의 개수를 계산하자. 두 수를 포함하는\n 범위이다. 즉 [low, high] 이다.\n\n똑똑하게 세기\n\n당연하지만 low부터 high까지 일일이 세면 안된다. 범위를 좀\n 살펴보자.\n\nlow, high를 포함하는 범위이므로 이 값이 모두 홀수일 때를\n 생각해보자. 예를 들어 [1, 2, 3, 4, 5] 를 생각해보면, 홀수의 개수는\n 3개이다. 즉 1과 5 범위의 길이 + 1 이 홀수의 개수가 된다.\n\n둘 다 짝수이거나 둘 중 하나만 짝수일 때에는 어떻게 될까? 예를 들어\n [0, 1, 2, 3]을 생각해보자. 짝수인 low는 홀수가 아니지만 이를 한\n 칸 오른쪽으로 민 1은 홀수이므로, 사실 이 때의 홀수 개수는 [1, 2,\n 3]에서의 홀수 개수와 같다. 반대의 경우도 마찬가지이다.\n\n따라서, 먼저 범위의 시작과 끝을 홀수로 맞춘 다음, 홀수 범위 안의\n 길이 + 1을 계산하면 된다.\n\ndef countOdds(low, high):\n    if low % 2 == 0:\n        low += 1\n    if high % 2 == 0:\n        high -= 1\n    return (high - low) // 2 + 1"
					}
					,
					"ps-leetcode-count-unreachable-pairs-of-nodes-in-an-undirected-graph": {
						"id": "ps-leetcode-count-unreachable-pairs-of-nodes-in-an-undirected-graph",
						"title": "Count Unreachable Pairs Of Nodes In An Undirected Graph",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/count-unreachable-pairs-of-nodes-in-an-undirected-graph/",
						"content": "Count Unreachable Pairs Of Nodes In An Undirected Graph\n유니온 파인드를 써야한다는 것까지는 접근했고, 컴포넌트 별로 원소를 유지하기까진\n  했다. O(N^2) 루프를 돌면서 가능한 경우를 세려고 하니 타임아웃이 나더라.\n두 가지 방법으로 이를 최적화할 수 있다.\n\n  유니온 파인드에서 컴포넌트 원소를 유지하면 유니온 연산이 O(N*logN) 이\n    되어버려서 비효율적이다. 노드의 개수가 정해져있으므로, 일단 이어진 노드들을\n    다 합친 다음 전체 노드에 대해서 대표 원소를 꺼내와서 직접 세면 O(N) 만에\n    끝낼 수 있다.\n  가능한 모든 경우를 세는 것도 비슷하다. 노드의 개수가 정해져있으므로,\n    컴포넌트의 크기를 가지고 가능한 쌍의 개수를 구할 때 남아있는 노드 의 수를\n    이용하면 O(N) 만에 끝낼 수 있다.\n\nclass UnionFind:\n    def __init__(self):\n        self.reps = {}\n\n    def find(self, x):\n        if x not in self.reps:\n            self.reps[x] = x\n\n        if x != self.reps[x]:\n            self.reps[x] = self.find(self.reps[x])\n        return self.reps[x]\n\n    def union(self, x, y):\n        x, y = self.find(x), self.find(y)\n        if x == y:\n            return\n        self.reps[x] = y\n\ndef countPairs(n: int, edges: List[List[int]]) -&gt; int:\n    uf = UnionFind()\n    for n1, n2 in edges:\n        uf.union(n1, n2)\n\n    components = Counter()\n    for node in range(n):\n        components[uf.find(node)] += 1\n\n    pairs, remaining = 0, n\n    for c in components.values():\n        pairs += c * (remaining - c)\n        remaining -= c\n    return pairs"
					}
					,
					"ps-leetcode-course-schedule": {
						"id": "ps-leetcode-course-schedule",
						"title": "Course Schedule",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/course-schedule/",
						"content": "Course Schedule\n\n총 numCourses 개의 수업을 들어야 한다. 배열 prerequisites이\n 주어지는데 prerequisites[i] = (ai, bi)는 수업 bi를 듣기 전에\n 반드시 들어야 하는 선행 과목 ai를 나타낸다. 예를 들어 (0, 1)\n 튜플은 수업 0을 들어야만 수업 1을 들을 수 있다는 뜻이다.\n\n수업을 다 끝낼 수 있는지를 확인하자.\n\n수업의 개수는 1~100,000 이고, 입력으로 들어오는 선행 과목은 0~5,000\n 사이이다. 선행 과목 정보의 쌍은 모두 [0, numCourses) 범위의\n 값이다. 모든 선행 과목 정보 쌍은 유니크하다.\n\n위상 정렬\n\n샘플 케이스를 보면서 감을 잡자.\n\nnumCourses = 2\nprerequisites = [(1,0)]\n\n\n위의 경우, 1 -&gt; 0 순으로 수업을 들으면 수업을 모두 끝마칠 수 있다.\n\nnumCourses = 2\nprerequisites = [(1,0), (0,1)]\n\n\n위의 경우, 1 -&gt; 0과 0 -&gt; 1을 동시에 만족시키는 것은 불가능하기\n 때문에, 수업을 모두 들을 수 없다.\n\n\n\n즉, 이 문제는 그래프와 관련이 있다. numCourses는 그래프의 노드\n 수이고, prerequisites는 그래프의 엣지를 나타낸다. 이로부터 그래프를\n 그렸을 때, 싸이클이 있다면, 어떤 수업을 듣기 위해서 선행해야 하는\n 과목이 무한 루프를 이루므로 수업을 끝마치는 것(=모든 노드를 방문하는\n 것)이 불가능하다. 따라서, 이 문제는 그래프에서 싸이클을 찾는\n 방법을 적용하면 된다.\n\n그래프 탐색은 보통 방문 여부를 배열이나 집합으로 기록하면서\n 진행된다. 만약 모든 엣지를 따라 나가다가 이전에 방문한 노드를 또\n 방문하게 되었다면, 이는 싸이클이 있는 것이다.\n\n그 외의 엣지 케이스는 없을까? 만약 선행 과목 정보에 아무것도 없으면\n 어떻게 될까? 이때는 어떤 과목을 듣기 위해서 필수적으로 들어야 할 게\n 아무것도 없으므로 그냥 아무거나 들으면 된다. 즉, 위의 싸이클만\n 확인하면 된다.\n\n파이썬에서 그래프를 표현하기 위한 가장 쉬운 방법은 그래프를 집합의\n 딕셔너리로 만드는 것이다. 즉, 말하자면 엣지 정보만 담은 일종의\n Adjacency List라고 볼 수 있다. Matrix로 표현하는 것도 가능하지만\n 파이썬은 이게 훨씬 편하다. 이때 한 가지 주의할 점은\n defaultdict(set)으로 구현하는 것보다는, 전체 노드 정보를 알고\n 있다면 {node: set() for node ...}로 초기화하는 것이 좋다는\n 점이다. defaultdict(set)으로 만든 그래프 딕셔너리는 원소가 없는\n (source, sink) 쌍을 무지성으로 넣기에는 편하지만, 그래프 자체에다가\n for 반복문을 아무 생각없이 돌려버리면 dictionary size changed\n during iteration 예외가 발생한다. 왜냐하면, 아무런 엣지도 없는\n 노드를 키 값으로 접근하는 순간 KeyError 예외가 발생하게 되고,\n defaultdict의 구현에 따라 __missing__이 호출되면서 해당 키 값에\n set()을 추가하게 되는데, 이렇게 되면 예외 메시지가 뜻하는 것처럼\n 딕셔너리 사이즈가 변하기 때문이다.\n\n싸이클을 찾기 위한 탐색은 DFS가 좋다. BFS로도 할 수 있는데, 구현이\n 까다롭다.\n\ndef canFinish(numCourses, prerequisites):\n    graph = {node: set() for node in range(numCourses)}\n    for (src, snk) in prerequisites:\n        graph[src].add(snk)\n\n    visiting = set()\n    visited = set()\n    def dfs(node):\n        nonlocal visited\n        nonlocal visiting\n        if node in visited:\n            return\n        visiting.add(node)\n        for sink in graph[node]:\n            if sink in visiting:\n                raise TypeError(\"Cycle detected\")\n            if sink not in visited:\n                dfs(sink)\n        visiting.remove(node)\n        visited.add(node)\n\n    try:\n        for node in graph:\n            dfs(node)\n    except TypeError:\n        return False\n\n    return True\n\n\n\n  정석대로 visiting과 visited 집합과 DFS를 이용해서 그래프에서의\n싸이클 체크를 구현하였다. 싸이클이 발견되면 TypeError를 던지도록\n했다.\n\n\n\n\n풀고나서 파이썬 라이브러리를 뒤져봤더니, 3.10 버전부터는 아예\n graphlib 이라는,\n 이터러블 객체의 딕셔너리를 그래프로 입력받아서 위상 정렬을 할 수 있는\n 라이브러리가 추가된 것을 확인할 수 있었다. 사용법은 대충 그래프를\n 위와 같은 방법으로 만든 다음 graphlib.TopologicalSorter(graph)에다\n 넘기고 static_order()를 호출해서 위상 정렬을 진행하는 것인데, 이\n 문제처럼 단순히 싸이클 유무만 판단하고 싶을 때에는 그냥 prepare()를\n 호출하면 된다. 그리고 구현을 잘 해놔서 defaultdict(set)을 그래프로\n 사용해도 잘 동작한다.\n\nimport graphlib\nfrom collections import defaultdict\ndef canFinish(numCourses, prerequisites):\n    graph = defaultdict(set)\n    for (src, snk) in prerequisites:\n        graph[src].add(snk)\n\n    try:\n        graphlib.TopologicalSorter(graph).prepare()\n    except graphlib.CycleError:\n        return False\n    return True\n\n\n\n  문서에 따르면 TopologicalSorter().static_order()가 동작하는 도중\n싸이클을 발견하면 CycleError를 던지고, 실제로 prepare()를\n호출하는 코드와 동일한 의미라고 하는데, 버그가 있는 것인지\n리트코드에서 static_order()를 호출해서 제출하면 싸이클이 있는\n테스트 케이스를 통과하지 못한다. 그러니 이정도 구현은 그냥\n라이브러리의 힘을 빌리지말고 직접 구현하는 것이 더 나을 것 같다."
					}
					,
					"ps-leetcode-critical-connections-in-a-network": {
						"id": "ps-leetcode-critical-connections-in-a-network",
						"title": "Critical Connections in a Network",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/critical-connections-in-a-network/",
						"content": "Critical Connections in a Network\nn개의 서버가 있고 0부터 n-1까지 번호가 매겨져있다. 서버끼리는\n 연결되어 있을 수 있는데 이 정보가 connections에 담겨 있고\n connections[i] = (a, b) 이면 a서버와 b서버가 연결되어 있다는\n 의미이다. 서버끼리 직접 연결되든 간접적으로 연결되든 네트워크를 통해\n 연결될 수 있다.\n\n서버 간 연결 중에서, 만약 연결이 끊긴다면 다른 어떤 서버에 더 이상\n 연결할 수 없게 되는 연결을 Critical Connection이라고 한다.\n\n네트워크 정보가 주어졌을 때 네트워크 안의 모든 Critical Connection을\n 구하자. 어떤 순서든 상관없다.\n\n문제의 이해\n문제만 읽어선 이게 대체 뭔 소리인가 싶었다. 이런건 예시를 봐야 한다.\n\n다음 그림(?)을 보자.\n\n0 ---- 1 --- 3\n \\    /\n  \\  /\n    2\n\n\n점점 아스키 아트가 늘어가는 기분이다. 아무튼 위와 같은 네트워크가\n 주어졌을 때, 크리티컬 커넥션은 어디일까? 잘 보면 (1, 3)을\n 끊어버리면 3은 그 어디와도 연결될 수 없게 된다. 그럼 대체 이 연결은\n 뭘까? 그래프에 익숙하다면 0, 1, 2는 싸이클을 형성하고 있다는\n 것을 알 수 있다.\n\n즉, 이 문제는 주어진 그래프의 모든 엣지들 중에서, 싸이클이 아닌\n 엣지를 찾는 문제로 환원할 수 있다.\n\n싸이클 찾기\n그래프의 싸이클은 DFS와 연관이 깊다. 그런데 보통은 visited에 추가로\n visiting을 둬서, 싸이클의 존재 여부를 판단하는 문제가\n 대부분이었다. 여기서는 모든 싸이클을 찾아야 하는데 어떻게\n 해야할까?\n\n싸이클을 좀더 유식한 말로는 SCC(Strongly Connected Components)라고\n 부르기도 한다. 정확한 수학적인 정의는 유향/무향 그래프에 따라 좀 다른\n 것 같긴 한데.. 암튼 여기서는 어차피 무향 그래프니까 같은 거라고\n 생각하자. SCC 안에 있는 모든 노드끼리는 서로 직/간접적으로 닿을 수\n 있다(Reachable). 따라서, SCC를 구하는 알고리즘을 조금 변형하면,\n 우리가 원하는 “SCC가 아닌” 엣지만 판변할 수 있다.\n\n타잔 알고리즘 변형\nSCC를 구하는 알고리즘 중에는 그 유명한 타잔의\n 알고리즘이\n 있다. 여기서는 이걸 조금 변경해서 문제를 풀어보려고 한다.\n\n기본은 DFS다. 단, visited나 visiting을 기록하진 않고, 노드의\n 랭크를 기록한다고 생각하자. 여기서 랭크는 방문한 순서 정도로\n 이해하면 된다.\n\n위의 그래프를 다시 가져와 봤다.\n\n0 ---- 1 --- 3\n \\    /\n  \\  /\n    2\n\n\n일단 그래프는 특별히 루트라고 불릴만 한 게 없으므로, 어떤\n 노드에서든 DFS를 시작할 수 있다. 여기서는 1에서 시작한다고\n 해보자. 랭크는 0부터 시작한다. 일단 1에는 랭크가 없는 상태이므로,\n 0을 랭크로 갖게 된다.\n\n0 ---- 1(0) --- 3\n \\    /\n  \\  /\n    2\n\n\n다음으로 노드 0을 방문하게 되었다. 랭크가 없으므로, 이전 랭크보다\n 1 증가한 1이 랭크가 된다.\n\n0(1) ---- 1(0) --- 3\n \\        /\n  \\      /\n      2\n\n\n다음으로 방문할 노드를 고를 때, 한 가지 원칙이 있다: 부모 노드는\n 방문하지 않는다. 즉, 0을 방문하기 이전 부모 노드인 1은 방문하지\n 않는다. 따라서 0 다음 방문할 노드는 2만 남았다. 역시 1 증가한\n 2를 랭크로 업데이트하게 된다.\n\n0(1) ---- 1(0) --- 3\n \\        /\n  \\      /\n     2(2)\n\n\n다음으로 방문할 노드는 1밖에 없다. 그런데 여기서 싸이클이 발생하게\n 된다! 어떻게 아냐고? 노드 1에 이미 랭크가 있고, 그 랭크가 지금\n 노드의 랭크인 2보다 작거나 같기 때문이다. 즉, 우리는 항상 다음\n 노드를 방문할 때마다 랭크를 증가시키기만 했는데, 랭크가 역전되었다는\n 것은 이미 이전에 방문한 노드라는 뜻이다.\n\n만약 그냥 싸이클이 있는지만 찾는거라면 이쯤에서 종료해도\n 된다. 익셉션을 날리든 리턴을 해버리든 하면 만사 오케이다. 하지만\n 여기서는 모든 SCC를 찾아야 하기 때문에, 여기서 끝내면 안되고 그\n 다음 SCC도 찾아야 한다. 어떻게 해야할까?\n\nDFS를 재귀적으로 구현하면, 다음 노드를 방문 후에 다시 돌아온다는\n 사실을 활용할 수 있다. 싸이클을 찾게 되면 랭크가 역전하게 되고, 이\n 역전된 랭크가 곧 싸이클 안에서의 랭크 최소값이 된다. 이 최소값을 재귀\n 호출 완료할 때 리턴하면, 각 노드의 랭크와 이 최소 랭크를 비교해서\n “내가 지금 싸이클에 있는가?”를 알 수 있을 것이다. 즉, 아래 그림처럼,\n\n0(1) ---- 1(0) --- 3(3)\n \\        /\n0 \\      / 0\n     2(2)\n\n\n노드 1 방문 -&gt; 노드 0 방문 -&gt; 노드 2 방문 -&gt; 노드 0을 다시\n 방문하게 되면서 싸이클임을 알게 되고, 최소 랭크인 0을 리턴 -&gt; 2의\n 랭크인 2와 비교해서 더 작으므로 싸이클이고, 다시 0을 리턴 -&gt;\n 0의 랭크인 1보다 작으므로 싸이클이고, 다시 0을 리턴 -&gt; 1의\n 랭크인 0과 같으므로 싸이클이고, 다음 탐색 계속 -&gt; …\n\n이런 느낌이 된다. 이를 구현해보자.\n\nfrom collections import defaultdict\n\ndef critical_connections(n, connections):\n    graph = defaultdict(set)\n    edges = set()\n    for src, snk in connections:\n        graph[src].add(snk)\n        graph[snk].add(src)\n        edges.add((min(src, snk), max(src, snk)))\n\n    ranks = [None] * n\n    def dfs(node, r):\n        if ranks[node]:\n            return ranks[node]\n\n        ranks[node] = r\n\n        min_rank = r + 1\n        for neighbor in graph[node]:\n            # skip parent\n            if ranks[neighbor] and ranks[neighbor] == r - 1:\n                continue\n\n            rr = dfs(neighbor, r + 1)\n            if rr &lt;= r:\n                # if current rank is less than or equals to recursive rank,\n                # the edge (node, neighbor) must be a part of scc\n                edges.remove((min(node, neighbor), max(node, neighbor)))\n\n            # update min_rank\n            min_rank = min(min_rank, rr)\n        # if you want to group all SCC, uncomment below:\n        # ranks[node] = min_rank\n        return min_rank\n\n    dfs(0, 0)\n    return edges\n\n\n  그래프를 나타내기 위해서 defaultdict(set)을 사용했다. OCaml로\nPS할 때에도 자주 쓰던 테크닉이다. 그래프는 Set의 Hash Table이다.\n  여기서는 SCC에 속하지 않는 엣지를 알아야 하기 때문에, 그래프의\n모든 엣지를 edges에 담아둔다. min, max를 이용해서\nnormalize하는 것을 잊지 말자.\n  노드의 랭크를 초기화할 때 [None] * n으로 했다. 리스트 안에 들어간\n값이 상수라서 다행히 업데이트가 전파되진 않는다. 만약 [[]] * n이\n필요한 경우였다면 모든 업데이트가 공유되어 버리니 주의하자.\n  DFS의 base case가 달라졌다. 원래는 visited 체크를 해야하지만,\n여기서는 단순히 “이미 계산한 랭크가 있나?” -&gt; “있다면 그걸\n리턴하자”가 된다.\n  r은 지금 방문하는 노드 node의 랭크이고, 그 다음 방문할 랭크의\n최소 랭크 후보는 r+1이다.\n  바로 직전에 방문한 부모 노드를 확인하는 로직을 주의하자. 일단\n계산한 랭크가 있어야 되고 (ranks[neighbor]), 이 값이 지금\n랭크보다 1 작아야 한다(ranks[neighbor] == r - 1).\n  부모가 아니라면, DFS 탐색을 해서 이른바 Recursive Rank를\n계산한다. 이 값이 지금 랭크보다 작거나 같으면, 지금 탐색 중인\n엣지는 싸이클에 속한다. 따라서 전체 엣지에서 삭제해준다.\n  이 DFS는 최종적으로 최소 랭크를 리턴해야 하므로, min_rank를\n업데이트해주고 이를 리턴한다.\n\n\n처음에는 ranks를 전부 min_rank로 업데이트 해야 하지 않나? 라고\n 생각했는데, 여기서는 싸이클이 아닌 엣지를 구하는게 목표라서 굳이\n 그럴 필요가 없었다. 만약 다른 문제에서, 예를 들어 모든 SCC를 구하라\n 하는 문제가 나온다면, min_rank를 리턴하기 직전에 ranks[node] =\n min_rank로 적절히 업데이트 해주고, ranks 전체를 훑으면서 같은\n 랭크를 가진 노드끼리 그룹화하면 된다."
					}
					,
					"wip-front-end-css": {
						"id": "wip-front-end-css",
						"title": "CSS",
						"version": "all",
						"categories": "",
						"url": " /wip/front-end/css/",
						"content": "CSS\n\nSelector\n\n*\n\n  페이지 전체 요소를 선택\n  보통 margin, padding 등의 디폴트 값을 설정\n  이거 처리하는데 오버헤드가 좀 있음\n  탑레벨 뿐만 아니라 자식 선택자에도 쓸 수 있음\n\n\ntype\n\n  해당 타입의 요소 전체를 선택\n  페이지 전체의 특정 요소 타입 e.g., a나 ul 을 선택함\n\n\n#id\n\n  아이디 선택자\n  아이디는 페이지에서 딱 하나 존재하므로 사용처를 고민해야 함\n\n\n.class\n\n  클래스 선택자\n  클래스는 여러 개 있을 수 있으므로 적절\n\n\nP C\n\n  자손(Descendant) 선택자\n  P로 선택된 요소 안에 있는 C 요소 전체를 선택함\n  자손이므로 부모 요소와 선택된 자손 요소 사이의 뎁스가 좀 되어도\n선택됨\n\n\nP &gt; C\n\n  직계 자식 (Direct Children) 선택자\n  P가 부모인 C만을 선택함\n\n\nX + Y\n\n  Adjacent 선택자… 라는데, X 바로 다음에 나오는 첫번째 Y만\n선택함\n  이거 쓸 일이 얼마나 되려나?\n\n\nX ~ Y\n\n  Sibling Combinator… 라는데, X + Y랑 거의 비슷한데 좀더\n너그럽다고 한다.\n  X가 앞서는 모든 Y 요소를 선택함\n\n\n:pseudo-class\n\n  가상 클래스 (Pseudo-class) 선택자. 엄청 많은 가상 클래스들이\n있다…\n\n\n\n  \n    \n      X:pseudo-class\n      설명\n    \n  \n  \n    \n      X:link\n      링크를 클릭하기 전 상태의 앵커 태그를 선택\n    \n    \n      X:visited\n      예전에 링크를 클릭했던 상태의 앵커 태그를 선택\n    \n    \n      X:checked\n      버튼, 체크박스 같은 “체크됨” 상태를 가지는 태그를 선택\n    \n    \n      X:before\n      요소 컨텐츠 바로 앞에 생성되는 자식 요소를 선택\n    \n    \n      X:after\n      요소 컨텐츠 바로 뒤에 생성되는 자식 요소를 선택\n    \n    \n      X:hover\n      유저 액션이랑 관련된 가상 클래스로 해당 요소 위에 커서가 올라가 있는 상태를 선택\n    \n    \n      X:not(Y)\n      모든 X 중에서 Y를 뺀 것을 선택\n    \n  \n\n\n::pseudo-element\n\n  가상 요소 (Pseudo-element) 선택자. 역시 엄청 많다…\n  맨 처음이나 마지막 항목에 대해서 세세한 조절을 할 때 유용하게\n쓰인다.\n\n\n\n  \n    \n      X::pseudo-element\n      설명\n    \n  \n  \n    \n      X::first-line\n      첫 번째 줄\n    \n    \n      X::first-letter\n      첫 번째 글자\n    \n    \n      X::first-child\n      첫 번째 자식 요소\n    \n    \n      X::last-child\n      마지막 자식 요소\n    \n    \n      X::nth-child(n)\n      1-indexed 기준 n번째 자식 요소\n    \n    \n      X::nth-last-child(n)\n      1-indexed 기준 마지막에서 n 번째 자식 요소\n    \n    \n      X::nth-of-type(n)\n      1-indexed 기준 n 번째 자식 요소 타입\n    \n    \n      X::nth-last-of-type(n)\n      1-indexed 기준 마지막에서 n 번째 자식 요소 타입\n    \n  \n\n\n단위 속성\n\n  px: 필셀 단위 (절대). 참고로 font-size 기본 값은 16px이다.\n  %: 부모 요소가 만들어준 공간 안에서의 비율.\n  em: 해당 요소에서의 폰트 사이즈의 배수. 예를 들어서 디폴트 폰트\n크기가 16px이므로 1.5em을 적용하면 16 의 1.5배인 24px이\n된다. 기준 값만 정하면 나머지는 다 이 기준 값에 대한 상대적인\n크기로 들어가므로 가장 많이 쓰인다.\n  rem: 문서의 기본값에 대한 배수. em과 비슷하지만 좀 다른 것이\nem은 해당 요소가 쓰여진 곳(부모 태그)의 기준 값에 따라\n달라지지만, rem은 문서 전체의 기준 값에 따라 달라진다.\n\n\n박스 속성\n\n  height, width: 제일 안쪽의 컨텐츠 크기\n  padding: 컨텐츠와 테두리 사이\n  border: 컨텐츠 + 패딩을 감싸는 테두리. 여기까지가 “눈에 보이는\n컨텐츠 크기”라고 봐도 될듯?\n  margin: 박스를 배치할 때 다른 박스와의 사이에 두는 거리"
					}
					,
					"ps-leetcode-data-stream-as-disjoint-intervals": {
						"id": "ps-leetcode-data-stream-as-disjoint-intervals",
						"title": "Data Stream As Disjoint Intervals",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/data-stream-as-disjoint-intervals/",
						"content": "Data Stream As Disjoint Intervals\n\n  대놓고 문제에 Disjoint가 있으므로 유니온 파인드를 가져다 써야 한다는 감이\n    온다.\n  addNum(int value) 으로 정수 가 하나씩 추가되므로, 추가된 정수 앞 뒤 범위, 즉 -1 과 +1\n    범위를 봐서 이미 집합이 있으면 그때가 바로 합쳐야 하는 시점이다.\n  집합의 대표 원소 뿐만 아니라 그 집합의 범위 정보도 같이 저장하자. 그러면\n    다음과 같이 두 범위를 합칠 수 있다: (두 범위의 시작점 중 최소, 두 범위의 끝점\n    중 최대). 이게 동작하는 이유는 모든 범위가 항상 Disjoint 하다는 invariant가\n    성립하기 때문이다.\n  getIntervals() 에서 정렬을 한번 해야하긴 하지만, 평균적으로 입력들이 인터벌로\n    합쳐져있을 것이기 때문에 복잡도가 크지 않다.\n\nclass DisjointSet:\n    def __init__(self):\n        self.reps = {}\n        self.itv = {}\n\n    def make_set(self, x):\n        if x in self.reps:\n            return\n        self.reps[x] = x\n        self.itv[x] = (x, x)\n\n    def find(self, x):\n        if x not in self.reps:\n            return None\n        if x != self.reps[x]:\n            self.reps[x] = self.find(self.reps[x])\n        return self.reps[x]\n\n    def union(self, x, y):\n        x, y = self.find(x), self.find(y)\n        if x is None or y is None or x == y:\n            return\n        # merge two intervals here.\n        # invariant: all intervals are disjoint.\n        self.reps[x] = y  # merge x to y\n        itvx, itvy = self.itv[x], self.itv[y]\n        del self.itv[x]\n        self.itv[y] = (min(itvx[0], itvy[0]), max(itvx[1], itvy[1]))\n\nclass SummaryRanges:\n    def __init__(self):\n        self.ds = DisjointSet()\n\n    def addNum(self, value: int) -&gt; None:\n        self.ds.make_set(value)\n        self.ds.union(value, value-1)\n        self.ds.union(value, value+1)\n\n    def getIntervals(self) -&gt; List[List[int]]:\n        return sorted(self.ds.itv.values())"
					}
					,
					"ps-leetcode-decode-ways": {
						"id": "ps-leetcode-decode-ways",
						"title": "Decode Ways",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/decode-ways/",
						"content": "Decode Ways\nA-Z를 담은 메시지는 다음과 같은 규칙에 의해서 숫자로 인코딩할 수\n 있다:\n\n'A' -&gt; \"1\"\n'B' -&gt; \"2\"\n...\n'Z' -&gt; \"26\"\n\n\n이렇게 인코딩된 메시지를 디코딩하려면, 이 맵핑을 거꾸로 적용해서\n 숫자들을 묶어야 한다. 그러면 가능한 경우가 여러 개일 수 있다. 예를\n 들면, “11106”은:\n\n(1 1 10 6) -&gt; \"AAJF\"\n(11 10 6)  -&gt; \"KJF\"\n\n\n이때 (1 11 06) 으로 묶는 것은 불가능하다. 왜냐하면 6과 06은\n 다르기 때문이다.\n\n숫자가 담긴, 즉 인코딩된 메시지가 주어졌을 때, 이걸 디코딩할 수 있는\n 방법의 개수를 구하자. 이 개수는 32 비트 정수 범위 안임이 보장된다.\n\nDynamic Programming\n내가 좋아하지 않는 토픽 두 가지가 섞인 문제다: 문자열 &amp; 다이나믹\n 프로그래밍. 문자열 문제는 대부분 수수께끼 같고, 다이나믹 프로그래밍은\n 점화식을 끌어내기가 어렵기 때문에 별로 선호하지 않는다. 그래도 피할\n 수 없으니 어쩌겠나. 되도록 즐기려고 노력할 수 밖에.\n\n주어진 숫자 문자열을 순서대로 가면서, 그 다음 가능한 선택지가 뭘지\n 판별해 나가보자. 이때, 중복되는 부분이 있을까? “2326” 문자열을 가지고\n 생각해보자.\n\n\"2326\"\n\"2\" -&gt; \"3\" -&gt; (2, 6), (26)\n\"23\" -&gt; (2, 6), (26)\n\n\n즉, “2”로 디코딩한 경우, 그 다음은 “3”만 디코딩 가능하니까 (32 &gt;\n 26) 남은 2, 6으로 가능한 경우는 두 가지 뿐이다. 그 다음 “23”을\n 디코딩한 경우, 역시 또 2, 6이 남고 이때 개수는 기존에 계산한 결과와\n 같다. 즉, 이 문제는 부분 문제로 쪼갤 수 있고, 부분 문제 중에서\n 중복되는 부분이 존재한다.\n\n그럼 어떻게 계산할 수 있을까? 인덱스를 기준으로 0부터 재귀적으로\n 시작해서, 가능한 경우에 따라 문자 1개 (i + 1) 또는 2개 (i + 2) 씩\n 확인한다고 해보자. 먼저 base case는 뭘까? 당연히 떠오르는 것 중\n 하나는 지금 위치의 문자가 0이면 가능한 개수도 0이다. 왜냐하면\n 인코딩이 1부터 시작하기 때문이다.\n\n또, 이렇게 하나 또는 둘 씩 가능한 경우를 확인하면서 문자열의 끝에\n 도달한 경우에는 최종적으로 가능한 1개를 찾은 것이다. 그런데 여기서\n 문자 1개 또는 2개를 확인하기 때문에 고려해야 할 사항이 있다. 예를\n 들어 “26”을 디코딩한다고 해보자. 그러면 가능한 경우는 아래와 같다.\n\n\n  i=0이고 1개를 확인(2) -&gt; 그 다음 i=1이고 1개를 확인(6) -&gt;\ni=1 이고 끝에 도달했으므로 1개 리턴\n  i=0이고 2개를 확인(26) -&gt; i=2 이고 끝에 도달했으므로 1개 리턴\n\n\n둘 다 끝에 도달한 건 맞지만 이때 1번과 2번의 경우 인덱스의 값이\n 다르다. 첫번째 경우는 i=1일 때 끝나는데 이는 곧 len - 1이다. 반면\n 두 번째 경우는 한번에 두 글자를 확인했기 때문에 i=2가 되고 이때는\n len과 같다. 따라서, “끝에 도달함”은 이 두 가지를 모두 고려해야\n 한다.\n\n그런데 여기서 또 하나 tricky한 부분이 있다. len - 1, 즉 한 글자의\n 유효함을 확인하기 전에, 현재 인덱스의 문자가 유효한지를 확인해야\n 한다. 즉, 지금 인덱스의 문자가 0인지 아닌지를 확인해야\n 한다. 왜냐하면, 이전까지 하나 또는 두개씩 잘 확인해오다가 갑자기\n 마지막에 0이 나와버리면, 디코딩 가능한 경우가 없기 때문이다.\n\n횡설수설 말이 많았는데, 아직 내가 핵심을 간결하게 설명하지 못하는 것\n 같다. 일단 코드로 작성해보자.\n\nfrom functools import cache\ndef num_decoding(s):\n\n    @cache\n    def count_valid(idx):\n        # base 1: end of 2-char check\n        if idx == len(s):\n            return 1\n\n        # base 2: impossible\n        if s[idx] == '0':\n            return 0\n\n        # base 3: end of 1-char check\n        if idx == len(s) - 1:\n            return 1\n\n        # accum 1-char\n        answer = count_valid(idx + 1)\n\n        # accum 2-char\n        if int(s[idx:idx + 2]) &lt;= 26:\n            answer += count_valid(idx + 2)\n\n        return answer\n\n    return count_valid(0)\n\n\n\n  앞서 말했듯 중복되는 부분이 있을 수 있기 때문에 (거의 무조건 있다고\n보면 된다) 기존 계산 결과를 메모아이제이션 하기 위해서 @cache\n어노테이션을 붙여준다.\n  제일 먼저 len(s)인 경우를 확인해준다. 이건 마지막 직전에서 문자\n두 개를 확인할 때 가능한 케이스인데, 이걸 먼저 해줘야 이후 로직에서\n인덱스가 아웃 바운드 되지 않는다.\n  그 다음은 먼저 지금 인덱스가 0인지 확인한다. 이럼 가능한 경우가\n없기 때문이다.\n  그리고 최종적으로 끝에 도달했으면, 1개가 가능하다고 리턴한다.\n  개수를 셀 때에도 먼저 1개 문자가 가능한지를 누적하고, 그 다음 2개가\n가능하다면(&lt;= 26) 2개를 누적한다."
					}
					,
					"ps-leetcode-delete-operation-for-two-strings": {
						"id": "ps-leetcode-delete-operation-for-two-strings",
						"title": "Delete Operation for Two Strings",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/delete-operation-for-two-strings/",
						"content": "Delete Operation for Two Strings\n\n두 문자열 word1과 word2가 주어졌을 때, word1과 word2를 같은\n 문자열을 만들기 위한 삭제 연산의 최소 횟수를 구하자.\n\n한 번의 연산에서는 두 문자열 중 하나에서 딱 하나의 글자를 삭제할 수\n 있다.\n\n문자열의 길이는 최대 500이고 알파벳 소문자만 담고 있다.\n\nLCS\n\n처음에 이 문제를 읽었을 때 “그냥 두 문자열에서 공통되는 글자만 남기면\n 그게 답 아닌가?” 싶어서 다음과 같이 짰었다.\n\nfrom collections import Counter\ndef minDistance(word1, word2):\n    intersect = Counter(word1) &amp; Counter(word2)\n    return len(word1) + len(word2) - sum(intersect.values()) * 2\n\n\n하지만 이렇게하니 바로 반례가 튀어나온다: “sea”와 “ate”.\n\n즉, 위와 같이 공통된 글자만 남겨버리면, 글자 간의 순서를\n 무시해버리기 때문에 올바른 답을 구할 수 없다.\n\n이 문제는 공통 부분열의 최장 길이\n 문제를 응용하면 쉽게 풀린다. 즉, 최소의 삭제 연산으로 남기는 최종\n 결과물이 곧 두 문자열의 공통 부분열 중 가장 긴 문자열인\n 것이다. 따라서, LCS를 알면 위의 틀린 접근의 수식과 거의 유사한\n 방법으로 풀 수 있다.\n\nimport functools\ndef minDistance(word1, word2):\n    @functools.cache\n    def lcs(i1, i2):\n        if i1 == len(word1) or i2 == len(word2):\n            return 0\n\n        if word1[i1] == word2[i2]:\n            return 1 + lcs(i1 + 1, i2 + 1)\n        else:\n            return max(lcs(i1 + 1, i2), lcs(i1, i2 + 1))\n\n    return len(word1) + len(word2) - lcs(0, 0) * 2"
					}
					,
					"ps-leetcode-design-add-and-search-words-data-structure": {
						"id": "ps-leetcode-design-add-and-search-words-data-structure",
						"title": "Design Add and Search Words Data Structure",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/design-add-and-search-words-data-structure/",
						"content": "Design Add and Search Words Data Structure\n\n새로운 단어를 사전에 추가하는 기능과, 사전에서 단어를 검색하는 기능을\n 지원하는 데이터 구조를 구현하자. WordDictionary 클래스에는 다음\n 함수가 있다.\n\n  생성자\n  void addWord(word): 단어 추가\n  bool search(word): 단어 검색\n\n\n단어의 길이는 1~25이고 모두 알파벳 소문자로만 이뤄진다. 검색할\n 단어에는 .이 포함될 수 있는데, 이는 모든 알파벳과\n 매칭된다. 검색에는 최대 3개의 .이 포함될 수 있다. 최대 \\(10^4\\)번의\n 함수 호출이 이뤄지는 환경을 고려하자.\n\n트라이\n\n요런 검색 문제는 보통 트라이가 가장 쉬운 접근이다. 단어가 추가될\n 때마다 트라이에 단어를 추가하면 된다. 단, 고려해야 하는 부분은 바로\n 검색에서 .이 있는 부분이다. 모든 알파벳이 매칭될 수 있기 때문에,\n 검색 부분을 잘 구현해야 한다.\n\nclass WordDictionary:\n    def __init__(self):\n        self.trie = {}\n\n    def addWord(self, word):\n        node = self.trie\n        for letter in word:\n            if letter not in node:\n                node[letter] = {}\n            node = node[letter]\n        node['$'] = True\n\n    def search(self, word):\n\n        def dfs(node, idx):\n            if not node:\n                return False\n            if idx == len(word):\n                return '$' in node\n\n            letter = word[idx]\n            if letter == '.':\n                for key in node:\n                    if key != '$' and dfs(node[key], idx + 1):\n                        return True\n                return False\n            if letter not in node:\n                return False\n            return dfs(node[letter], idx + 1)\n        return dfs(self.trie, 0)\n\n\n\n  트라이는 간단히 딕셔너리로 구현했다. 단어의 끝을 알리기 위해서\n특별한 키 $를 사용했다.\n  검색 함수의 경우 DFS로 구현했는데, 베이스 케이스와 다음 공간을 잘\n구분해야 한다. 특히 인덱스가 단어의 끝에 왔을 때에는 $ 키가\n있는지를 확인해야 한다. 현재 단어가 .일 때에는 모든 키에 대해서\nDFS를 수행해야 한다. 이때 Early Return을 위해서 중간에 단어를\n찾으면 곧바로 리턴한다.\n\n\n이렇게하면 기능은 잘 구현하긴 한데, 이런 트라이 문제를 풀 때마다\n 느끼는게 생각보다 트라이가 빠르진 않은 것 같다. 데이터가 더 큰\n 상황에서 잘 동작하려나? 아무튼 10초 이상이 걸린다.\n\n탐색\n\n그러면 좀더 빠르게, 좀더 똑똑하게 탐색하는 방법을 생각해보자.\n\n일단 프루닝을 생각해보자. 가장 먼저 떠오르는 것은 검색 단어에 .이\n 없는 경우이다. 이때는 곧바로 사전에서 탐색해볼 수 있다.\n\n문제의 조건에서 단어의 길이가 최대 25인 것을 활용해보자. 최대 10,000\n 번이 호출되기 때문에 데이터가 잘 분포되어 있다면 같은 길이의 단어가\n 10,000 / 25 = 400개가 될 것이라고 기대할 수 있다. 400개는 리얼\n 월드에서는 아주 적은 데이터이고, 이 정도 사이즈에서 탐색/정렬하는\n 것은 아주 값싼 작업이다. 이 관찰을 근거로, 사전을 트라이가 아니라\n 같은 단어끼리 묶어서, 일종의 버킷을 만들어서 관리할 수 있다.\n\n이렇게하면 .가 포함되지 않았을 때의 단어 검색은 해시 테이블과 해시\n 셋을 이용해서 O(1)에 가능하다. 문제는 .인데, 이때는 특별한\n 방법없이 일일이 다 검색해도 좋다.\n\nfrom collections import defaultdict\nclass WordDictionary:\n    def __init__(self):\n        self.buckets = defaultdict(set)\n\n    def addWord(self, word):\n        self.buckets[len(word)].add(word)\n\n    def search(self, word):\n        if '.' not in word:\n            return word in self.buckets[len(word)]\n\n        candidates = self.buckets[len(word)]\n        for cand in candidates:\n            for cand_letter, word_letter in zip(cand, word):\n                if word_letter != '.' and cand_letter != word_letter:\n                    break\n            else:\n                return True\n        return False\n\n\n\n  검색 키워드에 .가 있는 경우, 단어 길이의 버킷에서 후보 목록을 다\n꺼내와서 일일이 맞춰본다. 이때 Early Return을 위해서 파이썬의 for\nelse\n구문을 사용하고 있다. for 반복문이 정상적으로 완료되고 나면\nelse 부분을 실행한다. 만약 도중에 for 반복문 안에서 break가\n일어나서 강제적으로 루프를 빠져나온다면 else는 실행되지\n않는다. 즉, 검색 키워드와 단어 후보를 매칭하면서 키워드의 글자가\n.이 아닌데 단어 후보의 글자와 다르면 빠져나오고, 그렇지 않으면\nfor 반복문을 끝까지 수행하게 되는데 이 케이스가 바로 매칭되는\n단어를 찾은 경우이고 else에 들어갈 수 있다."
					}
					,
					"ps-leetcode-design-search-autocomplete-system": {
						"id": "ps-leetcode-design-search-autocomplete-system",
						"title": "Design Search Autocomplete System",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/design-search-autocomplete-system/",
						"content": "Design Search Autocomplete System\n\n말 그대로 검색 엔진의 자동완성 시스템을 디자인하고 구현하는 문제다.\n\n먼저 기존의 레거시가 입력으로 들어온다. 문장 배열 sentences와 해당\n 문장이 몇 번 나타났는지를 나타내는 times 배열이\n 들어온다. sentences[i]는 times[i]번 과거에 검색되었다. 두 배열의\n 길이는 같다.\n\n각 입력은 한 글자씩 타이핑 된다. 특수 문자 #는 입력의 끝을 알리는\n 것이다. 매 타이핑마다 과거의 기록 중 지금까지 타이핑한 문장이\n 접두사로 일치하는 문장 중에서 가장 많이 검색된 것 탑 3를 찾아서\n 리턴한다.\n\n\n  문장의 “핫한 정도(hot degree)”는 정확히 같은 문장을 유저가 이전에\n몇 번이나 타이핑했는지에 따라 결정된다.\n  핫한 정도에 따라 정렬된 문장 중 탑 3를 리턴한다. 같은 문장이 여러\n개 있다면 아스키 코드 순으로 정렬한 것이 먼저 나온다.\n  탑 3개 3개 미만이라면 최대한 많이 찾아서 리턴한다.\n  특수문자 #는 문장이 끝났다는 의미이며, 이 때는 빈 리스트를\n리턴한다.\n  특수문자 #가 나오기 이전까지 작성한 문장은 히스토리에 기록되어야\n한다.\n\n\n입력으로 주어지는 문장 개수는 1~100개다. 최대 5천번의 함수 호출이\n 이루어진다. 문장은 소문자 영어와 공백 뿐이다. 입력은 소문자 영어와\n 공백, # 뿐이다.\n\n트라이\n이 문제를 푸는 방법은 트레이드 오프에 따라 크게 두 가지가\n 있다. 하나는 메모리를 왕창 써서 시간 복잡도를 줄이는 것이고, 다른\n 하나는 메모리를 아끼는 대신 시간 복잡도를 조금 희생하는 것이다. 먼저\n 메모리를 왕창 희생하는 버전을 보자.\n\n접두사가 일치하는 … 이라는 문장에서 대놓고 힌트를 주듯이, 이 문제는\n 트라이를 도입해서 풀 수 있다. 추가로 트라이의 각 노드에 부가적인\n 정보를 매달아두면 메모리를 희생해서 복잡도를 잡을 수 있을 것 같다.\n\n그럼 각 노드에는 뭘 매달아야 할까? “핫한 정도”를 곧바로 매달면\n 안될까? 문제의 조건에 따라 #로 문장이 끝나면 입력된 문장이\n 히스토리에 기록되어야하기 때문에, 단순한 접근으로는 어렵다.\n\n처음에는 힙을 도입해서 검색 횟수대로 딱 3개만 남기려고 했는데, 아래\n 두 가지 트레이드 오프가 있다.\n\n  딱 3개만 남기면 문제의 조건을 만족하지 못한다. 예를 들어, 횟수만\n봤을 때 (3, 3, 2) 의 탑 3개만 유지하고 있었는데 만약 횟수 순으로\n4번째가 2회였고, 이번 입력으로 1이 증가된다면? 순서가 바뀌어야\n한다. 따라서, “탑 3”라고 해서 정말로 세개만 추적하면 안된다. 다\n기록해야 한다.\n  힙은 가장 순서가 많은(혹은 적은) 딱 한가지 원소를 곧바로 빼올 때에\n유용하다. 우리는 탑 3개가 필요하고, 계속 기존 원소의\n우선순위(횟수)가 업데이트 되어야 한다. 뭔가 해킹할 여지는 있지만\n그러고 싶진 않다.\n\n\n그래서, 가능한 방법은 아래 두 가지이다.\n\n  메모리를 적당히 희생하는 방법: 트라이의 각 노드에 횟수를 기록하고,\n입력이 들어오면 일단 (횟수, 문장)을 전부 복원한 다음 횟수 순으로\n정렬해서 탑 3를 구하는 방법\n  메모리를 많이 희생하는 방법: 트라이의 각 노드에 해당 접두사를 갖는\n문장의 횟수를 전부 기록해두고, 입력이 들어오면 바로 정렬해서 탑\n3를 구하는 방법\n\n\n쉽게 말해 1번은 트라이 위에서 DFS/BFS를 이용해서 매번 문장을 다\n 복원해준 뒤에 정렬하는 방법이고, 2번은 문장과 횟수를 노드마다 다\n 유지해서 곧바로 정렬하는 방법이다. 1번이 그나마 메모리를 덜 쓰지만,\n 매번 탐색해야 하고, 2번은 메모리를 엄청나게 쓸 것 같지만 탐색을\n 덜한다.\n\n여기서는 2번으로 구현해 보았다.\n\nfrom collections import Counter\nclass Trie:\n    class Node:\n        def __init__(self):\n            self.children = [None] * 27\n            self.counts = Counter()\n        def __contains__(self, key):\n            return self[key] is not None\n        def __getitem__(self, key):\n            idx = ord(key) - ord('a') if ord('a') &lt;= key &lt;= ord('z') else 26\n            return self.children[idx]\n        def __setitem__(self, key, value):\n            idx = ord(key) - ord('a') if ord('a') &lt;= key &lt;= ord('z') else 26\n            self.children[idx] = value\n\n        def update(self, sentence, time=1):\n            self.counts[sentence] += time\n\n    def __init__(self, sentences, times):\n        self.sentinel = Trie.Node()\n        for s, t in zip(sentences, times):\n            self.add(s, t)\n    def add(self, sentence, time=1):\n        node = self.sentinel\n        for char in sentence:\n            if char not in node:\n                node[char] = Trie.Node()\n            node = node[char]\n            node.update(sentence, time)\n\n    def top3(self, sentence):\n        node = self.sentinel\n        for char in sentence:\n            if char not in node:\n                return []\n            node = node[char]\n        return [n[0] for n in sorted(node.counts.items(), key=lambda x: (-x[1], x[0]))][:3]\n\nclass AutocompleteSystem:\n    def __init__(self, sentences, times):\n        self.trie = Trie(sentences, times)\n        self.query = []\n    def input(self, c):\n        if c == '#':\n            self.trie.add(''.join(self.query))\n            self.query.clear()\n            return []\n        else:\n            self.query.append(c)\n            return self.trie.top3(self.query)\n\n\n  top3 함수는 매번 정렬을 한다. 이때 조건에 따라 (1) 횟수 기준\n오름차순, (2) 아스키코드 기준 내림차순으로 정렬하기 위해서 키로\n튜플을 넘겨준다.\n  add 함수는 문장을 넣을 때마다 모든 노드에 매달린 문장 횟수를\n업데이트 한다.\n\n\n이렇게하면 통과하긴 하지만, 문제의 입력이 생각보다 작아서 오히려\n 시간이 그렇게 빠르지 않다.\n\n매번 정렬\n그래서 두 번째 방법인, 메모리를 덜 쓰면서 시간 복잡도를 조금\n 희생하는, 입력의 부분을 유지하면서 매번 정렬하는 방법을\n 적용해보았다. 사실 이게 코드도 더 깔끔하고 입력이 작을 때 더\n 빠르다. 파이썬 팀소트의 위력이다.\n\nfrom collections import Counter\nclass AutocompleteSystem:\n    def __init__(self, sentences, times):\n        self.query = []\n        self.matches = []\n        self.counts = Counter()\n        for s, t in zip(sentences, times):\n            self.counts[s] = t\n    def input(self, c):\n        if c == '#':\n            s = ''.join(self.query)\n            self.counts[s] += 1\n            self.query.clear()\n            self.matches = []\n            return []\n\n        if not self.query:\n            self.matches = [(-c, s) for s, c in self.counts.items() if s[0] == c]\n            self.matches.sort()\n            self.matches = [s for _, s in self.matches]\n        else:\n            i = len(self.query)\n            self.matches = [s for s in self.matches if len(s) &gt; i and s[i] == c]\n\n        self.query.append(c)\n        return self.matches[:3]\n\n\n여기서의 핵심 아이디어는 쿼리가 비어있을 때, 즉 첫 글자가 들어왔을 때\n 처리하는 로직이다. 먼저 이전까지의 횟수를 세어둔 counts\n 딕셔너리에서 (-횟수, 문장)을 꺼내와서 원하는 순서로 정렬한\n matches를 만든다. 이때, 첫 글자가 지금 입력한 문자인 애들만\n 필터링한다. 그 다음 횟수를 드랍하고 문장만 냄겨둔다. 그 후 입력이\n 들어오면, 이때까지 쌓아둔 쿼리의 길이를 이용해 문장에서 봐야하는\n 접두사 인덱스를 알 수 있고, 이를 이용해서 매번 matches를\n 필터링하기만 하면 된다. 이미 우리가 원하는 순서로 정렬을 해 두었기\n 때문에, 여기서 필터링 되면 그냥 걔는 접두사 매치가 안된\n 것이다. 이러면 매번 정렬하지 않아도 되고, 마지막에 [:3]로 최대\n 3개만 리턴하면 된다.\n\n트라이보다 이게 훨씬 빠르게 동작한다."
					}
					,
					"ps-theory-dfs": {
						"id": "ps-theory-dfs",
						"title": "Depth First Search",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/dfs/",
						"content": "DFS\nFlood Fill은 BFS, DFS 둘 다 가능하지만 거리 측정은 BFS만 가능하고\n DFS로는 불가능하다.\n\nDFS는 그래프와 트리 탐색할 때 요긴하게 쓰인다."
					}
					,
					"ps-theory-disjoint-set": {
						"id": "ps-theory-disjoint-set",
						"title": "Disjoint Set",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/disjoint-set/",
						"content": "서로소 집합\n\n위키피디아 구현은 다음과 같다.\n\nfunction MakeSet(x)\n  x.parent := x\n\nfunction Find(x)\n  if x.parent == x\n    return x\n  else\n    return Find(x.parent)\n\nfunction Union(x, y)\n  xRoot := Find(x)\n  yRoot := Find(y)\n  xRoot.parent := yRoot\n\n\n최적화\n\n  Union by Rank: Rank를 기록해서, Union 연산을 할 때 항상 더 작은\n길이의 트리를 더 큰 길이의 트리에 합치는 방법이다.\n  Path Compression: Find 연산을 할 때마다, 모든 속한 원소의 부모를\n하나의 대표 원소를 가리키게 하는 방법이다.\n\n\n문제 풀이 수준에서 Union by Rank는 큰 효과가 없고, Path Compression만\n 해줘도 충분하다. 물론 프로덕션 레벨에서 서로소 집합을 엄청 오래\n 유지하는 거라면 두 최적화 모두 필요하다.\n\n구현\n\nclass DisjointSet:\n    def __init__(self):\n        self._reps = dict()\n        self._count = 0\n        self._elts = defaultdict(list)\n\n    def __len__(self):\n        return self._count\n\n    def make_set(self, x):\n        if x not in self._reps:\n            self._reps[x] = x\n            self._count += 1\n            self._elts[x].append(x)\n\n    def find(self, x):\n        if x != self._reps[x]:\n            self._reps[x] = self.find(self._reps[x])\n\n        return self._reps[x]\n\n    def union(self, x, y):\n        px, py = self.find(x), self.find(y)\n        if px == py:\n            return False\n        # always merge smaller one into larger one\n        if len(self._elts[px]) &gt; len(self._elts[py]):\n            px, py = py, px\n        self._reps[px] = py\n        self._elts[py].extend(self._elts[px])\n        self._elts[px] = []\n        self._count -= 1\n        return True\n\n\n위의 구현은 서로소 집합의 개수 _count와 각 집합의 원소 정보\n _elts_도 같이\n 추적한다(출처). 이\n 두 가지를 추적하지 않는 경우 find와 union의 시간 복잡도는 아커만\n 함수로 거의 선형 시간이다. _count는 복잡도에 영향을 주지\n 않는다. _elts를 추적하는 경우는 항상 작은 쪽에 합치는 구현을 하면\n union의 복잡도는 O(n*logn)이 된다.\n\nunion의 리턴 값은 두 원소가 합쳐졌는지 아닌지 여부다."
					}
					,
					"wip-distinguishing-coroutines-and-fibers": {
						"id": "wip-distinguishing-coroutines-and-fibers",
						"title": "Distinguishing Coroutines and Fibers",
						"version": "all",
						"categories": "",
						"url": " /wip/distinguishing-coroutines-and-fibers/",
						"content": "Distinguishing Coroutines and Fibers\n\nFrom\n N4024.\n\nBackground\n\nIt might be useful for the authors to disambiguate the conceptual\n space addressed by the coroutine library from the conceptual space\n addressed by the fiber library.\n\n코루틴 라이브러리가 다루는 개념적인 부분과 파이버 라이브러리가 다루는\n 개념적인 부분을 구분하는 것이 저자들에게 도움이 될 것 같다.\n\nFibers\nA Quick Sketch of the Fiber Library\n\nFor purposes of this paper, we can regard the term ‘fiber’ to mean\n ‘user-space thread.’ A fiber is launched, and conceptually it can\n have a lifespan independent of the code that launched it. A fiber can\n be detached from the launching code; alternatively, one fiber can\n join another. A fiber can sleep until a specified time, or for a\n specified duration. Multiple conceptually-independent fibers can run\n on the same kernel thread. When a fiber blocks, for instance waiting\n for a result that’s not yet available, other fibers on the same\n thread continue to run. ‘Blocking’ a fiber implicitly transfers\n control to a fiber scheduler to dispatch some other ready-to-run\n fiber.\n\n이 글의 목적을 위해, ‘파이퍼’가 ‘유저 공간 쓰레드’를 뜻한다고\n 간주한다. 한 파이버가 시작되면, 개념적으로는 그 파이버를 실행한\n 코드와는 독립적인 수명을 가질 수 있다. 파이버는 그 파이버를 실행한\n 코드로부터 분리(detach)될 수 있다. 대신, 한 파이버는 다른 파이버와\n 합쳐질 수 있다(join). 파이버는 지정된 기간만큼 또는 지정된 시간이 될\n 때까지 잠들 수 있다(sleep). 개념적으로 독립적인 여러 개의 파이버가\n 같은 커널 쓰레드 위에서 돌 수 있다. 파이버가 차단되면(block), 예를\n 들어 아직 쓸 수 없는 결과를 기다린는 경우, 같은 쓰레드에 있는 다른\n 파이버가 계속해서 실행될 수 있다. 파이버 ‘차단(blocking)’은\n 묵시적으로 파이버 스케쥴러에게 제어권을 넘겨줘서 실행될 준비가 된\n 다른 파이버를 파견할 수 있게(dispatch) 한다.\n\n\n\nFibers conceptually resemble kernel threads. In fact, the forthcoming\n fiber library proposal intentionally emulates much of the\n std::thread API. It provides fiber-local storage. It provides\n several variants of fiber mutexes. It provides condition_variables\n and barriers. It provides bounded and unbounded queues. It provides\n future, shared_future, promise and packaged_task. These\n fiber-oriented synchronization mechanisms differ from their thread\n counterparts in that when (for instance) a mutex blocks its caller,\n it blocks only the calling fiber - not the whole thread on which that\n fiber is running.\n\n파이버는 개념적으로 커널 쓰레드를 닮아있다. 사실, 다가오는 파이버\n 라이브러리 제안은 의도적으로 많은 std::thread API를 모방하고\n 있다. 제안은 파이버 로컬 스토리지를 제공한다. 파이버 뮤텍스의 여러\n 변종도 제공한다. condition_variables와 barriers도\n 제공한다. 바운드/언바운드 큐도 제공한다. future, shared_future,\n promise와 packaged_task도 제공한다. 이런 파이버 지향 동기화\n 메커니즘은 그와 대응하는 쓰레드 메커니즘과는 다른데, 예를 들어\n 뮤텍스가 그 호출자를 차단할 때는, 파이버가 실행 중인 쓰레드 전체가\n 아니라 호출한 파이버만 차단한다.\n\n\n\nWhen a fiber blocks, it cannot assume that the scheduler will awaken\n it the moment its wait condition has been satisfied. Satisfaction of\n that condition marks the waiting fiber ready-to-run; eventually the\n scheduler will select that ready fiber for dispatch.\n\n파이버가 차단될 때는, 나중에 조건이 충족될 때 스케쥴러가 그 파이버를\n 깨워줄거라고 가정해서는 안된다. 조건을 만족하면 그 파이버가 실행될\n 준비가 되었다고 표시할 뿐이다. 결국에는 스케쥴러가 그 파이버를\n 파견하긴 할 것이다.\n\n\n\nThe key difference between fibers and kernel threads is that fibers\n use cooperative context switching, instead of preemptive\n time-slicing. Two fibers on the same kernel thread will not run\n simultaneously on different processor cores. At most one of the\n fibers on a particular kernel thread can be running at any given\n moment.\n\n파이버와 커널 쓰레드 간의 핵심 차이점은 파이버는 선점적인 시간 배분\n 대신에 협력적인 컨텍스트 스위칭을 사용한다는 것이다. 같은 커널\n 쓰레드에 있는 두 개의 파이버는 서로 다른 프로세서 코어에서 동시에\n 실행되지 않는다. 어떤 주어진 순간에는 특정 커널 쓰레드에 있는 최대\n 하나의 파이버만 실행될 수 있다.\n\n\n\nThis has several implications:\n\n  Fiber context switching does not engage the kernel: it takes place\nentirely in user space. This permits a fiber implementation to\nswitch context significantly faster than a thread context switch.\n  Two fibers in the same thread cannot execute simultaneously. This\ncan greatly simplify sharing data between such fibers: it is\nimpossible for two fibers in the same thread to race each\nother. Therefore, within the domain of a particular thread, it is\nnot necessary to lock shared data.\n  The coder of a fiber must take care to sprinkle voluntary context\nswitches into long CPU-bound operations. Since fiber context\nswitching is entirely cooperative, a fiber library cannot guarantee\nprogress for every fiber without such precautions.\n  A fiber that calls a standard library or operating-system function\nthat blocks the calling thread will in fact block the entire thread\non which it is running, including all other fibers on that same\nthread. The coder of a fiber must take care to use asynchronous I/O\noperations, or operations that engage fiber blocking rather than\nthread blocking.\n\n\n이는 몇 가지 결과를 낳는다:\n\n  파이버 컨텍스트 스위칭에는 커널 쓰레드가 관여하지 않는다. 전적으로\n유저 공간에서 일어난다. 이는 파이버 구현체의 컨텍스트 스위치를\n쓰레드보다 엄청나게 빠르게 만든다.\n  같은 쓰레드에 있는 두 개의 파이버는 동시에 실행될 수 없다. 이는\n이런 파이버들 사이에서 데이터를 공유하는 것을 아주 간단하게\n만든다. 같은 쓰레드 위의 두 파이버가 데이터 레이스를 일으키는 것은\n불가능하다. 따라서, 특정 쓰레드의 도메인 안에서는, 공유 데이터에\n락을 걸 필요가 없다.\n  파이버 코드를 짤 때에는 반드시 긴 CPU 연산 작업 도중에 간간이\n자발적인 컨텍스트 스위치를 섞어야 함에 주의하자. 파이버 컨텍스트\n스위치는 전적으로 협력적이기 때문에, 파이버 라이브러리는 이런\n예방책이 없이는 모든 파이버가 진행된다는 것을 보장할 수 없다.\n  한 파이버가 호출한 쓰레드를 차단하는 표준 라이브러리 또는 운영체제\n함수를 호출하면, 이는 곧 그 파이버가 실행되고 있는 쓰레드 전체와\n거기 속한 모든 다른 파이버를 차단하게 된다. 파이버 코드를 짤 때에는\n비동기 입출력 연산을 사용하거나, 쓰레드 차단이 아니라 파이버 차단이\n일어나는 연산을 쓰도록 주의해야 한다.\n\n\n\n\nIn effect, fibers extend the concurrency taxonomy:\n\n  on a single computer, multiple processes can run\n  within a single process, multiple threads can run\n  within a single thread, multiple fibers can run.\n\n\n사실상, 파이버는 동시성 분류 체계를 확장한다:\n\n  하나의 컴퓨터 위에서는 여러 개의 프로세스를 실행할 수 있다.\n  하나의 프로세스 안에서는 여러 개의 쓰레드를 실행할 수 있다.\n  하나의 쓰레드 안에서는 여러 개의 파이버를 실행할 수 있다.\n\n\nA Few Fiber Use Cases\n\nA fiber is useful when you want to launch a (possibly complex)\n sequence of asynchronous I/O operations, especially when you must\n iterate or make decisions based on their results.\n\n파이버는 (아마도 복잡한) 일련의 비동기 입출력 연산을 실행할 때\n 유용한데, 특히 그 결과 값에 따라 반복하거나 결정을 내려야 하는 경우에\n 더욱 그렇다.\n\n\n\nDistinct fibers can be used to perform concurrent asynchronous fetch\n operations, aggregating their results into a fiber-specific queue for\n another fiber to consume.\n\n별개의 파이버는 동시성 비동기 Fetch 연산을 수행하는데 쓰여서 그 결과\n 값들을 파이버 특화 큐에 집계해서 다른 파이버가 소비하도록 할 수 있다.\n\n\n\nFibers are useful for organizing response code in a event-driven\n program. Typically, an event handler in such a program cannot block\n its calling thread: that would stall handlers for all other events,\n such as mouse movement. Handlers must use asynchronous I/O instead of\n blocking I/O. A fiber allows a handler to resume upon completion of\n an asynchronous I/O operation, rather than breaking out subsequent\n logic as a completely distinct handler.\n\n파이버는 이벤트 기반 프로그램에서 응답 코드를 정리하는데\n 유용하다. 일반적으로, 이런 프로그램의 이벤트 핸들러는는 호출 쓰레드를\n 차단할 수 없다. 그러면 마우스 움직임과 같은 다른 모든 이벤트에 대한\n 핸들러가 중단되기 때문이다. 핸들러는 차단 입출력 대신 비동기 입출력을\n 사용해야 한다. 파이버를 사용하면 후속 로직을 완전히 별개의 핸들러로\n 분리하는 것이 아니라, 비동기 입출력 작입어 완료되면 핸들러를 재개할\n 수 있다.\n\n\n\nFibers can be used to implement a task handling framework to address\n the C10k-problem. For instance\n strict fork-join task parallelism with its two flavours -\n fully-strict computation (no task can proceed until it joins all of\n its child-tasks) and terminally-strict computations (child-tasks\n are joined only at the end of processing) - can be\n supported. Furthermore, different scheduling strategies are possible:\n work-stealing and continuation-stealing. For work-stealing, the\n scheduler creates a child-task (child-fiber) and immediately returns\n to the caller. Each child-task (child-fiber) is executed or stolen by\n the scheduler based on the available resources (CPU etc.). For\n continuation-stealing, the scheduler immediately executes the spawned\n child-task (child-fiber); the rest of the function (continuation) is\n stolen by the scheduler as resources are available.\n\nCoroutines\nA Quick Recap of the Coroutine Library\n\nA coroutine is instantiated and called. When the invoker calls a\n coroutine, control immediately transfers into that coroutine; when\n the coroutine yields, control immediately returns to its caller (or,\n in the case of symmetric coroutines, to the designated next\n coroutine).\n\n\n\nA coroutine does not have a conceptual lifespan independent of its\n invoker. Calling code instantiates a coroutine, passes control back\n and forth with it for some time, and then destroys it. It makes no\n sens to speak of ‘detaching’ a coroutine. It makes no sense to speak\n of ‘blocking’ a coroutine: the coroutine library provides no\n scheduler. The coroutine library provides no facilities for\n synchronizing coroutines: coroutines are already synchronous.\n\n\n\nCoroutines do not resemble threads. A coroutine much more closely\n resembles an ordinary function, with a semantic extension: passing\n control to its caller with the expectation of being resumed later at\n exactly the same point. When the invoker resumes a coroutine, the\n control transfer is immediate. There is no intermediary, no agent\n deciding which coroutine to resume next.\n\nA Few Coroutine Use Cases\n\nNormally, when consumer code calls a producer function to obtain a\n value, the producer must return that value to the consumer,\n discarding all its local state in so doing. A coroutine allows you to\n write producer code that ‘pushes’ values (via function call) to a\n consumer that ‘pulls’ them with a function call.\n\n일반적으로, 소비자 코드가 생성자 코드를 호출해서 값을 가져올 때,\n 생성자는 반드시 그 값을 만드는데 쓰였던 모든 로컬 상태를 버리고 그\n 값을 소비자에게 리턴해야 한다. 코루틴은 (함수 호출을 통해) 소비자\n 코드에게 값을 ‘전달’해서 소비자가 함수 호출로 그 값을 ‘가져’올 수\n 있도록 생성자 코드를 작성할 수 있도록 해준다.\n\n\n\nFor instance, a coroutine can adapt callbacks, as from a SAX parser,\n to values explicitly requested by the consumer.\n\n예를 들어, 코루틴은 소비자가 명시적으로 요청한 값을 위해서 콜백을\n 적용할 수 있고 그 예시는 SAX 파서에서 볼 수 있다.\n\n\n\nMoreover, the proposed coroutine library provides iterations over a\n producer coroutine so that a sequence of values from the producer can\n be fed directly into an STL algorithm. This can be used, for example,\n to flatten a tree structure.\n\n게다가, 제안된 코루틴 라이브러리는 생성자 코루틴을 훑으면서\n 생성자로부터 곧바로 STL 알고리즘에 먹일 수 있는 일련의 값을 가져오는\n 반복문을 제공한다. 이 기능은 예를 들어서 트리 구조를 1차원적으로\n 펴는데 사용할 수 있다.\n\n\n\nCoroutines can be chained: a source coroutine can feed values through\n one or more fiber coroutines before those values are ultimately\n delivered to consumer code.\n\n코루틴은 또한 체이닝될 수 있다. 시작 코루틴은 값이 궁극적으로 소비자\n 코드에게 전달되기 전에 그 값을 하나 이상의 파이버 코루틴에 먹일 수\n 있다.\n\n\n\nIn all the above examples, as in every coroutine usage, the handshake\n between producer and consumer is direct and immediate.\n\n모든 위의 예시에서 보듯이, 모든 코루틴 사용처에서 생성자와 소비자\n 간의 핸드셰이크는 직접적이고 즉각적이다.\n\nRelationship\n\nThe authors have a reference implementation of the forthcoming fiber\n library from boost.fiber. The reference implementation is entirely\n coded in portable C++; in fact its original implementation was\n entirely in c++03. This is possible because the reference\n implementation of the fiber library is built on boost.coroutine,\n which provides context management. The fiber library extends the\n coroutine library by adding a scheduler and the aforementioned\n synchronization mechanisms.\n\n\n\nOf course it would be possible to implement coroutines on top of\n fibers instead. But the concepts map more neatly to implementing\n fibers in terms of coroutines. The corresponding operations are:\n\n  a coroutine yields;\n  a fiber blocks.\n\n\nWhen a coroutine yields, it passes control directly to its caller\n (or, in the case of symmetric coroutines, a designated other\n coroutine). When a fiber blocks, it implicitly passes control to the\n fiber scheduler. Coroutines have no scheduler because they need no\n scheduler."
					}
					,
					"docs": {
						"id": "docs",
						"title": "Documents",
						"version": "all",
						"categories": "",
						"url": " /docs/",
						"content": "Documents"
					}
					,
					"ps-theory-doubly-linked-list": {
						"id": "ps-theory-doubly-linked-list",
						"title": "Doubly Linked List",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/doubly-linked-list/",
						"content": "Doubly Linked List\n싱글 링크드 리스트는 구현하긴 편하지만 써먹을 수 있는 곳이 한정되어 있다. 반면\n  더블 링크드 리스트는 구현이 좀 까다롭지만 한번 구현해두면 써먹을 수 있는 곳이\n  많다. 여기서는 특히 센티넬 노드를 이용해서 더블 링크드 리스트의 구현을 좀더 쉽게\n  처리할 수 있는 방법을 정리하고 나아가 이걸 어디서 써먹을 수 있는지 정리한다.\nSentinel Node\n센티넬 노드란 트리나 리스트에서 데이터를 담진 않지만 검색이나 연산의 구현을\n  편하게 하기 위해서 쓰이는 특별한 노드를 뜻한다. 예를 들어 리스트에서 원소를\n  추가/삭제할 때마다 리스트가 빈 경우에 특별한 처리를 하지 않고 일반적인 경우와\n  마찬가지로 구현할 수 있게 해준다.\n파이썬으로 구현하면 다음과 같다.\nclass Node:\n    def __init__(self, data=None):\n        self.data = data  # hold any data\n        self.prev = None\n        self.next = None\n\nclass DoublyLinkedList:\n    def __init__(self):\n        self.sentinel = Node()\n        # initialize - sentinel&#39;s prev, next are sentinel\n        self.sentinel.prev = self.sentinel.next = self.sentinel\n        self.size = 0\n\n    def append_after(self, node, after=None):\n        &quot;&quot;&quot;\n        append node after certain node.\n        if after is None, then append at the end of the list\n        &quot;&quot;&quot;\n        if after is None:\n            after = self.sentinel.prev  # append to the end\n\n        # the order of updating the prev/next link matters!\n        # if the order is broken, then nodes are invalidated.\n        after.next.prev = node\n        node.next = after.next\n        after.next = node\n        node.prev = after\n        self.size += 1\n\n    def append_before(self, node, before=None):\n        &quot;&quot;&quot;\n        append node before certain node.\n        if before is None, then append at the beginning.\n        &quot;&quot;&quot;\n        if before is None:\n            before = self.sentinel.next\n\n        # again, the order matters.\n        before.prev.next = node\n        node.prev = before.prev\n        before.prev = node\n        node.next = before\n        self.size += 1\n\n    def pop(self, node=None, last=True):\n        &quot;&quot;&quot;\n        One of pros of doubly linked list is that it can directly drop certain node. O(1).\n        if node is None, then drop the last one, and if first is true then drop the first one.\n        &quot;&quot;&quot;\n        if self.size == 0:\n            return\n\n        if node is None:\n            node = self.sentinel.prev if last else self.sentinel.next\n\n        node.prev.next = node.next\n        node.next.prev = node.prev\n        self.size -= 1\n\n        return node\n\n노드의 prev, next 링크를 업데이트하는 순서 에 주의하면서 구현하면 쉽다. 순서가\n  틀리면 특정 노드가 먼저 invalidate 되면서 리스트가 깨진다.\n더블 링크드 리스트의 장점 중 하나는 바로 대상 노드만 알면 노드의 삽입과 삭제를\n  원하는 위치에다 할 수 있다는 것이다. 위의 구현에서 그것을 볼 수 있다. 예를 들어\n  append_after 는 특정 노드 뒤(after)에다가 노드를 곧바로 삽입할 수 있다. 그리고\n  pop 의 경우도 특정 노드를 곧바로 삭제할 수 있다.\n이는 만약 어떤 키 값에 해당하는 노드 정보를 곧바로 찾을 수 있다면, 더블 링크드\n  리스트에서의 삽입과 삭제 연산을 O(1) 만에 할 수 있다는 의미이기도 하다. 그래서\n  순서 를 유지하는 데이터 구조의 경우, 즉 LRU 캐시 또는 LFU 캐시를 구현하기 위한\n  순서 있는 데이터 구조의 경우 내부 구현이 더블 링크드 리스트와 키 값에서 이\n  리스트의 노드로 가는 맵핑으로 구현되어 있다. 즉, 파이썬의 OrderedDict 구현은\n  다음과 같다.\nclass OrderedDict(dict):\n    def __init__(self):\n        self._order = DoublyLinkedList()  # contains order\n        self._map = {}  # random access to the node of d-list\n\n    def __setitem__(self, key, value):\n        if key not in self:\n            self._map[key] = node = Node(key)  # node contains key\n            self._order.append_before(node)\n        dict.__setitem__(self, key, value)\n\n    def __delitem__(self, key):\n        dict.__delitem__(self, key)\n        node = self._map.pop(key)\n        self._order.pop(node)\n\n    def __iter__(self):\n        &quot;&quot;&quot;\n        Traverse in order\n        &quot;&quot;&quot;\n        node = self._order.sentinel.next\n        while node is not self._order.sentinel:\n            yield node.data\n            node = node.next\n\n    def __reversed__(self):\n        &quot;&quot;&quot;\n        Traverse in reverse order\n        &quot;&quot;&quot;\n        node = self._order.sentinel.next\n        while node is not self._order.sentinel:\n            yield node.data\n            node = node.prev\n\n    def popitem(self, last=True):\n        &quot;&quot;&quot;\n        Remove and return a (key, value) pair from the dictionary.\n        Pairs are returned in LIFO order if last is true, or FIFO order otherwise.\n        &quot;&quot;&quot;\n        if not self:\n            raise KeyError(&#39;dictionary is empty&#39;)\n        node = self._order.pop(last=last)\n        key = node.data\n        del self._map[key]\n        value = dict.pop(self, key)\n        return key, value\n\n    def move_to_end(self, key, last=True):\n        &quot;&quot;&quot;\n        Move an existing element to the end (or beginning if last is false).\n        &quot;&quot;&quot;\n        node = self._map[key]\n        self._order.pop(node)\n        if last:\n            self._order.append_after(node)\n        else:\n            self._order.append_before(node)"
					}
					,
					"wip-multicore-ocaml-effect-handler": {
						"id": "wip-multicore-ocaml-effect-handler",
						"title": "Retrofitting Effect Handlers onto OCaml (WIP)",
						"version": "all",
						"categories": "",
						"url": " /wip/multicore-ocaml/effect-handler/",
						"content": "이팩트 핸들러 장착하기\n\n2. Background: OCaml Stacks\n멀티코어 OCaml에 이펙트 핸들러를 구현하는 데 있어 가장 큰 도전은 바로\n 프로그램 스택을 관리하고 바람직한 성질을 유지하는 것이다. 여기서는\n 프로그램 스택과 원래 OCaml에서의 메커니즘에 대한 개요를 살펴본다."
					}
					,
					"ps-leetcode-encode-and-decode-strings": {
						"id": "ps-leetcode-encode-and-decode-strings",
						"title": "Encode and Decode Strings",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/encode-and-decode-strings/",
						"content": "Encode and Decode Strings\n\n문자열 리스트를 하나의 문자열로 인코딩하는 함수와, 이렇게 인코딩된\n 문자열을 다시 원래의 문자열 리스트로 디코딩하는 함수를 구현하자.\n\n문자열은 모두 아스키코드 범위(0~256)의 글자만 담고있다.\n\n오답 노트\n\n  캐릭터가 전부 아스키코드 범위이기 때문에, ;든 #든 아니면 여러\n문자를 합친 것이든 리스트 구분자로 쓸 수 없다.\n\n\n올바른 접근\n\n  아스키 코드 범위를 벗어나는 글자를 구분자로 써야 한다.\n\n\ndef encode(strs):\n    return chr(300).join(strs)\n\ndef ecode(s):\n    return s.split(chr(300))"
					}
					,
					"ps-leetcode-evaluate-reverse-polish-notation": {
						"id": "ps-leetcode-evaluate-reverse-polish-notation",
						"title": "Evaluate Reverse Polish Notation",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/evaluate-reverse-polish-notation/",
						"content": "Evaluate Reverse Polish Notation\n\n역 폴란드 표기법으로 작성된 수식을 평가하고 결과 값을 계산하자.\n\n연산은 사칙연산만 주어지며, 나눗셈은 소숫점을 버림하여 계산한다.\n\n입력으로 주어지는 식은 모두 유효한 역 폴란드 표기법임이 보장된다.\n\nRPN\n\n계산기 문제의 eval 함수를 그대로 구현하면\n 된다. 단, 여기서는 이항 연산자 -와 단항 연산자 -가 아예\n 구분되어서 입력으로 들어온다. 즉, [2, 1, -]는 이항 연산이고,\n [-1]은 단항 연산이다. 수식을 파싱할 때 양수인지 음수인지를 확인해야\n 한다. 파이썬에서는 문자열을 곧바로 int()로 파싱하면 양수/음수 모두\n 가능한데, 이때 숫자가 아니라면 ValueError 예외가 발생한다. 이\n 성질을 이용해서 구현하면 다음과 같다.\n\ndef evalRPN(tokens):\n    stack = []\n    binop = {\n        '+': lambda x, y: x+y,\n        '-': lambda x, y: x-y,\n        '*': lambda x, y: x*y,\n        '/': lambda x, y: int(x/y),\n    }\n\n    for tok in tokens:\n        try:\n            stack.append(int(tok))\n        except ValueError:\n            y = stack.pop()\n            x = stack.pop()\n            stack.append(binop[tok](x, y))\n    return stack.pop()"
					}
					,
					"feed-xml": {
						"id": "feed-xml",
						"title": "",
						"version": "all",
						"categories": "",
						"url": " /feed.xml",
						"content": "Book\n        Engineering Book\n        /book/\n        \n        Mon, 08 Apr 2024 13:07:14 +0000\n        Mon, 08 Apr 2024 13:07:14 +0000\n        Jekyll v4.3.3\n        \n        \n        \n            1. Introduction\n            &lt;h1 id=&quot;1-소개&quot;&gt;1. 소개&lt;/h1&gt;\n\n&lt;p&gt;함수형 프로그래밍에서 재귀 하향식 파서를 만드는 대중적인 방법은\n 파서를 &lt;em&gt;함수&lt;/em&gt;로 모델링하고, 고차 함수(또는 &lt;em&gt;컴비네이터&lt;/em&gt;)를 정의해서\n 시퀀싱, 선택, 반복을 제공하는 문법을 구성하는 것이다. 기본 아이디어는\n 최소 Burge의 “재귀적인 프로그래밍 기술(1975)”에서 찾아야 하고, Wadler\n (1985), Hutton (1992), Fokker (1995) 그 외 많은 이들에 의해 저술된\n 함수형 프로그래밍에 의해 유명해졌다. 컴비네이터는 함수형 파서를\n 만드는 빠르고 쉬운 방법을 제공한다. 게다가, 이 방법은 다른 함수형\n 파서 생성기, 예를 들어 Ratatosk (Mogensen, 1993)과 Happy (Gill &amp;amp;\n Marlow, 1995)보다 좋다.&lt;/p&gt;\n\n&lt;p&gt;파서가 &lt;em&gt;모나드&lt;/em&gt;의 한 인스턴스라는 것은 일찍이 알려졌는데, 모나드란\n 수학에서 수많은 계산 문제를 해결하는데 유용한 것으로 증명된 대수적\n 구조이다. 수학적 관점에서 흥미로울 뿐만 아니라, 파서의 모나드적\n 천성을 인식하는 일은 실질적인 이득이 있다. 예를 들어, 파서를 만들 때\n 모나드식 시퀀싱 컴비네이터를 이용하면 중첩된 이전 작업 결과의 튜플을\n 다루는 지저분한 작업을 피할 수 있다 (바인드). 게다가, &lt;em&gt;모나드\n 컴프리헨션&lt;/em&gt; 표기를 이용하면 파서를 더욱 컴팩트하게 만들 수 있고 읽기\n 쉬워진다.&lt;/p&gt;\n\n&lt;p&gt;모나드식 접근을 더 취하면, 파서의 모나드는 두 개의 더 간단한 모나드를\n 통해 모듈 방식으로 표현할 수 있다. 이를 통한 즉각적인 이득은 기본적인\n 파서 컴비네이터가 더 이상 명시적으로 정의될 필요가 없다는\n 것이다. 대신, 이들은 기본 모나드 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;m&lt;/code&gt;으로부터 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;m&lt;/code&gt;을 파라미터화 한 다른\n 모나드를 리프팅해서 모나드 연산을 만드는 과정에서 자동으로 하나의\n 특수한 경우가 된다. 이는 또한 우리가 기본 모나드를 수정해서 (예를\n 들어 파서를 제한해서 최대 하나의 결과만 내게 하는) 파서의 천성을\n 바꾸면 이 수정된 파서 모나드를 위한 새로운 컴비네이터 역시 구성을\n 리프팅함으로써 자동으로 만들어진다는 뜻이다.&lt;/p&gt;\n\n&lt;p&gt;이 글의 목적은 함수형 파서를 만들기 위한 모나드식 접근을 단계 별로\n 설명하기 위한 튜토리얼을 제공하기 위함이며, 모나드를 적극 활용했을\n 때의 장점을 설명하기도 한다. 대부분의 내용은 이미 알려진\n 것들이다. 기여점은 &lt;em&gt;튜토리얼&lt;/em&gt;을 제공한다는 점이다. 렉서를 따로 두지\n 않고 렉싱을 다루는 새로운 컴비네이터를 소개하고, 모나드의 사용법에\n 영향을 받아 오프사이드 규칙을 구현하는 새로운 접근도 소개한다.&lt;/p&gt;\n\n            \n            /book/wip/monadic-parser-combinators/01-intro/\n            /book/wip/monadic-parser-combinators/01-intro/\n            \n            \n        \n        \n        \n            2. Combinator parsers\n            &lt;h1 id=&quot;2-컴비네이터-파서&quot;&gt;2. 컴비네이터 파서&lt;/h1&gt;\n&lt;p&gt;먼저 옛 현인들의 컴비네이터 파싱에 대한 기본 아이디어를 리뷰하는\n 것부터 시작하자. 구체적으로는 일단 파서와 세 개의 원시 파서, 더 큰\n 파서를 만들기 위한 두 개의 원시 컴비네이터에 대한 타입부터 정의한다.&lt;/p&gt;\n\n&lt;h2 id=&quot;21-파서의-타입&quot;&gt;2.1. 파서의 타입&lt;/h2&gt;\n&lt;p&gt;먼저 “파서”란 문자열을 입력으로 받아서 어떤 종류의 트리를 결과로\n 내놓는 함수로 생각하는 것부터 시작하자. 트리는 문자열의 문법적 구조를\n 명시적으로 드러낸다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;첫 번째 아이디어는 바로 파서가 입력 문자열을 전부 소모(consume)하지\n 않을 수도 있다는 것이다. 그러므로, 결과 트리만 리턴하기 보다는 입력\n 문자열에서 &lt;strong&gt;아직 소모되지 않은 접두사 부분&lt;/strong&gt;을 같이 리턴할 수\n 있다. 따라서 파서의 타입은 다음과 같다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;두 번째 아이디어는 바로 파서가 어떤 입력 문자열에 대해서는 &lt;em&gt;실패&lt;/em&gt;할\n 수도 있다는 것이다. 이럴 때 런타임 에러를 던지는 것보다는, 파서가\n 어느 부분에서 왜 실패했는지를 알려주면 디버깅에 유용할\n 것이다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Result&lt;/code&gt; 타입을 이용하면 좋을 것 같다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;명시적인 &lt;em&gt;실패&lt;/em&gt; 표현을 가지며 입력 문자열에서 &lt;em&gt;소모되지 않은 부분&lt;/em&gt;을\n 리턴하는 일은 작은 파서로부터 더 큰 파서를 만들기 위한 컴비네이터를\n 정의할 수 있게 해준다.&lt;/p&gt;\n\n&lt;p&gt;서로 다른 파서는 서로 다른 종류의 트리를 리턴하기 마련인데, 따라서\n 구체적인 트리의 타입을 추상화해서 파서의 타입을 파라미터화 하는 것이\n 좋다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;입력을 좀더 세분화해서 “어디까지”를 같이 기록하면 좋을 것 같다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;\n  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;\n  &lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pos&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;\n  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;\n\n&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_input&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pos&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;마지막으로, 우리는 파서가 항상 클로저를 갖고 있길 원한다. 따라서\n 최종적인 우리의 파서 타입은 다음과 같다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;\n  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;\n  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;h2 id=&quot;22-원시primitive-파서&quot;&gt;2.2. 원시(Primitive) 파서&lt;/h2&gt;\n&lt;p&gt;컴비네이터 파싱의 기본 구성 요소인 네 개의 원시 파서를 볼 것이다.&lt;/p&gt;\n\n&lt;p&gt;첫 번째 파서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;return v&lt;/code&gt;로 입력 문자열을 아무것도 소모하지 않고\n 성공하고 하나의 결과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;v&lt;/code&gt;를 리턴한다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Ok&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;두 번째 파서는 항상 실패하는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fail&lt;/code&gt;이다. 디버깅을 위한 에러 메시지를\n 함께 받는다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fail&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Error&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;세 번째 프리미티브는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;any_char&lt;/code&gt;으로, 입력 문자열에 대해서 첫 번째\n 글자를 항상 소모하거나, 문자열이 비어있으면 실패하는 함수이다. 우리의\n 입력 타입인 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;input&lt;/code&gt;을 좀더 손쉽게 다루기 위해서 먼저 입력에서 일부만\n 소모하는 함수 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;consume_input&lt;/code&gt;을 만들자. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;consume_input input pos\n len&lt;/code&gt;은 주어진 입력 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;input&lt;/code&gt;의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text&lt;/code&gt;의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pos&lt;/code&gt;부터 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;len&lt;/code&gt;만큼의 문자를\n 소모하고 남은 입력을 리턴한다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;consume_input&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pos&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;\n  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pos&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len&lt;/span&gt;\n  &lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pos&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pos&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pos&lt;/span&gt;\n  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;이를 이용해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;any_char&lt;/code&gt;를 구현할 수 있다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;any_char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;\n  &lt;span class=&quot;n&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;\n    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt;\n    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;\n      &lt;span class=&quot;n&quot;&gt;consume_input&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Ok&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nn&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Invalid_argument&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Error&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;expected any character&quot;&lt;/span&gt;\n&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;마지막으로, 입력을 직접 소모하지 않고 글자를 하나만 살펴보는 이른바\n 룩어헤드(Lookahead) 파서인 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;peek_char&lt;/code&gt;가 있다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;any_char&lt;/code&gt;와는 달리\n 조건부 파싱에 쓰일 수 있다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;peek_char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;\n  &lt;span class=&quot;n&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;\n    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;\n      &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Ok&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nn&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Invalid_argument&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Error&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;empty input&quot;&lt;/span&gt;\n&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;h2 id=&quot;23-파서-컴비네이터&quot;&gt;2.3. 파서 컴비네이터&lt;/h2&gt;\n&lt;p&gt;앞서 정의한 원시 파서들은 그 자체로는 그다지 쓸모있지는\n 않다. 여기서는 더 유용한 파서를 만들기 위해서 이 파서를 어떻게 이어\n 붙일 수 있는지(glue)를 살펴본다. 특히, 고차 함수(=컴비네이터)를\n 이용해서 코드를 깔끔하고 읽기 쉽게 만들 수 있다. 함수 적용과 유사한\n &lt;em&gt;시퀀싱(sequencing; 여러 개의 함수를 연달아 적용)&lt;/em&gt; 컴비네이터,\n &lt;em&gt;선택(choice; 여러 개의 함수 중 성공한 것을 적용)&lt;/em&gt; 컴비네이터, 앞\n 쪽을 버리는 컴비네이터, 뒷 쪽을 버리는 컴비네이터 등을 살펴볼\n 것이다. 이렇게 정의된 컴비네이터들은 실제 BNF 문법의 구조와 거의\n 유사한 구조로 파서를 합치는 것을 도와준다.&lt;/p&gt;\n\n&lt;p&gt;모나드 방식이 아닌 초창기의 컴비네이터 파싱에서, 파서의 시퀀싱 연산은\n 보통 다음 타입을 가졌었다:&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;즉, 두 파서를 번갈아 적용해서 두 파서의 결과를 튜플로 묶는\n 연산이다. 얼핏 보기에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;seq&lt;/code&gt; 컴비네이터는 자연스러운 합성 연산으로\n 보인다. 하지만 실제로는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;seq&lt;/code&gt;을 계속 사용하다 보면 그 결과로 엄청나게\n 중첩된 튜플을 갖게 되는데, 이를 다루는 것은 굉장히 지저분한 일이다.&lt;/p&gt;\n\n&lt;p&gt;중첩된 튜플 문제는 &lt;em&gt;모나드식&lt;/em&gt; 시퀀싱 컴비네이터를 적용해서 피할 수\n 있다. 흔히 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;바인드(bind)&lt;/code&gt; 연산으로 알려진 것으로, 한 파서의 결과 값을\n 처리해서 파서들을 시퀀싱하여 합치는 방식이다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bind&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;\n  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;\n      &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt;\n      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Ok&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input'&lt;/span&gt;\n      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Error&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Error&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err&lt;/span&gt;\n  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bind&lt;/code&gt;의 정의는 다음과 같이 이해할 수 있다. 먼저, 파서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p&lt;/code&gt;를 입력\n 문자열에 적용해서 결과로 소모되지 않은 입력과 결과 값을\n 가져온다. 만약 실패했다면 (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;match&lt;/code&gt;의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Error err&lt;/code&gt; 케이스), 실패를\n 그대로 리턴한다. 성공했다면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;'a&lt;/code&gt; 타입의 값을 얻을텐데 (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;match&lt;/code&gt;의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Ok\n x&lt;/code&gt; 케이스), &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f&lt;/code&gt;가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;'a&lt;/code&gt; 타입의 값을 받아 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;'b&lt;/code&gt; 타입의 파서를 리턴하는\n 함수이므로 이제 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt;에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f&lt;/code&gt;를 적용해서 새로운 파서를 만들 수 있다. 이때\n 남은 입력에 대해서 적용해야 함을 잊지말자.&lt;/p&gt;\n\n&lt;p&gt;참고로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bind&lt;/code&gt; 컴비네이터는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bind&lt;/code&gt; 라는 함수 그 자체로 호출되기 보다는\n 주로 다음과 같이 중위 연산자로 재정의 되어 쓰이는 것이 일반적이다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bind&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bind&lt;/code&gt; 컴비네이터는 결과의 중첩된 튜플 문제를 피하게 해준다. 왜냐하면\n 첫 번째 파서의 결과가 나중에 처리될 결과와 튜플로 묶이지 않고 곧바로\n 두 번째 파서에 의해서 처리될 수 있기 때문이다.&lt;/p&gt;\n\n&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bind&lt;/code&gt; 컴비네이터 (중위 연산자)를 이용한 아주 전형적인 예시를 하나\n 살펴보자. 두 파서를 튜플로 묶는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pair&lt;/code&gt;를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bind&lt;/code&gt;로 구현하면 다음과\n 같다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;\n  &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;\n  &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;\n  &lt;span class=&quot;n&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;이걸 해석하면 이렇다. 우리는 파서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p&lt;/code&gt;와 파서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;q&lt;/code&gt;를 합쳐서 다음과 같은\n 동작을 하는 파서를 만들 것이다: 먼저 파서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p&lt;/code&gt;를 적용한다. 성공한\n 경우에는 결과 값 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt;를 사용할 수 있다(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fun x -&amp;gt; ..&lt;/code&gt;).  그 다음 파서\n &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;q&lt;/code&gt;를 나머지 입력에 대해서 적용한다. 역시 성공한 경우 결과 값 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y&lt;/code&gt;를\n 곧바로 사용할 수 있다(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fun y -&amp;gt; ..&lt;/code&gt;). 최종적으로 두 결과를 튜플로\n 리턴하는 &lt;strong&gt;파서를 리턴한다(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;return (x, y)&lt;/code&gt;)&lt;/strong&gt;. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;q&lt;/code&gt; 둘 중 어느\n 파서든 파싱에 실패할 경우 곧바로 해당 에러를 리턴한다. 모나드식 접근\n 덕분에 코드가 아름답고 이해가 잘 된다.&lt;/p&gt;\n\n&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bind&lt;/code&gt; 컴비네이터를 이용하면 간단하지만 유용한 파서들을 정의할 수\n 있다. 예를 들어, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;any_char&lt;/code&gt; 파서는 하나의 글자를 &lt;em&gt;무조건적&lt;/em&gt;으로\n 파싱했는데, 실제 상황에서는 보통 “특정 글자”에만 관심있기\n 마련이다. 따라서 룩어헤드를 위한 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;peek_char&lt;/code&gt;와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;any_char&lt;/code&gt;를 이용해서\n 새로운 컴비네이터 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;satisfy&lt;/code&gt;를 만들 수 있다. 이 컴비네이터는 조건\n 함수(predicate)를 받아서 해당 조건을 만족하는 글자만 파싱하고 그렇지\n 않으면 실패한다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;satisfy&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;\n  &lt;span class=&quot;n&quot;&gt;peek_char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;any_char&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fail&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Predicate not satisfied.&quot;&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;이제 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;satisfy&lt;/code&gt;를 이용해서 특정 글자, 숫자, 소문자, 대문자 등을 파싱할\n 수 있다:&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;satisfy&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n\n&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;digit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;satisfy&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n\n&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;satisfy&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n\n&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;upper&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;satisfy&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;A'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;예를 들어 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;upper&lt;/code&gt; 파서를 입력 문자열 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;Hello&quot;&lt;/code&gt;에 적용하면 다음과 같은\n 결과를 리턴하며 성공할 것이다:&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;upper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;make_input&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hello&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;;;&lt;/span&gt;\n&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;ello&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pos&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Ok&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;H'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;즉 첫글자 대문자 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;H&lt;/code&gt;를 성공적으로 파싱한 결과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Ok 'H'&lt;/code&gt;와, 입력\n 문자열에서 아직 소모되지 않은 나머지 부분에 대한 정보를 잘 갖고 있다.&lt;/p&gt;\n\n&lt;p&gt;만약 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;digit&lt;/code&gt; 파서를 입력 문자열 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;Hello&quot;&lt;/code&gt;에 적용한다면, 파싱에\n 실패하게 되고 다음과 같이 입력 문자열을 하나도 소모하지 않는다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;digit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;make_input&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hello&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;;;&lt;/span&gt;\n&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;\n&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hello&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pos&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Error&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;predicate not satisfy&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;이제 위에서 만든 파서를 가지고 더 강력한 파서를 만들 수 있는\n 선택(choice) 컴비네이터를 살펴보자. 예를 들어, 우리는 소문자 파서\n &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lower&lt;/code&gt;와 대문자 파서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;upper&lt;/code&gt; 중 어느 것을 만족해도 상관없는 글자를\n 파싱하는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;letter&lt;/code&gt; 파서를 정의할 수 있다. 이를 위해서, 우리는 다음과\n 같은 선택 컴비네이터가 필요하다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;choice&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;\n  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;\n      &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;\n        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt;\n        &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt;\n        &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Ok&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Ok&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;\n        &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Error&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;\n  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;즉, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;choice&lt;/code&gt; 컴비네이터는 먼저 첫 번째 파서를 입력 문자열에\n 적용해보고 성공한 경우 남은 입력과 그 결과를 리턴한다. 실패한 경우 두\n 번째 파서를 마저 적용해본다. 둘 중 어느 것이든 만족하면 그만인\n 것이다. 참고로 선택 컴비네이터는 파서가 &lt;em&gt;실패&lt;/em&gt;했을 때 뭔가를 더\n 해야하므로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bind&lt;/code&gt; 컴비네이터로는 구현할 수 없다.&lt;/p&gt;\n\n&lt;p&gt;보통 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;choice&lt;/code&gt; 컴비네이터도 다음과 같이 중위 연산자로 정의해서 쓰는\n 것이 편리하다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;choice&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;그러면 우리는 다음과 같이 대/소문자 글자를 파싱하는 파서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;letter&lt;/code&gt;와,\n 알파벳과 숫자를 파싱하는 파서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;alphanum&lt;/code&gt;을 정의할 수 있다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;letter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;|&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;upper&lt;/span&gt;\n\n&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alphanum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;letter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;|&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;digit&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;마지막으로 조건을 만족하는 &lt;em&gt;단어&lt;/em&gt;를 파싱하는 파서를 만들어보자. 크게\n 두 종류의 컴비네이터를 사용해볼 수 있는데,&lt;/p&gt;\n&lt;ul&gt;\n  &lt;li&gt;조건(predicate)을 만족하는 동안 계속 파싱하는 컴비네이터,&lt;/li&gt;\n  &lt;li&gt;파서가 파싱에 성공하는 동안 계속 파싱하는 컴비네이터,&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;두 가지를 모두 살펴볼 것이다.&lt;/p&gt;\n\n&lt;p&gt;먼저 조건을 만족하는 동안 계속 파싱하는 컴비네이터 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;take_while&lt;/code&gt;은\n &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;satisfy&lt;/code&gt;와 유사하다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;take_while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;\n  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;\n      &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;\n        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt;\n        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ref&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt;\n        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt;\n          &lt;span class=&quot;n&quot;&gt;incr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;\n        &lt;span class=&quot;k&quot;&gt;done&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;\n        &lt;span class=&quot;n&quot;&gt;consume_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Ok&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nn&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;문자 그대로 주어진 조건 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f&lt;/code&gt;를 만족하는 동안 계속 입력 문자열을\n 소모하여 최종 파싱 결과를 리턴한다. 이 컴비네이터를 이용해서 단어를\n 파싱하는 파서를 만들면 다음과 같다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;take_while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;A'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;즉, 앞의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lower&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;upper&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;digit&lt;/code&gt;의 조건식으로 들어갔던 함수를\n 합쳐서 전달해주면 된다.&lt;/p&gt;\n\n&lt;p&gt;두 번째 방법은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;letter&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;upper&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;digit&lt;/code&gt;과 같은 미리 만들어둔 파서를\n 조합할 수 있는 방식이다. 먼저 마찬가지로 파서가 파싱 가능한 만큼\n 파싱하고 그 결과를 리스트(어떤 값일지 모르기 때문에 곧바로 문자열로\n 바꾸기는 어렵다)로 모아주는 컴비네이터 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;many&lt;/code&gt;를 정의하자.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;many&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;list&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;\n  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;\n      &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;\n        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ref&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt;\n        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;rec&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;\n          &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt;\n          &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt;\n          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Ok&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;\n            &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;\n            &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input'&lt;/span&gt;\n          &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Error&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;\n        &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt;\n        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt;\n        &lt;span class=&quot;n&quot;&gt;input'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Ok&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nn&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rev&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;입력으로 받은 파서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p&lt;/code&gt;를 실패할 때까지 계속 적용하면서 결과를\n 리스트에 쌓아뒀다가 최종적으로 파서가 파싱한 값의 리스트를 돌려주는\n 컴비네이터이다. 이 친구를 이용해서 단어 파서를 만들면 다음과 같다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;\n  &lt;span class=&quot;n&quot;&gt;many&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;|&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;upper&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;|&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;digit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt;\n  &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;\n    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;of_seq&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nn&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_seq&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt;\n    &lt;span class=&quot;n&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;즉, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lower&lt;/code&gt; 또는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;upper&lt;/code&gt; 또는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;digit&lt;/code&gt; 파서를 이용해서 입력을 계속\n 파싱하여 결과를 리스트에 모아두고, 최종적으로 이 (글자의) 리스트를\n 문자열로 합쳐서 돌려주는 파서다.&lt;/p&gt;\n\n&lt;p&gt;그 외에 유용한 컴비네이터로는 앞쪽의 결과를 버리는 컴비네이터 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*&amp;gt;&lt;/code&gt;가\n 있다. 예를 들어 문법에서 공백이나 중괄호를 무시하고 싶을 때 사용할 수\n 있다. 이 친구는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bind&lt;/code&gt;를 이용해서 깔끔하게 구현 가능하다.&lt;/p&gt;\n\n&lt;div class=&quot;language-ocaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fun&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;즉 첫 번째 파서의 결과 값은 버리고, 남은 입력만을 취하는 것이다.&lt;/p&gt;\n\n            \n            /book/wip/monadic-parser-combinators/02-combinator-parsers/\n            /book/wip/monadic-parser-combinators/02-combinator-parsers/\n            \n            \n        \n        \n        \n            1. Exploratory Data Analysis\n             &lt;h1 id=&quot;eda&quot;&gt;EDA&lt;/h1&gt;\n&lt;ul&gt;\n  &lt;li&gt;추론(Inference): 적은 표본(샘플)을 가지고 더 큰 &lt;i&gt;모집단&lt;/i&gt; 에 대한 &lt;b&gt;결론&lt;/b&gt; 을\n    도출하기 위한 일련의 복잡한 과정\n    &lt;ul&gt;\n      &lt;li&gt;표본과 샘플, 표본추출과 샘플링, 모형과 모델, 임의와 랜덤 등은 혼용함&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 id=&quot;eda--------------&quot;&gt;정형화된 데이터의 요소&lt;/h2&gt;\n&lt;p&gt;왜 데이터를 구분할까?&lt;/p&gt;\n&lt;ul&gt;\n  &lt;li&gt;그래프를 그리거나 모델을 피팅하는 등의 통계분석을 수행하는 방식을 결정하는데\n    큰 도움을 준다.&lt;/li&gt;\n  &lt;li&gt;범주형 데이터라는 결국 &lt;code&gt;enum&lt;/code&gt; 이다.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3 id=&quot;eda-----------------------&quot;&gt;수치형 데이터&lt;/h3&gt;\n&lt;p&gt;말 그대로 숫자로 표현된다.&lt;/p&gt;\n&lt;table&gt;\n  &lt;tr&gt;&lt;th&gt;데이터&lt;/th&gt;&lt;th&gt;설명&lt;/th&gt;&lt;th&gt;예시&lt;/th&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;연속형 데이터&lt;/td&gt;&lt;td&gt;어떤 범위 안에서 어떤 값이든 가질 수 있는 데이터로, 구간형 또는 실수형 이라고도 한다.&lt;/td&gt;&lt;td&gt;속도, 지속시간 등&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;이산형 데이터&lt;/td&gt;&lt;td&gt;셀 수 있는 값을 갖는 데이터&lt;/td&gt;&lt;td&gt;횟수, 사건의 발생 빈도 등&lt;/td&gt;&lt;/tr&gt;\n&lt;/table&gt;\n&lt;h3 id=&quot;eda-----------------------&quot;&gt;범주형 데이터&lt;/h3&gt;\n&lt;p&gt;카테고리로 나눌 수 있는 데이터로, 제품 종류나 도시 이름 같이 어떤 범위 안에서의\n  이산형 데이터로 볼 수도 있다.&lt;/p&gt;\n&lt;table&gt;\n  &lt;tr&gt;&lt;th&gt;데이터&lt;/th&gt;&lt;th&gt;설명&lt;/th&gt;&lt;th&gt;예시&lt;/th&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;이진 데이터&lt;/td&gt;&lt;td&gt;둘 중 하나&lt;/td&gt;&lt;td&gt;참/거짓, 예/아니오 등&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;순서형 데이터&lt;/td&gt;&lt;td&gt;범위 안에서 서로 order가 정의되는 데이터&lt;/td&gt;&lt;td&gt;평점 등&lt;/td&gt;&lt;/tr&gt;\n&lt;/table&gt;\n&lt;h2 id=&quot;eda---------&quot;&gt;테이블 데이터&lt;/h2&gt;\n&lt;table&gt;\n  &lt;tr&gt;&lt;th&gt;용어&lt;/th&gt;&lt;th&gt;설명&lt;/th&gt;&lt;th&gt;유의어&lt;/th&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;데이터 프레임&lt;/td&gt;&lt;td&gt;스프레드시트와 같은 테이블 형태의 데이터&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;피쳐 (Feature)&lt;/td&gt;&lt;td&gt;테이블의 각 &lt;b&gt;열&lt;/b&gt;&lt;/td&gt;&lt;td&gt;특징, 속성(Attribute), 입력, 예측 변수(Predictor), 변수&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;결과 (Outcome)&lt;/td&gt;&lt;td&gt;프로젝트의 목표. 결과를 &lt;b&gt;예측&lt;/b&gt; 하기 위해서 피쳐를 사용한다.&lt;/td&gt;&lt;td&gt;종속변수, 응답, 목표, 출력&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;레코드 (Record)&lt;/td&gt;&lt;td&gt;테이블의 각 &lt;b&gt;행&lt;/b&gt;&lt;/td&gt;&lt;td&gt;기록값, 사건(Case), 사례, 예제(Example), 관측값, 패턴, 샘플&lt;/td&gt;&lt;/tr&gt;\n&lt;/table&gt;\n&lt;ul&gt;\n  &lt;li&gt;통계: &lt;b&gt;응답변수&lt;/b&gt; (또는 &lt;b&gt;종속변수&lt;/b&gt;)를 예측하는 모델에서 &lt;b&gt;예측변수&lt;/b&gt; 를 사용한다&lt;/li&gt;\n  &lt;li&gt;데이터 과학: &lt;b&gt;목표&lt;/b&gt; 를 예측하는데 &lt;b&gt;피쳐&lt;/b&gt; 를 사용한다&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 id=&quot;eda-------&quot;&gt;위치 추정&lt;/h2&gt;\n&lt;p&gt;데이터가 주어졌을 때 데이터를 살펴보는 가장 &lt;i&gt;기초적인&lt;/i&gt; 단계는 각 피쳐(변수)의\n  &amp;#8220;대표값(Typical Value)&amp;#8221;을 구해서 -&amp;gt; &lt;i&gt;대부분의 값&lt;/i&gt; 이 어디쯤에 위치하는지를\n  추정해본다.&lt;/p&gt;\n&lt;table&gt;\n  &lt;tr&gt;&lt;th&gt;용어&lt;/th&gt;&lt;th&gt;설명&lt;/th&gt;&lt;th&gt;유의어&lt;/th&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;평균 (Mean)&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;td&gt;Average&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;가중평균(Weighted Mean)&lt;/td&gt;&lt;td&gt;가중치를 곱한 값의 총합을 가중치의 총합으로 나눈 값&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;중간값 (Median)&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;td&gt;50번째 백분위수 (Percentile)&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;백분위수&lt;/td&gt;&lt;td&gt;전체 데이터의 P%를 아래에 두는 값&lt;/td&gt;&lt;td&gt;분위수(Quantile)&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;절사평균 (Trimmed Mean)&lt;/td&gt;&lt;td&gt;정해진 개수의 극단값을 제외한 나머지 값들의 평균&lt;/td&gt;&lt;td&gt;절단평균 (Truncated Mean)&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;로버스트(Robust)&lt;/td&gt;&lt;td&gt;극단값들에 민감하지 않은 상태&lt;/td&gt;&lt;td&gt;저항성 (Resistant)&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;특잇값 (Outlier)&lt;/td&gt;&lt;td&gt;대부분의 값과 매우 다른 데이터 값&lt;/td&gt;&lt;td&gt;극단값(Extreme Value)&lt;/td&gt;&lt;/tr&gt;\n&lt;/table&gt;\n&lt;ul&gt;\n  &lt;li&gt;통계: 데이터로부터 계산된 값들에 보통 &lt;b&gt;추정값(estimate)&lt;/b&gt; 이라고 부른다. &amp;#8211;&amp;gt;\n    불확실성을 이해하기 위한 학문이다. 그래서 &lt;i&gt;추정&lt;/i&gt; 한다.&lt;/li&gt;\n  &lt;li&gt;데이터 과학: 데이터로부터 계산된 값을 &lt;b&gt;측정 지표(metric)&lt;/b&gt; 라고 부른다. &amp;#8211;&amp;gt;\n    구체적인 비즈니스 또는 조직의 목표치에 관심을 둔다. 그래서 &lt;i&gt;측정&lt;/i&gt; 한다.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3 id=&quot;eda-------------&quot;&gt;가중평균&lt;/h3&gt;\n&lt;ul&gt;\n  &lt;li&gt;어떤 값이 다른 값에 비해 &lt;i&gt;큰 변화량&lt;/i&gt; 을 가질 때, 이를 작은 가중치를 둬서 영향을\n    줄일 수 있다. 예를 들면, 여러 개의 센서 중 특정 센서의 정확도가 떨어지면 이\n    센서에는 가중치를 낮게 준다.&lt;/li&gt;\n  &lt;li&gt;데이터를 수집할 때 우리가 관심있는 서로 다른 대조군에 대해서 정확히 같은\n    비율을 맞추기란 불가능에 가깝다. 이를 보정하기 위해서 데이터가 부족한 소수\n    그룹에 더 높은 가중치를 적용할 수도 있다.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3 id=&quot;eda-----------------&quot;&gt;로버스트한 추정&lt;/h3&gt;\n&lt;ul&gt;\n  &lt;li&gt;많은 경우 데이터에 매우 민감한 평균보다는 중간값이 위치 추정에 더 유리하다.\n    예를 들어 가계소득 등. 왜냐하면 결과를 왜곡할 수도 있는 &lt;b&gt;특잇값(극단값)&lt;/b&gt; 의\n    영향을 받지 않으므로 &lt;b&gt;로버스트&lt;/b&gt; 하다고 여겨진다.&lt;/li&gt;\n  &lt;li&gt;절사평균도 괜찮다. 예를 들어 상하위 10%를 잘라내는 방법은 데이터가 너무\n    적지만 않다면 특잇값으로부터 데이터를 보호할 수 있다. 이는 평균과 중간값의\n    절충안이라고 볼 수도 있다.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pd&lt;/span&gt;\n&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy&lt;/span&gt;\n&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;\n&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;wquantiles&lt;/span&gt;\n\n&lt;span class=&quot;c1&quot;&gt;# load data - check out https://github.com/gedeck/practical-statistics-for-data-scientists/tree/master/data&lt;/span&gt;\n&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;state.csv&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n\n&lt;span class=&quot;c1&quot;&gt;# 평균, 절사평균(10%), 중간값&lt;/span&gt;\n&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Population&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;\n&lt;span class=&quot;n&quot;&gt;scipy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trim_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Population&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Population&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;median&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;\n\n&lt;span class=&quot;c1&quot;&gt;# 미국 전체의 평균 살인율 계산 - 인구를 가중치로&lt;/span&gt;\n&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;average&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Murder.Rate&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Population&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;\n&lt;span class=&quot;c1&quot;&gt;# 가중 중간값 - wquantiles 패키지&lt;/span&gt;\n&lt;span class=&quot;n&quot;&gt;wquantiles&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;median&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Murder.Rate&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Population&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;\n&lt;/pre&gt;&lt;/div&gt;\n&lt;h2 id=&quot;eda-------&quot;&gt;변이 추정&lt;/h2&gt;\n&lt;p&gt;변이(Variability)는 데이터 값들이 얼마나 &lt;i&gt;밀집&lt;/i&gt; 혹은 &lt;i&gt;퍼져&lt;/i&gt; 있는지를 나타내는\n  &lt;b&gt;산포도(Dispersion)&lt;/b&gt; 를 나타낸다.&lt;/p&gt;\n&lt;p&gt;변이를 측정하고, 줄이고, 변이와 랜덤값을 구분하고, 변이의 다양한 요인들을\n  살펴보고, 변이가 상황에서 어떻게 결정을 내리는지 등 통계의 핵심이다.&lt;/p&gt;\n&lt;table&gt;\n  &lt;tr&gt;&lt;th&gt;용어&lt;/th&gt;&lt;th&gt;설명&lt;/th&gt;&lt;th&gt;유의어&lt;/th&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;편차 (Deviation)&lt;/td&gt;&lt;td&gt;관측값과 위치 추정값 사이의 차이&lt;/td&gt;&lt;td&gt;오차, 잔차(Residual)&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;분산 (Variance)&lt;/td&gt;&lt;td&gt;평균과 편차의 제곱의 합을 (n-1)로 나눈 값&lt;/td&gt;&lt;td&gt;평균제곱오차&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;표준편차 (Standard Deviation)&lt;/td&gt;&lt;td&gt;분산의 제곱근&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;평균절대편차 (Mean Absolute Deviation)&lt;/td&gt;&lt;td&gt;평균과 편차의 절대값의 평균&lt;/td&gt;&lt;td&gt;L1 노름, 맨해튼 노름&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;중간값의 중위절대편차(MAD; Median Absolute Deviation from the median)&lt;/td&gt;&lt;td&gt;중간값과의 편차의 절대값의 중간값&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;범위&lt;/td&gt;&lt;td&gt;최대값 - 최소값&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;순서통계량 (Order Statistics)&lt;/td&gt;&lt;td&gt;최소~최대로 정렬된 데이터 값에 따른 계량형&lt;/td&gt;&lt;td&gt;순위&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;백분위수 (Percentile)&lt;/td&gt;&lt;td&gt;어떤 값들의 P 퍼센트가 이 값 이하의 값을 갖고, (100 - P) 퍼센트가 이 값 이상을 갖도록 하는 값&lt;/td&gt;&lt;td&gt;분위수&lt;/td&gt;&lt;/tr&gt;\n  &lt;tr&gt;&lt;td&gt;사분위범위 (IQR; InterQuantile Range)&lt;/td&gt;&lt;td&gt;75번째 백분위수와 25번째 백분위수의 차이&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;\n&lt;/table&gt;\n \n            \n            /book/wip/practical-statistics/1-exploratory-data-analysis/\n            /book/wip/practical-statistics/1-exploratory-data-analysis/\n            \n            statistics\n            \n            note\n            \n            \n        \n        \n        \n            2. Data and Sampling Distributions\n             &lt;h1 id=&quot;data-and-sampling-distributions&quot;&gt;Data and Sampling Distributions&lt;/h1&gt;\n \n            \n            /book/wip/practical-statistics/2-data-and-sampling-distributions/\n            /book/wip/practical-statistics/2-data-and-sampling-distributions/\n            \n            statistics\n            \n            note\n            \n            \n        \n        \n        \n            3. Statistical Experiments and Significance Testing\n             &lt;h1 id=&quot;statistical-experiments-and-significance-testing&quot;&gt;Statistical Experiments and Significance Testing&lt;/h1&gt;\n \n            \n            /book/wip/practical-statistics/3-statistical-experiments-and-significance-testing/\n            /book/wip/practical-statistics/3-statistical-experiments-and-significance-testing/\n            \n            statistics\n            \n            note\n            \n            \n        \n        \n        \n            3Sum\n            &lt;h1 id=&quot;3sum&quot;&gt;&lt;a href=&quot;https://leetcode.com/problems/3sum/&quot;&gt;3Sum&lt;/a&gt;&lt;/h1&gt;\n\n&lt;p&gt;정수 배열이 주어졌을 때, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nums[i] + nums[j] + nums[k] == 0&lt;/code&gt;이 되는\n 모든 정수 세 쌍의 집합을 구하자. 이때, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i != j &amp;amp;&amp;amp; i != k &amp;amp;&amp;amp; j != k&lt;/code&gt;를\n 만족해야 한다.&lt;/p&gt;\n\n&lt;p&gt;정답 배열은 중복되는 수를 담으면 안된다.&lt;/p&gt;\n\n&lt;p&gt;배열의 길이는 0~3,000 사이이고 배열의 값은 -100,000~100,000 사이이다.&lt;/p&gt;\n\n&lt;h2 id=&quot;투-포인터&quot;&gt;투 포인터&lt;/h2&gt;\n\n&lt;p&gt;두 수의 합은 해시 셋으로 금방 풀렸다. 세 수의 합은 어떻게 할 수\n 있을까? Brute Force를 생각해보면 O(N^3)의 솔루션을 떠올릴 수\n 있겠지만, 배열 최대 크기가 3000이라서 시간 초과가 날 것이다. N^3보다\n 작은 솔루션은 없을까?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=&quot;../two-sum/#two-sum-ii---input-array-is-sorted&quot;&gt;Two Sum II&lt;/a&gt;의 접근을\n 활용해야 한다: 배열이 정렬되어 있을 때, 투 포인터를 이용해 합이\n 원하는 값보다 작으면 더 작은 값의 포인터를 더 큰 값을 갖도록\n 이동하였고, 합이 더 크다면 더 큰 값의 포인터를 더 작은 값을 갖도록\n 이동하였다. 세 수의 합을 구하려면, 정수 하나는 배열 전체를 루프하도록\n 하면서, 다른 두 정수는 투 포인터를 이용해서 O(N)만에 구하도록 한다면,\n 총 복잡도 O(N^2)을 얻을 수 있을 것 같다. 그리고 이때 문제의 조건에\n 따라 (1) 세 정수의 &lt;strong&gt;인덱스&lt;/strong&gt;는 유니크해야 하고 (2) 세 정수의\n &lt;strong&gt;각각의 값&lt;/strong&gt;도 유니크해야 한다.&lt;/p&gt;\n\n&lt;p&gt;입력으로 들어오는 수가 정렬되어 있다는 말이 없기 때문에, 투 포인터를\n 사용하려면 정렬을 해야한다. 여기에 O(NlogN)의 복잡도가 소요되긴\n 하지만, 실제로 루프를 O(N^2)만큼 돌아야 하므로 이 부분은 괜찮다.&lt;/p&gt;\n\n&lt;p&gt;이 아이디어를 구현해보자.&lt;/p&gt;\n\n&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;threeSum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;\n    &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;\n    &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;\n        &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;\n            &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;\n            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;\n                &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;\n                &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n                &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n            &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;\n                &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;\n                &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i &amp;lt; left &amp;lt; right&lt;/code&gt;인 세 인덱스를 잘 고르려고 한다. 따라서, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;는\n&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n-3&lt;/code&gt;까지 가능하므로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;range(n-2)&lt;/code&gt;까지 루프를 돈다. 이렇게 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;를\n일단 고른다.&lt;/li&gt;\n  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;left&lt;/code&gt;는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt; 다음부터, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;right&lt;/code&gt;는 항상 마지막 수부터\n검사한다. 그리고 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;left&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;right&lt;/code&gt;를 가지고 투 포인터로 범위를\n좁혀가며 합이 0이 될 때 정답에 추가한다.&lt;/li&gt;\n  &lt;li&gt;정답의 정수 튜플은 중복되면 안되기 때문에, 최종적으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;set()&lt;/code&gt;\n연산으로 중복을 없앤다. 이때 튜플은 항상 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(i, left, right)&lt;/code&gt; 순으로\n넣어야 올바르게 중복을 제거할 수 있다.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;이렇게하면 대략 2초정도 걸리는 솔루션이 나온다. 더 빠르게 할 수 있는\n 방법은 없을까?&lt;/p&gt;\n\n&lt;h3 id=&quot;small-optimization---빨리감기&quot;&gt;Small Optimization - 빨리감기&lt;/h3&gt;\n\n&lt;p&gt;위의 솔루션에서 시간을 꽤 잡아먹는 부분은, 중복되는 튜플을 무지성으로\n 다 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;answer&lt;/code&gt;에 집어넣고 마지막에 이를 해싱해서 중복을 제거하는\n 부분이다. 이 부분을 더 똑똑하게 해보자.&lt;/p&gt;\n\n&lt;p&gt;일단 떠올리기 쉬운 부분은 투 포인터를 진행하는 부분이다. 우리가\n 원하는 합이 되었을 때 (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s == 0&lt;/code&gt;), 두 포인터를 한 칸씩만 움직이고\n 있는데, 배열이 정렬되어 있기 때문에, 이 조건을 만족하는 동안 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;left&lt;/code&gt;와\n &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;right&lt;/code&gt;의 값이 같으면 전부 스킵해도 된다. 따라서 다음과 같이 바꿀 수\n 있다.&lt;/p&gt;\n\n&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;threeSum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;\n    &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;\n    &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;\n        &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;\n            &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;\n            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;\n                &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;\n                &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;\n                    &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n                &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;\n                    &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n                &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n                &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n            &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;\n                &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;\n                &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;left&lt;/code&gt;는 왼쪽에서 오른쪽 방향으로 진행하기 때문에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;left&lt;/code&gt;와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;left +\n 1&lt;/code&gt;의 값이 같으면 싹 땡긴다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;right&lt;/code&gt;는 반대로 오른쪽에서 왼쪽으로\n 진행하기 때문에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;right - 1&lt;/code&gt;과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;right&lt;/code&gt;의 값이 같으면 싹 땡긴다. 이렇게\n 두 개의 반복문으로 빨리감기를 진행하고 나면, 그 위치는 합 조건을\n 만족하는 같은 값을 가진 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;left&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;right&lt;/code&gt; 의 마지막 부분에 위치하게\n 되고, 최종적으로 그 다음 탐색을 위해서 한 칸씩 더 이동해주면 된다.&lt;/p&gt;\n\n&lt;p&gt;이렇게하고 마지막의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;set()&lt;/code&gt; 연산을 풀면 답을 얻을 수 있지 않을까?\n 놀랍게도 다음 반례를 발견하게 된다.&lt;/p&gt;\n\n&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;\n&lt;span class=&quot;n&quot;&gt;Expected&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;\n&lt;span class=&quot;n&quot;&gt;Output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;중복을 다 제거한줄 알았는데 중복이 나왔다. 어디서 놓친 것일까? 위의\n 입력을 하나씩 따라가보자. 먼저 입력을 정렬하면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[-4,-1,-1,0,1,2]&lt;/code&gt;를\n 얻는다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i = 1&lt;/code&gt;일 때의 상황을 살펴보자. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(left, right) = (2, 5)&lt;/code&gt;에서\n &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(-1, -1, 2)&lt;/code&gt;의 해답 하나를 얻는다. 그 다음 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;left&lt;/code&gt;는 같은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-1&lt;/code&gt;을 가진\n &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;3&lt;/code&gt;을 거쳐 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;4&lt;/code&gt;가 되고, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;right&lt;/code&gt;는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;4&lt;/code&gt;가 되어 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(-1, 0, 1)&lt;/code&gt;의 해답을\n 얻는다. 여기까진 좋다. 그런데 그 다음 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i = 2&lt;/code&gt;가 되었을 때, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(left,\n right) = (3, 4)&lt;/code&gt;에서 똑같은 해답인 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(-1, 0, 1)&lt;/code&gt;을 얻게 된다!&lt;/p&gt;\n\n&lt;p&gt;앞서 우리는 두 개의 포인터, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;left&lt;/code&gt;와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;right&lt;/code&gt;에서만 중복을 스킵했지,\n &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;에 대해서는 중복을 스킵하지 않은 것이 문제다. 그럼 무엇을\n 해야할까? &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;left&lt;/code&gt;와 마찬가지로 왼쪽에서 오른쪽으로 진행하기\n 때문에, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nums[i] == nums[i+1]&lt;/code&gt;일 때 다 스킵하면 되지 않을까? 위의\n 예시를 생각해보자. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i = 1&lt;/code&gt;일 때, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i+1&lt;/code&gt;과 같기 때문에 이를 스킵하고 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i\n = 2&lt;/code&gt;로 곧장 넘어가버린다. 그런데 우리는 위에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i = 1&lt;/code&gt; 일 때 정답\n 튜플 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(-1, -1, 2)&lt;/code&gt;를 구한 것을 보았다. 따라서 정답을 하나 놓친\n 것이다. 그러므로, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;를 스킵할 때에는 일단 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;에 대해서 먼저 투\n 포인터로 가능한 공간을 전부 탐색해본 뒤에, 그 다음 또 같은 값을\n 만났을 때 이를 스킵해야 하는 것이다. 따라서, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nums[i-1] == nums[i]&lt;/code&gt;일\n 때 스킵해야 한다.&lt;/p&gt;\n\n&lt;p&gt;이 최적화를 다 적용한 코드는 다음과 같다.&lt;/p&gt;\n\n&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;threeSum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;\n    &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;\n    &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\n    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;\n        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;\n            &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;\n        &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;\n            &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;\n            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;\n                &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;\n                &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;\n                    &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n                &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;\n                    &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n                &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n                &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n            &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;\n                &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;\n                &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;\n    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;\n&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;\n\n&lt;p&gt;투 포인터에서의 빨리감기와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;의 빨리감기를 모두 적용하였기 때문에,\n 마지막의 해싱 연산은 더 이상 필요하지 않다. 이렇게 1초 미만의\n 솔루션을 얻을 수 있다.&lt;/p&gt;\n\n            \n            /book/ps/leetcode/3sum/\n            /book/ps/leetcode/3sum/\n            \n            problem-solving\n            \n            leetcode\n            \n            python\n            \n            array\n            \n            \n        \n        \n        \n            4. Regression and Prediction\n             &lt;h1 id=&quot;regression-and-prediction&quot;&gt;Regression and Prediction&lt;/h1&gt;\n \n            \n            /book/wip/practical-statistics/4-regression-and-prediction/\n            /book/wip/practical-statistics/4-regression-and-prediction/\n            \n            statistics\n            \n            note\n            \n            \n        \n        \n        \n            \n            &lt;h1 id=&quot;page-not-found&quot;&gt;Page Not Found&lt;/h1&gt;\n\n&lt;p&gt;Unfortunately we were unable to find the page you requested. It could be the page doesn’t exist or only exists for a specific version of these documents so please use the search feature to see if you are able to locate the information you were after.&lt;/p&gt;\n\n            \n            /book/404.html\n            /book/404.html\n            \n            \n        \n        \n        \n            5. Classification\n             &lt;h1 id=&quot;classification&quot;&gt;Classification&lt;/h1&gt;\n \n            \n            /book/wip/practical-statistics/5-classification/\n            /book/wip/practical-statistics/5-classification/\n            \n            statistics\n            \n            note\n            \n            \n        \n        \n        \n            6. Statistical Machine Learning\n             &lt;h1 id=&quot;statistical-machine-learning&quot;&gt;Statistical Machine Learning&lt;/h1&gt;\n \n            \n            /book/wip/practical-statistics/6-statistical-machine-learning/\n            /book/wip/practical-statistics/6-statistical-machine-learning/\n            \n            statistics\n            \n            note"
					}
					,
					"ps-leetcode-find-all-anagrams-in-a-string": {
						"id": "ps-leetcode-find-all-anagrams-in-a-string",
						"title": "Find All Anagrams In A String",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/find-all-anagrams-in-a-string/",
						"content": "Find All Anagrams In A String\n\n  두 문자열의 길이가 다르면 애너그램일 수 없다.\n  길이가 같은 두 문자열의 각 글자 수가 같아야 애너그램이다.\n  p의 글자수를 미리 세 둔 다음 s 안에서 p의 길이만큼의 모든 부분 문자열에\n    대해서 확인해보면 된다. 움직일 때마다 앞에 글자 수를 빼고 뒤에 글자 수를\n    더하는 슬라이딩 윈도우 방식이 훨씬 빠르긴 하지만 그냥 매번 세도 통과하긴\n    한다.\n\n매번 세는 방법\ndef findAnagrams(s: str, p: str) -&gt; List[int]:\n    target, sn, pn = Counter(p), len(s), len(p)\n    if pn &gt; sn:\n        return []\n    answer = []\n    for start in range(sn - pn + 1):\n        # count every time using Counter\n        if target == Counter(s[start:start + pn]):\n            answer.append(start)\n\n    return answer\n\n슬라이딩 윈도우\ndef findAnagrams(s: str, p: str) -&gt; List[int]:\n    # keep only 26 characters\n    def idx(char):\n        return ord(char) - ord(&#39;a&#39;)\n\n    def count(word: str)\n        arr = [0] * 26\n        for char in word:\n            arr[idx(char)] += 1\n        return arr\n\n    target, sn, pn = count(p), len(s), len(p)\n    if sn &gt; pn:\n        return []\n    # keep track of window\n    check, start = count(s[:pn]), 0\n    answer = []\n    while start &lt; sn - pn + 1:\n        if check == count:\n            answer.append(start)\n\n        check[idx(s[start])] -= 1\n        if start + pn &lt; sn:\n            check(idx(s[start + pn])) += 1\n        start += 1\n    return answer"
					}
					,
					"ps-leetcode-find-and-replace-in-string": {
						"id": "ps-leetcode-find-and-replace-in-string",
						"title": "Find And Replace in String",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/find-and-replace-in-string/",
						"content": "Find And Replace in String\n\n어떤 단어 s가 주어지고 여기에 k번의 교체 연산을 하려고 한다. 교체\n 연산은 다음과 같은 0부터 시작하는 인덱스를 기준으로, 세 배열\n indices, sources, targets로 주어지며 길이는 모두 k이다.\n\ni 번째 교체 연산은 다음과 같이 이뤄진다:\n\n  부분 문자열 sources[i]이 원본 문자열 s의 인덱스 indices[i]에\n있는지 확인한다.\n  만약 없으면, 아무것도 안한다.\n  만약 있으면, 이 부분 문자열을 targets[i]랑 교체한다.\n\n\n예를 들어서 s = \"abcd\"이고 indices[i] = 0, sources[i] = ab,\n targets[i] == eee 라면, 이 교체 연산의 결과는 eeecd가 된다.\n\n모든 교체 연산은 동시에 수행되어야 한다. 즉, 교체 연산으로\n 문자열이 수정되었을 때, 서로 다른 교체 연산에게 (특히 인덱싱 관련)\n 영향을 주지 않아야 한다. 입력은 이런 교체 연산끼리 수정하는 부분이\n 겹치지 않음이 보장된다.\n\n예를 들어, s = \"abc\"이고 indices = [0, 1], sources = [\"ab\",\n \"bc\"]인 경우는 절대 입력으로 주어지지 않음이 보장된다. 왜냐하면\n \"ab\"와 \"bc\"를 교체하는 연산이 서로 겹치기 때문이다.\n\n모든 연산을 수행한 결과 문자열을 계산하자.\n\n문자열 s의 길이는 1 ~ 1,000 사이이고 \\(1 \\leq k \\leq 100\\)\n 이다. 세 교체 연산 배열의 크기는 모두 k이다. 부분 문자열 source와\n 교체 문자열 target의 길이는 1 ~ 50이다. 모든 문자열은 알파벳\n 소문자만 포함한다.\n\n역방향으로 수정하기\n\n얼핏보면 쉬워 보이지만, 문제는 모든 연산이 동시에 수행되어야\n 한다는 점이다. 이는 바꿔말하면 어떤 연산이 다른 연산에게 영향을\n 미치면 안된다는 것이다. 특히, 문자열을 수정한 뒤 길이가 바뀌는\n 경우에, 다른 교체 연산의 인덱스에 영향을 미치면 안된다.\n\n예를 들어 s = \"abcd\"이고 indices = [0, 2], sources = [\"ab,\n \"cd], targets = [\"eeee\", \"ddd\"]라고 하자. 이걸 순서대로 첫번째\n 연산부터 수행하면 abcd가 eeeecd가 되는데, 이러면 두번째 연산의\n 인덱스 2 위치에 cd가 아닌 ee가 있어서 두번째 연산이\n 실패한다. 하지만 동시에 연산을 수행하면, ab와 cd를 eeee와\n ddd로 바꿔서 정상적으로 eeeeddd 결과를 얻을 수 있다.\n\n위와 같이 서로 다른 연산에게 영향을 주지 않으려면 어떤 순서로\n 연산을 해야할까? 키 포인트는 교체 연산을 인덱스의 역순으로 하는\n 것이다. 위의 예시에서 cd -&gt; ddd 연산을 먼저 하면 이후 ab -&gt; eeee\n 연산을 하는데 영향을 주지 않는 것을 알 수 있다. 이런 관찰에 따라,\n 교체 연산을 먼저 인덱스의 역순으로 정렬한 후에 차례로 수행하면 될 것\n 같다.\n\ndef findReplaceString(s, indices, sources, targets):\n    res = s\n    for idx, subs, tgt in sorted(zip(indices, sources, targets), reverse=True):\n        if res.find(subs, idx) == idx:\n            res = res[:idx] + target + res[idx + len(subs):]\n    return res\n\n\n\n  zip 연산으로 세 교체 연산을 튜플로 묶었다. 이때 인덱스 정보를\n가장 앞쪽에 두어서 역순으로 정렬한다.\n  조건에 따라 string.find 연산으로 부분 문자열이 있을 때에만 교체를\n한다. 이때, find(subs)가 아니라 find(subs, idx) 처럼 시작\n인덱스를 넘겨줘야 올바른 위치를 교체할 수 있다.\n  파이썬의 슬라이싱 연산을 통해서 교체 결과 문자열을 쉽게 계산할 수\n있다. 반 열린 구간인 [start, end)를 뜻하는 [start:end]\n연산이므로, res[:idx]는 부분 문자열이 나타난 바로 직전까지의 부분\n분자열이고, res[idx + len(subs):]는 부분 문자열이 나타난 이후부터\n끝까지의 문자열이 된다.\n\n\n이렇게 하면 정렬에 O(nlogn), 전체 반복에 O(ns) (s는 부분\n 문자열의 최대 길이) 복잡도가 소요되고 이때 문제의 조건에 따라\n logn(=log1000)는 s(=50)보다 훨씬 작기 때문에 O(sn)이 최종\n 복잡도가 된다.\n\n정방향으로 수정하기\n\n그럼 역방향이 아니라 정방향으로는 어떻게 할 수 있을까? 여기서는\n 파이썬의 동적인 성질을 이용해보자.\n\n먼저 입력 문자열을 쪼개서 글자의 리스트로 만든다. 예를 들어 abcd는\n [a, b, c, d]로 만든다. 그 후 순서에 상관없이 교체 연산을\n 수행하는데, 이때 다음과 같이 진행한다.\n\n  먼저 원본 문자열에서 연산에 쓰이는 부분 문자열이 있는지\n확인한다.\n  교체해야 하는 경우, 먼저 indices[i] 부분의 인덱스에다 곧바로\ntargets[i]를 덮어씌운다. 그 후 sources[i]의 길이 만큼\n글자의 리스트를 빈 글자로 만든다. 예를 들어 이전 예시의 ab -&gt;\neeee 교체 연산을 한다면, [a, b, c, d] 리스트를 [eeee, '', c,\nd]로 만든다.\n  마지막으로 파이썬의 join 연산으로 글자 리스트를 하나의 문자열로\n합친다.\n\n\n이 아이디어를 구현하면 다음과 같다.\n\ndef findReplaceString(s, indices, sources, targets):\n    res = list(s)\n    for idx, sub, tgt in zip(indices, sources, targets):\n        if s.find(sub, idx) != idx:\n            continue\n        res[idx] = tgt\n        for i in range(idx+1, idx+len(sub)):\n            res[i] = ''\n    return ''.join(res)"
					}
					,
					"ps-leetcode-find-and-replace-pattern": {
						"id": "ps-leetcode-find-and-replace-pattern",
						"title": "Find and Replace Pattern",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/find-and-replace-pattern/",
						"content": "Find and Replace Pattern\n\n단어 목록 words와 문자열 pattern이 주어진다. 이때 pattern과\n 매치 되는 단어 목록을 구하자. 단어 목록의 순서는 상관없다.\n\n어떤 단어가 패턴과 매치된다는 것의 의미는 다음과 같다: 단어에\n 등장하는 글자 x를 다른 글자로 교체하는 어떤 순열(permutation)이\n 존재해서, p(x)를 적용하면 두 단어가 같아지는 것이다. 이때 서로 다른\n 글자가 같은 글자로 맵핑되면 안된다.\n\n단어와 패턴의 길이는 1~20이고 단어 목록의 크기는 1~50이다. 모두\n 알파벳 소문자만 담고 있다.\n\n예를 들어 단어 “mee”는 패턴 “abb”와 매칭된다. a -&gt; m, b -&gt; e로 맵핑할\n 수 있기 때문이다. 반면 “mem”과는 매칭되지 않는다.\n\nAlpha Conversion\n\n글자를 세거나 글자 위치를 찾는 문제랑은 다른 종류의 문제다. 설명에\n “교체(replace)”라는 단어가 있는데, 여기에 현혹되어서 진짜 글자랑 글자\n 사이의 맵핑을 구하면 안된다.\n\n“글자 개수만 맞으면 되지 않을까?”라고 생각했는데, 같은 개수의\n 글자라도 상대적인 순서가 중요하다는 걸 알았다. 그렇게 좀\n 생각하다보니 이 문제는 PL에 친숙한 문제인 Alpha\n Conversion과\n 같다는 것을 깨달았다.\n\n여기서는 De Bruijin 인덱스까지 쓸 필요는 없고 (애초에 Lambda\n Abstraction이 없으니), 그냥 왼쪽부터 쭉 읽어가면서 글자를 만나는\n 순서대로 인덱스를 매기면 될 것 같다. 최종적으로는 하나의 비교 가능한\n 튜플을 만들어 낸다면 단어 목록에서 필터해버리면 된다.\n\ndef findAndReplacePattern(words, pattern):\n    def alpha_conv(word):\n        id_map = {}\n        i = 0\n        res = []\n        for letter in word:\n            if letter not in id_map:\n                id_map[letter] = i\n                i += 1\n            res.append(id_map[letter])\n        return tuple(res)\n\n    palpha = alpha_conv(pattern)\n    return list(filter(lambda word: alpha_conv(word) == palpha, words))"
					}
					,
					"ps-leetcode-find-closest-node-to-given-two-nodes": {
						"id": "ps-leetcode-find-closest-node-to-given-two-nodes",
						"title": "Find Closest Node To Given Two Nodes",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/find-closest-node-to-given-two-nodes/",
						"content": "Find Closest Node To Given Two Nodes\n지문이 좀 헷갈리는데&#8230;\n\n  정방향 거리랑 역방향 거리를 각각 찾는다.\n  정방향으로 갈 수 있는 노드 집합이랑 역방향으로 갈 수 있는 노드 집합의\n    교집합을 찾는다.\n  교집합을 정렬한 순서대로 훑어가면서 해당 조건을 만족하는 노드를 찾는다.\n\n가장 헷갈리는 부분은 마지막 조건을 만족하는 노드 를 찾는 부분이다. 지문에\n  이렇게 되어 있는데: &#8220;&#8230; such that maximum between the distance from node1 to\n  that node, and from node2 to that node is minimized.&#8221; 저 중간의 , 때문에 &#8221;node1\n  까지의 거리는 최대 이면서 node2 까지의 거리는 최소 &#8220;로 이해를 해버려서 계속\n  틀렸었다. 근데 저 컴마는 사실 큰 의미가 없고 제대로 해석하면 &#8221;node1 과 node2\n  사이의 거리 중 최대가 최소가 되도록 &#8220;하는 것이 제대로 된 조건이다.\ndef closestMeetingNode(edges: List[int], node1: int, node2: int) -&gt; int:\n    reachable1, reachable2 = set(), set()\n    dist1, dist2 = {}, {}\n    def bfs(start, reachable, dist):\n        q = deque()\n        q.append((start, 0))\n        dist[start] = 0\n        reachable.add(start)\n        while q:\n            node, d = q.popleft()\n            succ = edges[node]\n            if succ == -1 or succ in reachable:\n                continue\n            dist[succ] = d + 1\n            q.append((succ, d + 1))\n            reachable.add(succ)\n\n    bfs(node1, reachable1, dist1)\n    bfs(node2, reachable2, dist2)\n    answer, min_dist = -1, float(&#39;inf&#39;)\n    for node in sorted(reachable1 &amp; reachable2):\n        t = max(dist1[node], dist2[node])\n        if t &lt; min_dist:\n            answer = node\n            min_dist = t\n    return answer"
					}
					,
					"ps-leetcode-find-leaves-of-binary-tree": {
						"id": "ps-leetcode-find-leaves-of-binary-tree",
						"title": "Find Leaves of Binary Tree",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/find-leaves-of-binary-tree/",
						"content": "Find Leaves of Binary Tree\n\n바이너리 트리의 루트 노드가 주어졌을 때, 다음 결과를 구하자:\n\n\n  모든 리프 노드의 값을 수집한다.\n  모든 리프 노드를 지운다.\n  트리가 빌 때까지 1, 2를 반복한다.\n\n\n따라서 결과 값은 리스트의 리스트가 된다. 같은 리프 노드 집합 안에서의\n 순서는 상관없다.\n\n\n  노드 개수: 1~100\n  노드 값: -100~100\n\n\n재귀적으로 구현\n\n  레벨 오더 탐색의 일종이라고 생각해도 될듯. 리프 노드부터 레벨 0으로\n시작해서 루트 노드까지 1씩 증가하면서 거꾸로 올라오면 된다.\n  트리를 재귀적으로 탐색하면 항상 어떤 서브 트리의 루트 노드를 보게\n되므로, 리프 노드가 레벨 0이라는 것을 올바르게 계산하려면 현재 루트\n노드의 양 서브 트리의 높이를 계산한 다음 둘 중 더 큰 것을 취하면\n된다.\n  즉, 일반적인 트리의 높이를 구하는 것과 같다. 재귀적으로 트리의\n높이를 구하면서 동시에 내 높이 (= 레벨) 에 값을 덧붙이면 된다.\n\n\ndef findLeaves(root):\n    levels = defaultdict(list)\n\n    def heights(node):\n        if node is None:\n            return 0\n\n        lh, rh = heights(node.left), heights(node.right)\n        curh = max(lh, rh)\n        levels[curh].append(node.val)\n        return curh + 1\n\n    heights(root)\n    return levels.values()"
					}
					,
					"ps-leetcode-find-median-from-data-stream": {
						"id": "ps-leetcode-find-median-from-data-stream",
						"title": "Find Median from Data Stream",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/find-median-from-data-stream/",
						"content": "Find Median from Data Stream\n\n배열에서 중앙값(median)이란 정렬된 배열의 중간에 위치한\n 값이다. 배열 사이즈가 홀수면 정중앙의 값이고, 짝수이면 중간의 두 값의\n 평균값이다.\n\n  [2,3,4]의 중앙값은 3\n  [2,3]의 중앙값은 (2+3)/2 = 2.5\n\n\n데이터가 스트림처럼 계속 들어오는 상황에서 중앙값을 찾는 쿼리를\n 처리해주는 MedianFinder 클래스를 구현하자.\n\n  MedianFinder() 생성자는 오브젝트를 초기화한다.\n  void addNum(int num)은 정수 num을 데이터 스트림에 추가한다.\n  double findMedian()은 지금까지 추가된 스트림에서 중앙값을\n계산한다. 오차 범위 \\(10^{-5}\\) 까지는 허용된다.\n\n\nnum의 값은 -100,000~100,000 사이이고, findMedian() 함수가 불리기\n 전에 최소 한번의 addNum 함수가 호출됨이 보장된다. 최대 \\(5 \\times\n 10^4\\) 만큼의 함수 호출이 이뤄진다.\n\n정렬\n\n가장 먼저 떠오르는 방법은 AVL트리나 레드블랙트리 같은 BST에 데이터\n 스트림을 계속 보관하고 중앙값 쿼리가 올 때마다 이 트리로부터 중간\n 위치의 원소를 가져오는 방법이다. 하지만, 아쉽게도 파이썬의 표준\n 라이브러리에는 이런 Self-Adjusting 트리가 없다.\n\n그럼 다음으로 생각할 수 있는 방법은, 그냥 무작정 배열에 넣다가 중앙값\n 쿼리 요청이 올 때마다 매번 정렬하는 것이다. 파이썬의 정렬은 팀\n 정렬로 구현되어 있는데,\n 삽입 정렬과 병합 정렬을 합친 하이브리드 정렬이다. 실제로는 더 복잡한\n 구현이\n 되어있지만, 아무튼 리얼 월드 데이터를 정렬하는데 엄청나기 최적화되어\n 있어서, 이렇게 매번 정렬하면 이론적인 복잡도는 O(KNlogN) (K는 함수\n 호출 횟수)이겠지만 생각보다는 괜찮을지도 모른다.\n\nclass MedianFinder:\n    def __init__(self):\n        self.data = []\n\n    def addNum(self, num):\n        self.data.append(num)\n\n    def findMedian():\n        self.data.sort()\n        n = len(self.data)\n        if n % 2 == 0:\n            return (self.data[n//2] + self.data[n//2 - 1]) / 2\n        else:\n            return self.data[n//2]\n\n\n실제로 매우 느리긴 하지만 통과하긴 한다.\n\n힙\n\n그러면 더 최적화된 방법은 뭘까? 정확히는 어떤 데이터 구조를 쓰면 이걸\n 최적화할 수 있을까? 한 가지 방법은 들어오는 데이터 스트림, 즉 정수의\n 배열을 두 묶음으로 나눠 생각하는 것이다. 우리는 정렬된 배열의 중간\n 원소에만 관심이 있다. 그러면 이 중간 원소를 기준으로 왼쪽 절반과\n 오른쪽 절반을 따로 관리하면 어떨까? 구체적으로는, 힙을 이용해서, 왼쪽\n 절반은 죄다 최대힙에 넣고, 오른쪽 절반은 최소힙에다 넣으면, 양쪽 힙의\n Top에 있는 값을 이용해서 중앙값을 구할 수 있을 것 같다.\n\n이 아이디어를 좀더 구체화해서, 정확한 Invariant를 이끌어내보자.\n\n  최소힙의 크기는 최대힙과 같거나, 정확히 하나 더 크다. (반대여도\n상관없다)\n  최대힙의 최대원소는 최소힙의 최소원소보다 작거나 같다. 즉, Top의\n원소끼리 순서가 보장된다.\n\n\n이렇게 하면 (정렬된) 배열의 중간값은 이 두 힙으로부터 구할 수\n 있다. 만약 배열의 크기가 홀수라면 최소힙에(최대힙을 더 크게한 경우는\n 최대힙에), 짝수라면 최소힙과 최대힙의 Top원소의 평균값을 구하면\n 된다. O(logN)의 복잡도가 든다.\n\n추가하는 작업은 조금 까다롭다. 두 Invariant를 유지하도록 해야하기\n 때문이다. 단순하게 하려면 먼저 둘 중 한 곳에 원소를 추가하고 1을\n 확인한 후에 2를 확인하면 된다. 만약 2가 깨졌다면, 두 힙의 Top 값을\n 서로 뒤바꿔준다. 숫자를 하나씩 힙에 추가하기 때문에, 한 번만 숫자를\n 바꿔도 2의 Invariant가 유지된다. 이 역시 O(logN)의 복잡도가 드므로,\n 총 함수 횟수에 대해서 O(KlogN)의 복잡도가 든다. 정렬 방법과 비교해\n N이 빠진 만큼 아주 빠를 것으로 기대한다.\n\n이 아이디어를 구현해보자. 파이썬의 heapq 라이브러리는 기본적으로는\n 배열을 기준으로 동작하며, 최소힙만을 구현하기 때문에 최대힙의 경우\n 부호를 뒤집어서 키 값으로 주면 된다.\n\nimport heapq\nclass MedianFinder:\n    def __init__(self):\n        self.left = []\n        self.right = []\n\n    def addNum(self, num):\n        # invariant 1\n        if len(self.left) == len(self.right):\n            heapq.heappush(self.left, (-num, num))\n        else:\n            heapq.heappush(self.right, (num, num))\n\n        # invariant 2\n        if self.left and self.right and not (self.left[0][1] &lt; self.right[0][1]):\n            topl, topr = heapq.heappop(self.left), heapq.heappop(self.right)\n            heapq.heappush(self.left, (-topr[0], topr[1]))\n            heapq.heappush(self.right, (-topl[0], topl[1]))\n\n    def findMedian(self):\n        if len(self.left) == len(self.right):\n            return (self.left[0][1] + self.right[0][1]) / 2\n        else:\n            return self.left[0][1]\n\n\n\n  left는 최대힙, right는 최소힙이다. heapq는 기본적으로\n최소힙이므로 left에 값을 넣을 때 키 값으로 -num을 줬다. 힙에\n들어가는 데이터의 타입을 맞추기 위해서 right에도 튜플을 추가한다.\n  한 가지 주의할 점은 Invariant 2를 확인할 때 최대힙과 최소힙이\n비어있는지를 같이 확인해야 한다는 점이다. 문제의 조건에\nfindMedian이 호출되기 전에 최소 1번의 addNum이 호출된다고\n나와있기 때문에 둘 중 하나는 비어있을 수도 있다.\n  왼쪽 절반을 하나 더 크게 유지하고 있기 때문에 배열이 홀수인 경우는\n왼쪽의 Top이 중앙값이다."
					}
					,
					"ps-leetcode-find-minimum-in-rotated-sorted-array": {
						"id": "ps-leetcode-find-minimum-in-rotated-sorted-array",
						"title": "Find Minimum in Rotated Sorted Array",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/find-minimum-in-rotated-sorted-array/",
						"content": "Find Minimum in Rotated Sorted Array\n\n길이 n인 리스트가 정렬되어 있다. 이 정렬을 한 번 회전하면 제일 큰\n 원소가 제일 앞으로 온다. 예를 들어 [0, 1, 2, 4, 5, 6, 7]이 있을 때,\n\n  1번 회전: [7, 0, 1, 2, 4, 5, 6]\n  2번 회전: [6, 7, 0, 1, 2, 4, 5]\n  4번 회전: [4, 5, 6, 7, 0, 1, 2]\n  7번 회전: [0, 1, 2, 4, 5, 6, 7]\n\n\n이 된다.\n\n정렬된 k번 회전한 리스트 nums가 입력으로 들어왔을 때, 그 중 가장\n 작은 원소를 구하자. 알고리즘은 반드시 \\(O(log n)\\) 복잡도여야\n 한다.\n\n이분 탐색으로 Pivot 구하기\n\n내 블로그 글 중 이분\n 탐색글을\n 참조하면 좋다.\n\n요는 피벗, 즉 회전한 부분의 위치를 찾는 것이다. 시간 복잡도가\n 명시적으로 주어져 있기 때문에 이분 탐색을 써야하는 것은\n 자명하다. 그러면 피벗의 위치를 어떻게 알 수 있을까? 다음 그림을\n 생각해보자.\n\narr[low], arr[low+1], ..., arr[mid], ..., arr[high-1], arr[high]\n\n\n이분 탐색처럼 low, high, mid를 잡았다고 해보자. 목표는 low와\n high를 적절히 줄여가면서 피벗의 위치를 low에 찾는 것이다. 그러면\n 다음 두 가지 경우가 나온다:\n\n1) arr[high] &lt; arr[mid]: 중앙의 원소가 이분 범위 끝보다 큰 경우\n\n이 때는 mid와 high 사이 어딘가에서 회전이 된 것이다. 즉, 회전하기\n 전 원래 모습은 다음과 같을 것이다.\n\n pivot, ... arr[high], ... arr[low], ... arr[mid], ...\n\n --&gt; rotated --&gt; arr[low], ... arr[mid], ...pivot... arr[high]\n\n\n따라서, 피벗의 위치는 mid와 high 사이 어딘가에 존재할\n 것이다. 그러므로 이 경우에는 low를 mid + 1로 업데이트 해준다.\n\n2) arr[mid] &lt;= arr[high]: 중앙의 원소가 이분 범위 끝보다 작거나 같은 경우\n\n이 때는 mid와 high 사이는 잘 정렬이 되어 있으므로, low와 mid\n 사이 어딘가에서 회전이 된 것이다. 앞의 예시처럼 길이만큼 회전한 경우,\n 즉 그냥 정렬된 경우도 회전된 경우라고 본다면 여기 포함된다. 이 때는\n 그냥 일반적인 이분 탐색을 하듯이 high를 mid로 업데이트 해준다.\n\n\n\n이 아이디어를 구현하면 다음과 같다.\n\ndef findMin(nums):\n    low, high = 0, len(nums)-1\n    while low &lt; high:\n        mid = low + (high - low) // 2\n        if nums[mid] &gt; nums[high]:\n            # rotated in somewhere mid..high\n            low = mid + 1\n        else:\n            # rotated in somewhere low..mid\n            high = mid\n\n    pivot = low\n    return nums[pivot]\n\n\n\n  low, high 모두 인덱스임에 주의하자. 따라서 첫 번째\n케이스에서 low를 업데이트할 때 mid + 1이 옳다.\n  mid를 계산할 때 (low + high) // 2가 아니라 low + (high - low)\n// 2를 한 이유는 오버플로우를 막기 위함이다. 파이썬에서는\n괜찮겠지만 빅인트로 넘어가는 순간 성능이 문제될 수 있기 때문에 그냥\n늘 저렇게 하는게 속편한다."
					}
					,
					"ps-leetcode-graph-valid-tree": {
						"id": "ps-leetcode-graph-valid-tree",
						"title": "Graph Valid Tree",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/graph-valid-tree/",
						"content": "Graph Valid Tree\n0부터 n-1까지 레이블링 된 n 개의 노드가 있는 그래프가\n 있다. 엣지 정보를 담은 edges 가 주어지고, edges[i] = (a_i, b_i)는\n 노드 a_i와 b_i 사이에 무향 엣지가 있음을 나타낸다.\n\nn과 edges가 주어졌을 때, 이 그래프가 유효한 트리를 만들어내는지를\n 확인하자.\n\nValid Tree?\n문제를 정확하게 이해하기 위해서 정의를 살펴볼 필요가 있다. 유효한\n 트리의 정의가 뭘까? 위키피디아를 찾아보면 여러가지가 있는데,\n 눈여겨볼 것은 다음과 같다:\n\n  트리는 무향 그래프이다.\n  트리는 연결\n그래프이다. 즉,\n트리의 모든 노드는 연결되어 있다.\n  트리는 싸이클이 없다.\n\n\n여기서 무향 그래프를 제외한 나머지를 확인하는 것이 바로 이 문제의\n 핵심이 된다. 이 중에서 싸이클을 판단하는 것은 잠깐 뒤로 미뤄두고,\n 연결 그래프의 의미를 좀더 살펴보자. 어떤 그래프가 연결 그래프라면\n 이건 대체 무엇을 뜻할까? 모든 노드가 연결되어 있다는 말은 곧 모든\n 노드 사이에는 경로(path)가 있다는 뜻이고, 이건 다르게 말해서 n개의\n 노드를 갖는 그래프가 트리라면 여기에는 정확하게 n-1개의 엣지가\n 있다는 것을 뜻한다. n-1개보다 적으면 뭔가 연결 안된 노드가 있는\n 거고, n-1개 보다 많으면 무조건 싸이클이 있다는 것이다. 그러므로\n 일단 이것부터 제외할 수 있다.\n\nDisjoint Set\n그럼 싸이클은 어떻게 찾으면 될까? Condition of\n Cycle에서 했던 것처럼,\n visited와 visiting을 유지하면서 DFS를 돌리는 것은 어떨까?\n 아쉽게도 이 방법은 유향 그래프에서만 먹힌다. 우리는 트리, 즉 무향\n 그래프를 갖고 있기 때문에 일반적인 그래프 순회로 판단하기는 조금\n 까다롭다. 추가로 부모 노드를 쌓아가면서 확인하는 방법이 가능하지만,\n 여기서는 다른 방법을 써보자.\n\n어떤 무향 그래프에 싸이클이 있다는 사실을 어떻게 다르게 표현할 수\n 있을까? 다음 싸이클이 있는 엣지를 생각해보자.\n\nedges = [(0, 1), (1, 2), (2, 0)]\n\n\n첫번째 엣지에서 노드 0과 1이 연결된다. 두번째에서 노드 1과\n 2가 연결된다. 여기까지오면 0, 1, 2가 하나로 연결된\n 상태다. 여기에 추가로 2와 0을 연결하는 순간 싸이클이 생긴다.\n\n다르게 표현하면 이렇다. 먼저 노드 0과 1이 하나의 집합에\n 속한다. 그리고 (1, 2)가 들어오면 노드 2가 1이 속해있던 집합에\n 추가된다. 마지막으로 (2, 0)을 추가하려는 순간, 2와 0이 이미\n 같은 집합에 속해있음을 알게 되고, 이게 곧 싸이클이 된다.\n\n여기까지 오면 눈치챌 수 있다: 이 문제는 서로소 집합으로 풀 수\n 있다. 즉, 무향 그래프에서, 모든 엣지 정보를 서로소 집합에 추가하면서,\n 만약 union 연산을 할 때 두 집합이 이미 같은 집합에 속하면 (= 두\n 집합의 대표 원소가 같으면), 싸이클이 발생한 것이다.\n\n따라서 구현할 알고리즘의 아이디어는 다음과 같다.\n\n  연결 그래프의 조건인 “엣지 개수가 n-1개인가?”를 먼저 확인한다.\n  모든 엣지의 노드를 서로소 집합에 추가하면서, 이미 같은 집합에 속해\n있는 경우가 하나라도 발견되면 바로 False를 리턴한다.\n  위의 1, 2 검사를 모두 통과하면 비로소 True를 리턴한다.\n\n\n코드는 다음과 같다.\n\nclass DisjointSet:\n    class IdentityDict(dict):\n        def __missing__(self, x):\n            self[x] = x\n            return x\n\n    def __init__(self):\n        self._data = DisjointSet.IdentityDict()\n\n    def find(self, x):\n        if x != self._data[x]:\n            self._data[x] = self.find(self._data[x])\n        return self._data[x]\n\n    def union(self, x, y):\n        px, py = self.find(x), self.find(y)\n\n        if px == py:\n            # cycle is detected\n            raise TypeError\n\n        self._data[px] = py\n\ndef is_valid_tree(n, edges):\n    if len(edges) != (n - 1):\n        return False\n\n    dset = DisjointSet()\n\n    try:\n        for src, snk in edges:\n            dset.union(src, snk)\n    except TypeError:\n        return False\n\n    return True\n\n\n  연결 그래프 검사를 하고 나면, 사실상 모든 노드에 대해서 이미\nmake_set 함수를 호출했다고 가정해도 된다. 즉, 모든 노드는 이미\n하나의 서로소 집합(= 스스로가 스스로의 대표원소)을 이룬다. 이걸\n좀더 편하게 하기 위한 트릭으로 IdentityDict를 만들었다. dict를\n상속받아서 __missing__ 메소드를 제공하면, dict[x]를 할 때\nKeyError 예외가 발생한 순간 __missing__을 호출해서 디폴트 값을\n처리한다. 종종 쓰이는 테크닉이다.\n  섬의 개수를 세던\n문제처럼\n개수를 셀 필요는 없지만, 여기에 쓰인 최적화인 경로 압축은\n적용해뒀다.\n  union을 시도할 때 이미 같은 집합을 합치려는 시도가 발견되면\nTypeError를 발생시키도록 했다. 그냥 리턴으로 처리해도\n된다. 바깥에서 이걸 호출할 때에만 잘 처리해주면 된다."
					}
					,
					"ps-leetcode-group-anagrams": {
						"id": "ps-leetcode-group-anagrams",
						"title": "Group Anagrams",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/group-anagrams/",
						"content": "Group Anagrams\n\n단어 배열이 주어졌을 때, 아나그램끼리 배열로 묶어서 배열로\n 리턴하다. 배열 안에서의 아나그램 순서는 상관없다.\n\n아나그램이란 원래 단어의 글자의 순서를 바꿔서 다른 단어를 만들어내는\n 것이다.\n\n단어는 모두 알파벳 소문자만 담고 있다.\n\n접근 1 - 정렬\n\n  아나그램이면 단어를 이루는 글자의 개수가 같다. 따라서, 단어의\n글자를 알파벳 순으로 정렬하면 모든 아나그램은 다 같은 단어로\n정규화할 수 있다.\n  정규화된(정렬된) 단어를 키 값으로 하는 해시테이블에 원래 단어를\n누적한다. (순서 상관 없음)\n\n\ndef groupAnagrams(strs):\n    answer = defaultdict(list)\n    for word in strs:\n        key = ''.join(sorted(word))\n        answer[key].append(word)\n    return answer.values()\n\n\n접근 2 - 인코딩\n\n  어떻게든 아나그램을 하나의 표현으로 정규화하기만 하면 된다는 걸\n깨달았다.\n  아나그램의 정의에 따라 단어에 쓰인 글자의 개수가 같으면\n아나그램이다. 이 개수를 직접 정규화된 키로 쓸 수 있다. 알파벳\n소문자만 담겨있기 때문에 26개의 글자에 대해서만 세면 된다.\n\n\ndef groupAnagrams(strs):\n    def norm(word):\n        counts = [0] * 26\n        for letter in word:\n            counts[ord(letter) - ord('a')] += 1\n        return tuple(counts)\n    answer = defaultdict(list)\n    for word in strs:\n        key = norm(word)\n        answer[key].append(word)\n    return answer.values()"
					}
					,
					"ps-cpp-hash": {
						"id": "ps-cpp-hash",
						"title": "Hash",
						"version": "all",
						"categories": "",
						"url": " /ps/cpp/hash/",
						"content": "Hash\n충돌을 최대한 덜 나게 하는 암호학적 해시 함수를 만드는 일반적인 방법은\n  머클-담가드 쌓기라는 방법이다. 이 방법의 단순한 버전은 꽤 잘 동작하는 범용 해시\n  함수를 만드는데 쓸 수 있다. 입력 메시지(데이터)가 주어질 때, 이 방법은 다음과\n  같이 동작한다.\n\n  초기 상태 를 초기화 한다.\n  메시지에서 N 비트 씩 한번에 소모한다. 이를 블록 이라고 부르며 보통은\n    32비트, 64비트, 128비트 등으로 커진다.\n  현재 블록과 내부 상태 (이전 상태)를 가지고 믹스 연산을 수행해서 새로운 내부\n    상태를 만든다.\n  소모할 블록이 더이상 남아있지 않을 때까지 2로 돌아가서 블록을 소모한다.\n  내부 상태를 마무리짓고(finalize) 해시 값을 최종 리턴한다.\n\n여기서 내부 상태 란 최소한 해시 값의 크기만큼은 되는 메모리를 말한다. 1번에서\n  초기화된 값을 보통 초기화 벡터(Initialisation Vector)라고 한다. 이 상태 값은\n  이후 블록에 대한 믹싱 연산을 진행할 때 체이닝되어 사용되는데, 이를 통해 메시지\n  블록 사이의 데이터 종속성을 담을 수 있다.\n5번에서 내부 상태를 마무리짓는 과정은 최종적으로 리턴할 해시 값을 준비하는\n  과정이다. 예를 들어 내부 블록 체이닝 연산에 쓰인 중간 값이 최종 해시 값보다 큰\n  경우 이를 잘라내거나, 기타 매직 넘버를 이용해서 한번 더 최종 해싱을 하는 등의\n  작업을 한다.\nHash Functions\nRS Hash\nC 책에 나오는 Robert Sedgwicks의 알고리즘이다.\nunsigned int RSHash(const char* str, unsigned int length) {\n  unsigned int b = 378551;\n  unsigned int a = 63689;\n  unsigned int hash = 0;\n  unsigned int i = 0;\n  for(; i &lt; length; ++str, ++i) {\n    hash = hash * a + (*str);\n    a = a * b;\n  }\n  return hash;\n}\n\nJS Hash\nby Justin Sobel\nunsigned int JSHash(const char* str, unsigned int length) {\n  unsigned int hash = 1315423911;\n  unsigned int i = 0;\n  for (; i &lt; length; ++str, ++i) {\n    hash ^= ( (hash &lt;&lt; 5) + (*str) + (hash &gt;&gt; 2) );\n  }\n  return hash;\n}\n\nPJW Hash\n르네상스 테크놀로지의 Peter J. Weinberger 가 만든 알고리즘이다. 컴파일러\n  책에서 이 방법을 언급한다고 한다.\nunsigned int PJWHash(const char* str, unsigned int length) {\n  const unsigned int BitsInUnsignedInt = (unsigned int) (sizeof(unsigned int) * 8);\n  const unsigned int ThreeQuarters = (unsigned int) ((BitsInUnsignedInt * 3) / 4);\n  const unsigned int OneEighth = (unsigned int) (BitsInUnsignedInt / 8);\n  const unsigned int HighBits = (unsigned int) (0xFFFFFFFF) &lt;&lt; (BitsInUnsignedInt - OneEighth);\n\n  unsigned int hash = 0, test = 0, i = 0;\n  for (; i &lt; length; ++str, ++i) {\n    hash = (hash &lt;&lt; OneEighth) + (*str);\n    if ((test = hash &amp; HighBits) != 0) {\n      hash = ((hash ^ (test &gt;&gt; ThreeQuarters)) &amp; (~HighBits));\n    }\n  }\n  return hash;\n}\n\nELF Hash\nPJW Hash랑 비슷한데 32비트 프로세서를 위한 트윅이 들어가있다. 유닉스 기반\n  운영체제에서 많이 쓰인다.\nunsigned int ELFHash(const char* str, unsigned int length) {\n  unsigned int hash = 0, x = 0, i = 0;\n  for (; i &lt; length; ++str, ++i) {\n    hash = (hash &lt;&lt; 4) + (*str);\n    if ((x = hash &amp; 0xF0000000L) != 0) {\n      hash ^= (x &gt;&gt; 24);\n    }\n    hash &amp;= ~x;\n  }\n  return hash;\n}\n\nDJB Hash\nDaniel J. Bernstein 교수가 제안한 해시 방법으로 유즈넷 뉴스그룹 comp.lang.c 에서\n  처음 공개되었다. 발표된 것중 가장 효율적인 해시 함수 중 하나이다.\nunsigned int DJBHash(const char* str, unsigned int length) {\n  unsigned int hash = 5381, i = 0;\n  for (; i &lt; length; str++, i++) {\n    hash = ((hash &lt;&lt; 5) + hash) + (*str);\n  }\n  return hash;\n}"
					}
					,
					"ps-theory-heap": {
						"id": "ps-theory-heap",
						"title": "Heap",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/heap/",
						"content": "Heap"
					}
					,
					"wip-type-hindley-milner-type-system": {
						"id": "wip-type-hindley-milner-type-system",
						"title": "Hindley-Milner Type System",
						"version": "all",
						"categories": "",
						"url": " /wip/type/hindley-milner-type-system/",
						"content": "힌들리-밀너 타입 시스템\n람다 대수에 매개변수 다형성 (Parametric Polymorphism)을 구현한\n 전형적인 타입 시스템이다. J. Roger Hindley에 의해 처음 연구되었고\n 이후에 Robin Milner에 의해 재발견되었다. Luis Damas가 나중에 박사\n 학위 논문에서 증명했다.\n\nHM의 뛰어난 성질 중 놀라운 점은 완전성(completeness)과 가장 일반적인\n 타입 (Most General Type; 또는 Principal Type이라고 함)을 프로그래머의\n 도움(타입 어노테이션) 없이 추론할 수 있는 능력이다. 알고리즘 W를 통해\n 실제로 효율적인 타입 추론 방법을 구현할 수 있으며 이론적으로는 높은\n 복잡도를 갖고 있지만 아주 큰 코드베이스에서도 잘 동작한다. HM은\n 함수형 언어에서 자주 사용된다. HM은 ML 프로그래밍 언어의 타입\n 시스템의 일부로 최초 구현되었다. 그 이후로 하스켈의 타입 클래스처럼\n 다양한 방법으로 확장되었다.\n\n소개\n타입 추론 방법으로써, HM은 타입이 전혀 적혀있지 않은 프로그램의 변수,\n 표현식, 함수의 타입을 추론(연역; deduce)할 수 있다. 범위에 민감하기\n 때문에, 소스 코드의 작은 부분의 타입을 추론하는 것에 한정되지 않고\n 완전한 프로그램이나 모듈에서 추론하는 것도 가능하다. 또한 매개변수\n 타입에 대응할 수 있기 때문에, 수많은 함수형 프로그래밍 언어의 타입\n 시스템의 핵심이다.\n\n단순 타입 람다 대수를 위한 타입 추론 알고리즘의 기원은 1958년 Haskell\n Curry와 Robert Feys까지 거슬러 간다. 1969년에는 J. Roger Hindley가 이\n 타입 추론이 항상 가장 일반적인 타입(프린시펄 타입)을 추론한다는 것을\n 증명한다. 1978년에는 Robin Milner가 Hindley의 작업과는 독립적으로\n 동일한 알고리즘인 알고리즘 W를 만들었다. 1982년에 Luis Damas는 마침내\n 밀너의 알고리즘이 완전하다는 것을 증명하고 이를 확장하여 다형성을\n 추가하였다.\n\n단형성과 다형성\n단순 타입 람다 대수에서는 타입 T는 하나의 원자 타입 상수이거나 T -&gt;\n T 형태의 함수 타입이다. 이런 타입을 단형성(monomorphic)이라고\n 한다. 산술 계산에 사용된 타입이 대표적이다.\n\n3        : Number\nadd 3 4  : Number\nadd      : Number -&gt; Number -&gt; Number\n\n\n이와 반대로, 타입이 없는 람다 대수는 완전히 타입 중립적이고 많은\n 함수들이 모든 타입의 아규먼트에 유효하게 적용될 수 있다. 항등\n 함수(Identity function)가 대표적이다.\n\nid = \\x. x\n\n\n다형성(polymorphism)이란 일반적으로 어떤 연산이 하나 이상의 타입의\n 값을 받아들인다는 뜻인데, 위 예시의 다형성에서는 매개변수화 되어\n 있다. 단어 뜻 그대로 타입 스킴(Type Schemes)이라는 용어를 쓰기도\n 하는데, 다형성의 매개변수적 특성을 강조한다. 추가적으로 상수는\n 양화된(Quantified) 타입 변수와 함께 타입되기도 한다.\n\ncons :  forall a. a -&gt; List a -&gt; a\nnil  :  forall a. List a\nid   :  forall a. a -&gt; a\n\n\n다형 타입은 타입 변수의 일관적인 대입을 통해 단형 타입이 될 수도\n 있다. 단형 인스턴스의 예시는 다음과 같다.\n\nid'  : String -&gt; String\nnil' : List Number\n\n\n좀더 일반적으로, 타입은 타입 변수를 포함하고 있을 때 다형성을 가지고,\n 그렇지 않으면 단형성을 갖는다.\n\n단형 타입만을 지원하는 파스칼이나 C에서 사용된 타입 시스템과는\n 반대로, HM은 매개변수 다형성을 위해 태어났다. C++와 같은 이후에 나온\n 언어는 다른 형태의 다형성에 집중하고 있는데 객체 지향\n 프로그래밍에서의 서브 타이핑과 오버로딩이다. 서브 타이핑은 HM과\n 호환될 수 없는 반면, 오버로딩의 변종들은 하스켈의 HM 기반 타입\n 시스템에서 사용할 수 있다.\n\nLet-다형성\n단순 타입 람다 대수를 위한 타입 추론을 다형성을 갖도록 확장할 때,\n 언제 값의 인스턴스를 추론해야 하는지를 정의해야 한다. 이상적으로는\n 묶인(bound) 변수는 모두 허용되어야 할 것 같다.\n\n(\\ id. .... (id 3)  .... (id \"text\") ...  ) (\\ x. x)\n\n\n안타깝지만, 다형 타입 람다 대수에서의 타입 추론은 결정\n 불가능(Undecidable)이다. 대신, HM은 다음과 같은 형태의 Let-다형성을\n 제공한다.\n\nlet id = \\ x. x\n  in ... (id 3) ... (id \"text\") ...\n\n\n문법의 표현식을 확장해서 변수가 묶이는 메커니즘을 제한한다. 오직\n let 생성자로 묶인 값만이 인스턴스화의 대상이 되는데, 이것이 곧\n 다형성이며, 람다 추상화 안의 매개변수는 단형성으로 취급된다.\n\n힌들리-밀너 타입 시스템\n타입 시스템은 표현식, 타입 등에 대한 언어를 수정하는 문법 규칙을 통해\n 형식적으로(formally) 설명할 수 있다. 여기서는 너무 형식적으로\n 설명하진 않는다. 그 후 타입 규칙을 통해 어떻게 표현식과 타입이\n 연관되는지를 정의한다.\n\n문법\n타입될 표현식은 람다 대수를 let 표현식으로 확장한 것과 정확히\n 일치한다. 괄호는 표현식의 모호함을 해결하는데 쓰인다. 함수 적용은\n 왼쪽부터 묶이며 추상화나 let 생성자보다 우선순위가 높다.\n\ne = x                    variable\n  | e1 e2                application\n  | \\x. e                abstraction\n  | let x = e1 in e2     let-binding\n\n\n타입은 문법적으로 모노 타입과 폴리 타입으로 나뉘어진다.\n\n모노 타입\n모노 타입은 항상 구체적인 타입을 지정한다. 모노 타입 t는\n 문법적으로는 터미널로 표현된다.\n\n모노 타입의 예시는 타입 상수인 int나 string, 그리고 매개변수화\n 타입인 Map (Set string) int 등이 있다. 후자의 타입은 타입 함수의\n 적용의 한 예시로, 집합 \\(\\{Map^2, Set^1, string^0, int^0,\n \\rightarrow^2\\}\\) (윗첨자는 타입 매개변수의 개수를 뜻함)의\n 원소이다. 타입 함수 C의 완전한 집합은 HM에서 반드시 함수 타입인\n \\(\\rightarrow^2\\)를 포함해야 한다는 것만 빼면 임의로 만들 수 있다. 예를 들면\n 정수를 문자열로 맵핑하는 함수는 int -&gt; string 타입을\n 갖는다. 여기서도 괄호를 이용해서 타입 표현식의 모호함을 없앨 수\n 있다. 타입 함수의 적용은 중위 화살표 연산자 -&gt;보다 우선 순위가\n 높으므로 우측부터 묶인다.\n\n타입 변수는 모노 타입으로 취급된다. 모노 타입을 단형 타입과 헷갈릴 수\n 있는데, 단형 타입은 타입 변수가 없고 오직 터미널만 허용한다.\n\n두 모노 타입이 동일한 터미널을 가지면 같다.\n\n폴리 타입\n폴리 타입, 또는 타입 스킴은 0개 이상의 보편 양화사(Universal\n Quantifier, \\(\\forall\\))를 통해 묶인 타입 변수를 포함하는\n 타입이다. 예를 들면 \\(\\forall a. a \\rightarrow a\\)과 같이.\n\n폴리 타입 \\(\\forall a. a \\rightarrow a\\)을 갖는 함수는, 같은 타입을\n 갖는 모든 값을 스스로에게 맵핑할 수 있고, 항등 함수가 이 타입을\n 갖는다.\n\n또 다른 예시로, \\(\\forall a. (Set\\,a) \\rightarrow int\\) 는 모든\n 타입의 유한 집합을 받아서 정수로 맵핑하는 함수의 타입이다. 집합의\n 기수를 계산하는 함수가 이 타입을 갖는다.\n\n양화사는 오직 최상위 레벨에서만 나타날 수 있다. 예를 들어, 타입 \\(\\forall a. a \\rightarrow \\forall a. a\\) 는 제외된다. 또한 정의에 따라\n 모노 타입은 폴리 타입에 포함되는데, 따라서 타입은 일반적인 형태인 \\(\\forall a_1. ... \\forall a_n. \\tau, n \\ge 0\\)를 갖는다. 이때 \\(\\tau\\)는 모노 타입이다.\n\n폴리 타입의 동일함은 양화의 순서와 양화된 변수의 이름을 바꾸는(알파\n 변환) 일에 달려 있다. 게다가 모노 타입에 나타나지 않는 양화된 변수는\n 버릴 수 있다.\n\n컨텍스트와 타이핑\n여전히 서로소인 두 부분을 의미있게 합칠려면, 세 번째 부분이 필요하다:\n 바로 컨텍스트이다. 문법적으로, 컨텍스트는 x: a 쌍의 리스트로, 대입,\n 가정, 또는 바인딩이라고 부른다. 각각의 쌍이 뜻하는 것은 값의 변수\n x는 타입 a를 갖는다는 것이다. 여기까지 세 가지 부분을 합치면\n 타이핑 판단이라는 것을 할 수 있는데, \\(\\Gamma \\vdash e: a\\)의\n 형태이며, 이는 “어떤 가정 \\(\\Gamma\\) 하에 표현식 e는 타입 a를\n 갖는다”를 말한다.\n\n자유 타입 변수\n타입 \\(\\forall a_1. ... \\forall a_n. \\tau\\) 에서, 심볼 \\(\\forall\\)은 타입 변수 \\(a_i\\)를 모노 타입 \\(\\tau\\) 에 묶는(바인딩)\n 양화사이다. 변수 \\(a_i\\) 는 양화되었다고 하며, \\(\\tau\\) 안에서\n 등장하는 모든 양화된 타입 변수는 묶였다(bound)고 하고, \\(\\tau\\)\n 안에 묶이지 않은 모든 타입 변수는 자유롭다(free)고 한다. 폴리\n 타입에서의 양화사 \\(\\forall\\)과 더불어 타입 변수는 컨텍스트를\n 통해서도 묶일 수 있다. 이런 변수는 타입 상수처럼\n 행동한다. 마지막으로, 타입 변수는 타이핑 도중에 안묶여도 괜찮은데,\n 이런 경우 암묵적으로 모두 양화된 것으로 본다.\n\n묶인 타입 변수와 안묶인(자유) 타입 변수의 존재는 프로그래밍\n 언어에서는 흔하지 않다. 때때로 모든 타입 변수는 암묵적으로 모두\n 양화된 것으로 취급된다. 예를 들면, 프롤로그에서는 자유 변수가 있는\n 클로즈는 없다. 하스켈에서처럼, 모든 타입 변수는 암묵적으로 양화되어\n 등장하는데, 즉 하스켈 타입 a -&gt; a는 \\(\\forall a. a \\rightarrow a\\)를 뜻한다."
					}
					,
					"wip-type-how-ocaml-type-checker-works": {
						"id": "wip-type-how-ocaml-type-checker-works",
						"title": "How OCaml Type Checker Works",
						"version": "all",
						"categories": "",
						"url": " /wip/type/how-ocaml-type-checker-works/",
						"content": "How OCaml Type Checker Works - or What Polymorphism and Garbage Collection Have In Common\n\n힌들리-밀너 타입 추론에는 알고리즘 W 말고도 좀 더 많은 것이\n 있다. 1988년에, 디디어 레미(Didier Remy)는 Caml의 타입 추론 속도를\n 높일려고 하고 있었는데, 타입 일반화(type generalization)를 위한\n 우아한 방법을 발견했다. 타입 환경(type environment)을 스캐닝하지\n 않아도 되서 빠를 뿐만이 아니다. 이 방법은 로컬에 선언되었지만\n 보편적(universal; \\(\\forall\\)) 또는 존재적(existential; \\(\\exists\\)) 양화로 빠져나가는(escape) 타입을 잡을 수 있게 스무스하게\n 확장된다.\n\nOCaml 타입 체커의 알고리즘과 구현은 모두 거의 알려져있지 않고 또 거의\n 문서화되어 있지 않다. 이 페이지는 레미의 알고리즘을 설명하고 널리\n 알리려 한다. 또, OCaml 타입 체커의 일부를 해석하려는 시도다. 레미의\n 알고리즘의 역사 또한 보존하고자 한다.\n\n레미의 알고리즘의 매력은 타입 일반화를 일종의 의존성 추적으로 바라본\n 통찰력에 있다. 이는 (메모리) 구역과 세대별 가비지 콜렉션과 같은 자동\n 메모리 관리에서 쓰이는 추적 방법과 같은 종류이다. (타입) 일반화는\n 노드에는 타입을 어노테이트하고 엣지는 공유된 타입을 나타내도록 표현한\n AST에서 도미네이터를 찾는 일로 볼 수 있다.\n\nIntroduction\n이 페이지는 원래 광범위하고, 복잡하고, 거의 문서화가 안된 OCaml 타입\n 체커 코드를 이해하기 위해서 작성하던 노트로 시작했다. 코드를 파고\n 들어가 보니 엄청난 보물이 발견되었다. 그 중 하나인 효율적이고 우아한\n 타입 일반화 방법을 여기서 소개한다.\n\nOCaml의 타입 일반화는 이른바 타입의 레벨(levels) 추적\n 기반이다. 완전히 같은 레벨은 모듈 안에 정의된 타입이 더 넓은 범위로\n 빠져나가는(escape) 것을 막아준다. 따라서 레벨은 지역적으로 도입된\n 타입 생성자에게 구역 규율(region discipline)을 강제한다. 일반화와\n 구역이 아주 균일한 방법으로 처리되는 것은 굉장히 흥미롭다. OCaml 타입\n 체커에서 레벨은 더 많은 쓰임새가 있는데, 폴리모픽 필드와 존재\n 양화사(existential)를 가진 레코드에도 쓰인다. MetaOCaml은 미래에 쓰일\n (future-stage) 바인딩 범위를 추적하기 위해서 레벨에 간접적으로\n 의존하고 있었다. 이런 모든 어플리케이션에는 공통적인 불평이 있었는데,\n 의존성을 추적하는 일과 구역 억제 또는 데이터 의존 그래프의\n 도미네이터를 계산하는 일이었다. 하나는 곧바로 Tofte와 Talpin의 구역\n 기반의 메모리 관리를 떠올리게 한다. Fluet과 Morrisett이 보여줬듯이,\n 구역을 위한 Tofte와 Taplin 타입 시스템은 할당된 데이터가 그 구역에서\n 빠져나가는 것을 정적으로 막기 위해서 보편 양화사에 의존하여 System\n F에서 인코딩될 수 있다. 이것과 듀얼하게, 레벨 기반 일반화는 타입\n 변수의 구역을 결정하기 위해서 타입 변수가 빠져나가는 것을 추적하는\n 것에 의존하고, 따라서 보편 양화사를 위한 장소이다.\n\nOCaml의 일반화는 1988년에 디디어 레미에 의해 발견된 알고리즘의\n (부분적인) 구현이다. 이 아이디어는 타입이 명시된 AST 위에서 타입의\n 공유를 명시적으로 표현하는 것이다. 타입 변수는 오직 그 변수의 모든\n 발생(all occurrences)을 도미네이트하는 노드에서만 양화될 수\n 있다. 타입 일반화는 그래프 도미네이터의 증분 계산에 해당한다. 레미의\n MLF는 이 아이디어의 자연스러운 결과물이다.\n\n아쉽게도, 레미의 일반화 알고리즘과 그 기저의 아이디어는 거의 알려져\n 있지 않다. OCaml에 있는 것과 같은 구현은 OCaml 소스 코드에 아주 짧고\n 헷갈리게 작성된 주석 외에는 전혀 문서화되어 있지 않는 것 같다. 이건\n 널리 알려져야 한다. 이를 위해서, (1) 알고리즘에 대한 동기 부여와\n 설명을 해서 그 직관과 뼈대 구현을 드러내고, (2) OCaml 타입 체커를\n 해석한다.\n\n이 글의 두 번째 파트는 OCaml 타입 체커의 일부분에 주석을 다는 것이\n 목적이고, 따라서, 꽤 기술적이다. OCaml 4.00.1 버전의 타입 체킹 코드를\n 참조하고 있다. typing/ 디렉토리 안에 있다. typecore.ml 파일이\n 타입 체커의 핵심이다. AST의 노드를 타입과 타이핑 환경으로\n 어노테이트한다. 정확히는, parsing/parsetree.mli에 정의된\n Parsetree를 Typedtree로 변환한다. ctype.ml 파일은 유니피케이션\n 알고리즘과 레벨 조작 함수를 구현하고 있다.\n\nGeneralization\n\n이 배경 설명에서는 힌들리 밀너 타입 시스템의 타입 일반화를 설명하고\n 나이브한 구현의 미묘한 점과 비효율적인 점을 강조한다. 이 비효율은\n 레미가 레벨 기반 일반화 알고리즘을 발견하는 동기가 되었다.\n\n타입 환경 G에 대한 타입 t의 일반화(generalization) GEN(G,\n t)가 G에서 자유로 나타나지 않는 t의 자유 타입 변수를 양화하는\n 것임을 떠올려보자. 즉, GET(G, t) =  \\(\\forall \\alpha_1\n ... \\alpha_n .\\) t where \\({ \\alpha_1, ..., \\alpha_n} =\\)\n FV(t) - FV(G). 힌들리 밀너 식으로 얘기하면, 이 양화는 타입을 이른바\n 타입 스키마(type schema)로 바꾼다. 일반화는 let 표현식의 타입\n 체킹에 쓰인다.\n\nG ㅏ e : t     G, (x: GEN(G, t)) ㅏ e2 : t2\n---------------------------------------------\nG ㅏ let x = e in e2 : t2\n\n\n즉, let에 묶인 변수에 추론된 타입은 let 표현식의 바디를 타입\n 체킹할 때 일반화된다. ML은 일반화에 조건을 추가하는데, 이른바 값\n 제약(value restriction)이다. let에 묶인 표현식 e는 겉보기에는\n 반드시 눈에 보이는 사이드 이펙트가 없어야 한다. 기술적으로는, e는\n 반드시 비확장성(nonexpansive)이라는 문법 테스트를 통과해야\n 한다. OCaml은 이 값 제약을 완화하는데, 뒤에서 나온다.\n\n일반화의 단순한 예시는 다음과 같다.\n\nfun x -&gt; let y = fun z -&gt; z in y\n(* 'a -&gt; ('b -&gt; 'b) *)\n\n\n타입 체커는 fun z -&gt; z에 대해서 새로운, 그래서 유니크한 타입 변수\n \\(\\beta\\)를 도입하여 \\(\\beta \\to \\beta\\) 타입을 추론한다. 표현식\n fun z -&gt; z는 문법적으로는 값이고, 일반화가 진행되고, 그래서 y는\n 타입 \\(\\forall \\beta. \\beta \\to \\beta\\)를 갖는다. 폴리모픽 타입이기\n 때문에, y는 다른 타입 문맥에서 등장할 수도 있다. 즉, 다른 타입의\n 아규먼트에 적용될 수도 있다. 예를 들면 다음과 같다.\n\nfun x -&gt;\n  let y = fun z -&gt; z in\n  (y 1, y true)\n(* 'a -&gt; int * bool *)\n\n\n일반화 GEN(G, t)는 G에 나타나지 않는 t의 자유 타입 변수에\n 대해서만 양화한다. 이 조건은 미묘하지만 아주 중요하다. 이게 없으면,\n \\(\\alpha \\to \\beta\\) 같은 불안전한 타입이 다음 함수에 대해서 추론될\n 수 있다.\n\nfun x -&gt; let y = x in y\n\n\n함수 타입을 추론하려면, 먼저 함수의 바디 let y = x in y의 타입을\n 새로운 타입 변수 'a(\\(\\alpha\\))가 도입된 타입 환경 x:'a에서\n 추론한다. 위의 let 규칙에 의해서 y에 타입이 추론되는데,\n 결과적으로 타입 GEN(x:'a, 'a)를 추론한다. 분명히 'a는 타입 환경\n x:'a에서 나타난다. 그럼에도 불구하고 여기에 양화를 해버리면, y는\n 폴리모픽 타입 \\(\\forall \\alpha. \\alpha\\)를 받게 되고, 따라서 어떤\n 타입으로든 인스턴스화 될 수 있다. 그 결과 함수는 표면적으로\n 아규먼트를 그 어떤 타입으로 바꿀 수 있게 된다.\n\n따라서, 양화할 각각의 타입 변수에 대해서 우리는 반드시 타입 환경에\n 나타나지 않음을 확인해야 한다. 나이브하게 생각하면, 그냥 타입\n 환경을 다 스캔해서 모든 바인딩의 타입을 살펴볼 수 있다. 사실, 원래\n Caml이 정확히 이걸 구현했었다. 하지만 타입 환경은 엄청나게 커질 수\n 있다. 일반적으로 ML 함수들은 아주 긴 let 표현식 시퀀스를 담고\n 있다. 일반적인 let은 이전에 나타난 모든 let들의 바인딩을 타입\n 환경에 갖고 있다. 재귀적인 let의 환경은 모든 let 형제(sibling)의\n 바인딩을 갖고 있다. 하나의 let에 대한 일반화의 일부로 이 환경을\n 스캔하면 함수 크기에 대해 선형 시간이 걸린다. 그러면 전체 프로그램의\n 타입 체킹은 제곱이 된다. 레미가 회상하기로 비효율적인 일반화는 Caml\n 컴파일의 느린 속도의 주된 이유 중 하나였다. 컴파일러를\n 부트스트래핑하면서 패턴과 표현식을 컴파일하기 위해서 두 개의 상호\n 재귀 함수를 타입 체킹하는 일은 거의 20분 걸렸다.\n\n타입 환경을 스캔하지 않는 방법이 있어야 한다.\n\nUnsound generalization as memory mismanagement\n\n여기서는 먼저 레미의 알고리즘 뒤에 있는 아이디어를 구역 기반 메모리\n 관리와 관련지어 소개한다. 구체성을 위해서 토이 힌들리 밀너 타입\n 추론기를 쓸 것이다. 여기서 추론기는 타입 환경을 고려하지 않고 타입의\n 자유 타입 변수를 양화하는 불안전한(unsound) 일반화 함수를 갖고\n 있다. 세 가지 간단한 예시를 타입 체크할 것이고, 불안전한 타입을\n 추론하는 일을 수동 메모리 관리에서의 일반적인 문제와 연관지을 것이다:\n 여전히 사용 중인 메모리를 해제하는 일이다. 불안전한 일반화는 이 다음\n 섹션에서 수정되는데, 자원의 성급한 해제를 막는 표준적인 방법에서\n 영감을 얻었다.\n\n우리의 힌들리 밀너 타입 추론기가 장난감이긴 하지만, 진짜 OCaml 타입\n 체커의 많은 구현적인 결정(그리고 몇몇 함수 이름)을 공유한다. 이걸\n 이해하면 나중에 OCaml 내부를 살펴볼 때 많은 도움이 된다.\n\n우리의 토이 언어는 표준적인 순수 람다 대수에 let을 추가한 것이다.\n\ntype exp =\n    | Var of varname\n    | App of exp * exp\n    | Lam of varname * exp\n    | Let of varname * exp * exp\n\n\n타입은 (자유 또는 묶인) 타입 변수, 양화된 타입 변수, 함수 타입으로\n 구성된다.\n\ntype qname = string\ntype typ =\n    | TVar of tv ref\n    | QVar of qname\n    | TArrow of typ * typ\nand tv = Unbound of string | Link of typ\n\n\nQVar 타입은 타입 스키마이다. 즉, 단순 타입이 아니다. 힌들리 밀너\n 시스템에서의 타입 스키마, 또는 양화된 타입은 전치형(prenex form), 즉\n 보편 양화사가 모두 바깥에 붙는데, 그래서 양화사를 명시적으로\n 표현해주지 않아도 된다.\n\n프롤로그 언어로부터 내려온 전통에 따라, 타입 변수는 레퍼런스 쎌로\n 표현된다. 안묶인 변수(자유 변수)는 널 또는 셀프 포인터를 담고\n 있다. 또는, 우리의 경우, 쉬운 출력을 위해서 변수 이름을 담고\n 있다. 자유 타입 변수가 다른 타입 t'과 합쳐질 때(unified), 레퍼런스\n 쎌은 t' 포인터로 덮어 써진다. 원형 타입(즉, 불안전한 타입)을 막기\n 위해서, “나타나는지 체크(occur check)”를 먼저 수행한다. occurs tv\n t'는 t'를 탐색하면서 만약 타입 변수 tv를 만나면 예외를\n 발생시킨다.\n\nlet rec unify : typ -&gt; typ -&gt; unit = fun t1 t2 -&gt;\n    if t1 == t2 then ()  (* t1 and t2 are physically the same *)\n    else match (t1, t2) with\n    | (TVar ({contents= Unbound _} as tv), t')\n    | (t', TVar ({contents= Unbound _} as tv)) -&gt;\n        occurs tv t' ;\n        tv := Link t'\n    | (TVar {contents= Link t1}, t2) | (t1, TVar {contents= Link t2}) -&gt;\n        unify t1 t2\n    | (TArrow (tyl1, tyl2), TArrow (tyr1, tyr2)) -&gt;\n        unify tyl1 tyr1 ;\n        unify tyl2 tyr2\n    (* everything else is error *)\n\n\n타입 체커는 완전히 표준적인 구현이다. 타입 환경 env에서의 표현식\n exp의 타입을 추론한다.\n\ntype env = (varname * typ) list\nlet rec typeof : env -&gt; exp -&gt; typ = fun env -&gt; function\n    | Var x -&gt; inst (List.assoc x env)\n    | Lam (x, e) -&gt;\n        let ty_x = newvar () in\n        let ty_e = typeof ((x, ty_x) :: env) e in\n        TArrow (ty_x, ty_e)\n    | App (e1, e2) -&gt;\n        let ty_fun = typeof env e1 in\n        let ty_arg = typeof env e2 in\n        let ty_res = newvar () in\n        unify ty_fun (TArrow (ty_arg, ty_res)) ;\n        ty_res\n    | Let (x, e, e2) -&gt;\n        let ty_e = typeof env e in\n        typeof ((x, gen ty_e) :: env) e2\n\n\nnewvar 함수는 새로운 TVar를 유니크한 이름으로 할당한다. inst\n 함수는 타입 스키마를 인스턴스화하는데, 즉 모든 QVar를 새로운\n TVar로 대체한다. 이것도 표준적 구현이다. 일반화 함수는\n 불안전(unsound)하다: 타입 환경과 상관없이 타입에 있는 모든 자유\n 변수를 양화해버린다.\n\nlet rec gen : typ -&gt; typ = function (* unsound! *)\n    | TVar {contents= Unbound name} -&gt; QVar name\n    | TVar {contents= Link ty} -&gt; gen ty\n    | TArrow (ty1, ty2) -&gt; TArrow (gen ty1, gen ty2)\n    | ty -&gt; ty\n\n\n양화는 TVar를 해당하는 QVar로 대체한다. 따라서 원래의 TVar는\n 암묵적으로 해제(deallocated)된다: 자유 변수가 묶일 때, 말 그대로\n “사라지고(disappears)”, 바인더를 가리키는 포인터로 대체된다. 즉,\n\n  TVar를 할당 (newvar ()) &lt;-&gt; 메모리 할당\n  TVar를 QVar로 대체 (양화, 즉 일반화) &lt;-&gt; 메모리 해제\n\n\n의 비유가 성립한다.\n\n타입 변수의 관점에서 보면, typeof는 자유 변수를 할당하고, 이것들을\n 합친 다음, 양화를 한 다음 다시 해제한다. 자유 타입 변수에 영향을 주는\n 이 세 가지 메인 연산의 시퀀스를 관찰할 수 있는 단순한 예시를 타입\n 체크해보자. 첫 번째 예시는 아무 문제가 없어야 하는 예이다.\n\nfun x -&gt; let y = fun z -&gt; z in y\n\n\n타입 체킹의 트레이스에서 타입 변수와 관계된 연산만 보여주면 다음과\n 같다.\n\n1 ty_x = newvar ()         (* fun x -&gt; .... *)\n2   ty_e =                 (* let y = fun z -&gt; z in y *)\n3     ty_z = newvar ();    (* fun z -&gt; ... *)\n3     TArrow (ty_z, ty_z)  (* inferred for: fun z -&gt; z *)\n2   ty_y = gen ty_e        (* ty_z remains free, and so *)\n2   deallocate ty_z        (* quantified and disposed of *)\n1 TArrow (ty_x, inst ty_y) (* inferred for: fun x -&gt; ...*)\n\n\n각 줄에 있는 번호는 typeof 재귀 함수의 호출 깊이이다. typeof가\n AST의 리프가 아닌 각 노드에 대해서 재귀하기 때문에, 재귀 호출의\n 깊이는 곧 아직 타입 체킹되지 않은 AST 노드의 깊이와 같다. 추론된\n 타입은 예상대로 'a -&gt; 'b -&gt; 'b 이다. 아무 문제가 없다.\n\n두 번째 예시는 앞에서 본 것인데, 불안전한 일반화가 불안전한 타입 'a\n -&gt; 'b를 추론하는 것이다.\n\nfun x -&gt; let y = x in y\n\n\n마찬가지로 TVar 연산 트레이스를 살펴보면 문제점이 드러난다.\n\n1 ty_x = newvar ()         (* fun x -&gt; .... *)\n2   ty_e =                 (* let y = x in y *)\n3     inst ty_x            (* inferred for x, same as ty_x *)\n2   ty_y = gen ty_e        (* ty_x remains free, and is *)\n2   deallocate ty_x        (* quantified and disposed of *)\n1 TArrow (ty_x, inst ty_y) (* inferred for: fun x -&gt; ...*)\n\n\n타입 변수 ty_x가 깊이 1에서 쓰였고 리턴 타입의 일부이다. 그런데\n 양화되고 나서 깊이 2에서 버려진다. 여전히 쓰이고 있는 변수가 버려진\n 것이다!\n\n세 번째 예시도 문제가 있다. 불안전한 일반화가 또 불안전한 타입 ('a\n -&gt; 'b) -&gt; ('c -&gt; 'd)를 추론해버린다.\n\nfun x -&gt; let y = fun z -&gt; x z in y\n\n\n이 트레이스는 메모리 관리 문제를 또 보여준다.\n\n1 ty_x = newvar ()           (* fun x -&gt; .... *)\n2   ty_e =                   (* let y = ... *)\n3     ty_z = newvar ()       (* fun z -&gt; ... *)\n4       ty_res = newvar ()   (* typechecking: x z *)\n4       ty_x :=              (* as the result of unify *)\n4         TArrow (ty_z, ty_res)\n4       ty_res               (* inferred for: x z *)\n3     TArrow (ty_z, ty_res)  (* inferred for: fun z -&gt; x z*)\n2   ty_y = gen ty_e          (* ty_z, ty_res remain free *)\n2   deallocate ty_z          (* quantified and disposed of *)\n2   deallocate ty_res        (* quantified and disposed of *)\n1 TArrow (ty_x, inst ty_y)   (* inferred for: fun x -&gt; ... *)\n\n\n타입 변수 ty_z와 ty_res가 양화되고 난 후 깊이 2에서 버려지는데,\n 여전히 TArrow (ty_z, ty_res) 타입의 일부로 할당되어 있는 채로\n ty_x에 할당되고 결과의 일부로 리턴된다.\n\n모든 불안전한 예시는 여전히 사용 중인 메모리(TVar)를 해제하는\n 이른바 “메모리 관리 문제”를 보여준다. 타입 변수가 양화될 때, 나중에\n 그 어떤 타입이든 간에 이것과 함께 인스턴스화 될 수 있다. 하지만, 타입\n 환경에 나타나는 타입 변수는 나머지 타입 체킹에 영향을 주지 않고서는\n 어떤 타입으로도 대체될 수 없다. 비슷하게, 우리가 메모리를 해제할 때,\n 우리는 런타임에 그 메모리를 재할당해서 임의의 데이터로 덮어쓸 수 있는\n 권한을 준다. 프로그램의 나머지 부분은 해제된 메모리에 어떤 식으로든\n 의존해서는 안된다. 마치 정말로 해제된 것처럼 가정해서, 프로그램에서\n 더 이상 필요하지 않은 것처럼 다뤄야 한다. 사실, “사용하지 않는\n 메모리”는 프로그램의 나머지 부분에 영향을 미치지 않는 메모리에 대한\n 임의의 변경으로 정의할 수 있다. 여전히 사용 중인 메모리를 해제하는\n 것은 프로그램의 나머지 부분에 영향을 미쳐서, 크래시를 내기도\n 한다. 덧붙여서, 위의 예시에서 추론된 불안전한 타입은 종종 동일한\n 결과를 초래하기도 한다 (즉, 크래시 난다).\n\n참조: 불안전한 타입 체커 전체 코드\n\ntype varname = string\n\ntype exp =\n    | Var of varname\n    | App of exp * exp\n    | Lam of varname * exp\n    | Let of varname * exp * exp\n\ntype qname = string\ntype typ =\n    | TVar of tv ref\n    | QVar of qname\n    | TArrow of typ * typ\nand tv = Unbound of string | Link of typ\n\nlet gensym_counter = ref 0\nlet reset_gensym : unit -&gt; unit =\n    fun () -&gt; gensym_counter := 0\n\nlet gensym : unit -&gt; string = fun () -&gt;\n    let n = !gensym_counter in\n    let () = incr gensym_counter in\n    if n &lt; 26 then String.make 1 (Char.chr (Char.code 'a' + n))\n        else \"t\" ^ string_of_int n\n\nlet newvar : unit -&gt; typ =\n    fun () -&gt; TVar (ref (Unbound (gensym ())))\n\nlet rec occurs : tv ref -&gt; typ -&gt; unit = fun tvr -&gt; function\n    | TVar tvr' when tvr == tvr' -&gt; failwith \"occurs check\"\n    | TVar {contents= Link ty} -&gt; occurs tvr ty\n    | TTArrow (t1, t2) -&gt;\n        occurs tvr t1 ;\n        occurs tvr t2\n    | _ -&gt; ()\n\nlet rec unify : typ -&gt; typ -&gt; unit = fun t1 t2 -&gt;\n    if t1 == t2 then ()\n    else match (t1, t2) with\n    | (TVar ({contents= Unbound _} as tv), t')\n    | (t', TVar ({contents= Unbound _} as tv)) -&gt;\n        occurs tv t' ;\n        tv := Link t'\n    | (TVar {contents= Link t1}, t2) | (t1, TVar {contents= Link t2}) -&gt; unify t1 t2\n    | (TArrow (tyl1, tyl2), TArrow (tyr1, tyr2)) -&gt;\n        unify tyl1 tyr1 ;\n        unify tyl2 tyr2\n    (* everything else is error *)\n\ntype env = (varname * typ) list\n\nlet rec gen : typ -&gt; typ = function\n    | TVar {contents= Unbound name} -&gt; QVar name\n    | TVar {contents= Link ty} -&gt; gen ty\n    | TArrow (ty1, ty2) -&gt; TArrow (gen ty1, gen ty2)\n    | ty -&gt; ty\n\nlet inst : typ -&gt; typ =\n    let rec loop subst = function\n        | QVar name -&gt;\n            (try (List.assoc name subst, subst)\n             with Not_found -&gt;\n                 let tv = newvar () in\n                 (tv, (name, tv) :: subst))\n        | TVar {contents= Link ty} -&gt; loop subst ty\n        | TArrow (ty1, ty2) -&gt;\n            let (ty1, subst) = loop subst ty1 in\n            let (ty2, subst) = loop subst ty2 in\n            (TArrow (ty1, ty2), subst)\n        | ty -&gt; (ty, subst)\n    in\n    fun ty -&gt; fst (loop [] ty)\n\nlet rec typeof : env -&gt; exp -&gt; typ = fun env -&gt; function\n    | Var x -&gt; inst (List.assoc x env)\n    | Lam (x, e) -&gt;\n        let ty_x = newvar () in\n        let ty_e = typeof ((x, ty_x)::env) e in\n        TArrow (ty_x, ty_e)\n    | App (e1, e2) -&gt;\n        let ty_fun = typeof env e1 in\n        let ty_arg = typeof env e2 in\n        let ty_res = newvar () in\n        unify ty_fun (TArrow (ty_arg, ty_res)) ;\n        ty_res\n    | Let (x, e, e2) -&gt;\n        let ty_e = typeof env e in\n        typeof ((x, gen ty_e)::env) e2\n\n\nEfficient generalization with levels\n\n여기서는 레미의 알고리즘 뒤에 있는 아이디어를 계속해서 설명한다. 이제\n 우리는 불안전한 일반화가 아직 사용 중인 메모리를 해제하는 것과 어떻게\n 관련되는지 보았기 때문에, 성급한 해제에 대한 표준적인 해결책인\n 소유권(또는 구역; owership or regions) 추적을 적용해서 많은 오버헤드\n 없이 이를 해결하려고 한다. 레미의 알고리즘의 주요 특징을 포착한\n 최적의 방법인 sound_lazy는 다음에 나온다.\n\n분명히, 메모리를 해제하기 전에 메모리가 여전히 사용 중인지 반드시\n 확인해야 한다. 나이브하게 구현하면, 우리는 해제 후보의 참조를 찾기\n 위해서 지금 사용 중인 모든 메모리를 스캔할 수도 있다. 즉, 일종의 GC의\n 전체 마킹 페이즈를 수행해서 후보가 마킹됐는지 확인할 수 있다. 이런\n 식으로 하면, 이 확인 방법은 엄청나게 비쌀 것이다. 최소한 우리는\n 가비지가 쌓일 때까지는 기다려야 한번에 수집할 수 있다. 아, 힌들리\n 밀너 타입 시스템에서 우리는 양화를 임의로 지연할 수 없는데, 왜냐하면\n 일반화된 타입은 아마 곧바로 쓰일 수 있기 때문이다.\n\n좀더 괜찮은 방법은 이른바 소유권(ownership) 추적이다: 할당된 자원을\n 소유자, 개체, 또는 함수 활성화(activation)과 연결한다. 오직\n 소유자만이 자원을 해제할 수 있다. 이것과 유사한 전략은 이른바 구역,\n 즉 letregion 프리미티브로 사전적 범위로 지정된 힙 메모리의\n 영역이다(areas of heap memory created by a lexically-scoped so-called\n letregion primitive). letregion이 범위를 벗어나면, 그 전체 영역이\n 즉시 해제된다. 이 아이디어는 일반화와도 잘 맞는다. 힌들리 밀너\n 시스템에서 일반화는 항상 let의 일부이다. let x = e in e2 에서의\n let 표현식은 e의 타입을 추론할 때 할당되는 모든 타입 변수의\n 자연스러운 소유자이다. e의 타입이 발견되면, let 표현식이 소유하고\n 있는 모든 자유 타입 변수는 버려질 수 있다. 즉, 양화될 수 있다.\n\n이러한 직관은 안전하고 효율적인 일반화 알고리즘의 기초가 된다. 먼저\n sound_eager를 설명한다. 이 방법의 구현은 이전의 작은 힌들리 밀너\n 추론기에서 조금만 다르지만, 굉장히 중요하다. 여기서는 이 차이점만\n 설명한다. 전체 코드는 밑에 있다. 주요한 차이점은 자유 타입 변수가\n 안묶여있을(자유) 지라도, 이제 소유자에게 소유되어 소유자를 참조한다는\n 것이다. 소유자는 항상 let 표현식이고, 이는 level 이라고 불리는\n 양의 정수로 식별된다. 이것은 드 브루인(De Bruijin) 레벨 또는 해당\n let 표현식의 중첩되는 깊이를 나타낸다. 레벨 1은 암묵적으로 최상위의\n let에 해당한다. 참고로, (let x = e1 in eb1, let y = e2 in eb2)에\n 있는 두 let은 모두 레벨 2를 갖지만, 두 let 모두 서로의 범위에\n 없으므로 구역이 분리되어 있기 때문에 혼동이 발생할 수 없다. let\n 중첩 깊이는 let 표현식의 타입 체킹 재귀 깊이와 동일하고 이는 하나의\n 레퍼런스 쎌만 있으면 알아내기 쉽다.\n\ntype level = int\nlet current_level = ref 1\nlet enter_level () = incr current_level\nlet leave_level () = decr current_level\n\n\n타입 추론기는 이제 let 표현식을 타입 체킹할 때 깊이를 유지한다.\n\nlet rec typeof : env -&gt; exp -&gt; typ = fun env -&gt; function\n    ... (* the other cases are the same as before *)\n    | Let (x, e, e2) -&gt;\n        enter_level () ;\n        let ty_e = typeof env e in\n        leave_level () ;\n        typeof ((x, gen ty_e) :: env) e2\n\n\n메인 타입 추론 함수에서 바뀐 점은 enter_level과 leave_level\n 함수를 호출해서 레벨을 추적하는 것 뿐이다. 나머지 부분은 그대로다.\n\n자유 타입 변수는 이제 그 소유자를 확인할 수 있는 레벨과 같이\n 간다. 새로 할당된 타입 변수는 current_level을 통해 가장 최근에 타입\n 체킹된 let 표현식, 즉 소유자를 알 수 있다. 구역 기반 메모리\n 관리에서, 모든 새로운 메모리는 가장 안쪽의 살아있는 구역에 할당되는\n 것과 같다.\n\ntype typ =\n    | TVar of tv ref\n    | QVar of qname\n    | TArrow of typ * typ\nand tv = Unbound of string * level | Link of typ\n\nlet newvar = fun () -&gt; TVar (ref (Unbound (gensym (), !current_level)))\n\n\n대입 연산이 할당된 메모리 조각의 소유자를 바꿀 수 있는 것처럼,\n 유니피케이션도 자유 타입 변수의 레벨(소유자)을 바꿀 수 있다. 예를\n 들어, 만약 ty_x (레벨 1)과 ty_y (레벨 2)가 둘다 자유 변수이고\n ty_x가 TArrow(ty_y, ty_y)와 합쳐진다면, 이 함수 타입과 그\n 구성요소는 구역 1로 내보내지고 따라서 ty_y의 레벨이 1로 바뀐다. 이\n 유니피케이션이 모든 ty_x가 나타나는 것을 TArrow(ty_y, ty_y)로\n 바꾸는 것이라고 볼 수도 있다. ty_x가 더 작은 레벨을 가지고 있고\n 따라서 안쪽 구역인 레벨 2의 let보다 더 바깥에 나타나기 때문에, 안쪽\n let 표현식이 타입 체크되고 난 이후에도 ty_y는 해제되어서는\n 안된다. ty_y 레벨이 업데이트되었다면 그렇지 않다. 대체로, 자유 타입\n 변수 ty_x와 t를 합치려면 각각의 자유 타입 변수 ty_y의 레벨을\n ty_y와 ty_x 레벨 중 작은 값으로 업데이트해야 한다. 자유 타입\n 변수를 t와 합치려면 또한 occurs check도 해야하는데, 이것도 타입\n 트리를 탐색한다. 이 두 탐색은 합쳐질 수 있다. 새로운 occurs 함수는\n occurs check와 레벨 갱신을 동시에 한다.\n\nlet rec occurs : tv ref -&gt; typ -&gt; unit = fun tvr -&gt; function\n    | TVar tvr' when tvr == tvr' -&gt; failwith \"occurs check\"\n    | TVar ({contents= Unbound (name, l')} as tv) -&gt;\n        let min_level =\n            (match !tvr with Unbound (_, l) -&gt; min l l' | _ -&gt; l') in\n        tv := Unbound (name, min_level)\n    | TVar {contents= Link ty} -&gt; occurs tvr ty\n    | TArrow (t1, t2) -&gt; occurs tvr t1 ; occurs tvr t2\n    | _ -&gt; ()\n\n\n원래의 occurs와 다른 부분은 두 번째 패턴 매치 부분\n 뿐이다. 유니피케이션 코드는 수정될 필요가 전혀 없다. 마지막으로,\n 일반화 함수를 수정해서 안전하게 만들자.\n\nlet rec gen : typ -&gt; typ = function\n    | TVar {contents= Unbound (name, l)} when l &gt; !current_level -&gt; QVar name\n    | TVar {contents= Link ty} -&gt; gen ty\n    | TArrow (ty1, ty2) -&gt; TArrow (gen ty1, gen ty2)\n    | ty -&gt; ty\n\n\n아주 작은 수정인 when l &gt; !current_level 조건만 추가되었다. 새로운\n typeof 코드를 다시 떠올려 보자.\n\nlet rec typeof : env -&gt; exp -&gt; typ = fun env -&gt; function\n    ...\n    | Let (x, e, e2) -&gt;\n        enter_level () ;\n        let ty_e = typeof env e in\n        leave_level () ;\n        typeof ((x, gen ty_e) :: env) e2\n\n\ne의 타입 체킹을 위해서 만든 구역에서 빠져나간 이후에 gen을\n 호출하고 있다. 그 구역이 여전히 소유하고 있는 자유 타입 변수는 현재\n 레벨보다 더 큰 레벨을 가질 것이다. 구역이 이제 죽었기 때문에, 그러한\n 자유 변수는 해제될 수 있는데, 이는 곧 양화될 수 있다는 뜻이다.\n\n이게 불안전했던 알고리즘을 수정한 sound_eager의 전부이다. 이제\n 불안전한 타입 추론을 해결했다. 이전에 문제가 되었던 예시를 다시\n 살펴보자.\n\nfun x -&gt; let y = x in y\n\n\nTVar 연산과 관련된 흐름을 보면 이제 문제가 없다.\n\n1  1  ty_x/1 = newvar ()           (* fun x -&gt; ... *)\n2  2    ty_e =                     (* let y = x in y *)\n3  2      inst ty_x/1              (* inferred for x, same as ty_x *)\n2  1    ty_y = gen ty_e            (* ty_x/1 remains free, but is level = current, can't quantify, can't dispose *)\n1  1  TArrow(ty_x/1, inst ty_y)    (* inferred for: fun x -&gt; ... *)\n\n\n한 가지 정보가 추가되었다. 컬럼의 첫 번째 숫자는 typeof의 재귀 깊이\n 또는 아직 타입 체크되지 않은 AST 노드의 깊이를 나타내고, 두 번째\n 숫자는 current_level, 즉 let 중첩 깊이를 나타낸다. 자유 타입\n 변수의 레벨은 ty_x/1와 같이 슬래쉬 뒤에 표시한다. ty_x/1이 현재\n 레벨, 즉 여전히 살아있는 구역 1에 속하기 때문에, 해당 변수는 더 이상\n 깊이 2(레벨 1)의 gen에 의해 양화되지 않는다. 따라서, 추론된 타입은\n 예상대로 'a -&gt; 'a가 된다.\n\n좀더 복잡한 예시를 살펴보면\n\nfun x -&gt; let y = fun z -&gt; x in y\n\n\nx의 타입을 위한 타입 변수 ty_x는 레벨 1에서 할당되는 반면,\n ty_z는 레벨 2에서 할당된다. 안쪽의 구역 2인 let이 끝난 이후에,\n ty_z/2는 양화되어 버려지지만, ty_x/1는 아니다. 따라서 추론된\n 타입은 'a -&gt; 'b -&gt; 'a가 된다. 다이어그램을 그려보면 이게 안전하게\n 추론된 타입이라는 것을 알 수 있다.\n\n레벨 추적은 레퍼런스 카운팅과 비슷하게 생겼을 수도 있다. 하지만, 자유\n 타입 변수의 모든 사용자 수를 세는 것이 아니라, 우리는 딱 한명의\n 유저만 추적하는데, 바로 가장 넓은 범위이다. 레벨 추적은 따라서 세대간\n 가비지 콜렉션과 더 많이 닮아 있다: 메모리는 마이너 세대에서 할당되고,\n 다른 부모가 할당되거나 스택이 참조하지 않는 이상 마이너 콜렉션에서\n 한번에 버려진다. 메이저 세대는 새로운 세대에 대한 참조를 스캔할\n 필요가 없는데, 왜냐하면 메이저 데이터 구조의 필드를 가리키는 마이너\n 값(또는 이에 대한 포인터)의 대입 연산이 없는 이상 그런 참조는 없을\n 것으로 예상되기 때문이다. OCaml GC와 같은 세대간 가비지 콜렉터는\n 마이너 세대에서 메이저 세대로의 대입 연산을 추적한다. 마이너\n 콜렉션에서, 메이저 데이터에서 참조된 마이너 데이터가 메이저 세대로\n 승격된다. 타입 일반화는 실제로 마이너 GC와 매우 유사하다.\n\nEven more efficient level-based generalization\n\n여기서는 레미의 알고리즘의 핵심 아이디어를 계속해서 살펴보고\n sound_lazy를 설명한다. 이는 이전 섹션에서 살펴본 sound_eager의\n 최적화된 버전이다. sound_lazy 알고리즘은 유니피케이션, 일반화,\n 인스턴스화 도중 발생하는 반복되는 불필요한 타입 탐색을 피하고,\n 일반화하거나 인스턴스화 하기 위해 변수를 포함하지 않는 부분을\n 복사하는 것을 피해서 데이터 공유를 개선한다. 이 알고리즘은 occurs\n check과 레벨 갱신을 늦춰서 자유 타입 변수와의 유니피케이션이 상수\n 시간이 걸리도록 한다. 레벨은 점진적으로 필요할 때에만\n 갱신된다. sound_lazy는 레미의 알고리즘의 핵심 아이디어를 구현하고\n 있다. 이 중 일부는 실제 OCaml 타입 체커에 구현되어 있다.\n\n최적화를 위해서 먼저 타입의 문법을 수정해야 한다. sound_eager에서는\n 타입이 자유(Unbound) 또는 묶인(Link) 타입 변수 TVar,\n (암묵적으로 보편적) 양화된 타입 변수 QVar, 그리고 함수 타입\n TArrow로 구성되었던 것을 기억하자. 먼저, 겉보기에는 무의미한\n 수정인데, QVar를 제거해서 별개의 대안인 아주 큰 양의 정수\n generic_level을 도입하는데, 이는 접근할 수 없는 서수 \\(\\omega\\)를\n 의미한다. generic_level에 있는 자유 타입 변수 TVar 양화된 타입\n 변수로 간주된다. 그리고, 이제 자유 타입 변수뿐만 아니라 모든 타입이\n 레벨을 갖는다. 복합 타입(우리의 경우 TArrow)의 레벨은, 반드시\n 정확하지는 않지만, 그 구성 요소의 레벨의 상한(Upper Bound)이\n 된다. 즉, 만약 타입이 살아있는 구역에 속해있다면, 그 구성 요소도 모두\n 살아있어야 한다. 따라서 (복합) 타입이 generic_level에 있으면, 이는\n 양화된 타입 변수를 포함할 수 있다. 반대로, 만약 타입이\n generic_level에 없으면, 어떤 양화된 변수도 포함하지 않는다. 따라서,\n 이런 타입을 인스턴스화 하면 타입을 탐색하지 않고 그대로 리턴해야\n 한다. 마찬가지로, 타입의 레벨이 현재 레벨보다 더 크면, 일반화할 자유\n 타입 변수를 포함하고 있을 수 있다. 반면에, 일반화 함수는 레벨이 현재\n 레벨보다 작거나 같은 타입을 탐색해서는 안된다. 이것이 바로 레벨이\n 어떻게 과도한 탐색과 타입의 재구축을 제거해서 공유를 개선하는데\n 도움이 되는 첫 번째 예시이다.\n\n타입을 자유 타입 변수와 합칠 때는 타입의 레벨을 타입 변수의 레벨이 더\n 작으면 해당 레벨로 업데이트해야 한다. 합성 타입에 대해서는 이런\n 업데이트가 곧 타입의 모든 구성요소의 레벨을 재귀적으로 업데이트해야\n 한다는 뜻이다. 이런 비싼 탐색을 늦추기 위해서, 우리는 합성 타입에 두\n 개의 레벨을 저장해 둔다: level_old는 타입의 구성요소의 레벨에 대한\n 상한이고; level_new는 level_old보다 작거나 같은 값으로 타입이\n 업데이트 이후에 가져야하는 레벨 값이다. 만약 level_new &lt; level_old\n 라면, 타입은 보류 중인 레벨 갱신이 있다. sound_lazy의 타입 문법은\n 따라서:\n\ntype level = int\nlet generic_level = 100_000_000  (* as in OCaml typing/btype.ml *)\nlet marked_level = -1            (* for marking a node, to check for cycles *)\n\nlype typ =\n    | TVar of tv ref\n    | TArrow of typ * typ * levels\nand tv = Unbound of string * level | Link of typ\nand levels = {mutable level_old: level; mutable level_new: level}\n\n\n아직 marked_level은 설명하지 않았다. 각각의 자유 타입 변수와의\n 유니피케이션에서 occurs check는 비싼 연산이라서 유니피케이션과 타입\n 체킹 알고리즘의 복잡도를 올린다. 우리는 이제 이 체크를 전체 표현식이\n 타입 체크될 때까지 늦출 것이다. 그러는 동안, 유니피케이션이 타입에서\n 싸이클을 만들 수 있다. 타입 탐색은 이 싸이클을 탐색해야\n 한다. marked_level은 임시로 합성 타입의 level_new로 할당되어\n 타입이 탐색 중이라는 것을 알린다. 탐색 도중 marked_level을 만난다는\n 것은 싸이클을 발견했다는 뜻이고, occurs check는 에러를\n 알린다. 덧붙여서, OCaml 타입은 일반적으로 싸이클릭하다: 오브젝트와\n 폴리모픽 배리언트를 타입 체킹할 때 재귀적인 타입이 발생하고,\n -rectypes 컴파일러 옵션이 켜져있으면 된다. OCaml 타입 체커는\n marked_level과 비슷한 트릭을 이용해서 싸이클을 찾아서 에러를\n 막는다.\n\nsound_lazy의 유니피케이션은 몇 가지 중요한 차이점이 있다:\n\nlet rec unify : typ -&gt; typ -&gt; unit = fun t1 t2 -&gt;\n    if t1 == t2 then ()\n    else match (repr t1, repr t2) with\n    | (TVar ({contents= Unbound (_, l1)} as tv1) as t1,\n      (TVar ({contents= Unbound (_, l2)} as tv2) as t2)) -&gt;\n          (* unify two free vars *)\n          if l1 &gt; l2 then tv1 := Link t2 else tv2 := Link t1\n    | (TVar ({contents= Unbound (_, l)} as tv), t')\n    | (t', TVar ({contents= Unbound (_, l)} as tv)) -&gt;\n        update_level l t' ;\n        tv := Link t'\n    | (TArrow (tyl1, tyl2, ll), TArrow (tyr1, tyr2, lr)) -&gt;\n        if ll.level_new = marked_level || lr.level_new = marked_level then\n            failwith \"cycle: occurs check\" ;\n        let min_level = min ll.level_new lr.level_new in\n        ll.level_new &lt;- marked_level ;\n        lr.level_new &lt;- marked_level ;\n        unify_lev min_level tyl1 tyr1 ;\n        unify_lev min_level tyl2 tyr2 ;\n        ll.level_new &lt;- min_level ;\n        lr.level_new &lt;- min_level ;\nand unify_lev l ty1 ty2 =\n    let ty1 = repr ty1 in\n    update_level l ty1 ;\n    unify ty1 ty2\n\n\n여기서 repr은 OCaml의 Btype.repr과 비슷하게 자유 변수 또는 생성된\n 타입을 리턴하는 묶인 변수의 링크를 따라간다. OCaml과 다르게, 우리는\n 경로 압축(유니온 파인드의 최적화 방법)을 적용한다. 유니피케이션\n 함수는 더 이상 occurs check을 하지 않는다. 따라서, 우연히 만들어진\n 싸이클을 찾도록 노력해야 한다. 자유 변수를 합치는 일은 이제 얕은\n update_level 이후에 변수를 바인드하여 상수 시간이 걸린다.\n\nupdate_level 함수는 최적화 알고리즘의 핵심 부분 중 하나이다. 이것은\n 그저 타입의 레벨을 주어진 레벨로 업데이트할 것을 약속한다. 이것은\n 상수 시간에 동작하고 타입 레벨이 오직 감소하기만 할 수 있는 불변식을\n 유지한다. 타입 변수의 레벨은 즉각 갱신된다. 합성 타입에 대해서는\n level_new가 필요한 새로운 (더 작은) 레벨로 업데이트된다. 추가로,\n 만약 이전의 level_new와 level_old가 같다면, 타입은\n to_be_level_adjusted 큐에 추가되어 구성 요소의 레벨을 나중에\n 업데이트한다. 이런 작업 큐는 세대간 가비지 콜렉터의 마이너 세대로부터\n 메이저 세대로의 대입 연산의 리스트와 닮아있다.\n\nlet to_be_level_adjusted = ref []\n\nlet update_level : level -&gt; typ -&gt; unit = fun l -&gt; function\n    | TVar ({contents= Unbound (n, l')} as tvr) -&gt;\n        assert (not (l' = generic_level)) ;\n        if l &lt; l' then tvr := Unbound (n, l)\n    | TArrow (_, _, ls) as ty -&gt;\n        assert (not (ls.level_new = generic_level)) ;\n        if ls.level_new = marked_level then failwith \"occurs check\" ;\n        if l &lt; ls.level_new then (\n            if ls.level_new = ls.level_old then\n                to_be_level_adujsted := ty :: !to_be_level_adjusted ;\n            ls.level_new &lt;- l\n        )\n    | _ -&gt; assert false\n\n\n보류 중인 레벨 갱신은 반드시 일반화 이전에 수행되어야 한다. 결국 보류\n 중인 갱신은 타입 변수의 레벨을 감소시킬 수 있는데, 즉 더 넓은\n 구역으로 승격되어서 양화로부터 구해준다. 하지만 모든 보류 중인\n 업데이트가 강제될 필요는 없다. 오직 level_old &gt; current_level 인\n 타입만 하면 된다. 그렇지 않으면, 타입은 현재 시점에서 일반화 가능한\n 변수가 없게 되고, 레벨 갱신이 더 늦춰질 수 있다. 이런 강제된\n 알고리즘은 force_delayed_adjustments에 구현되어 있다. 덧붙여, 만약\n 합성 타입의 레벨 업데이트가 정말로 수행된다면, 타입은 탐색되어야\n 한다. 두 TArrow 타입의 유니피케이션은 또한 이들을 탐색해야\n 한다. 따라서, 유니피케이션은 원칙적으로는 그 과정에서 레벨을\n 업데이트할 수도 있다. 하지만 해당 최적화는 구현되어 있지 않다.\n\n일반화 함수는 죽은 구역에 속한 (즉, 레벨이 현재 레벨보다 큰) 자유\n TVar를 찾고 그들의 레벨을 generic_level로 설정해서 변수를\n 양화한다. 함수는 오직 타입이 일반화 해야할 타입 변수를 담고 있을 수\n 있는 부분만 탐색한다. 만약 타입이 (새로운) 현재 레벨 current_level\n 또는 이보다 작은 레벨을 갖고 있다면, 그 타입의 모든 구성요소는\n 살아있는 구역에 속해있고 따라서 일반화할 게 없다. 일반화가 끝난 뒤에\n 만약 양화된 타입 변수를 담고 있으면 합성 타입은 generic_level을\n 받는다. 나중에 인스턴스화 함수는 따라서 레벨이 generic_level인\n 타입만 살펴보면 된다.\n\nlet gen : typ -&gt; unit = fun ty -&gt;\n    force_delayed_adjustments () ;\n    let rec loop ty =\n        match repr ty with\n        | TVar ({contents= Unbound (name, l)} as tvr) when l &gt; !current_level -&gt;\n            tvr := Unbound (name, generic_level)\n        | TArrow (ty1, ty2, ls) when ls.level_new &gt; !current_level -&gt;\n            let ty1 = repr ty1 and ty2 = repr ty2 in\n            loop ty1 ;\n            loop ty2 ;\n            let l = max (get_level ty1) (get_level ty2) in\n            (* set the exact level upper bound *)\n            ls.level_old &lt;- l ;\n            ls.level_new &lt;- l\n        | _ -&gt; ()\n    in loop ty\n\n\n테입 체커의 typeof는 수정하지 않아도 된다. 여전히 let 표현식을\n 타입 체킹할 때 새로운 구역에 들어가야 한다.\n\n여기까지, 최적화된 sound_lazy 타입 일반화 알고리즘을 통해\n 일반화마다 타입 환경 전체를 스캐닝 하지 않아도 될 뿐만 아니라 각각의\n 자유 타입 변수와의 유니피케이션에서 occurs check도 피할 수\n 있었다. 결과적으로 유니피케이션에 상수 시간이 소요된다. 알고리즘은\n 불필요한 타입 탐색과 복사를 줄여서 시간과 공간을 절약했다. 자유 타입\n 변수를 위한 타입 레벨 외에도 두 개의 아이디어가 최적화의 뿌리가\n 된다. 하나는 합성 타입의 레벨을 배치해서 타입을 살펴보지 않고도\n 타입이 무엇을 담고 있을지를 확인하는 것이다. 다른 하나는 비싼 연산인\n 타입 탐색을 늦춰서 나중에 다른 작업이랑 같이 하는 것이다. 즉, 문제를\n 해결하는 일이 충분히 미뤄진다면, 어쩌면 사라질 수도 있다: 미루는 것이\n 때로는 도움이 된다.\n\nInside the OCaml Type Checker\nGeneralization with levels in OCaml\n\n여기서는 OCaml 타입 체커의 타입 레벨 구현과 효율적인 일반화에 대한\n 적용을 설명한다.\n\nOCaml의 타입 일반화 뒤에 있는 아이디어는 이전에 설명한\n sound_eager와 sound_lazy와 같다. 이 코드들은 일부러 OCaml의 타입\n 체커와 닮도록 구현했었다. OCaml 타입 체커는 sound_eager 알고리즘을\n 구현했고 sound_lazy 에서 약간의 최적화를 적용했다. OCaml은 훨씬 더\n 복잡하다: 토이 코드에서의 유니피케이션은 몇 줄 안되었지만, OCaml의\n 유니피케이션 코드 (ctype.ml)는 1,634 줄이다. 그럼에도 불구하고 앞의\n 핵심 아이디어를 이해하는 것은 OCaml 타입 체커를 해석하는데 도움이\n 된다.\n\nsound_eager 알고리즘과 마찬가지로 OCaml 타입 체커는 occurs check와\n 레벨 업데이트를 각각의 자유 변수와의 유니피케이션에서\n 수행한다. Ctype.unify_var 코드에서 확인할 수 있다. 반면에,\n sound_lazy에서 했던 것처럼, OCaml 타입 체커는 모든 타입에 레벨을\n 할당한다. types.mli의 type_expr에서 볼 수 있다. 이러는 이유는\n 로컬 타입 생성자가 지역을 벗어나는 것을 감지하기 위함이다. 또\n sound_lazy처럼, generic_level이 양화된 타입 변수와 양화된 변수를\n 담고 있을 수 있는 타입을 구분한다. 즉, 이른바 제네릭 타입이라고\n 불리는 녀석이다. 따라서, 스키마 인스턴스화 함수인 Ctype.instance와\n Ctype.copy는 타입의 제네릭이 아닌 부분을 탐색하거나 복사하지 않고,\n 그대로 리턴하여 공유를 개선한다. generic_level에 있는 타입 변수는\n 'a와 같이 출력된다. 다른 레벨은 '_a와 같이 출력된다. 우리의 토이\n 알고리즘에서 봤듯이, 가변 글로벌 Ctype.current_level이 현재 레벨을\n 추적하고 새롭게 생성된 타입이나 타입 변수에 할당된다. Ctype.newty와\n Ctype.newvar에서 볼 수 있다. current_level은 enter_def() 함수로\n 증가되고 end_def() 함수로 감소된다. current_level 외에도\n nongen_level이라는 게 있는데, 클래스 정의를 타입 체킹할 때\n 쓰인다. global_level은 타입 선언에 있는 타입 변수에 쓰인다.\n\nlet x = e in body 표현식을 타입 체킹하는 아주 단순화된 코드는\n 다음과 같다.\n\nlet e_typed =\n    enter_def () ;\n    let r = type_check env e_source in\n    end_def () ;\n    r\nin\ngeneralize e_typed.exp_type ;\nlet new_env = bind env x e_typed.exp_type in\ntype_check new_env body_source\n\n\n여기서 e_source는 AST 또는 Parsetree.expression인데 e를 위한\n 표현식이다. e_typed는 Typedtree.expression으로 exp_type 필드로\n 추론된 타입을 각 노드에 어노테이트하고 있는 AST이다.\n\n따라서, OCaml 타입 체커에서 자주 보이는 전체적인 타입 일반화 패턴은\n 다음과 같다.\n\nlet ty =\n    enter_def () ;\n    let r = ... let tv = newvar () in ... ( ...tv ... )\n    end_def () ;\n    r in\ngeneralize ty\n\n\n만약 tv가 enter_def() 이전에 타입 환경에 존재하는 다른 것과\n 합쳐지지 않는다면, 변수는 일반화 될 것이다. 이 코드는 우리의 토이\n 코드와 매우 닮았다.\n\n흥미롭게도, 레벨은 다른 용법이 있는데, 로컬 타입 선언을 위한 구역\n 규칙을 강제하는 것이다.\n\nType Regions\n\nOCaml 타입 체커는 또한 타입이 선언되기 전에 쓰이지 않고 지역적으로\n 도입된 타입이 더 넓은 범위로 빠져나가지 않도록 확인하기 위해서 타입\n 레벨에 의존하고 있다. 대입 연산과 비슷하게, 유니피케이션은 두 가지를\n 모두 용이하게 한다. 우리는 타입 레벨이 구역 기반 메모리 관리와 어떻게\n 관계되어 있는지를 봤다. 그래서 레벨이 유니피케이션을 억제하는데\n 도움이 되어서 자원의 잘못된 관리를 막는 것은 놀랍지 않다. 이번에는,\n 타입 변수가 아니라 타입 상수일 뿐이다.\n\nSML과 다르게 OCaml 에서는 로컬 모듈 또는 로컬 범위에 정의된 모듈을\n 지원한다. 문법은 let module 형태이다. 로컬 모듈은 타입을 선언하거나\n 심지어는 이 타입을 이스케이프하게 하기도 한다.\n\nlet y =\n    let module M = struct\n        type t = Foo\n        let x = Foo\n    end\nin M.x\n   ^^^\nError: This expression has type M.t but an expression was expected of type 'a\n       The type constructor M.t would escape its scope\n\n\n이런 이스케이프는 에러다. 그렇지 않으면 y는 M.t 타입을 받게\n 되는데 M.t와 심지어 M 마저도 y의 범위에 있지 않게 된다. 이\n 문제는 마치 C 함수에서 자동 지역 변수의 주소를 리턴하는 것과\n 비슷하다.\n\nchar * esc_res(void) {\n    char str [] = \"local string\";\n    return str;\n}\n\n\n지역적으로 선언된 타입은 결과 타입 뿐만 아니라 존재하는 타입 변수와의\n 유니피케이션을 통해서도 빠져나갈 수 있다.\n\nfun y -&gt;\n    let module M = struct\n        type t = Foo\n        let r = y Foo\n    end\nin ()\n                  ^^^\nError: This expression has type t but an expression was expected of type 'a\n       The type constructor t would escape its scope\n\n\n이런 종류의 에러는 C 프로그래머에게는 익숙할지도 모르겠다.\n\nchar *y = (char*)0;\nvoid esc_ext(void) {\n    char str [] = \"local string\";\n    y = str;\n}\n\n\n심지어 탑 레벨의 모듈도 타입이 빠져나가는 문제가 생길 수 있다. 다음\n 예시는 OCaml 타입 체커 코드의 코멘트에서 가져왔다.\n\nlet x = ref []\nmodule M = struct\n    type t\n    let _ = (x : t list ref)\nend\n\n\n변수 x는 제네릭이 아닌 타입 '_a list ref를 가지고 있다. 모듈\n M은 로컬 타입 t를 정의한다. 타입 속성은 t 이전에 정의된 x를\n 타입 x : t list ref를 갖게 만든다. t가 정의되기 전에 쓰인 것처럼\n 보인다. 이런 타입 이스케이핑 문제는 심지어 모듈이 아니어도 발생할 수\n 있다.\n\nlet r = ref []\ntype t = Foo\nlet () = r := [Foo]\n               ^^^\nError: This expression has type t but an expression was expected of type 'weak1\n       The type constructor t would escape its scope\n\n\nOCaml은 이런 탈출을 그대로 내버려둘 수가 없다. 어떤 경우에도 타입\n 생성자는 선언된 범위 밖에서 사용될 수 없다. 타입 레벨은 이런 구역\n 같은 원칙을 타입 생성자에 강제한다.\n\nOCaml 타입 체커는 이미 타입 일반화를 위해서 구역을 지원하는데,\n begin_def로 새 구역에 진입하고 end_def로 새 구역을\n 벗어난다(파괴한다). 그리고 구역의 소유자에게 타입을 연결해서\n 유니피케이션이 수행되는 동안 소유권의 변경을 추적한다. 남은 것은 타입\n 선언이 새 구역에 들어가고 선언된 타입 생성자가 이 구역과 연결하는\n 것이다. 이 타입 생성자가 나타나는 모든 구역은 타입 선언 구역 내의\n 구역에 속해야 한다. 타입 생성자의 선언은 모든 사용 이전에 나타나야\n 한다(dominate).\n\n이전에 설명했듯이, 타입 구역은 양의 정수인 타입 레벨로 식별된다. 이는\n 구역의 중첩된 깊이이다. 각각의 타입은 level 필드가 있어서 소유된\n 구역의 레벨을 알 수 있다. 타입 생성자는 이거랑 비슷한 레벨\n 어노테이션이 필요하다. OCaml의 다른 기능이 정확히 이 목적을\n 제공한다는 것이 밝혀졌다. 타입 생성자, 데이터 생성자, 텀 변수는 OCaml\n 프로그램 안에서 재정의 될 수 있다. 타입은 재선언될 수 있고, 변수는\n 여러 번 다시 묶일 수 있다. OCaml은 식별자(identifier)\n (ident.ml)에 의존하는데, 이를 통해 같은 이름으로 나타나지만\n 실제로는 다르게 선언되거나 묶인 것들을 구별할 수 있다. 식별자는\n 이름과 양의 정수인 타임 스탬프를 갖고 있다. 글로벌 가변\n Ident.currentstamp는 현재 시간을 추적하고 새로운 식별자가 선언 또는\n 바인딩으로 생성되면 이를 증가시킨다. 식별자의 타임스탬프는 따라서\n 그게 바인딩 타임(binding time; 묶인 시간)이다. 바인딩 타임은 식별자를\n 타입 구역에 연결하는 자연스러운 방법이다. 만약 현재 시간이 현재\n 레벨로 설정되어 있다면, 새로운 식별자는 현재 레벨보다 더 작은 바인딩\n 타임을 가질 수 없다. 이들은 현재 타입 구역에 소유된 것으로\n 간주된다. 빠져나가지 않는다는 것(non-escaping)은 곧 타입의 레벨이\n 타입 안에 있는 각각의 타입 생성자의 바인딩 타임보다 작지 않다는 것을\n 뜻한다.\n\n유니피케이션, 구체적으로는 자유 타입 변수와의 유니피케이션은 할당과도\n 비슷한데, 타입의 소유자를 바꿀 수 있어서 이에 따라 타입 레벨을\n 업데이트 해줘야 한다. 동시에 이는 빠져나가지 않는 성질(non-escaping\n property)가 여전히 유효한지 검사한다. Ctype.update_level에서 볼 수\n 있다.\n\n이제 우리는 로컬 모듈, 즉 let module name = modl in body 표현식을\n 타입 체킹하기 위한 OCaml 코드를 이해할 수 있다. typecore.ml에서\n 발췌했다.\n\n    | Pexp_letmodule(name, smodl, sbody) -&gt;\n        let ty = newvar () in\n        (* remember the original level *)\n        begin_def () ;\n        Ident.set_current_time ty.level ;\n        let context = Typetexp.narrow () in\n        let modl = !type_module env smodl in\n        let (id, new_env) = Env.enter_module name.txt modl.mod_type env in\n        Ctype.init_def (Ident.current_time()) ;\n        Typetexp.widen context ;\n        let body = type_expect new_env sbody ty_expected in\n        (* go back to original level *)\n        end_def () ;\n        (* Check that the local types declared in modl don't escape\n           through the return type of body *)\n        begin try\n            Ctype.unify_var new_env ty body.exp_type\n        with Unify _ -&gt;\n            raise (Error (loc, Scoping_let_module (name.txt, body.exp_type)))\n        end ;\n        re {\n            exp_desc = Texp_letmodule (id, name, modl, body) ;\n            exp_loc = loc ;\n            exp_extra = [] ;\n            exp_type = ty ;\n            exp_env = env }\n\n\n타입 변수 ty는 표현식의 추론된 타입을 받기 위해서 생성된다. 변수는\n 현재 구역에서 생성된다. 그러고 나면 begin_def()로 새로운 타입\n 구역에 들어가게 되고 식별자 타임스탬프 클럭이 새로운\n current_level로 지정된다.\n\nDiscovery of levels\nCreating fresh type variables\nTrue complexity of generalization"
					}
					,
					"wip-how-to-use-3rd-party-jekyll-plugins-in-github-pages": {
						"id": "wip-how-to-use-3rd-party-jekyll-plugins-in-github-pages",
						"title": "GitHub Pages에서 써드 파티 Jekyll Plugins 사용하기",
						"version": "all",
						"categories": "",
						"url": " /wip/how-to-use-3rd-party-jekyll-plugins-in-github-pages/",
						"content": "GitHub Pages에서 써드 파티 Jekyll Plugins 사용하기\n공식 문서에 따르면 GitHub Pages를 빌드할 때 쓰는 Jekyll 플러그인은 허용\n  목록으로 관리되고 있다. 그래서 무작정 jekyll-org 플러그인을 가져다 쓰면 안된다.\n  액션 로그를 잘 살펴보면 애초에 내가 정의한 Gem 파일의 플러그인은 단 하나도\n  설치하고 있지 않다는 것을 확인할 수 있다.\n그러면 어떻게 해야할까? 당연히 방법은 있다. 하이 레벨에서 설명하자면 다음과\n  같다.\n\n  소스 브랜치와 깃헙 페이지 브랜치를 나눈다. 각각 master 와 gh-pages 라고\n    하자. 깃헙 페이지 배포는 gh-pages 브랜치에서만 한다.\n  소스 브랜치에 커밋이 추가되면 커스텀 액션 을 통해 Jekyll 블로그를 빌드하고,\n    빌드 결과물을 gh-pages 브랜치에 커밋 한다.\n  gh-pages 브랜치에는 항상 빌드 결과물만 있게 되므로 곧바로 깃헙 페이지로\n    배포된다.\n\n이를 위해서 요 액션을 사용하면 된다.\n\n  소스 브랜치와 깃헙 페이지 브랜치를 나누고, 깃헙 페이지 브랜치에서 배포하도록\n    설정한다.\n  해당 액션의 예시를 거의 다 가져오면 되지만, 만약 서브 도메인으로 배포하고\n    있다면 (예: 이 사이트) 한 가지 추가 설정을 해줘야한다. 바로 jekyll_baseurl\n    을 서브 도메인으로 설정해주는 것이다. 이러면 _config.yml 이랑 별개로 이\n    옵션이 더 우선순위 높게 먹혀서 로컬에서 개발하기도 편하다.\n  소스 브랜치의 빌드 결과를 깃헙 페이지 브랜치에다가 커밋 해야 하므로 해당\n    깃헙 액션이 쓰기 권한 을 가져야 한다. Settings -&gt; Actions -&gt; General 탭의\n    제일 하단 Workflow permissions 에서 읽기와 쓰기 권한을 모두 주자.\n\n이렇게 설정해주면 jekyll-org 와 같이 허용 목록에 없는 플러그인도 마음껏 쓸 수\n  있다!"
					}
					,
					"ps-leetcode-implement-trie": {
						"id": "ps-leetcode-implement-trie",
						"title": "Implement Trie",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/implement-trie/",
						"content": "Implement Trie\n\n제목 그대로 트라이를 구현하는 문제다.\n\n\n  Trie(): 생성자\n  void insert(String word): word를 추가\n  boolean search(String word): word가 트라이에 있으면 true,\n아니면 false\n  boolean startsWith(String prefix): prefix로 시작하는 단어가\n있으면 true, 없으면 false\n  모든 단어와 접두어는 소문자 영어로만 구성되며, 길이는 2천을 넘지\n않는다.\n  최대 \\(3 \\times 10^4\\) 번의 insert, search, startsWith 함수\n호출이 일어난다.\n\n\n구현\n\n특별한 것은 없고 파이썬에서 트라이를 구현할 때의 팁이랄지 유의해야 할\n 부분만 조심하면 되겠다.\n\nclass Trie:\n    class Node:\n        def __init__(self):\n            self.child = [None] * 26\n            self.end = False\n\n        def __getitem__(self, key):\n            return self.child[ord(key) - ord('a')]\n\n        def __setitem__(self, key, value):\n            self.child[ord(key) - ord('a')] = value\n\n    def __init__(self):\n        self.trie = Trie.Node()\n\n    def insert(self, word):\n        node = self.trie\n        for char in word:\n            if node[char] is None:\n                node[char] = Trie.Node()\n            node = node[char]\n        node.end = True\n\n    def search(self, word):\n        node = self.trie\n        for char in word:\n            if node[char] is None:\n                return False\n            node = node[char]\n        return node.end\n\n    def startsWith(self, prefix):\n        node = self.trie\n        for char in word:\n            if node[char] is None:\n                return False\n            node = node[char]\n        return True\n\n\nTrie.Node\n\n트라이의 노드를 따로 구현했다. Trie 트라이 안에 구현했기 때문에\n 호출할 때에는 Trie.Node로 경로를 다 줘야한다.\n\n입력 단어가 모두 소문자 알파벳으로만 구성되기 때문에 자식 노드를\n 26개의 None으로 초기화한다. end 필드는 지금 노드의 위치가 단어의\n 끝인지 아닌지를 기록한다.\n\n파이썬의 클래스 어트리뷰트에는 __getitem__과 __setitem__이\n 있다. 이 어트리뷰트 함수를 적절히 오버로딩해서 트라이 노드의 자식에\n 접근하거나 자식 노드에 새 노드를 추가할 때 번거로운 계산을 이쪽으로\n 빼둘 수 있다. 파이썬에는 문자 타입이 없기 때문에, C처럼 char 타입을\n int 대신 써서 아스키코드를 곧바로 쓰고.. 이런건 못한다. 대신 ord\n 라는 함수를 통해서 문자열의 아스키 코드 값을 직접 계산해야 한다. 자식\n 노드는 리스트로 관리하기 때문에 ord('a')를 빼줘야 올바른 0-인덱스가\n 된다. 이걸 __getitem__과 __setitem__ 모두에 적용하면 된다.\n\ninsert\n\nword의 각 문자에 대해서 트라이 노드를 쭉 따라간다. node[char]는\n __getitem__으로 해석되고 따라서 자식 노드를 바로 빼올 수\n 있다. None이면 아직 자식이 추가 안된거니 node[char] = ... 를\n 이용해서 __setitem__을 호출하여 자식 노드를 만들어 둔다.\n\n이렇게 word의 끝까지 순회하면서 트라이 노드를 함께 움직이고 나면\n node는 단어의 마지막 문자의 노드를 가리킨다. 따라서, node.end =\n True로 기록해야 이 단어가 해당 노드에서 끝난다는 것을 기록할 수\n 있다.\n\nsearch, startsWith\n\nsearch와 startsWith은 딱 하나만 빼고 동일하다: 입력 단어를 따라\n 트라이 노드를 쭉 이동했을 때, 해당 노드가 단어의 끝인지 아닌지를\n 판단해야 하는지 여부다. search는 이걸 판단해야 하고 startsWith는\n 곧바로 True를 리턴하면 된다. 왜냐하면 해당 문자들로 시작하는 단어가\n 아예 없었다면 애초에 자식 노드가 None이었을 것이기 때문이다."
					}
					,
					"": {
						"id": "",
						"title": "",
						"version": "all",
						"categories": "",
						"url": " /",
						"content": "Book\n\n책."
					}
					,
					"ps-boj": {
						"id": "ps-boj",
						"title": "Baekjoon",
						"version": "all",
						"categories": "",
						"url": " /ps/boj/",
						"content": ""
					}
					,
					"ps-theory": {
						"id": "ps-theory",
						"title": "Theory",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/",
						"content": ""
					}
					,
					"ps-leetcode": {
						"id": "ps-leetcode",
						"title": "LeetCode",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/",
						"content": "Leetcode\n\nOmakase\n\n\n\nLanguage\n\n  Basic Calculator\n  Evaluate Reverse Polish Notation\n  Parsing A Boolean Expression\n\n\nArray\n\n  3Sum\n  Best Time to Buy and Sell Stock\n  Candy\n  Container With Most Water\n  Find Minimum in Rotated Sorted Array\n  Longest Consecutive Sequence\n  Maximum Area of a Piece of Cake After Horizontal and Vertical Cuts\n  Maximum Erasure Value\n  Maximum Points You Can Obtain from Cards\n  Maximum Product Subarray\n  Maximum Size Subarray Sum Equals k\n  Maximum Subarray\n  Minimum Difference Between Largest and Smallest Value in Three Moves\n  Minimum Moves to Equal Array Elements II\n  Minimum Operations to Reduce X to Zero\n  Minimum Size Subarray Sum\n  Monotonic Array\n  Non-decreasing Array\n  Pairs of Songs with Total Durations Divisible by 60\n  Prison Cells after N Days\n  Product of Array Except Self\n  Queue Reconstruction by Height\n  Remove Duplicates from Sorted Array\n  Search in Rotated Sorted Array\n  Shortest Unsorted Continuous Subarray\n  Snapshot Array\n  Two Sum\n  Walking Robot Simulation\n\n\nSorting\n\n  Sort an Array\n\n\nInterval\n\n  Count Odd Numbers in an Interval Range\n  Insert Interval\n  Meeting Rooms II\n  Meeting Rooms\n  Merge Intervals\n  Non-overlapping Intervals\n\n\nLinked List\n\n  LRU Cache\n  Linked List Cycle\n  Merge K Sorted Lists\n  Merge Two Sorted Lists\n  Middle of the Linked List\n  Palindrome Linked List\n  Partition List\n  Remove Nth Node From End Of List\n  Reorder List\n  Reverse Linked List II\n  Reverse Linked List\n  Split Linked List In Parts\n\n\nString\n\n  Encode and Decode Strings\n  Group Anagrams\n  Longest Palindromic Substring\n  Valid Palindrome\n  Count Common Words With One Occurrence\n  Delete Operation for Two Strings\n  Design Add and Search Words Data Structure\n  Design Search Autocomplete System\n  Find All Anagrams In A String\n  Find and Replace Pattern\n  Longest Common Subsequence\n  Longest Repeating Character Replacement\n  Longest Substring Without Repeating Characters\n  Minimum Window Substring\n  Optimal Partition Of String\n  Palindromic Substrings\n  Roman to Integer\n  Search Suggestions System\n  Short Encoding of Words\n  String Compression\n  Text Justification\n  Valid Anagram\n  Valid Parentheses\n  Find And Replace in String\n  Longest Palindrome by Concatenating Two Letter Words\n  Zigzag Conversion\n  Valid Word Abbreviation\n\n\nGraph\n\n  Alien Dictionary\n  As Far From Land As Possible\n  The Most Similar Path in a Graph\n  Clone Graph\n  Course Schedule\n  Critical Connections in a Network\n  Find Closest Node To Given Two Nodes\n  Graph Valid Tree\n  Is Graph Bipartite?\n  Longest Cycle In A Graph\n  Number of Connected Components in an Undirected Graph\n  Number of Islands\n  Number of Distinct Islands\n  Number of Provinces\n  Pacific Atlantic Water Flow\n  Rotting Oranges\n  Minimum Genetic Mutation\n  Shortest Path With Alternating Colors\n  Reorder Routes To Make All Paths Lead To The City Zero\n  Web Crawler\n\n\nTree\n\n  Find Leaves of Binary Tree\n  Step-By-Step Directions From a Binary Tree Node to Another\n  Binary Tree Cameras\n  Binary Tree Level Order Traversal\n  Binary Tree Maximum Path Sum\n  Check Completeness Of A Binary Tree\n  Construct Binary Tree from Preorder and Inorder Traversal\n  Convert Sorted List to BST\n  Implement Trie\n  Invert/Flip Binary Tree\n  Kth Smallest Element in a BST\n  Lowest Common Ancestor of a Binary Search Tree\n  Maximum Depth of Binary Tree\n  Same Tree\n  Serialize and Deserialize Binary Tree\n  Stream of Characters\n  Subtree of Another Tree\n  Validate Binary Search Tree\n\n\nDisjoint Set\n\n  Data Stream As Disjoint Intervals\n  Count Unreachable Pairs Of Nodes In An Undirected Graph\n\n\nHeap\n\n  Find Median from Data Stream\n  Maximum Units on a Truck\n  Merge K Sorted Lists\n  Minimum Deletions to Make Character Frequencies Unique\n  Top K Frequent Elements\n\n\nMatrix\n\n  Set Matrix Zeroes\n  Shortest Path in a Grid with Obstacles Elimination\n  Spiral Matrix\n  Rotate Image\n\n\nSearch\n\n  Expression Add Operators\n  Guess the Word\n  Combination Sum\n  Pow(x, n)\n  Sqrt(x)\n  Word Search II\n  Word Search\n  Contains Duplicate\n  Campus Bikes\n  Can Place Flowers\n\n\nDP\n\n  Minimum Window Subsequence\n  House Robber II\n  House Robber\n  Jump Game\n  Longest Common Subsequence\n  Race Car\n  Word Break Problem\n  Climbing Stairs\n  Coin Change\n  Decode Ways\n  Interleaving String\n  Longest Increasing Subsequence\n  Longest String Chain\n  Matchsticks to Square\n  Minimum Difficulty of a Job Schedule\n  Paint House III\n  Paint House II\n  Paint House\n  Partition Equal Subset Sum\n  Pascal’s Triangle\n  Range Sum Query 2D Immutable\n  Triangle\n  Unique Paths\n  Wiggle Subsequence\n  Wildcard Matching\n\n\nBitwise Operation\n\n  Counting Bits\n  Missing Number\n  Number of 1 Bits\n  Reverse Bits\n  Sum of Two Integers\n  Single Number\n\n\nMath\n\n  Power of Three\n  RLE Iterator\n  Rectangle Area\n  Ugly Number"
					}
					,
					"ps-cpp": {
						"id": "ps-cpp",
						"title": "PS with C++",
						"version": "all",
						"categories": "",
						"url": " /ps/cpp/",
						"content": ""
					}
					,
					"ps": {
						"id": "ps",
						"title": "Problem Solving",
						"version": "all",
						"categories": "",
						"url": " /ps/",
						"content": ""
					}
					,
					"wip-u3-ocaml": {
						"id": "wip-u3-ocaml",
						"title": "U3 OCaml",
						"version": "all",
						"categories": "",
						"url": " /wip/u3-ocaml/",
						"content": "Using, Understanding, and Unraveling The OCaml Language\n\nOCaml의 타입 체커와 관련해서 Didier\n Re’my가 APPSEM’ 2000 Summer\n School에서 했던 강의\n 노트를 한번\n 정리해보자."
					}
					,
					"wip-multicore-ocaml": {
						"id": "wip-multicore-ocaml",
						"title": "Multicore OCaml",
						"version": "all",
						"categories": "",
						"url": " /wip/multicore-ocaml/",
						"content": ""
					}
					,
					"wip-monadic-parser-combinators": {
						"id": "wip-monadic-parser-combinators",
						"title": "Monadic Parser Combinators",
						"version": "all",
						"categories": "",
						"url": " /wip/monadic-parser-combinators/",
						"content": ""
					}
					,
					"wip-lwt": {
						"id": "wip-lwt",
						"title": "Lwt",
						"version": "all",
						"categories": "",
						"url": " /wip/lwt/",
						"content": ""
					}
					,
					"wip-optimization": {
						"id": "wip-optimization",
						"title": "Optimization",
						"version": "all",
						"categories": "",
						"url": " /wip/optimization/",
						"content": ""
					}
					,
					"wip-practical-statistics": {
						"id": "wip-practical-statistics",
						"title": "Notes on Practical Statistics",
						"version": "all",
						"categories": "",
						"url": " /wip/practical-statistics/",
						"content": ""
					}
					,
					"wip-books": {
						"id": "wip-books",
						"title": "Books",
						"version": "all",
						"categories": "",
						"url": " /wip/books/",
						"content": ""
					}
					,
					"wip-algorithms-for-modern-hardware": {
						"id": "wip-algorithms-for-modern-hardware",
						"title": "Algorithms for Modern Hardware",
						"version": "all",
						"categories": "",
						"url": " /wip/algorithms-for-modern-hardware/",
						"content": "Algorithms for Modern Hardware"
					}
					,
					"wip-front-end": {
						"id": "wip-front-end",
						"title": "Front-End",
						"version": "all",
						"categories": "",
						"url": " /wip/front-end/",
						"content": ""
					}
					,
					"wip-distributed-systems": {
						"id": "wip-distributed-systems",
						"title": "Distributed Systems",
						"version": "all",
						"categories": "",
						"url": " /wip/distributed-systems/",
						"content": "Distributed Systems\n마틴 클레프만의 강의 Distributed\n Systems\n 의 강의 노트를 정리해보자."
					}
					,
					"wip-type": {
						"id": "wip-type",
						"title": "Type",
						"version": "all",
						"categories": "",
						"url": " /wip/type/",
						"content": ""
					}
					,
					"wip": {
						"id": "wip",
						"title": "Work in Progress",
						"version": "all",
						"categories": "",
						"url": " /wip/",
						"content": ""
					}
					,
					"ps-leetcode-insert-interval": {
						"id": "ps-leetcode-insert-interval",
						"title": "Insert Interval",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/insert-interval/",
						"content": "Insert Interval\n\n범위란 시작점과 끝점의 튜플 (start, end) 이고 start &lt;= end\n 이다. 범위의 리스트 intervals는 겹치지 않는 범위들이 start의\n 오름차순으로 정렬되어 있다.\n\n추가할 범위 newInterval을 intervals에 삽입해서 새로운 범위\n 리스트를 만들어야 하는데, 원래의 범위 리스트와 마찬가지로 겹치는 부분\n 없이 오름차순이어야 한다.\n\nO(N) - 1\n\n범위 리스트가 서로 겹치지 않는 것이 보장되어 있기 때문에, 삽입할\n 범위를 기준으로 둘로 나눌 수 있다. 즉,\n\nleft &lt; (newInterval.start, newInterval.end) &lt; right\n\n\n요런 느낌으로 왼쪽과 오른쪽으로 나눠볼 수 있다. 이러면 두 가지\n 케이스가 생기는데,\n\n\n  len(left) + len(right) == len(intervals)인 경우: 즉 삽입할\n범위를 기준으로 반 짤랐는데, 자른 두 길이를 합친 것이 원래 길이와\n같다는 것은 원래 범위 리스트 중 삽입할 범위와 겹치는 것이 아무것도\n없다는 뜻이다. 이때는 그냥 left와 right 사이에 newInterval을\n집어넣으면 된다.\n  아닌 경우: 이 때는 left와 right 사이에 newInterval과 범위가\n겹치는 부분이 있다는 뜻이다. 그러면 겹치는 부분을 어떻게 알 수\n있을까?\n\n\n겹치는 부분 파악하기\n\n왼쪽을 먼저 생각해보자. 범위 리스트에서 len(left)만큼을 제외하고\n 처음 나타나는 범위의 시작점과 삽입할 newInterval의 시작점 중 더\n 작은 것이 삽입할 범위의 시작점이 될 것이다. 그래야 범위를 다 커버할\n 수 있기 때문이다. 즉, len(left)-1 +1 인덱스의 범위와 비교하면\n 된다.\n\n다음으로 오른쪽을 생각해보자. 범위 리스트에서 거꾸로 len(right)\n 만큼을 제외하고 처음 나타나는 범위의 끝점과 삽입할 newInterval의\n 끝점 중 더 큰 것이 삽입할 범위의 끝점이 될 것이다. 역시 이것도 범위를\n 다 커버하기 위함이다. 이때, 파이썬에서는 음수 인덱스를 활용할 수\n 있는데, 양수와는 달리 0이 아니라 -1 부터 시작하므로 -len(right) -1\n 인덱스의 범위와 비교하면 된다.\n\n\n\n이 아이디어를 구현하면 다음과 같다.\n\ndef insert(intervals, newInterval):\n    start, end = newInterval\n    left = [itv for itv in intervals if itv[1] &lt; start]\n    right = [itv for itv in intervals if end &lt; itv[0]]\n    if len(left) + len(right) != len(intervals):\n        start = min(start, intervals[len(left)][0])\n        end = max(end, intervals[-len(right)-1][1])\n    return left + [(start, end)] + right"
					}
					,
					"ps-leetcode-interleaving-string": {
						"id": "ps-leetcode-interleaving-string",
						"title": "Interleaving String",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/interleaving-string/",
						"content": "Interleaving String\n\n문자열 세 개 s1, s2, s3가 주어진다. 이때, s1과 s2의 글자를\n 서로 사이에 끼워서(interleaving) s3를 만들 수 있는지 없는지\n 판별하자.\n\n두 문자열 s와 t를 서로 사이에 끼우는 연산은 다음 조건을\n 만족하는 비지 않은 부분 문자열로 나눠지는 것을 의미한다:\n\n  s = s1 + s2 + ... + sn\n  t = t1 + t2 + ... + tm\n  | n - m | &lt;= 1\n  서로 사이에 끼운 문자열은 s1 + t1 + s2 + t2 + ... 이거나\nt1 + s1 + t2 + s2 + ... 이다.\n\n\n참고로 a + b는 문자열 a와 b를 잇는 것이다.\n\ns1과 s2의 길이는 0 ~ 100 사이이고 s3는 0 ~ 200 사이이다. 모두\n 알파벳 소문자만 담고 있다.\n\n예를 들어 s1 = aabcc, s2 = dbbca, s3 = aadbbcbcac라고\n 하자. 이때, s1을 aa, bc, c 로, s2를 dbbc, a로 나눈 다음\n s1부터 번갈아 끼우면 aa + dbbc + bc + a + c = s3가 되므로 정답은\n 참이다.\n\n동적 프로그래밍은 완전 탐색부터\n\n일단 단순히 각 문자열에 있는 글자 개수를 세서 비교하는 접근은\n 안된다. 부분 문자열의 순서가 중요하고, 또 s1과 s2가 서로\n 번갈아 나와야 하기 때문이다.\n\n가장 먼저 완전 탐색 알고리즘부터 생각해보자. 일단 기저 조건으로, 각\n 문자열의 글자 수가 아니라 문자열의 길이가 맞지 않으면 불가능하다. 즉\n |s1| + |s2| != |s3|인 경우는 아예 인터리빙 자체가 불가능하다.\n\n그럼 이제 문자열 길이가 맞춰진 경우를 생각해보자. s1, s2, s3에\n 대해서 각각 지금 어느 부분의 글자를 탐색하고 있는지를 알기 위해서 세\n 인덱스 i1, i2, i3를 유지하자. 먼저 s1이 먼저 나오는 경우부터\n 생각해보자. s1[i1]의 글자가 s3[i3]와 같은 경우에 다음 둘 중\n 하나를 진행할 수 있다:\n\n  만약 또 s1[i1 + 1]이 s3[i1 + 1]과 같다면, 계속 같을 때 까지\n이어나간다.\n  s2[i2]가 s3[i + 1]과 같다면, 이번에는 s2를 선택해서\n이어나간다.\n\n\ns2가 먼저 나오는 경우도 위와 비슷하다. 즉, 만약 i1, i2 모두\n 0부터 시작하여 s1과 s2를 번갈아 재귀적으로 확인한다면, 모든\n 경우의 수를 확인할 수 있다.\n\n이렇게 계속 이어나간다면, 언제 탐색이 종료될까? s1이든 s2든 한쪽\n 문자열의 끝에 도달한 경우일 것이다. 예를 들어 i1이 s1의 끝에\n 도달했다면, 남은 것은 다음을 확인하는 것이다: s2에 대해서 i2\n 이후의 부분문자열이, s3에 대해서 i3 이후의 부분문자열과\n 같은지. 즉, i1은 더 이상 매칭이 불가능하니, 남은 모든 기운(?)을\n 써서 s2의 남은 부분문자열과 s3의 남은 부분문자열이 같기를 바라는\n 것이다.\n\n말로 설명하니 뭔가 꼬이는 것 같은데, 코드로 나타내면 아래와 같다.\n\ndef isInterleave(s1, s2, s3):\n    if len(s1) + len(s2) != len(s3):\n        return False\n\n    def check(i1, i2, i3):\n        if i1 == len(s1):\n            return s2[i2:] == s3[i3:]\n        if i2 == len(s2):\n            return s1[i1:] == s3[i3:]\n\n        return (s1[i1] == s3[i3] and check(i1 + 1, i2, i3 + 1)) \\\n            or (s2[i2] == s3[i3] and check(i1, i2 + 1, i3 + 1))\n\n    return check(0, 0, 0)\n\n\ncheck 함수가 앞에서 설명한 재귀적인 확인을 한다. 기저 조건은 i1\n 또는 i2가 끝에 도달했을 때 이다. 앞에서 미리 글자 수가 다른 경우를\n 걸러내기 때문에, i1 또는 i2가 끝에 도달했을 때 s2[i2:] 또는\n s1[i1:]은 남은 s3[i3:] 부분문자열과 항상 길이가 같음이 보장된다.\n\n교묘한 부분은 재귀를 타고들어가는 부분이다. s1[i1] == s3[i3], 즉\n 지금 s1의 부분문자열의 일부가 먼저 나올 수 있는 상황이라면, i1과\n i3를 동시에 하나씩 진행한다. s2의 경우도 비슷하다. 이렇게하면 (1)\n s1와 s2가 번갈아 올 수 있는 모든 경우를 확인하면서 (2) 둘 중\n 하나가 끝에 도달했을 때 나머지를 전부 확인하는, 문제의 조건을\n 만족하게 된다.\n\n당연하지만, 이렇게하면 복잡도가 지수적이라서 터진다. s1의 길이를\n n, s2의 길이를 m이라고 했을 때, s3의 길이는 n + m이 되고\n 모든 s3의 각 글자에 대해서 s1 또는 s2 두 가지 경우가\n 가능하므로, 시간 복잡도는 \\(O(2 ^ {n + m})\\)이 된다.\n\n메모아이제이션\n\n그럼 복잡도를 낮출 수 있는 방법을 찾아보자. 재귀가 일어날 때, i3는\n 항상 증가하지만 i1와 i2는 둘 중 하나만 증가한다. 따라서 잘\n 생각해보면, i3가 1 증가하면, i1이 1 증가하기 전과 i2가 1\n 증가하기 전 모두를 살펴보게 된다. 그림으로 그리면 다음과 같다.\n\n    i3   | 0 -----------&gt; 1 ----------&gt; 2 ---------------&gt; 3\n(i1, i2) | (0, 0)      (0, 1)         (0, 2)        (0, 3), (1, 2)\n         |                            (1, 1)        (1, 2), (2, 1)\n         |             (1, 0)         (2, 0)        (2, 1), (3, 0)\n         |                            (1, 1)        (1, 2), (2, 1)\n\n\n즉, i3 = 3 일 때, (i1, i2)는 꽤 많이 중복된다: (1, 2)가 세번,\n (2, 1)도 세번. 따라서, s3(i3)를 기준으로 생각해보면, s1과\n s2의 일부를 반드시 중복해서 보게 된다. 입력 문자열이 변하지 않기\n 때문에 이 반복되는 부분은 i3의 값에 상관없이 변하지 않는다. 따라서\n 최적 부분구조(optimal substructure)를 가지고 있다고 판단할 수\n 있고, 이를 캐싱해서 속도를 높일 수 있다.\n\ni1, i2 페어에 대해서 기존에 결과를 빠르게 돌려주면 되므로, 다음과\n 같이 메모아이제이션을 하면 된다.\n\ndef isInterleave(s1, s2, s3):\n    memo = {}\n    def check(i1, i2, i3):\n        if i1 == len(s1):\n            return s2[i2:] == s3[i3:]\n        if i2 == len(s2):\n            return s1[i1:] == s3[i3:]\n        if (i1, i2) in memo:\n            return memo[(i1, i2)]\n        res = (s1[i1] == s3[i3] and check(i1+1, i2, i3+1)) \\\n            or (s2[i2] == s3[i3] and check(i1, i2+1, i3+1))\n        memo[(i1, i2)] = res\n        return res\n    return check(0, 0, 0)\n\n\n이를 통해 시간과 공간 복잡도 모두 O(nm)의 솔루션을 얻을 수 있다."
					}
					,
					"wip-distributed-systems-intro": {
						"id": "wip-distributed-systems-intro",
						"title": "01. Introduction (WIP)",
						"version": "all",
						"categories": "",
						"url": " /wip/distributed-systems/intro/",
						"content": "동시성(Concurrency)은 하나의 머신에서 동작한다. 주로 같은 메모리\n 공간을 갖는 멀티 쓰레드를 활용하기 때문에 공유 메모리\n 동시성(shared-memory concurrency)를 말한다. 이때는 데이터를 다른\n 쓰레드와 쉽게 공유할 수 있다.\n\n분산 시스템에서는 다르다. 여전히 동시에 일어나긴 하지만, 프로그램이\n 병렬적으로 여러 대의 머신에서 동작하기 때문에, 공유하는 메모리 공간이\n 없다. 서로 다른 머신(컴퓨터)은 오직 네트워크를 통한 메시지를 주고\n 받아서만 통신할 수 있다.\n\n분산 시스템에서 각각의 머신(컴퓨터)는 노드(node)라고 부른다. 여기서\n 머신(컴퓨터)은 아주 광범위한데, 데스크탑, 서버, 모바일 기기, 자동차,\n 센서 등을 모두 포함한다. 통신할 수 있는 모든 기기를 노드라고 하자.\n\n저명한 Leslie Lamport는 분산 시스템을 아래와 같이 정의했다:\n\n\n  … a system in which the failure of a computer you didn’t even know\nexisted can render your own computer unusable – Leslie Lamport\n\n\n분산 시스템이란?\n\n왜 만드는 걸까?\n\n분산 시스템 같은 걸 대체 왜 만드는 걸까?\n\n어떤 프로그램은 본질적으로 분산되어 있다. 모바일 기기 사이에서\n 문자를 전송하는 일은, 본질적으로 분산 시스템이다.\n\n또 어떤 프로그램은 사실 머신 한대로도 할 수 있지만 더 좋은\n 신뢰성(reliability)을 위해서 분산되기도 한다. 시스템 안의 노드\n 하나가 죽어도(failure), 시스템 전체는 여전히 동작하도록 설계할 수\n 있다.\n\n또 다른 이유로는 더 좋은 성능(performance)을 위한 것도 있다. 전\n 세계에 사용자가 어떤 서비스를 이용하는데, 만약 하나의 노드로만\n 서비스가 제공된다면, (빛이 끔찍하게 느리기 때문에) 끔찍한 성능을 낼\n 것이다.\n\n마지막으로, 아주 큰 (large-scale) 데이터 처리나 연산 작업을 하고\n 싶은데 단순히 머신 한대에서 처리하기에 너무 큰 경우에도 분산\n 시스템은 필연적이다. 예를 들면 CERN 의 Large Hadron Collider의\n 연산에는 백만 개의 CPU와 1 엑사바이트의 저장 공간이 필요하다. 머신\n 한대로는 할 수 없다.\n\n정리하자면, 분산 시스템을 만드는 이유는 다음 네 가지로 요약할 수\n 있다.\n\n\n  본질적으로 분산 시스템\n  더 좋은 신뢰성을 위해\n  더 좋은 성능을 위해\n  아주 큰 문제를 풀기 위해\n\n\n하지만 모든 일은 잘못될 수 있고 시스템은 이런 잘못을 처리해야 하기\n 때문에, 분산 시스템에도 단점은 존재한다.\n\n가장 먼저 네트워크가 부러질 수 있다. 이러면 노드끼리 통신을 못한다.\n\n노드가 죽거나(crash), 평소랑 달리 엄청나게 느리게 동작하거나,\n 소프트웨어 버그 또는 하드웨어 오류로 이상하게 동작할 수도 있다. 이\n 모든 걸 죽는(crash) 걸로 퉁친다면, 어떤 노드가 죽는지 감시하면 되지\n 않을까? 라고 생각할 수 있지만, 이것조차 쉽지 않다. 노드나 네트워크는\n 아무런 경고도 없이 죽는다.\n\n단일 머신에서 어떤 작업을 하는 도중에 머신의 일부(예를 들어 RAM)가\n 망가지면, 보통은 그 작업이 계속될 거라고 예상하지 않는다. 그냥 죽을\n 것이다. 하지만 분산 시스템에서는 보통 시스템의 일부가 부러져도\n 나머지는 계속해서 동작하길 기대한다. 예를 들면 노드 하나가 죽으면\n (부분 고장; partial failure), 나머지 노드들은 여전히 서비스를\n 지탱할 수 있다.\n\n시스템의 일부가 동작을 멈추는 것을 고장(fault)이라고 하고 많은"
					}
					,
					"ps-leetcode-invert-flip-binary-tree": {
						"id": "ps-leetcode-invert-flip-binary-tree",
						"title": "Invert/Flip Binary Tree",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/invert-flip-binary-tree/",
						"content": "Invert/Flip Binary Tree\n\n바이너리 트리의 루트 노도가 주어졌을 때, 해당 트리를 뒤집어서 새로운\n 트리를 리턴하자.\n\n\n\n재귀\n\n딱 봐도 재귀적인 접근이 먹힐 것 같다. 루트를 기준으로 왼쪽과 오른쪽\n 노드를 바꾼 다음, 계속 내려가면 된다.\n\n\"\"\"\nclass TreeNode:\n    def __init__(self, val=0, left=None, right=None):\n        self.val = val\n        self.left = left\n        self.right = right\n\"\"\"\ndef invertTree(root):\n    def invert(node):\n        if node is None:\n            return\n        node.left, node.right = node.right, node.left\n        invert(node.left)\n        invert(node.right)\n    invert(root)\n    return root\n\n\n위 코드는 원래 트리를 직접 수정한다. 만약 트리를 수정하지 않고 뒤집은\n 트리를 새롭게 만들어서 리턴해야 하는 경우는 어떻게 하면 될까? 다음과\n 같이 invert 함수가 뒤집은 트리 노드를 매번 돌려주면 된다.\n\ndef invertTree(root):\n    def invert(node):\n        if node is None:\n            return None\n        fresh = TreeNode(val=node.val)\n        fresh.left, fresh.right = invert(node.right), invert(node.left)\n        return fresh\n    return invert(root)"
					}
					,
					"ps-leetcode-is-graph-bipartite": {
						"id": "ps-leetcode-is-graph-bipartite",
						"title": "Is Graph Bipartite?",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/is-graph-bipartite/",
						"content": "Is Graph Bipartite?\n\nn개의 노드를 가진 무향 그래프가 주어진다. 노드는 0부터 n-1까지\n 레이블링 되어 있다is-graph-bipartite. 2차원 배열 graph가 입력으로 들어오는데,\n graph[u]는 노드 u와 인접한 노드의 배열이다.\n\n  자기 자신에게 가는 엣지는 없다. 즉, \\(\\forall node, graph[node]\n\\neq node\\)\n  여러 개의 엣지도 없다. graph[u]는 중복 원소를 담고 있지 않는다.\n  v가 graph[u]안에 있다면, graph[v] 안에도 u가 있다. 즉,\n무향이다.\n  그래프는 연결이 안되어 있을 수도 있다. 즉, 어떤 두 노드 u와 v\n사이에 엣지가 없을 수도 있다.\n\n\n어떤 그래프의 모든 노드가 두 개의 독립적인 집합 A와 B로 나누어지고\n A에 있는 모든 노드와 B에 있는 모든 노드 사이에 엣지가 존재한다면,\n 그래프는 이분(Bipartite)이라고 불린다.\n\n그래프가 이분 그래프인지 판단하자.\n\n번갈아 가며 색깔 칠하기\n\n유명한 이분 그래프 문제다. 인접한 노드끼리 서로 다른 색으로 칠해\n 나아가면서, 모든 정점을 두 가지 색으로만 칠할 수 있는지를 확인하는\n 문제다.\n\n결국 그래프를 탐색하면서 서로 다른 색을 칠하면 된다. 탐색은 BFS, DFS\n 모두 가능하다. 어차피 엣지가 연결된 두 노드에 서로 다른 색을 칠하기만\n 하면 된다.\n\n색깔을 칠하기 위한 해시 테이블을 도입하자. 그러면, 아직 색이 칠해지지\n 않은 노드는 곧 아직 방문하지 않은 노드이기 때문에, 탐색에 쓰이던\n visited 집합이 필요없다.\n\n또한, 입력으로 들어오는 그래프가 연결 그래프가 아닐 수 있기 때문에,\n 모든 노드에 대해서 탐색을 해야 한다는 사실에 주의하자.\n\nfrom collections import deque\ndef isBipartite(graph):\n    colors = {}  # we can check visited by coloring\n    q = deque()\n    bipartite = True\n\n    for node in range(len(graph)):\n        if node not in colors and bipartite:\n            q.append(node)\n            colors[node] = 1\n\n            while q and bipartite:\n                top = q.popleft()\n                for neighbor in graph[top]:\n                    if neighbor not in colors:\n                        q.append(neighbor)\n                        colors[neighbor] = -colors[top]\n                    elif colors[neighbor] == colors[top]:\n                        bipartite = False\n                        break\n    return bipartite\n\n\n\n  BFS로 구현했다. 현재 방문 중인 노드와 인접한 모든 노드를 보면서,\n아직 색이 칠해지지 않았다면(=아직 방문하지 않았다면) 지금 노드와\n다른 색을 칠한다. 색은 1과 -1을 이용해서 손쉽게 서로 다른\n색임을 표현했다.\n  만약 색이 같다면 이분 그래프가 아니므로, 더 이상 탐색할 필요가\n없다. 따라서 글로벌 상태로 bipartite를 두고, 여전히 이분\n그래프라고 판단될 때에만 그래프를 탐색하도록 최적화했다."
					}
					,
					"ps-leetcode-jump-game": {
						"id": "ps-leetcode-jump-game",
						"title": "Jump Game",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/jump-game/",
						"content": "Jump Game\n쉽지 않다.. 딱 원소 값 만큼만 점프할 수 있는게 아니라 최대 그 값 만큼 점프할 수\n  있는 거라서 경우의 수가 매우 많다.\n백트래킹\n일단은 타임아웃 나더라도 정직하게 모든 경우를 추적하는 백 트래킹 구현은 다음과\n  같다.\ndef canJump(nums: List[int]) -&gt; bool:\n    def backtrack_from(pos):\n        if pos == len(nums) - 1:\n            return True\n        farthest = min(pos + nums[pos], len(nums) - 1)\n        for i in range(pos+1, furthest+1):\n            if backtrack_from(i):\n                return True\n        return False\n    return backtrack_from(0)\n\n탑 다운 다이나믹 프로그래밍\n원소 값의 모든 경우를 다 따져보기 전까지는 그 원소 값이 좋은지 안좋은지 모르기\n  때문에, 각 경우를 다음 세 가지로 나눈다: 아직 모름, 좋음, 나쁨.\ndef canJump(nums: List[int]) -&gt; bool:\n    GOOD, BAD, UNKNOWN = 0, 1, 2\n    memo = [UNKNOWN] * len(nums)\n    def can_jump_from(pos):\n        if memo[pos] != UNKNOWN:\n            return memo[pos] == GOOD\n        farthest = min(pos + nums[pos], len(nums) - 1)\n        for i in range(pos+1, farthest+1):\n            if can_jump_from(i):\n                memo[pos] = GOOD\n                return True\n        # cannot reach from pos\n        memo[pos] = BAD\n        return False\n\n    memo[len(nums) - 1] = GOOD  # the goal is good\n    return can_jump_from(0)\n\n바텀 업 다이나믹 프로그래밍\n비슷한 방법으로 태뷸레이션을 채워갈 수도 있다.\ndef canJump(nums: List[int]) -&gt; bool:\n    n = len(nums)\n    GOOD, BAD, UNKNOWN = 0, 1, 2\n    memo = [UNKNOWN] * n\n    memo[n-1] = GOOD\n    for i in range(n-2, -1, -1):\n        farthest = min(i + nums[i], n-1)\n        for j in range(i+1, farthest+1):\n            if memo[j] == GOOD:\n                memo[i] = GOOD\n                break\n    return memo[0] == GOOD\n\n그리디\n이 문제는 탐욕법으로도 풀린다. 바텀 업 다이나믹 프로그래밍 알고리즘을 잘 보면,\n  어떤 주어진 위치로부터 GOOD 위치를 찾아야 하는데, 이는 그 중에서 가장 왼쪽\n  (break) 이다. 즉, 가장 왼쪽의 GOOD 위치들만 모아두면 될 것 같다.\n따라서 오른쪽에서 왼쪽으로 거꾸로 훑어가면서, 각각의 위치에서 좋은 위치로\n  점프가 가능한지를 확인하면 된다.\ndef canJump(nums: List[int]) -&gt; bool:\n    n = len(nums)\n    last = n - 1\n    for i in range(n-1, -1, -1):\n        if i + nums[i] &gt;= last:\n            last = i\n    return last == 0"
					}
					,
					"ps-theory-knapsack": {
						"id": "ps-theory-knapsack",
						"title": "Knapsack",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/knapsack/",
						"content": "Knapsack Problem\n\n조합 최적화 문제 중 가장 유명한 문제 중 하나인 배낭 문제, 혹은 냅색\n 문제를 알아보자.\n\n기본적인 문제 세팅은 다음과 같다.\n\n\n  최대 W 만큼의 무게를 담을 수 있는 배낭이 있다. 여기에 각각 가치와\n무게가 다른 N개의 보석이 있다. 보석 i는 무게 w_i와 가치\nv_i를 갖는다. 이때 가치의 합이 최대가 되도록 배낭에 보석을\n담는 방법을 찾자.\n\n\n보석을 쪼갤 수 있는 경우를 Fractional Knapsack 문제라고 하는데, 이\n 경우는 가치/무게가 높은 보석부터 골라서 넣는 탐욕법으로 쉽게\n 풀린다.\n\n0-1 Knapsack\n\n우리가 관심있는 다이나믹 프로그래밍의 단골 주제는 보석을 쪼갤 수\n 없는, 이른바 0-1 Knapsack 문제라고 한다. 이 문제를 수식으로 표현하면\n 다음 최적화 문제가 된다.\n\n다음을 만족하는 \\(x_1, x_2, ..., x_N\\) 을 찾아야 한다:\n\n\\[\\begin{equation}\n\\begin{cases}\n    \\text{maximize: } &amp; \\sum_{i=1} ^{N} v_i x_i \\\\\n    \\text{subject to:} &amp; \\sum{i=1} ^{N} w_i x_i \\leq W \\\\\n        &amp; x_i \\in \\{0, 1\\}, 1 \\leq i \\leq N \\\\\n\\end{cases}\n\\end{equation}\\]\n\nNaive Approach\n\n가장 나이브한 접근은 모든 경우의 수를 다 나열해보면서 가치의 합이\n 최대가 되는 조합을 찾는 방법이다. 보석이 N개이고, 각각의 보석에\n 대해서 배낭에 넣거나(1) 빼거나(0) 둘 중 하나이므로 가능한 모든 경우의\n 수는 \\(2^N\\) 이 된다. 복잡도 \\(O(2^N)\\)은 터진다.\n\nDynamic Programming\n\n다이나믹 프로그래밍이 동작하려면 두 가지 성질을 만족해야\n 한다.\n\n첫 번째는 Optimal Substructure 이다. 최적 부분 구조… 라고도 말하는\n 것 같은데, 다음과 같이 정의한다.\n\n\n  부분 문제의 최적해로부터 전체 문제의 최적해를 만들 수 있을 때, 그\n문제는 최적 부분 구조를 갖는다고 말한다. 즉, 어떤 문제의 최적해가\n부분 문제의 최적해를 항상 포함한다.\n\n\n두 번째는 Overlapping Subproblems, 부분 문제가 중복되어야 한다는\n 것이다. 다이나믹 프로그래밍은 결국 메모아이제이션, 캐싱이 핵심인데\n 이게 잘 동작하려면 당연히 같은 부분 문제를 여러 번 재활용할 수 있어야\n 한다.\n\n이제 냅색 문제가 이 성질을 만족하는지 살펴보자. 어떤 해집합 A가\n 순서대로 k개의 보석을 가지고 만든 최적해라고 하자.\n\n  A가 k 번째 보석을 포함하지 않는다면, A는 나머지 k-1개의\n보석들로 만든 최적해와 같을 것이다.\n  A가 k 번째 보석을 포함한다면, A는 k-1개의 보석들로 만든\n최적해에 k 번째 보석을 추가한 것이다. 단, 이때 k 번째 보석을\n넣을 수 있어야 한다.\n\n\n그러므로 Optimal Substructure와 Overlapping Subproblems 두 성질을\n 모두 만족한다는 것을 알 수 있다. 이를 이용해서 첫 번째 보석부터 N\n 번째 보석까지 순서대로 해를 구해나가면 마지막에 구한 해집합이 곧\n 최적해가 된다.\n\n이 내용을 수식으로 표현하면 다음과 같다. 먼저 여기서\n 정의된 문제를 \\(\\mathsf{Knapsack}(1, N, W)\\) 라고 하자. 즉, 배낭의\n 무게 한도 W 내에서 최대의 가치가 되도록 N 개의 보석 중에서 고르는\n 문제이다. 최적해는 i 번째 보석을 고르거나 고르지 않도록 하는 변수의\n 튜플 \\((x_1, x_2, ..., x_N)\\) 이고 \\(x_i \\in \\{0, 1\\}, 1 \\leq i\n \\leq n\\) 이다. 그러면,\n\n  만약 \\(x_N = 0\\), 즉 N 번째 보석을 고르지 않는다면, trivial\n하게 \\((x_1, x_2, ..., x_{N-1})\\) 만으로도 최적해가 되고 이는 곧\n\\(\\mathsf{Knapsak}(1, N-1, M)\\)의 최적해와 같다.\n  만약 \\(x_N = 1\\), 즉 N 번째 보석을 고른다면, \\((x_1, x_2,\n..., x_{N-1})\\) 는 \\(\\mathsf{Knapsak}(1, N-1, M - w_N)\\)의\n최적해와 같다.\n\n\n이전의 “k 번째 보석을 넣을 수 있어야 한다”는 조건을 어떻게 수식에\n 표현했는지 눈여겨 보자 (\\(M - w_N\\)).\n\nOptimal Substructure에 근거해서, 이 최적해를 다음과 같이 쪼개서\n 표현할 수 있다. 먼저 \\(\\mathsf{Knapsak}(1, N-1, M - w_N)\\)의 최적해\n \\((x_1, x_2, ..., x_N)\\) 를 \\(\\mathsf{Opt}(N, M)\\) 이라고\n 하자. 그러면 이는 다음과 같다.\n\n\\[\\begin{equation}\n\\begin{split}\n\\mathsf{Opt}(N, M) &amp; =  \\mathtt{max}(\\text{Case 1의 가치}, \\text{Case 2의 가치}) \\\\\n    &amp; =  \\mathtt{max}(\\mathsf{Opt}(N-1, M), \\mathsf{Opt}(N-1, M-w_N) + v_N) \\\\\n\\end{split}\n\\end{equation}\\]\n\n조합 찾기\n\n근데 이렇게 다이나믹 프로그래밍으로 풀면, 최적해가 만드는 가치의\n 합만을 알 수 있다. 최적해를 만드는 보석의 조합, 즉 \\((x_1, x_2,\n ..., x_N)\\) 의 맵핑은 어떻게 알 수 있을까?\n\n최적해가 만드는 가치의 합인 \\(\\mathsf{Opt}(i, k)\\) 을\n 생각해보자. 그러면 앞의 두 성질(로 부터 끌어낸 점화식)에 의해서,\n\n\n  \\(\\mathsf{Opt}(i, k) \\neq \\mathsf{Opt}(i - 1, k)\\) 이라면, i\n번째 보석이 포함되었다는 뜻이다 (by Case 2). 따라서 i 번째\n보석을 포함했다고 기록하고 다음 보석을 찾기 위해서 \\(i \\mapsto i -\n1, k \\mapsto k - w_i\\) 로 다음 것을 계산한다.\n  \\(\\mathsf{Opt}(i, k) = \\mathsf{Opt}(i - 1, k)\\) 라면 이는 곧\ni 번째 보삭이 포함되지 않았다는 뜻이다 (by Case 1). 따라서\ni 번째 보석을 포함하지 않았다고 기록하고, 다음 보석을 찾기 위해서\n\\(i \\mapsto i - 1\\) 로 진행하면 된다."
					}
					,
					"ps-leetcode-kth-smallest-element-in-a-bst": {
						"id": "ps-leetcode-kth-smallest-element-in-a-bst",
						"title": "Kth Smallest Element in a BST",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/kth-smallest-element-in-a-bst/",
						"content": "Kth Smallest Element in a BST\n\n이진 탐색 트리의 루트 노드와 정수 k가 주어졌을 때, k 번째로 작은\n 값을 찾아라. 이때 k은 1-indexed 기준이다.\n\n트리의 노드 개수와 k는 1~10,000 이다.\n\nBST 탐색\n\n기본적으로 트리는 왼쪽 -&gt; 오른쪽으로 탐색하는데, 루트 노드를 언제\n 방문하느냐에 따라서 다음과 같이 세 가지 탐색 방법이 있다.\n\n  Preorder: 루트 -&gt; 왼쪽 -&gt; 오른쪽\n  Inorder: 왼쪽 -&gt; 루트 -&gt; 오른쪽\n  Postorder: 왼쪽 -&gt; 오른쪽 -&gt; 루트\n\n\n추가로, BST, 즉 이진 탐색 트리라면 모든 서브트리에 대해서 다음 Search\n Property를 만족한다: 어떤 서브트리에 대해서, 서브트리의 왼쪽\n 서브트리의 모든 값은 서브트리의 루트 노드의 값보다 작고, 서브트리의\n 오른쪽 서브트리의 모든 값은 서브트리의 루트 노드의 값보다 크다.\n\n따라서, BST 위에서 Inorder 탐색을 하면, 자연스럽게 오름차순으로\n 노드를 방문하게 된다. 그러므로 우리는 BST를 Inorder로 방문하면서\n 오름차순 배열을 만들 수 있고, 여기서 k번째 원소를 돌려주면 된다.\n\ndef kthSmallest(root, k):\n    arr = []\n    def inorder(node):\n        if node is None:\n            return\n        nonlocal arr\n        inorder(node.left)\n        arr.append(node.val)\n        inorder(node.right)\n\n    inorder(root)\n    return arr[k-1]\n\n\n이때, k가 1-indexed 이므로 0-indexed인 배열에 맞춰 k-1 번째\n 원소를 돌려주면 된다. 이렇게하면 O(N)의 시간 복잡도와 공간 복잡도를\n 갖는다.\n\n\n\n그러면 O(1) 공간 복잡도의 접근도 가능하지 않을까? 방문 순서를 0으로\n 초기화하고, Inorder로 탐색해 나아가면서 루트를 방문할 때마다 방문\n 순서를 1씩 증가시키다가 k와 같아지는 순간 값을 구하면 될 것 같다.\n\ndef kthSmallest(root, k):\n    th, val = 0, None\n    def inorder(node):\n        if node is None:\n            return\n        nonlocal th\n        nonlocal val\n        if th &gt; k:\n            return\n        inorder(node.left)\n        th += 1\n        if th == k:\n            val = node.val\n            return\n        inorder(node.right)\n\n    inorder(root)\n    return val\n\n\nInorder의 정의대로 왼쪽 -&gt; 루트 -&gt; 오른쪽만 잘 지킨다면 올바른 순서로\n k 번째 원소를 찾을 수 있다."
					}
					,
					"ps-leetcode-linked-list-cycle": {
						"id": "ps-leetcode-linked-list-cycle",
						"title": "Linked List Cycle",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/linked-list-cycle/",
						"content": "Linked List Cycle\n\n링크드 리스트의 헤드 노드가 주어졌을 때, 해당 리스트에 싸이클이\n 있는지를 확인하자.\n\n노드 개수는 최대 10000개 이다.\n\n접근 1 - DFS\n\n  DFS 하다가 이전에 방문한 적 있는 노드를 또 방문한 경우 싸이클이다.\n  공간, 시간 복잡도 모두 O(N)\n\n\n\"\"\"\nclass ListNode:\n    def __init__(self, x):\n        self.val = x\n        self.next = None\n\"\"\"\ndef hasCycle(head):\n    if not head:\n        return False\n    stack = []\n    visited = set()\n    stack.append(head)\n    while stack:\n        node = stack.pop()\n        if node in visited:\n            return True\n        visited.add(node)\n        if node.next:\n            stack.append(node.next)\n\n    return False\n\n\n접근 2 - 거북이와 토끼 포인터\n\n  거북이 포인터와 토끼 포인터를 동시에 리스트를 여행할 때, 만약\n싸이클이 있으면 둘은 항상 만나게 된다.\n  공간 복잡도가 O(1)\n\n\ndef hasCycle(head):\n    if not head:\n        return False\n    fast, slow = head, head\n    while fast.next and fast.next.next:\n        fast = fast.next.next\n        slow = slow.next\n        if slow == fast:\n            return True\n    return False"
					}
					,
					"wip-multicore-ocaml-lock-free": {
						"id": "wip-multicore-ocaml-lock-free",
						"title": "An Introduction to Lock-Free Programming",
						"version": "all",
						"categories": "",
						"url": " /wip/multicore-ocaml/lock-free/",
						"content": "source\n\nAn Introduction to Lock-Free Programming\n락 프리 프로그래밍은 그 자체가 복잡하기도 하지만 애초에 이 주제를\n 이해하기조차 힘들기 때문에 아주 도전적이다.\n\nWhat Is It?\n락 프리 프로그래밍을 뮤텍스(락) 없이 프로그래밍하는 거라고 말하는\n 사람들이 있다. 맞는 말이긴 한데, 이건 일부분일 뿐이다. 학계에서\n 일반적으로 동의하는 정의는 좀더 넓다. 본질적으로 락 프리는 어떤\n 코드가 실제로 어떻게 작성됐는지에 대해서 너무 많이 얘기하지 않으면서\n 그 코드를 설명하기 위한 속성이다.\n\n기본적으로 프로그램의 일부분이 다음과 같은 조건을 만족하면, 그 부분은\n 락 프리로 여겨진다. 반대로, 코드의 일부분이 아래 조건을 만족하지\n 못한다면, 그 부분은 락 프리가 아니다.\n\n\n\n요약하면:\n\n  여러 개의 쓰레드 또는 인터럽트 또는 시그널 핸들러가 존재하고,\n  쓰레드끼리 메모리를 공유하고,\n  쓰레드끼리 서로 블록하지 않으면,\n\n\n락 프리이다.\n\n이런 관점에서, 락 프리의 락은 직접적으로 뮤텍스를 가리키는 말이\n 아니라, 전체 어플리케이션을 어떤 방식으로든 “잠궈버리는(locking up)”\n 가능성을 가리킨다. 예를 들어서 데드락, 라이브 락, 또는 최악의 가정\n 하에 어떤 가상의 쓰레드 스케쥴링 때문에 발생했든 상관없다.\n\n뮤텍스가 없고 락 프리가 아닌 단순한 예제 코드는 다음과 같다.\n\nwhile (X == 0)\n{\n  X = 1 - X;\n}\n\n\n커다란 어플리케이션 전체가 락 프리일거라고는 아무도 예상하지\n 않는다. 보통 전체 코드 베이스에서 구체적인 락 프리 연산을\n 확인한다. 예를 들면, 락 프리 큐에서는 push, pop, isEmpty와 같은\n 락 프리 연산이 있을 수 있다.\n\n프로그램이 이런 락 프리 연산을 호출하는 것을 유지하기만 한다면,\n 완료된 호출의 수는 계속 늘어날 것이다.\n\n락 프리 프로그래밍의 중요한 점 중 하나는, 만약 쓰레드 하나를\n 중지하면, 다른 쓰레드가 락 프리 연산을 통해 그룹으로 연산을 계속\n 진행하는 걸 막을 수 없다는 점이다. 그러므로 프로그램의 나머지 상태와\n 관계없이 특정 작업이 특정 시간 제한 이내에 완료되어야 하는 인터럽트\n 핸들러나 실시간 시스템을 작성할 때 락 프리 프로그래밍은 가치 있다.\n\n마지막으로, 블록하도록 디자인된 연산이 락 프리 알고리즘을 깨진\n 않는다. 예를 들어, 큐가 비었을 때 큐의 pop 연산이 의도적으로 블록할\n 수 있다. 나머지 코드 경로는 여전히 락 프리로 여겨진다.\n\nLock-Free Programming Techniques\n락 프리 프로그래밍의 논 블로킹 조건을 만족시킬 수 있는 기술은 다음과\n 같다: 아토믹 연산, 메모리 배리어, ABA 문제 피하기, 등. 여기서부터\n 사악해진다.\n\n이 기술들이 서로 어떤 관계를 가질까? 다음 플로우 차트를 보자.\n\n\n\n\n  RMW(Read-Modify-Write) 인스트럭션\n  메모리 펜스\n  CAS(Compare-and-Swap)와 ABA 문제 피하기\n  (메모리 순서를 강제하기 위한) 메모리 배리어 또는 Acquire and Release semantics\n  volatile 또는 아토믹 타입을 이용한 sequential consistency\n\n\nAtomic Read-Modify-Write Operations\n아토믹 연산이란 나눌 수 없는 방식으로로 메모리를 조작하는\n 연산이다. 어떤 쓰레드도 연산이 반만 완료된 상태를 볼 수 없다. 현대\n 프로세서에서는 많은 연산이 이미 아토믹이다. 예를 들면, 단순 타입의\n 정렬된 읽기와 쓰기은 대부분 아토믹이다.\n\n읽고-수정하고-쓰기 (RMW) 연산은 여기서 한 단계 더 나아가서, 더 복잡한\n 연산을 아토믹하게 수행할 수 있게 해준다. 특히 락 프리 알고리즘이\n 데이터를 쓰는 쓰레드를 여러 개 지원해야 할 때 유용한데, 여러 개의\n 쓰레드가 같은 주소에 대해서 RMW를 시도하려고 하면 이 시도를\n 효과적으로 한 줄로 새워서 한 번에 하나 씩 실행하기 때문이다.\n\nRMW 연산의 예시로는 Win32의 _InterlockedIncrement, iOS의\n OSAtomicAdd32, C++11의 std::atomic&lt;int&gt;fetch_add 등이\n 있다. C++11의 아토믹 표준은 모든 플랫폼에서 락 프리를 보장하지 않기\n 때문에, 사용할 플랫폼과 툴체인이 뭘 지원하는지를 미리 알아두는게\n 좋다. std::atomic&lt;&gt;::is_lock_free로 확인해볼 수도 있다.\n\nCPU 제조사들은 서로 다른 방법으로 RMW를 지원한다. PowerPC나 ARM같은\n 프로세서는\n load-link/store-conditional\n 인스트럭션을 제공하는데, 저수준에서 직접 RMW 프리미티브 연산을 구현할\n 수 있는 효과적인 방법이다.\n\n위의 플로우 차트에서 보듯이, 싱글 프로세서 시스템에서 조차 아토믹\n RMW은 락 프리 프로그래밍을 위해서 필요한 부분이다. 아토믹 연산이\n 없다면, 쓰레드는 트랜잭션 도중에 인터럽트 되어 일관되지 않은 상태가\n 될 수 있다.\n\nCompare-And-Swap Loops\n아마 가장 자주 논의되는 RMW 연산은 CAS 연산일 것이다. Win32에서 CAS는\n _InterlockedCompareExchange 같은 인트린직 연산으로 제공된다. 종종\n 프로그래머는 반복적으로 트랜잭션을 시도하는 루프로 CAS를\n 수행한다. 이런 패턴은 보통 공유 변수에서 지역 변수로 값을 복사한\n 다음, 뭔가 투기적인 작업을 하고, CAS를 이용해 최종 변화를 덮어쓰려는\n 시도를 한다.\n\nvoid LockFreeQueue::push(Node* newHead)\n{\n  for (;;)\n  {\n    // Copy a shared variable (m_Head) to a local.\n    Node* oldHead = m_Head;\n\n    // Do some speculative work, not yet visible to other threads.\n    newHead-&gt;next = oldHead;\n\n    // Next, attempt to publish our changes to the shared variable.\n    // If the shared variable hasn't changed, the CAS succeeds and we return.\n    // Otherwise, repeat.\n    if (_InterlockedCompareExchange(&amp;m_Head, newHead, oldHead) == oldHead)\n      return;\n  }\n}\n\n\n하나의 쓰레드가 테스트에 실패한다면 다른 쓰레드는 반드시 성공해야\n 한다는 것을 뜻하기 때문에, 이런 루프는 여전히 락 프리 성질을\n 만족한다. 하지만 몇몇 아키텍쳐에서는 좀더 약간 CAS의 변형을\n 제공하기도 하는데 이 경우는 반드시 만족하진 않는다. CAS 루프를 구현할\n 때에는 항상 ABA 문제를\n 피하기 위해서 주의를 기울여야 한다.\n\nSequential Consistency\n순차적 일관성(Sequential consistency)이란 메모리 연산이 어떤 순서로\n 발생해야 하는지에 대해서 모든 쓰레드가 동의하고 그 순서가 프로그램의\n 소스 코드에 적힌 연산의 순서와도 일관된다는 것을 뜻한다. 순차적\n 일관성 하에서는 메모리 연산 순서가 뒤바뀌는 속임수는 불가능하다.\n\n순차적 일관성을 얻기 위한 간단(하지만 명백히 비현실적인)한 방법은\n 모든 컴파일러 최적화를 꺼버리고 모든 쓰레드가 싱글 쓰레드에서만\n 동작하도록 강제하는 것이다. 프로세서는 어떤 쓰레드가 선점되어서\n 임의의 시간에 스케쥴링 된다 하더라도 절대로 메모리 연산 순서가 꼬이는\n 것을 볼 수 없다.\n\n몇몇 프로그래밍 언어는 멀티 프로세서 환경에서 동작하는 최적화된\n 코드에 대해서도 순차적 일관성을 제공한다. C++11에서는 모든 공유\n 변수를 디폴트 메모리 오더링 제약을 갖는 C++11 아토믹 타입으로\n 선언하면 된다. 자바에서는 모든 공유 변수를 volatile로 선언하면\n 된다.\n\nstd::atomic&lt;int&gt; X(0), Y(0);\nint r1, r2;\n\nvoid thread1()\n{\n  X.store(1);\n  r1 = Y.load();\n}\n\nvoid thread2()\n{\n  Y.store(1);\n  r2 = X.load();\n}\n\n\nC++11 아토믹 타입이 순차적 일관성을 보장하기 때문에, r1 = r2 = 0은\n 불가능하다. 이걸 위해서 컴파일러는 눈에 보이지 않는 추가적인 명령어를\n 끼워넣는데, 보통 메모리 펜스와/또는 RMW 연산이다. 이런 추가적인\n 명령어는 프로그래머가 직접 메모리 오더링을 관리하는 것과 비교해서\n 구현의 성능을 떨어뜨릴 수 있다.\n\nMemory Ordering\n플로우차트에서 보듯이, 멀티코어에서 락 프리 프로그래밍을 할 때마다,\n 그리고 순차적 일관성을 보장하지 않는다면, 메모리 순서가 바뀌는 것을\n 막는 방법을 고려해야만 한다.\n\n현대 아키텍쳐에서, 올바른 메모리 오더링을 강제하기 위한 도구는 보통\n 세 가지 종류로 나뉜다. 이 방법은 컴파일러 리오더링과 프로세서\n 리오더링을 모두 막는다.\n\n\n  가벼운 동기화 또는 펜스 인스트럭션\n  전체 메모리 펜스 인스트럭션\n  acquire/release 시맨틱을 제공하는 메모리 연산\n\n\nAcquire 시맨틱은 프로그램에 순서 뒤에 오는 연산의 메모리 리오더링을\n 막고, release 시맨틱은 순서 앞에 오는 메모리 리오더링을 막는다. 이\n 시맨틱은 하나의 쓰레드가 어떤 정보를 생산하고 다른 여러 쓰레드가\n 이것을 읽는 생산자/소비자 관계에서 특히 적절하다.\n\nDifferent Processors Have Different Memory Models\n서로 다른 CPU는 메모리 리오더링과 관련해서 서로 다른 행동을 한다. 그\n 규칙은 CPU 벤더가 문서화 해두었고 하드웨어가 엄격하게 지킨다. 예를\n 들면 PowerPC와 ARM 프로세서는 명령어 자체와 관련된 메모리 저장(store)\n 연산의 순서를 바꿀 수 있지만, 일반적으로 인텔 및 AMD의 x86/64\n 프로세서 제품군은 그렇지 않다. 전자를 좀더 너그러운 메모리\n 모델을\n 갖고 있다고 말한다.\n\n특히 C++11가 제공하는 포터블한 락 프리 코드를 작성할 수 있게 해주는\n 표준적인 방식처럼, 이런 플랫품 특화 디테일을 추상화해버리고 싶은\n 유혹이 있을 것이다. 하지만 현재, 대부분의 락 프리 프로그래머는 플랫폼\n 별로 차이가 있다는 사실에 약간 감사하고 있는 것 같다. 한 가지 핵심\n 차이점은, x86/64 인스트럭션 레벨에서, 메모리에서 값을 읽는(load) 모든\n 연산은 acquire 시맨틱을 갖고, 모든 저장(store) 연산은 release\n 시맨틱을 갖는다는 것이다. 최소한 SSE가 아닌 인스트럭션과\n non-write-combined 메모리에 한해서는 그렇다. 결과적으로, 과거에는\n x86/64에서는 잘 동작하지만 다른 프로세서에서는 그렇지 못한 락 프리\n 코드가 작성되는 것이 일반적이었다."
					}
					,
					"ps-leetcode-longest-common-subsequence": {
						"id": "ps-leetcode-longest-common-subsequence",
						"title": "Longest Common Subsequence",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/longest-common-subsequence/",
						"content": "Longest Common Subsequence\n\n두 문자열 text1과 text2가 주어졌을 때, 공통 부분열(common\n subsequence) 중 가장 길이가 긴 것의 길이를 구하자. 공통 부분열이\n 없다면 0을 리턴하자.\n\n어떤 문자열의 부분열(subsequence)이란 원래 문자열이 담고 있는\n 글자들 사이의 순서를 바꾸지 않고 0개 이상의 글자를 삭제해서 얻을 수\n 있는 문자열을 뜻한다. 예를 들어 “ace”는 “abcde”의 부분열이다.\n\n두 문자열의 공통 부분열(common subsequence)이란 양쪽 문자열에\n 모두 존재하는 부분열이다.\n\n두 문자열의 길이는 최대 1,000이고 모두 소문자 알파벳만을 담고 있다.\n\n아아 다이나믹 프로그래밍이여\n\n아주 유명한 다이나믹 프로그래밍 문제이다. 여기서 파생되는 문제가 꽤\n 있는 편이라서, 최장길이 공통 부분열 또는 LCS 문제는 필수적으로 짚고\n 넘어가야 한다. 또 현실 세계의 문제에서도 LCS가 응용되는 곳이\n 많다. 예를 들면 diff도 결국 두 문자열 중에서 다른 부분열을 찾는\n 것이기 때문에 이 방법을 응용할 수 있다. 그리고 가장 유명한 것은 역시\n 유전체 분석이다. 염기 서열을 일종의 문자열로 볼 수 있기 때문에 특히\n 문자열과 관련된 알고리즘에 대한 연구는 끊임없이 이뤄지고 있다.\n\n아무튼 어떻게 접근할지 차근차근 살펴보자. 일단 다이나믹\n 프로그래밍에는 두 가지 방법이 있는데, 하나는 탑 다운 방식의 재귀적인\n 접근이고 다른 하나는 바텀 업 방식의 (미리) 반복문으로 계산하는\n 접근이다.\n\n탑 다운 - 1\n\n일단 탑 다운 접근을 먼저 고민해보자. 보통 재귀적인 점화식을 쉽게\n 생각해낼 수 있고, 문제의 사이즈가 부분 문제를 다 풀어야 하는 경우 탑\n 다운이 방식의 구현이 직관적이고 이해하기 쉽다.\n\n일단 이 문제를 부분 문제로 쪼개보자.\n\ntext1에서 text2에도 있는 글자 c를 골랐을 때, 가능한 경우는 두\n 가지이다: (1) 이 글자가 최적해에 들어있거나, (2) 이 글자가 최적해에\n 없거나. c가 최적해에 포함된다면, 나머지 부분열은 두 문자열에서 c\n 이후에 있는 부분 문자열에서 골라야 하고, 그렇게 구한 길이에서\n c만큼의 길이 1을 더한 값이 원하는 값이다. 만약 최적해에 포함되지\n 않는다면, 이 말은 곧 이 글자를 무시하고 나머지 전체를 부분 문제로\n 생각해야 한다.\n\n문제는 이 둘 중 어떤 게 올바른 방향인지를 모른다는 거다. 그러므로\n 우리는 두 경우 다 고려해야 한다.\n\n그러면 위의 케이스를 생각하면서 알고리즘을 구성해보자. 두 문자열의\n LCS 길이를 구하는 함수 LCS(text1, text2)는 다음과 같이 동작한다.\n\n  일단 베이스 케이스. 둘 문자열 중 하나라도 빈 문자열이면 자연히\n답은 0이다.\n  text1의 첫번째 글자 letter1을 뽑는다.\n  letter1이 text2에서 처음으로 나타나는 위치를 찾는다. 이를\nfirst_occur라고 하자.\n  앞서 두 가지 경우를 모두 고려해서 후보를 각각 구한다:\n    \n      first_occur 위치가 최적해에 포함되는 경우를 구한다. 즉, 1 +\nLCS(text1[1:], text2[first_occur+1:])이다. 1은 letter1의\n길이이다. letter1을 포함했기 때문에, 나머지 부분 문자열은\n각각 text1[1:]과 text2[first_occur+1:]이 된다.\n      first_occur 위치가 최적해에 포함되지 않는 경우를 구한다. 이는\n단순히 LCS(text1[1:], text2)가 된다. letter1이 포함되지\n않고, text2에서 이 글자가 나타난 위치를 무시하면 된다.\n    \n  \n  이렇게 구한 두 후보 값 중 최대 값을 리턴한다.\n\n\n이 알고리즘에서 빠진 부분은 letter1이 text2에 없으면 어떻게\n 해야할지 이다. 이 경우는 그냥 더 탐색할 부분 문제가 없는 것이기\n 때문에, 그냥 무시하면 된다.\n\n따라서 이 알고리즘을 구현하고, 추가로 탑 다운 방식의 다이나믹\n 프로그래밍, 즉 메모이제이션까지 적용한 코드는 다음과 같다.\n\nimport functools\ndef longestCommonSubsequence(text1, text2):\n    @functools.cache\n    def lcs(text1, text2):\n        # base case) empty\n        if not text1 or not text2:\n            return 0\n\n        # case 1) include text1[0]\n        first_occur = text2.find(text1[0])\n        cand1 = 0\n        if first_occur != -1:\n            cand1 = 1 + lcs(text1[1:], text2[first_occur + 1:])\n\n        # case 2) not include text1[0]\n        cand2 = lcs(text1[1:], text2)\n\n        # get best\n        return max(cand1, cand2)\n    return lcs(text1, text2)\n\n\n잘 동작한다. 하지만, 매번 부분 문자열을 복사해서 넘기기 때문에,\n 여기서 생기는 오버헤드가 엄청나다. 어차피 입력 문자열이 바뀌는 것이\n 아니기 때문에, 문자열을 파라미터로 직접 넘기기 보다는 문자열 안의\n 인덱스만 계산하면 더 빠르게 할 수 있을 것 같다. 이 부분을 개선하면\n 다음과 같다.\n\ndef longestCommonSubsequence(text1, text2):\n    @functools.cache\n    def lcs(i1, i2):\n        # base case) empty\n        if i1 == len(text1) or i2 == len(text2):\n            return 0\n\n        # case 1) include text1[i1], from i2\n        first_occur = text2.find(text1[i1], i2)\n        cand1 = 0\n        if first_occur != -1:\n            cand1 = 1 + lcs(i1 + 1, first_occur + 1)\n\n        # case 2) not include text1[i1]\n        cand2 = lcs(i1 + 1, i2)\n\n        # get best\n        return max(cand1, cand2)\n    return lcs(0, 0)\n\n\n여기서 i1의 의미는 명확한데, i2의 의미를 곱씹어 볼 필요가\n 있다. i2는 first_occur를 찾을 때, 즉 text1[i1]이 text2에서\n 처음으로 나타난 위치를 찾을 때 기준점 역할을 한다. 앞서 문자열을\n 통째로 넘길 때에는 이 부분이 항상 부분 문자열로 넘어갔지만, 인덱스만\n 유지하는 경우는 text2에서 text1[i1] 글자를 찾을 때 어디서부터\n 찾아야 할지, 즉 어떤 부분 문자열에서 찾아야 할지를 가이드하는 역할을\n 해야 올바른 정답을 찾을 수 있다.\n\n이렇게하면 시간 복잡도는 O(M * N^2)이 된다. M은 text1의\n 길이이고 N은 text2의 길이이다.\n\n탑 다운 - 2\n\n좀더 개선된 탑 다운 방식을 고민해보자.\n\n전체적인 접근은 1번 방법과 유사하지만, 부분 문제를 쪼개는 방식을 조금\n 달리하면 개선의 여지가 있다.\n\n첫 번째 글자가 같다면, 이 글자를 최적해에 포함시킬 수\n 있다. 따라서, LCS는 1 + LCS(p1 + 1, p2 + 2)이 된다. 왜냐하면 두\n 글자가 이미 같다면, 이를 최적해에서 제외시킬 이유가 없기 때문이다.\n\n두 문자열의 첫 번째 글자가 다르면, 두 글자 중 하나 또는 둘 다가\n 최적해에 포함되지 않을 것이다. 따라서, LCS는 max(LCS(p1 + 1, p2),\n LCS(p1, p2 + 1))이 된다.\n\ndef longestCommonSubsequence(text1, text2):\n    @functools.cache\n    def lcs(i1, i2):\n        if i1 == len(text1) or i2 == len(text2):\n            return 0\n\n        if text1[i1] == text2[i2]:\n            # case 1) first letters are the same\n            return 1 + lcs(i1 + 1, i2 + 1)\n        else:\n            # case 2) first letters are not the same\n            return max(lcs(i1 + 1, i2), lcs(i1, i2 + 1))\n    return lcs(0, 0)\n\n\n시간 복잡도는 O(M*N)이 된다. 각각의 부분 문제를 푸는 데에는 상수\n 시간 O(1)이 든다. 더 이상 text2에서 검색하지 않기 때문이다. 부분\n 문제의 개수는 M * N 만큼이 있기 때문에 이 복잡도를 얻는다.\n\n1, 2 모두 공간 복잡도는 O(M * N)이다."
					}
					,
					"ps-leetcode-longest-consecutive-sequence": {
						"id": "ps-leetcode-longest-consecutive-sequence",
						"title": "Longest Consecutive Sequence.",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/longest-consecutive-sequence/",
						"content": "Longest Consecutive Sequence\n정렬되지 않은 정수 배열 nums 에 대해서, 연속되는 원소 시퀀스의 가장\n 긴 길이를 구해라.\n\n알고리즘의 시간 복잡도는 반드시 O(N)이어야 한다.\n\n배열의 길이는 0 ~ 100,000 이고 각 원소의 범위는 \\(-10^9 \\sim\n 10^9\\)이다.\n\n[100, 4, 200, 1, 3, 2] -&gt; 4\n[0, 3, 7, 2, 5, 8, 4, 6, 0, 1] -&gt; 9\n\n\n정렬\n일단 문제에서부터 ‘정렬 안된’, ‘연속된’ 키워드가 있기 때문에, 가장\n 쉬운 접근은 정렬이다. 이때 “연속되는 원소 시퀀스”는 중복이 없는\n 시퀀스이지만, 실제 배열에는 중복이 있을 수도 있음을 주의하자.\n\ndef lognest_consecutive(nums):\n    if not nums:\n        return 0\n\n    nums.sort()\n    answer, cur = 1, 1\n\n    for i in range(1, len(nums)):\n        if nums[i-1] == nums[i]:\n            continue\n\n        if nums[i-1] + 1 == nums[i]:\n            cur += 1\n        else:\n            answer = max(answer, cur)\n            cur = 1\n\n    return max(answer, cur)\n\n\n  연속되는걸 알려면 원소가 적어도 하나는 있어야 되므로, 길이가 0인\n경우를 미리 잘라준다.\n  nums[i-1] == nums[i] 인 경우는 스킵한다.\n  연속되는 경우는 cur 늘려서 현재 길이를 계산해주고, 연속이 끊기게\n되는 순간 max를 구해서 업데이트하고 동시에 현재 길이를 1로\n리셋한다.\n  루프가 끝나고 마지막 리턴하기 전에 max를 한번 더 구해줘야\n한다. 마지막 계산한 cur가 아직 업데이트 되지 않았을 수 있기\n때문이다.\n\n\n이렇게 하면 정렬해야 하니까 O(n*logn)의 복잡도를 갖는다.\n\n해시셋\n더 빠르게는 못할까? 좀 생각해보면 “연속된”의 정의를 활용하면,\n 해시셋을 가지고 뭔가 해볼 수 있을 것 같다. 일단 정렬하지 말고 숫자를\n 전부 해시셋에 넣는다. 그러면 중복도 사라지고 어떤 값이 있는지\n 없는지를 O(1)만에 판단할 수 있다.\n\n이 해시셋의 원소를 돌면서, 만약 어떤 원소보다 1 작은 원소가\n 없다면, 해당 원소가 어떤 연속되는 시퀀스의 시작점이라는\n 사실을 알 수 있다. 그러면, 그 원소로부터 출발해서 1씩 늘려가면서\n 연속되는 시퀀스가 가능한지 해시셋에 쿼리를 날리면서 최대를 누적하면\n 된다.\n\n아이디어는 간단하다. 다음과 같이 구현할 수 있다.\n\ndef longest_consecutive(nums):\n    numset = set(nums)\n    answer = 0\n\n    for n in numset:\n        if (n-1) in numset:\n            continue\n        start, end = n, n\n        while end in numset:\n            end += 1\n        answer = max(answer, end - start)\n    return answer\n\n\n  말한대로 (n-1)이 해시셋에 없으면 n부터 시작하는 시퀀스가 존재할\n수도 있다. n은 그 자체로 이미 길이 1의 시퀀스이므로 이를 잘\n고려해서 해시셋 전체를 다시 확인하면 된다.\n  시작점, 즉 (n-1)이 셋에 없는 n을 찾을 때, n을 원래 배열\nnums에서 꺼내오면 중복이 있을 수 있어서 느릴수 있다. 따라서\n여기서는 numset에서 꺼내오도록 한다.\n\n\n이러면 최대 2번 해시셋 전체를 순회하게 되므로 복잡도는 O(n)으로 확\n 떨어진다."
					}
					,
					"ps-leetcode-longest-cycle-in-a-graph": {
						"id": "ps-leetcode-longest-cycle-in-a-graph",
						"title": "Longest Cycle In A Graph",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/longest-cycle-in-a-graph/",
						"content": "Longest Cycle In A Graph\n코사라주 알고리즘 (Kosaraju&#8217;s Algorithm)\ndef longestCycle(edges: List[int]) -&gt; int:\n    graph, tgraph = defaultdict(set), defaultdict(set)\n    for src, snk in enumerate(edges):\n        if snk == -1: continue\n        graph[src].add(snk)\n        tgraph[snk].add(src)\n\n    # first dfs\n    visited = set()\n    stack = []\n    def dfs(node):\n        visited.add(node)\n        for succ in graph[src]:\n            if succ in visited: continue\n            dfs(succ)\n        stack.append(succ)\n\n    for node in range(len(edges)):\n        if node in visited: continue\n        dfs(node)\n\n    # second dfs\n    visited.clear()\n    scc, path = [], []\n    def tdfs(node):\n        visited.add(node)\n        path.append(node)\n        for succ in tgraph[node]:\n            if succ in visited: continue\n            tdfs(succ)\n\n    while stack:\n        node = stack.pop()\n        if node in visited: continue\n        path.clear()\n        tdfs(node)\n        scc.append(path[:])\n\n    scc_lengths = [len(c) for c in scc if len(c) != 1]\n    return max(scc_lengths) if scc_lengths else -1\n\n타잔 알고리즘 (Tarjan&#8217;s Algorithm)\ndef longestCycle(edges: List[int]) -&gt; int:\n    graph = defaultdict(set)\n    for src, snk in enumerate(edges):\n        if snk == -1: continue\n        graph[src].add(snk)\n\n    ranks, low_links = {}, {}\n    scc, path = [], []\n    rank = 0\n    def dfs(node):\n        nonlocal rank\n        ranks[node] = rank\n        low_links[node] = rank\n        path.append(node)\n        rank += 1\n\n        for succ in graph[node]:\n            if succ not in ranks:\n                dfs(succ)\n                low_links[node] = min(low_links[node], low_links[succ])\n            elif succ in path:\n                low_links[node] = min(low_links[node], ranks[succ])\n\n        if low_links[node] == ranks[node]:  # cycle\n            c = []\n            while True:\n                top = path.pop()\n                c.append(pop)\n                if top == node: break\n            scc.append(c)\n\n    for node in range(len(edges)):\n        if node in ranks: continue\n        dfs(node)\n\n    scc_lengths = [len(c) for c in scc if len(c) != 1]\n    return max(scc_lengths) if scc_lengths else -1\n\n칸의 알고리즘 (Kahn&#8217;s Algorithm) 활용\ndef longestCycle(edges: List[int]) -&gt; int:\n    indegree = Counter()\n    for snk in edges:\n        if snk == -1: continue\n        indegree[snk] += 1\n\n    q = deque()\n    for node in range(len(edges)):\n        if indegree[node] == 0:\n            q.append(node)\n\n    visited = set()\n    while q:\n        node = q.popleft()\n        visited.add(node)\n        succ = edges[node]\n        if succ == -1: continue\n        indegree[succ] -= 1\n        if indegree[succ] == 0:\n            q.append(succ)\n\n    answer = -1\n    for node in range(len(edges)):\n        if node in visited: continue\n        succ = edges[node]\n        size = 1\n        visited.add(node)\n        while succ != node:\n            visited.add(succ)\n            size += 1\n            succ = edges[succ]\n        answer = max(answer, size)\n\n    return answer"
					}
					,
					"ps-leetcode-longest-increasing-subsequence": {
						"id": "ps-leetcode-longest-increasing-subsequence",
						"title": "Longest Increasing Subsequence",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/longest-increasing-subsequence/",
						"content": "Longest Increasing Subsequence\n\n정수 배열 nums가 주어질 때, 가장 길이가 긴 증가 부분 수열의 길이를\n 리턴하자.\n\n부분 수열(subsequence)이란 배열의 원소 순서는 바꾸지 않은 채로\n 0개 이상의 원소를 삭제해서 얻을 수 있는 수열이다. 예를 들어,\n [3,6,2,7]은 [0,3,1,6,2,2,7]의 부분 수열이다.\n\n부분 수열 만들면서 구하기\n\n이 문제는 다이나믹 프로그래밍으로 풀어도 되지만, 최적해를 구하는\n 최적(O(nlogn))의 방법이 알려져있다. 최적 방법을 설명하기 위해서\n 먼저 최적이 아닌 O(N^2) 방법을 설명한다.\n\n그 방법은 문제 조건을 만족하는 부분 수열, 즉 증가하는 부분 수열을\n 직접 만들어가는 방법이다.\n\n\n  배열의 첫 번째 원소만 담은 부분 수열 sub를 초기화한다.\n  배열의 두 번째 원소부터 훑으면서:\n    \n      만약 원소가 sub의 마지막 원소보다 크다면 (증가), sub의 끝에\n넣는다.\n      그렇지 않으면, sub를 돌면서 원소보다 크거나 같은 첫 원소를\n찾아서 지금 원소와 바꾼다.\n    \n  \n  sub의 길이를 구한다.\n\n\ndef lengthOfLIS(nums):\n    sub = [nums[0]]\n\n    for n in nums[1:]:\n        if n &gt; sub[-1]:\n            sub.append(n)\n        else: # Find the first element in sub that is greater than or equal to n\n            i = 0\n            while n &gt; sub[i]:\n                i += 1\n            sub[i] = n\n    return len(sub)\n\n\n참고로 이 알고리즘은 최장 부분 증가 수열의 길이는 제대로 구하지만\n 실제 부분 수열은 제대로 못구한다. 예를 들어 입력이\n [3,4,5,1]이면, 마지막 sub는 [1,4,5]가 되지만, 길이는 올바른데,\n 왜냐면 새 원소가 부분 수열의 모든 원소보다 클 때에만 길이가 변하기\n 때문이다.\n\n부분 수열 좀더 잘 만들기\n\n이제 O(nlogn)의 알고리즘을 소개하겠다. 위의 방법에서 n이 증가하지\n 않을 때 부분 수열 위치를 찾을 때 선형 탐색을 했는데, 이 부분을 좀더\n 잘 해서 logn으로 떨어뜨릴 수 있다. 바로 이분 탐색을 이용하는\n 것이다.\n\ndef lengthOfLIS(nums):\n    sub = []\n    for n in nums:\n        i = bisect.bisect_left(sub, n)\n        if i == len(sub):\n            sub.append(n)\n        else:\n            sub[i] = n\n\n    return len(sub)\n\n\n참고로 이 알고리즘도 부분 수열의 길이만 제대로 구할 수 있다."
					}
					,
					"ps-leetcode-longest-palindrome-by-concatenating-two-letter-words": {
						"id": "ps-leetcode-longest-palindrome-by-concatenating-two-letter-words",
						"title": "Longest Palindrome by Concatenating Two Letter Words",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/longest-palindrome-by-concatenating-two-letter-words/",
						"content": "Longest Palindrome by Concatenating Two Letter Words\n\n두 글자로 이뤄진 단어 목록 words가 주어진다.\n\n이 단어 목록에서 단어를 골라서 이어붙였을 때 만들 수 있는 가장 긴\n 팰린드롬의 길이를 구하자. 각각의 단어는 최대 한번 사용될 수\n 있다.\n\n\n  단어 목록의 크기는 1~100,000\n  각 단어는 항상 두 글자임이 보장되고 소문자 알파벳만 포함한다.\n\n\n정직한 접근\n\n  두 종류의 단어가 중요하다.\n    \n      같은 글자로만 이뤄진 단어: aa, bb와 같은 것들. 얘네는\n팰린드롬의 중간에도 올 수 있고, 짝수 개인 경우 양 옆에도 붙일 수\n있다.\n      단어와 거꾸로된 단어의 쌍: (lr, rl)과 같은 쌍들. 얘네는 양 끝에\n하나씩 이어붙여서 팰린드롬을 만들 수 있다. 길이만 구하면 되므로\n순서는 상관없다.\n    \n  \n  일단 두 종류의 단어 개수를 따로 센다. 각각 same, pair라고 하자.\n  same의 개수 중 홀수인 친구는 그 중 하나를 빼서 팰린드롬의\n중간으로 쓸 수 있다.\n  나머지 same은 짝수 개 만큼만 써서 팰린드롬을 만들 수 있다.\n  pair는 만드는 방법에 따라 만약 lr과 rl이 둘 다 들어있다면,\n그리고 짝이 맞을 때에만 갯수를 세었다면, 그냥 pair의 개수 곱하기\n글자 수(= 2) 만큼 더하면 된다.\n\n\ndef longestPalindrome(words):\n    word_counts = Counter(words)\n    same, pair = Counter(), Counter()\n    for word in words:\n        rev = word[::-1]\n        if word[0] == word[1]:\n            same[word] += 1\n        elif word_counts[rev] and word_counts[word]:\n            pair[word] += 1\n            pair[rev] += 1\n            word_counts[word] -= 1\n            word_counts[rev] -= 1\n\n    answer = 0\n    for word in same:\n        if same[word] % 2 == 1:\n            answer = 2\n            same[word] -= 1\n            break\n    for word in same:\n        cnt = same[word]\n        answer += (cnt * 2 if cnt % 2 == 0 else (cnt - 1) * 2)\n    for word in pair:\n        answer += pair[word] * 2\n    return answer\n\n\n좀더 나은 접근\n\n  Counter로 단어 개수를 세었기 때문에 직접 이 갯수를 훑는게 더\n효율적이다. words보다 크기가 작을 것이기 때문이다.\n  단지 중간에 올 수 있는 단어가 있는지만을 확인하기 위해서 루프를\n돌리기 보다는 한 번에 할 수 있으면 좋겠다. 따라서, 홀수인 경우에는\n플래그를 하나 세워두면서 값을 하나 깐 다음, 마지막에 플래그를\n확인하고 더할 수 있다.\n  단어 목록이든 Counter든, 항상 같은 순서로 단어를 확인하도록\n강제할 수 있다. 예를 들어, 단어는 항상 두 글자이므로 word[0] &lt;\nword[1] (또는 word[0] &gt; word[1]) 인 경우에만 팰린드롬인 경우를\n확인한다고 하자. 그러면 자연스럽게 앞의 pair 경우를 한 번만\n확인해도 된다.\n  순서가 강제되어서 pair를 확인할 때에는, pair를 이루는 두 단어의\n개수 중 더 적은 쪽의 개수가 팰린드롬의 크기를 결정한다.\n\n\ndef longestPalindrome(words):\n    word_counts = Counter(words)\n    answer = 0\n    has_center = False\n\n    for word, count in word_counts.items():\n        if word[0] == word[1]:\n            answer += ((count - 1) * 2 if count % 2 else count * 2)\n            if count % 2 == 1: has_center = True\n        elif word[0] &lt; word[1]:\n            pair = word[1] + word[0]\n            answer += 4 * min(count, word_counts[pair])\n    return (answer + 2) if has_center else answer"
					}
					,
					"ps-leetcode-longest-palindromic-substring": {
						"id": "ps-leetcode-longest-palindromic-substring",
						"title": "Longest Palindromic Substring",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/longest-palindromic-substring/",
						"content": "Longest Palindromic Substring\n\n주어진 단어에서 가장 긴 팰린드롬 부분문자열을 구하자.\n\n단어의 길이는 1~1,000 사이이고 알파벳 소문자와 숫자만 담고 있다.\n\n접근 - 중심부에서 세기\n\n  가장 긴 팰린드롬을 찾아야 한다.\n  인덱스 i를 중심으로 가장 긴 팰린드롬의 길이를 찾는 함수 O(N),\n이를 모든 글자에 대해서 해봐야 하므로 O(N^2) 복잡도가 든다.\n  중심이 되는 글자는 한 글자와 두 글자 모두 가능한 것을 주의하자.\n  중심부에서 팰린드롬 범위를 세는 함수의 while 루프가 끝나는\n순간의 left, right는 팰린드롬 인덱스 범위를 하나 씩\n벗어나있음에 주의하자.\n  정답 범위의 초기 값에 주의하자. 빈 문자열을 나타내기 위해서 [0,\n-1]과 같은 조금 비 직관적인 값을 줘야 한다. 그래야 문자열 길이\n계산 공식에 따라 -1 - 0 + 1 = 0이 된다.\n\n\ndef lognestPalindrome(s):\n    def palindrome_range(left, right):\n        while left &gt;= 0 and right &lt; len(s) and s[left] == s[right]:\n            left -= 1\n            right += 1\n        return (left + 1, right - 1)\n\n    answer_start, answer_end = 0, -1\n    for i in range(len(s)):\n        start, end = palindrome_range(i, i)\n        if (answer_end - answer_start + 1) &lt; (end - start + 1):\n            answer_start, answer_end = start, end\n        start, end = palindrome_range(i, i+1)\n        if (answer_end - answer_start + 1) &lt; (end - start + 1):\n            answer_start, answer_end = start, end\n\n    return s[answer_start:answer_end+1]"
					}
					,
					"ps-leetcode-longest-repeating-character-replacement": {
						"id": "ps-leetcode-longest-repeating-character-replacement",
						"title": "Longest Repeating Character Replacement",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/longest-repeating-character-replacement/",
						"content": "Longest Repeating Character Replacement\n\n문자열 s와 정수 k가 주어진다. 문자열은 모두 알파벳 대문자로만\n 이뤄져 있다. 문자열에서 아무 글자나 하나 골라서 다른 대문자로 바꾸는\n 연산을 최대 k번 할 수 있다.\n\n이때, 위의 연산을 통해 얻을 수 있는 같은 글자만으로 이뤄지는 부분\n 문자열 중에서 가장 긴 것의 길이를 구하자.\n\n문자열의 길이는 1 ~ 100,000 사이이고 \\(0 \\leq k \\leq s.length\\)이다.\n\n예를 들어 s = \"ABAB\" 이고 k = 2 일 때, A를 B로 바꾸는 연산을\n 두 번 하면 B로만 이뤄진 최장 부분 문자열 \"BBBB\"를 얻을 수 있고\n 길이는 4이다.\n\n직관으로 이해가 잘 안되지만 아무튼 되는 솔루션\n\n타이틀 그대로 직관으로는 잘 이해가 안되지만 아무튼 되는 솔루션을\n 설명해보겠다.\n\n일단 조건인 k가 없을 때, 최소의 횟수로 글자를 다른 글자로\n 바꿔서 같은 글자로만 이뤄진 문자열을 만들려고 해보자. 최소인 이유는\n 나중에 조건 k가 추가되는 것을 염두에 둔 것이다. 아무튼 이때의 최소\n 횟수 다음과 같을 것이다: 전체 문자열의 길이 - *가장 많이 나타나는*\n 글자의 수. 여기에 k 조건이 추가된다면, 우리는 다음 불변식을\n 만족하는 슬라이딩 윈도우를 움직이면서 답을 찾을 수 있다: (부분\n 문자열의 길이 - 해당 부분 문자열에서 *가장 많이 나타나는* 글자의 수)\n &lt;= k.\n\n이 아이디어를 구현하면 다음과 같다.\n\nfrom collections import Counter\ndef characterReplacement(s, k):\n    count = Counter()\n    start = 0\n    maxlen, maxcnt = 0, 0\n    for end in range(len(s)):\n        count[s[end]] += 1\n        maxcnt = max(maxcnt, count[s[end]])\n        while (end - start + 1 - maxcnt) &gt; k:\n            count[s[start]] -= 1\n            start += 1\n        maxlen = max(maxlen, end - start + 1)\n    return maxlen\n\n\n\n  여타 다른 문제들 처럼 Counter로 곧바로 글자 수를 세면\n안된다. 조건에 맞는 부분 문자열을 구해야 하므로 윈도우가 커질 때\n(end 포인터가 커질 때) 하나 씩 증가되야 한다.\n  현재 부분 문자열에서 가장 많이 나타나는 글자의 수를 구하기 위해서\n특별하게 뭔가 할 필요는 없다. end 포인터가 이동하면서 count에\n글자 수를 하나 씩 추가하고, 이 값을 이전의 최대 글자수와 비교하기만\n하면 된다. start 포인터가 이동하면서 윈도우가 줄어들 때 부분\n문자열 안의 글자 수 count도 업데이트 (글자수가 빠짐) 되기 때문에\n올바른 값이 들어간다.\n  앞에서 설명했듯 end - start + 1 - maxcnt 값이 곧 “현재 부분\n문자열을 모두 같은 글자로 바꾸기 위해 필요한 바꾸기 연산의 최소의\n횟수”이고 이 값이 k보다 큰 경우에만 start 포인터를 움직여서\n(=윈도우를 줄여서) 탐색할 수 있다.\n  이 알고리즘은 길이를 구할 순 있지만 연산을 적용할 부분\n문자열의 위치는 올바르게 구하지 못한다. 예를 들어 CCCCCXXX와\nk=2에서, end가 마지막에 도달했을 때 최종적으로 구하게 되는 부분\n문자열은 CCCCXXX이 되는데, 이는 2번 이상 수정해야 하는 것이지만,\n우리는 길이만 원하기 때문에 크게 문제되진 않는다."
					}
					,
					"ps-leetcode-longest-string-chain": {
						"id": "ps-leetcode-longest-string-chain",
						"title": "Longest String Chain",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/longest-string-chain/",
						"content": "Longest String Chain\n\n알파벳 소문자로만 이뤄진 단어 목록 words가 주어진다.\n\n단어 word_a의 어떤 위치든 딱 한 글자만 추가하고 다른 단어의\n 순서를 바꾸지 않으면서 word_b를 만들 수 있으면, word_a는\n word_b의 predecessor라고 한다. 예를 들면, “abc”는 “abac”의\n predecessor이지만 “cba”는 “bcad”의 predecessor가 아니다.\n\n단어 체인이란 k &gt;= 1에 대한 단어의 수열 [word_1, word_2, ...,\n word_k]이면서, 어떤 i에 대해서 word_i가 word_(i+1)의\n predecessor인 것을 말한다. 정의에 따라 단어 하나인 목록은 k == 1인\n 단어 체인이 된다.\n\n주어진 단어 목록에서 만들 수 있는 가장 긴 단어 체인의 길이를\n 구하자.\n\n단어 목록의 크기는 최대 1,000 이고 단어 하나의 길이는 최대\n 16이다. 모두 알파벳 소문자만 담고 있다.\n\n탑 다운 다이나믹 프로그래밍\n\nPredecessor 때문에 그래프 문제인가 싶었지만 다이나믹 프로그래밍\n 문제다. 힌트를 다 까봤는데, predecessor를 순서대로, 즉 어떤 단어에서\n 가능한 모든 글자를 모든 위치에 하나 씩 추가해가면서 만들기 보다는,\n 반대로 어떤 단어에서 한 글자씩 빼서 거꾸로 만들어 보라고\n 하더라. 그래서 이것저것 코드 구조를 잡아 봤는데 잘 안되어서 솔루션을\n 보고 무릎을 탁 쳤다.\n\n일단 단어 word가 주어졌을 때, 여기서 한 글자씩 빼서 만들 수 있는\n 모든 predecessor를 만드는 것은 파이썬에서 다음과 같이 할 수\n 있다. 파이썬이 half-open interval로 시퀀스를 표현하기 때문에\n 가능하다.\n\nfor i in range(len(word)):\n    pred_cand = word[:i] + word[i+1:]\n\n\n그러면 힌트에 충실하게 거꾸로 만들어가는 과정을 고민해보자. 어떤\n 단어가 주어졌을 때, 그 단어와 주어진 단어 목록을 가지고 만들 수 있는\n 단어 체인의 길이 중 가장 긴 것을 구하는 함수 max_word_chain을\n 만들자. 한 글자를 빼서 만든 predecessor 후보 단어가 단어 목록에\n 없으면, 정의에 따라 가장 긴 단어 체인의 길이는 1이 된다. 그렇지 않은\n 경우, 다음과 같은 점화식이 성립한다: 1 +\n max_word_chain(pred_cand). 문제의 조건에 따라 주어진 단어 목록만 쓸\n 수 있기 때문에, 단어 하나에 대해서 단어 체인의 최대 길이를 구할 때\n 발생하는 모든 부분 문제는 반복되어 나온다. 따라서 이 부분을 캐싱하면\n 아주 빠르게 구할 수 있다.\n\nfrom functools import cache\ndef lognestStrChain(words):\n    word_set = set(words)\n\n    @cache\n    def max_word_chain(word):\n        maxlen = 1\n        for i in range(len(word)):\n            pred_cand = word[:i] + word[i+1:]\n            if cand in word_set:\n                maxlen = max(maxlen, 1 + max_word_chain(cand))\n        return maxlen\n\n    answer = 0\n    for word in words:\n        answer = max(answer, max_word_chain(word))\n    return answer\n\n\n\n  단어 목록을 미리 해시 셋으로 만들어 둔다. 그러면 단어에서 한 글자를\n뺀 predecessor 후보 단어가 주어진 단어 목록에 있는지 O(1)만에\n확인할 수 있다.\n  단어 목록 전체를 훑을 때 단어 순서는 상관이\n없다. max_word_chain이 구하려고 하는 것은 어떤 단어에서 글자를\n하나씩 빼가면서 만들 수 있는 단어 체인의 길이 중 최대를 구하는\n것이기 때문이다. 만약 바텀 업 접근이라면 단어를 방문하는 순서도\n영향을 미칠 것이다."
					}
					,
					"ps-leetcode-longest-substring-without-repeating-characters": {
						"id": "ps-leetcode-longest-substring-without-repeating-characters",
						"title": "Longest Substring Without Repeating Characters",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/longest-substring-without-repeating-characters/",
						"content": "Longest Substring Without Repeating Characters\n문자열이 주어졌을 때, 반복되는 문자 없이 만들 수 있는 가장 긴 부분\n 분자열의 길이를 구하자.\n\n예를 들면 “abchabcbb”가 주어지면, 가능한 부분 문자열 중 (1) 중복\n 문자가 없고 (2) 가장 긴 것은 “abc” 이므로 답은 3이다.\n\nBrute Force\n극혐 문자열 문제다. 일단 Brute Force로는 어떻게 구현할 수 있을지\n 생각해보자.\n\n문자열의 시작과 끝을 증가시키면서 가능한 모든 부분 문자열을 만들 수\n 있다. 그렇게 한 후에 해당 문자열에 있는 문자 개수를 세어서, 개수가\n 1이 넘어가는게 하나라도 있으면 0이고, 가능하다면 그 문자의 개수가\n 될 것이다. 이를 코드로 짜면 다음과 같다.\n\nfrom collections import Counter\ndef longest_substring_without_repeating(s):\n    def is_valid(start, end):\n        c = Counter(s[start:end + 1])\n        return all(num == 1 for num in c.values())\n\n    n = len(s)\n    answer = 0\n    for start in range(n):\n        for end in range(start, n):\n            if is_valid(start, end):\n                answer = max(answer, end - start + 1)\n\n    return answer\n\n\n\n  start, end는 모두 인덱스이므로 리스트 슬라이싱을 할 때 end +\n1을 해줘야 한다.\n  조건에 맞는지 검사하기 위해서 Counter 모듈로 문자의 개수를 센 후에,\n전부 개수가 1인지를 체크했다.\n  조건에 맞으면 문자열의 길이는 end - start + 1로 구할 수 있고, 이\n중 최대 길이를 누적하면 된다.\n\n\n당연하지만 이렇게하면 O(n^3)이 되어서 무척 느리다.\n\n슬라이딩 윈도우\n보통 이런 문제는 start와 end 포인터를 최대한 덜 움직여야\n 한다. 그럼 어떻게 해야 덜 움직일 수 있을까?\n\n일단 start, end 모두 0부터 시작하자. end를 하나씩 움직이면서,\n 문자가 나타난 위치(인덱스)를 기록해두자. 만약 이미 기록된 위치가\n 있다면 (= end 위치에서 중복이 일어났다면), 그 다음 위치로\n start를 옮기면 된다. 즉, 각 문자가 나타나는 위치를 계속 업데이트해\n 나아가면서, 동시에 반복되는 문자를 만나자마자 그 위치를 스킵해버리면\n 된다.\n\n말은 쉽다. 이걸 코드로 짜면 다음과 같다.\n\ndef longest_substring_without_repeating(s):\n    occured_index = {}\n    answer = 0\n    start = 0\n\n    for end, char in enumerate(s):\n        if char in occured_index:\n            start = max(start, occured_index[char] + 1)\n\n        answer = max(answer, end - start + 1)\n        occured_index[char] = end\n\n    return answer\n\n\n  문자가 나타난 인덱스를 해시 테이블 occured_index에 기록한다.\n  문자열의 최대 길이를 구하는 로직은 같다.\n  이전에 나타난 위치가 있으면, start를 그 다음 위치로\n빨리감기한다. 이때 지금 start보다 큰 경우에만 빨리감기\n해야한다. 왜냐하면, 예를 들어 “abba”의 경우,\n    \n      a, b를 거치면서 occured_index = {'a': 0,\n'b': 1}이 된다.\n      두번째 b를 만나면 start = 2이 된다.\n      두번째 a를 만나면 start = 1이 된다(??)\n    \n  \n\n\n이런 경우가 발생할 수 있기 때문이다."
					}
					,
					"ps-leetcode-lowest-common-ancestor-of-a-binary-search-tree": {
						"id": "ps-leetcode-lowest-common-ancestor-of-a-binary-search-tree",
						"title": "Lowest Common Ancestor of a Binary Search Tree",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/lowest-common-ancestor-of-a-binary-search-tree/",
						"content": "Lowest Common Ancestor of a Binary Search Tree\n\n이진 탐색 트리의 루트 노드와 두 개의 노드가 주어진다. 두 노드는\n BST안에 반드시 존재하는 노드이다. 이때 두 노드의 LCA(Lowest Common\n Ancestor)를 구하자.\n\nLCA의 정의는 위키피디아에 따르면 다음과 같다: 두 노드 p와 q의\n LCA는 p와 q를 자손으로 가지면서 트리의 가장 낮은 위치에 있는\n 노드이다. 이때, 노드는 그 자신의 자손이다.\n\n예를 들어서, 다음과 같은 BST 있을 때\n\n\n\n\n  2와 8의 LCA는 루트인 6\n  3과 5의 LCA는 4\n  0과 2의 LCA는 2\n  0과 5의 LCA는 2\n\n\n가 된다.\n\n노드의 수는 2~100,000이고 모든 노드의 값은 유니크하다. p와 q는\n 서로 다르며 반드시 BST 안에 있음이 보장된다.\n\nGeneral Approach\n\n일반적인 트리에서 LCA를 구하는 가장 직관적인 방법은 다음과 같다.\n\n\n  일단 트리의 모든 노드의 레벨(또는 높이)를 구한다. 여기서는\n레벨이라고 하자.\n  노드에 부모 포인터가 없다면 부모로 가는 정보도 구해둔다.\n  두 노드의 레벨을 같도록 맞춘다. 레벨이 더 큰 쪽의 노드가 작은 쪽과\n같아질 때까지 부모를 따라 거슬러 올라간다.\n  두 노드가 같은 레벨에 있게 되면, 두 노드가 같아질 때까지 함께\n부모를 거슬러 올라간다.\n  두 노드가 같아지면 종료. 이 노드가 LCA이다.\n\n\n이 방법은 일종의 Bottom-Up 방법이다. 일단 두 노드가 같은 레벨에\n 있도록 맞춘 다음, 서로 만날 때까지 부모를 거슬러 올라간다. 아주\n 직관적인 방법이다. 이 아이디어를 구현하면 다음과 같다.\n\ndef lowestCommonAncestor(root, p, q):\n    levels = {}\n    def set_levels(node, lv):\n        if node is None:\n            return\n        levels[node] = lv\n        set_levels(node.left, lv+1)\n        set_levels(node.right, lv+1)\n    set_levels(root, 0)\n\n    parents = {}\n    def set_parent(node):\n        if node is None:\n            return\n        if node.left:\n            parents[node.left] = node\n        if node.right:\n            parents[node.right] = node\n        set_parent(node.left)\n        set_parent(node.right)\n    set_parent(root)\n\n    if levels[p] &lt; levels[q]:\n        p, q = q, p\n    # now levels(p) &gt;= levels(q)\n    while levels[p] != levels[q]:\n        p = parents[p]\n    while p != q:\n        p, q = parents[p], parents[q]\n    return q\n\n\nBST의 균형에 대한 조건은 언급되어 있지 않기 때문에, 트리 노드의\n 개수를 N이라고 하면 O(N)의 시간 및 공간 복잡도를 얻는다.\n\nUse Search Property\n\n그런데 문제에서 트리가 그냥 트리가 아니라 BST라고 했다. BST는 Search\n Property라고 불리는 다음 성질을 만족하는데:\n\n  모든 노드에 대해서, 노드의 값은 왼쪽 서브트리의 모든 값보다 크고\n오른쪽 서브트리의 모든 값보다 작다.\n\n\n이 성질을 이용할 수는 없을까?\n\n\n  일단 루트 노드에서 출발한다.\n  두 노드의 값이 루트 노드보다 작다면, 두 노드는 반드시 루트의\n왼쪽 서브트리에 있다.\n  두 노드의 값이 루트 노드보다 크다면, 두 노드는 반드시 루트의\n오른쪽 서브트리에 있다.\n  만약 둘다 아니라면, 이 뜻은 처음으로 두 노드 사이에 있는\n노드에 도달했다는 뜻이다. 그리고 이게 바로 LCA이다.\n\n\ndef lowestCommonAncestor(root, p, q):\n    node = root\n    while node:\n        if p.val &lt; node.val and q.val &lt; node.val:\n            node = node.left\n        elif p.val &gt; node.val and q.val &gt; node.val:\n            node = node.right\n        else:\n            return node\n\n\n아무런 저장 공간을 소모하지 않으므로 O(1)의 공간 복잡도를 소모한다.\n\nLowest Common Ancestor of a Binary Tree\n\n이 문제는 위의 문제에서 입력이 BST가 아닌 일반 트리로 바뀐 것\n 뿐이다. 따라서, 위의 첫 번째 솔루션을 그대로 활용할 수 있다. 여기서는\n 추가로 재귀적인 솔루션을 살펴보려고 한다.\n\n\n  루트부터 시작해서 재귀적으로 탐색해 나아간다.\n  null 노드이거나, 찾고자 하는 LCA의 대상 노드 중 하나라면, 곧바로\n리턴한다. 이는 곧 LCA가 되거나 또는 p, q 둘 중 하나의 조상노드\n중 하나가 된다.\n  양쪽 서브트리에서 재귀적으로 가능한 LCA 또는 p, q의 조상\n노드가 될 수 있는 노드를 찾는다. 만약 양쪽에서 모두 null이 아닌\n노드를 발견한다면, 지금 있는 루트노드가 곧 LCA가 된다. 그게\n아니라면, 둘 중 null이 아닌 노드가 LCA이다.\n\n\ndef lowestCommonAncestor(root, p, q):\n    if root in [None, p, q]:\n        return root\n\n    left = lowestCommonAncestor(root.left, p, q)\n    right = lowestCommonAncestor(root.right, p, q)\n    if left and right:\n        return root\n    return left or right\n\n\n\n  마지막의 return left or right는 파이썬의 트릭 중 하나로, C에서\nreturn left != null ? left : right;와 같은 의미이다."
					}
					,
					"ps-leetcode-lru-cache": {
						"id": "ps-leetcode-lru-cache",
						"title": "LRU Cache",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/lru-cache/",
						"content": "LRU Cache\n\n말 그대로 LRU Cache를 만드는 문제다.\n\nLRU 캐시는 아래 성질을 만족한다:\n\n  capacity 만큼의 캐시 사이즈를 유지한다.\n  get(key), put(key, value) 메소드가 호출될 때 마다 key 값에\n해당하는 캐시는 가장 최근에 사용한 친구로 기록된다.\n  put이 호출될 때 캐시 사이즈가 넘치게 되면, 가장 안쓰이는 친구가\n방출되어야 한다.\n\n\n접근\n\n  LRU 캐시의 기능(Functionality)을 구현하려면 아래 세 가지가\n필요하다:\n    \n      키-밸류 맵핑: 일반적인 해시맵, 딕셔너리와 같다.\n      키에 접근한 순서를 유지: 키에 접근한 순서를 관리하기 위한\n자료구조가 추가적으로 필요하다. 보통은 더블 링크드 리스트를\n사용한다. 이유는 어떤 노드를 리스트의 가장 앞(헤드) 또는 가장\n마지막(테일)에 옮기는 연산을 O(1) 만에 할 수 있기 때문이다.\n      키에 접근한 순서를 빠르게 연산: 키에 접근 순서를 위해서 그냥\n더블 링크드 리스트만 쓰면 어떤 키(노드)인지를 찾는데 O(N)의\n복잡도가 필요하다. 이를 해결하기 위해서 추가적인 키-노드 맵핑이\n필요하다. 역시 해시맵을 쓴다.\n    \n  \n  이 기능을 구현한 파이썬 라이브러리 OrderedDict를 가져다 쓰면\n된다:\n    \n      move_to_end(key, last=False)를 이용해서 접근 순서를 앞/뒤로\n움직일 수 있다.\n      popitem(last=True)를 이용해서 가장 최근/마지막에 접근한\n아이템을 버릴 수 있다.\n    \n  \n\n\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.cap = capacity\n        self.cache = OrderedDict()\n\n    def get(self, key: int) -&gt; int:\n        if key not in self.cache:\n            return -1\n        self.cache.move_to_end(key, last=False)\n        return self.cache[key]\n\n    def put(self, key: int, value: int) -&gt; None:\n        self.cache[key] = value\n        self.cache.move_to_end(key, last=False)\n        if len(self.cache) &gt; self.cap:\n            self.cache.popitem(last=True)"
					}
					,
					"assets-js-main-js": {
						"id": "assets-js-main-js",
						"title": "",
						"version": "all",
						"categories": "",
						"url": " /assets/js/main.js",
						"content": "(function($) {\n    'use strict';\n    $(function() {\n        $('[data-toggle=\"tooltip\"]').tooltip();\n        $('[data-toggle=\"popover\"]').popover();\n        $('.popover-dismiss').popover({\n            trigger: 'focus'\n        })\n    });\n\n    function bottomPos(element) {\n        return element.offset().top + element.outerHeight();\n    }\n    $(function() {\n        var promo = $(\".js-td-cover\");\n        if (!promo.length) {\n            return\n        }\n        var promoOffset = bottomPos(promo);\n        var navbarOffset = $('.js-navbar-scroll').offset().top;\n        var threshold = Math.ceil($('.js-navbar-scroll').outerHeight());\n        if ((promoOffset - navbarOffset)  {\n    var tags = document.getElementsByTagName(\"button\");\n    for (let tag of tags) {\n        updateTagCounts(tag.dataset.tag);\n    }\n    let currentTag = \"\";\n    const queryTag = getQuery().tag;\n\n    if (queryTag) {\n        filterByTagName(queryTag);\n    } else {\n        clear();\n    }\n\n    $(\"button\").on(\"click\", (e) => {\n        currentTag = e.target.dataset.tag;\n        if (currentTag != \"clear\"){\n            filterByTagName(currentTag);\n        } else {\n            clear();\n        }\n    });\n});\n\nfunction updateTagCounts(tagName) {\n    if (tagName == \"clear\"){\n        return;\n    }\n    var counter = 0;\n    $('.post-wrapper').each((index, elt) => {\n        if (elt.hasAttribute(`data-${tagName}`)) {\n            counter += 1;\n        }\n    });\n\n    var updated = $(`.btn[data-tag=${tagName}]`).text() + \" (\" + counter + \")\";\n    console.log(updated);\n    $(`.btn[data-tag=${tagName}]`).html(updated);\n}\n\nfunction getQuery() {\n    var params = {};\n    window.location.search.replace(/[?&]+([^=&]+)=([^&]*)/gi, function(str, key, value) {\n\n        params[key] = value;\n    });\n\n    return params;\n}\n\nfunction filterByTagName(tagName) {\n    var counter = 0;\n    $('.hidden').removeClass('hidden');\n    $('.post-wrapper').each((index, elt) => {\n        if (!elt.hasAttribute(`data-${tagName}`)) {\n            $(elt).addClass('hidden');\n        } else {\n            counter += 1;\n        }\n    });\n\n    $(`.btn`).removeClass('selected');\n    $(`.btn[data-tag=${tagName}]`).addClass('selected');\n    $(\".count\").text(counter);\n}\n\nfunction clear() {\n    $('.post-wrapper').addClass('hidden');\n    $(`.btn`).removeClass('selected');\n    $(`.btn[data-tag=clear]`).addClass('selected');\n    $('.count').text(\"Tag unset\");\n}"
					}
					,
					"wip-mantra": {
						"id": "wip-mantra",
						"title": "Mantra",
						"version": "all",
						"categories": "",
						"url": " /wip/mantra/",
						"content": "Mantra\n\n  Plans are useless, but planning is indispensable. - General Dwight D. Eisenhower\n\n\n  Enthusiasm is common. Endurance is rare. - Angela Duckworth\n\n\n  Speech is silver, silence is golden. - Thomas Carlyle\n\n\n  We don&#8217;t rise to the level of our expectations; we fall to the level of our\n    training. - Archilochus\n\n\n  Young man, in mathematics you don&#8217;t understand things. You just get used to\n    them. - John von Neumann\n\nAn Old Hacker&#8217;s Tips\nI stole this from here.\nThe &#8220;Do It Anyway&#8221; Principle\n\n  &#8230; but sooner or later you will end up on some task or project that is\n    difficult to accomplish and/or generally unpleasant, all due to factors outside\n    of your control.\n\n\n  .. would be the people that somehow got their tasks done anyway, even though\n    there were ridiculous contstraints imposed by our environment issues that made it\n    a lot harder.\n\n\n  The brutal truth though is, &#8230; We are all constantly measured in the eyes of\n    our employers by what we actually deliver, and those who can find a way to\n    succeed even in the face of adversity will always have an advantage over those\n    who cannot, or do not want to.\n\nThe &#8220;Two-and-Done&#8221; Rule\n\n  It has to do with how to handle disagreements that come up at work.... have a\n    pretty strong desire to always have the right answer to things, &#8230; I would\n    tenaciously argue my point, without letting go.\n\n\n  &#8230; I would let them know just why they were wrong, and why we needed to do it\n    my way &#8230; because something that I knew was better was being ignored.\n\n\n  But this take-no-prisoners approach to debate **did not** do me any good&#8230; it\n    would negatively impact my ability to affect change. If I did this too often,\n    people would begin to see me as argumentative, difficult to work with, not a\n    team player, ....\n\n\n  .... I&#8217;m still a big fan of being right all the time, &#8230; What&#8217;s changed over\n    the years though is first, an enhanced understanding that I in fact **am not\n    right all the time**. But also that even when I am right, it isn&#8217;t always a\n    guarantee that others will **follow my advice**, and if they do not, that it&#8217;s\n    sill OK.\n\n\n  &#8230; I will state my case the first time, and if whoever is arguing to the\n    contrary does not agree after hearing my position, I&#8217;ll let it go. But the next\n    time the opportunity comes up, I will argue my point again. Maybe allowing for a\n    gap of time for people to consider my original point, or maybe allowing me time\n    to refine and rephrase my ideas to be more convincing.\n\n\n  &#8230; I will state my case the first time, and if whoever is arguing to the\n    contrary does not agree after hearing my position, I&#8217;ll let it go. But the next\n    time the opportunity comes up, I will argue my point again. Maybe allowing for a\n    gap of time for people to consider my original point, or maybe allowing me time\n    to refine and rephrase my ideas to be more convincing.If I fail to &#8230; the\n    second time though, **I am done.** .... &#8220;OK, let&#8217;s go your way then. I still don&#8217;t\n    completely agree with everything proposed here, but I think I&#8217;ve made my case,\n    and we ened to **move on**.&#8221;\n\n\n  Yielding in an argument like this has some weird, powerful effects. One is it\n    kind of releases you from responsibility if things should go wrong. And if a\n    truly bad decision has been made, it is actually pretty likely that things wil\n    start going wrong. If you fail to convince people after two tries, you really do\n    have to get behind the decision, and not try to sabotage or undermine it.\n\n\n  &#8230; it bumps up your personal brand, as someone who should maybe be listened to\n    more often."
					}
					,
					"ps-leetcode-matchsticks-to-square": {
						"id": "ps-leetcode-matchsticks-to-square",
						"title": "Matchsticks to Square",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/matchsticks-to-square/",
						"content": "Matchsticks to Square\n\n정수 배열 matchsticks가 주어지는데, matchsticks[i]는 i번째\n 성냥의 길이를 나타낸다. 모든 성냥을 사용해서 하나의 정사각형을\n 만드려고 한다. 성냥을 부러뜨릴 수 없고, 대신 연결할 수는\n 있다. 모든 성냥은 딱 한번만 사용할 수 있다.\n\n주어진 성냥으로 사각형을 만들 수 있는지 없는지 확인하자.\n\n성냥 배열의 길이는 1~15이고, 각 성냥의 길이는 \\(1 \\sim 10^8\\) 이다.\n\n예를 들어 matchsticks = [1, 1, 2, 2, 2] 라면, 한 변의 길이가 2인\n 정사각형을 만들 수 있다.\n\n백트래킹 - 타임아웃\n\n일단 정사각형이 불가능한 경우부터 걸러낼 수 있다. 먼저 성냥 길이의\n 합이 4의 배수가 아닌 경우는 불가능하다. 성냥 길이의 합이 4의 배수라면\n 합을 4로 나눈 값이 곧 한 변의 길이가 된다는 것을 알 수 있고 이를\n side라고 하면, 성냥 길이 중 side보다 큰 값이 하나라도 있으면 역시\n 불가능하다.\n\n이렇게 두 가지 쉽게 생각할 수 있는 케이스를 쳐내고 나면, 생각나는\n 방법은 그냥 일일이 (…) 모든 변을 하나 씩 만들면서 상태 공간을\n 탐색하는 것이다. 다만 목표가 뚜렷하기 때문에 어느 정도 프루닝이\n 가능하여 백트래킹할 수 있다.\n\ndef makesquare(matchsticks):\n    s, n = sum(matchsticks), len(matchsticks)\n    if s % 4 != 0:\n        return False\n\n    side = s // 4\n    if any(x &gt; side for x in matchsticks):\n        return False\n\n    def match(idx, matched):\n        if idx == n:\n            return matched[0] == matched[1] == matched[2] == matched[3] == side\n\n        cur_len = matchsticks[idx]\n        for i in range(4):\n            if cur_len + matched[i] &lt;= side:\n                matched[i] += cur_len\n                if match(idx + 1, matched):\n                    return True\n                matched[i] -= cur_len\n        return False\n\n    return match(0, [0, 0, 0, 0])\n\n\n유지할 상태는 두 가지이다. 살펴보려는 성냥의 인덱스와, 지금까지\n 완성한 사각형의 변의 길이 4개이다. 성냥을 다 봤으면, 네 변이 다 같은\n side인지를 확인한다. 그렇지 않으면, 네 변 모두에 대해서 각각 지금\n 인덱스의 성냥 길이를 추가할 수 있는지 살펴보고, 가능한 경우 그 변에\n 성냥을 이어서 추가로 탐색한다. 이때 주의할 것은 탐색이 끝나고 나면\n 원래 길이를 원복해줘야 한다는 것이다.\n\n이렇게하면 정직하게 모든 상태 공간을 탐색할 수 있지만, 모든 가능한 네\n 변을 다 만들어보기 때문에 복잡도는 \\(O(4^N)\\)이 되어 터진다.\n\n다이나믹 프로그래밍 + 비트 마스킹\n\n사실 이 문제는 잘 알려진 NP-Complete 문제 중 하나인 Bin Packing\n Problem으로\n 환원할 수 있는 문제라고 한다. 한마디로 아직 선형 시간에 가능한\n 솔루션이 없다. 그러니 최선을 다해도 지수 시간이다. 그렇지만\n \\(4^N\\)보다는 더 줄일 여지가 있다.\n\n먼저 생각해볼 부분은, 사각형을 만드는데 필요한 네 변을 전부 유지할\n 필요가 있을까? 예를 들어, 사각형을 만드는 도중에 몇 개의 변을 이미\n 완성한 상태에서 남은 성냥이 [3, 3, 4, 4, 5, 5]라고 해보자. 완성한\n 변의 길이가 8이라고 하면, 여러 가능성이 있겠지만 다음과 같은 상태가\n 가능할 것이다.\n\n(4, 4), (3, 5), (3, 5)   -&gt; 3 변 완성\n(3, 4), (3, 5), (4), (5) -&gt; 0 변\n(3, 3), (4, 4), (5), (5) -&gt; 1 변\n\n\n즉 같은 성냥 집합이라도, 이걸 어떻게 (재귀적으로 탐색해서) 이어\n 붙이느냐에 따라서 결과(상태)가 완전히 달라진다. 다시 말해, 어떤\n 성냥을 사용했는지가 곧 상태를 결정한다.\n\n그런데 사용한 성냥을 하나의 집합으로 추적하더라도 정사각형을 만들지\n 못하는 수많은 부분 문제(위에서 본 것처럼)로 갈 수 있을\n 것이다. 따라서, 사용한 성냥 뿐 아니라 얼마나 변을 완성했는지도\n 함께 추적해야 한다. 이때, 이전처럼 일일이 네 변을 유지할 필요가 전혀\n 없다. 이전 접근에서 초반에 성냥의 합이 4로 나누어 떨어지는지를\n 확인해서 불가능한 케이스를 판별했었는데, 여기서도 이 방법을 유사하게\n 사용할 수 있다: 즉, 지금까지 사용한 성냥의 길이 합이 변의 길이로\n 나누어 떨어지는지를 보면 된다.\n\n추가적으로 상태를 쳐낼 수 있는 것 중 하나는, 정사각형이기 때문에,\n 세 변만 완성하면 (전체 성냥 길이가 4로 나누어 떨어진다면) 나머지 한\n 변은 자동으로 완성된다는 점이다.\n\n여기까지 문제를 재정의하고 나면, 부분 문제가 있는지 살펴볼 수\n 있다. 작은 케이스에서 살펴보자. 성냥이 [1, 1, 1, 1] 있고 완성한\n 변이 0개인 상태에서 시작해보자. 다음과 같이 반드시 중복되는 부분\n 문제가 있다는 걸 알 수 있다. (_은 변을 만드는데 사용됐다는 의미)\n\n(1, 1, 1, 1), 0\n\n  +-- (1, _, 1, 1), 1  ---+- ....\n  |                       |\n  |                       +---- (1, _, _, 1), 2 *\n  +-- (1, 1, _, 1), 1  ---+- ...\n  |                       |\n  ...                     +---- (1, _, _, 1), 2 *\n\n*: 중복되는 상태\n\n\n따라서, 메모아이제이션을 하면 더 빨라질 수 있다.\n\n즉, (1) 어떤 성냥을 사용했는지, 그리고 몇 개의 변을 완성했는지를\n 추적하면서 (2) 메모아이제이션을 한다. 이 두 가지를 제외하면 나머지\n 전체적인 구조는 이전의 백트래킹과 같다.\n\nfrom functools import cache\ndef makesquare(matchsticks):\n    s, n = sum(matchsticks), len(matchsticks)\n    if s % 4 != 0:\n        return False\n\n    side = s // 4\n    if any(x &gt; side for x in matchsticks):\n        return False\n\n    @cache\n    def match(used: Tuple[int], made: int):\n        acc = 0\n        for i in range(n):\n            if used[i]:\n                acc += matchsticks[i]\n        if acc &gt; 0 and acc % side == 0:\n            made += 1\n\n        if made == 3: # quick return\n            return True\n\n        margin = side - (acc % side)\n        for i in range(n):\n            if matchsticks[i] &lt;= margin and not used[i]:\n                used_l = list(used)\n                used_l[i] = True\n                if match(tuple(used_l), made):\n                    return True\n        return False\n    return match(tuple([False] * n), 0)\n\n\n\n  성냥의 사용 여부를 추적하기 위해서 불리언의 튜플을 사용했는데,\n왜냐하면 @cache 어노테이션으로 메모아이제이션 하려면 키 값을\n해싱할 수 있어야 하기 때문이다. 파이썬에서 리스트 타입은 해싱할 수\n없지만 튜플은 가능하다. 대신 이렇게 하려면 사용 여부를 변경해서\n재귀 호출을 할 때 조금 번거로운(리스트로 변환하여 값을 바꾸고 다시\n튜플로 변환) 작업을 해줘야 한다. 사실 이렇게 하지 않고 비트\n마스킹을 이용한 방법이 주된 방법이겠지만, 이 문제의 N이 작기도 하고\n파이썬에서는 속도 면에서 크게 차이가 나지 않아서 더 읽기 쉬운\n방법인 (해싱 가능한) 튜플을 썼다.\n  사용 여부를 이용해서 모든 성냥 길이의 합 acc를 먼저 계산한다. 그\n후 이 합이 변의 길이 side로 나누어 떨어지는지를 확인한다. 만약\n나누어 떨어지면 지금 상태에서 가능한 변이 하나 더 추가된 것이므로\nmade를 1 증가해준다. 좀더 상태를 쳐내기 위해서, 정사각형의 성질을\n이용해서 세 변이 완성되는 순간 재귀 호출을 끝낼 수 있다. (하지만\n실험해보니 4변을 다 확인하는 것과 큰 차이가 나지 않았다)\n  재귀 호출을 타고 들어갈 때 반드시 확인해야 하는 것이 바로 지금\n변에 추가 가능한 길이이다. 여기서는 어떤 성냥이 변에 쓰였는지\n추적하지 않지만, 대신 지금까지 사용한 성냥과 만든 변의 수로 그 다음\n가능한 길이를 계산해볼 수 있다: 성냥 길이의 합을 변의 길이로 나눈\n나머지가 곧 지금 만드는 중인 변의 길이가 되는데, 이 값을 변의\n길이에서 빼주면 지금 만들 변에 추가 가능한 길이인 margin을 원복할\n수 있다.\n\n\n복잡도는 어떻게 될까? 성냥의 사용 유무에 따라서 모든 성냥을 훑어봐야\n 하기 때문에, 시간 복잡도는 \\(O(N \\times 2^N)\\)이 된다. 공간 복잡도의\n 경우 먼저 최대 N번의 재귀 호출을 하게 되고 성냥의 사용 유무를 상태로\n 하여 메모아이제이션을 하고 있기 때문에 \\(O(N + 2^N)\\)의 복잡도를\n 갖는다."
					}
					,
					"ps-leetcode-maximum-area-of-a-piece-of-cake-after-horizontal-and-vertical-cuts": {
						"id": "ps-leetcode-maximum-area-of-a-piece-of-cake-after-horizontal-and-vertical-cuts",
						"title": "Maximum Area of a Piece of Cake After Horizontal and Vertical Cuts",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/maximum-area-of-a-piece-of-cake-after-horizontal-and-vertical-cuts/",
						"content": "Maximum Area of a Piece of Cake After Horizontal and Vertical Cuts\n\nh x w 사이즈의 사각형 모양의 케익이 주어진다. 이를 각각 수평 방향과\n 수직 방향으로 자르려고 하는데 이 정보가 horizontalCuts와\n verticalCuts로 주어진다.\n\n  horizontalCuts[i]는 사각 케익의 위에서부터 수평 방향으로 자른\ni번째 부분까지의 거리이다.\n  verticalCuts[j]는 사각 케익의 왼쪽에서부터 소직 방향으로 자른\nj번째 부분가지의 거리이다.\n\n\n이때 케익을 다 자르고 난 뒤 가져갈 수 있는 가장 큰 케익 조각의 면적을\n 구하자. 답의 범위가 벗어날 수 있으므로 \\(10^9+7\\)로 나눈 나머지를\n 리턴하자.\n\n\\(2 \\leq h, w \\leq 10^9\\) 이고 각각의 자르는 정보는 최대 \\(10^5\\)개\n 이다. 모든 원소는 유일하다.\n\n정렬..한다..\n\n2차원이라서 헷갈리는 부분이 있는데, 문제가 1차원 수직선을\n 왼쪽으로부터 수직 방향으로 자르는문제라고 생각해보자. 그러면 당연히\n 이 중 가장 긴 길이의 선은 자르는 부분 사이의 길이가 가장 큰 부분일\n 것이다. 이걸 2차원으로 확장하면 이 문제와 동일하다. 즉, 수직과 수평\n 방향의 가장 큰 부분을 각각 찾아서 곱하면 된다.\n\n단, 여기서 한 가지 조심해야 하는 부분은 케익의 범위를 잊으면\n 안된다는 것이다. 입력으로 들어오는 자르는 범위 정보는 케익의 어디를\n 자르라는 얘기만 있지, 케익의 범위는 암묵적으로 주어져있다: 바로\n 0부터 h, 또는 0부터 w가 그것이다. 따라서 문제를 조금 쉽게\n 풀려면 자르는 정보에 이 값을 각각 보충(augment)한 다음 일괄적으로\n 구해도 되겠다.\n\ndef maxArea(h, w, horizontalCuts, verticalCuts):\n    MOD = 10 ** 9 + 7\n    hh, vv = sorted(horizontalCuts + [0, h]), sorted(verticalCuts + [0, w])\n    maxh, maxw = 0, 0\n    for h0, h1 in zip(hh, hh[1:]):\n        maxh = max(maxh, h1 - h0)\n    for v0, v1 in zip(vv, vv[1:]):\n        maxw = max(maxw, v1 - v0)\n    return maxh* maxw % MOD\n\n\n\n  [0, h]와 [0, w]를 각각 보충해서 전체를 정렬하고 있다.\n  인접한 두 원소의 차이를 계산하기 위해서 파이썬의 슬라이스 연산과\nzip연산을 활용했다. 특히 zip은 두 오브젝트 중 작은 쪽의 길이로\n맞추기 때문에 zip(hh, hh[1:])은 곧 (hh[0], hh[1]), (hh[1],\nhh[2]), ..., (hh[n-2], hh[n-1])이 된다."
					}
					,
					"ps-leetcode-maximum-depth-of-binary-tree": {
						"id": "ps-leetcode-maximum-depth-of-binary-tree",
						"title": "Maximum Depth of Binary Tree",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/maximum-depth-of-binary-tree/",
						"content": "Maximum Depth of Binary Tree\n\n바이너리 트리의 루트가 주어졌을 때, 트리의 최대 깊이를 구하자. 트리의\n 최대 깊이란 루트 노드로부터 가장 멀리 있는 리프 노드까지 가는 경로의\n 길이와 같다. 노드의 개수 범위는 0~10,000이다.\n\n재귀적으로 구하기\n\n나의 옛날 포스트 AVL 트리 정복하기를 참조하면 좋다.\n\n트리의 깊이는 다음과 같이 재귀적으로 정의된다.\n\n  노드가 null 이면 0\n  노드가 null이 아니라면, 왼쪽 서브트리와 오른쪽 서브트리의 깊이 중\n더 큰 값 + 1\n\n\ndef maxDepth(root):\n    def height(node):\n        if node is None:\n            return 0\n        else:\n            return max(height(node.left), height(node.right)) + 1\n    return height(root)"
					}
					,
					"ps-leetcode-maximum-erasure-value": {
						"id": "ps-leetcode-maximum-erasure-value",
						"title": "Maximum Erasure Value",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/maximum-erasure-value/",
						"content": "Maximum Erasure Value\n\n정수 배열 nums가 주어진다. 여기서 유일한 원소만을 담은 부분\n 배열을 삭제하고 싶다. 어떤 부분 배열을 삭제해서 얻을 수 있는\n 점수는 그 부분 배열의 원소의 합과 같다.\n\n딱 하나 부분 배열만을 삭제했을 때 획득할 수 있는 점수의\n 최대값을 구하자.\n\n배열의 길이는 \\(1 \\sim 10^5\\) 이고 원소의 범위는 \\(1 \\sim 10^4\\)\n 이다. 따라서 가능한 점수는 32비트 정수 안에 다 들어갈 수 있다(대충\n 10억 언저리).\n\n투 포인터 접근\n\n문제 설명을 읽었을 때 가장 먼저 떠오른 유사 문제는 반복되는 글자\n 없는 가장 긴 부분\n 문자열\n 문제였다. 해당 문제를 이 문제 식으로 설명하면, 유일한 원소만을 담은\n 부분 배열 중 가장 길이가 긴 것을 구하는 문제이다. 여기서는 길이가\n 아니라 해당 부분의 합을 구하기만 하면 될 것 같았다. 그래서 예전\n 풀이 방법을 떠올리며 아래와 같이 짜서 제출했다.\n\ndef maximumUniqueSubarray(nums):\n    previous_occurrence = {}\n    start = 0\n    score = 0\n    for end, num in enumerate(nums):\n        if num in previous_occurrence:\n            start = max(start, previous_occurrence[num] + 1)\n        previous_occurrence[num] = end\n        score = max(score, sum(nums[start:end + 1]))\n    return score\n\n\n예전 문제와 마찬가지로 해시 테이블에 이전에 나타났던 위치의 인덱스를\n 기록해두면서, 이전 위치가 발견된 경우 (원소가 유일해야 하므로) 이전\n 위치 다음 위치로 빨리감기를 해준다. 이때 주의할 것은 역시 코너\n 케이스로, 예를 들어 [1, 2, 2, 1]에서 1, 2를 거쳐 {1: 0, 2:\n 1}을 만들고 나면 두번째 2를 만나면서 start = 2가 되고, 또 두번째\n 1을 만날 때 start = 1이 되어 되려 줄어버리는 경우가 발생하기\n 때문에, start는 무작정 이전에 나타났던 위치의 다음 위치로\n 빨리감기를 하면 안되고 지금 위치보다 더 클 때에만 빨리감기를\n 해야한다.\n\n이렇게 하면 문제의 조건에 맞게 잘 구현했고 복잡도도 나쁘지\n 않아보이지만, 그렇지 않다. 시간 초과가 났다.\n\n+ 부분합\n\n시간 초과가 난 부분은 바로 점수를 계산하는 부분, 즉 배열의 합을\n 구하는 부분이다. 반복문 자체는 투 포인터를 이용해서 O(N) 만큼만\n 돌고 있지만, 매번 점수를 계산하기 위해서 sum(nums[start:end+1])\n 부분을 일일이 구하고 있는 것이 문제였다.\n\n따라서 이 부분만 부분합으로 최적화해주면 된다. 부분합을 구할 때에는\n 인덱스에 주의해야 하는데, 아무것도 더하지 않은 상태인 0을 유지해줘야\n 한다는 것만 주의하면 된다.\n\ndef maximumUniqueSubarray(nums):\n    n = len(nums)\n    partial_sum = [0] * (n + 1)\n    for i in range(n):\n        partial_sum[i+1] = partial_sum[i] + nums[i]\n\n    previous_occurrence = {}\n    start = 0\n    score = 0\n    for end, num in enumerate(nums):\n        if num in previous_occurrence:\n            start = max(start, previous_occurrence[num] + 1)\n        previous_occurrence[num] = end\n        score = max(score, partial_sum[end + 1] - partial_sum[start])\n    return score\n\n\n\n  길이 n의 정수 배열의 부분합을 구하면 길이가 n + 1이 된다.\n  이제 부분합을 알기 때문에 점수를 O(1)만에 계산 가능하다. 이때\n인덱스에 주의하자. start 부터 end (둘다 인덱스) 까지의 부분합은\nend까지의 부분합에서 start - 1까지의 부분합을 뺀 값이 되고,\n우리가 계산해둔 부분합의 인덱스는 모두 1씩 더해졌으므로, 부분합에\n들어갈 인덱스는 end + 1과 start가 된다.\n\n\n\n\n처음으로 솔루션이나 힌트의 도움없이 푼 Hard 난이도 문제라는 것을\n 기록해둔다. 예이!\n\n… 는 근데 쥐도 새도 모르게 난이도가 Medium으로 다운그레이드 되어\n 있었다… 흑흑."
					}
					,
					"ps-leetcode-maximum-points-you-can-obtain-from-cards": {
						"id": "ps-leetcode-maximum-points-you-can-obtain-from-cards",
						"title": "Maximum Points You Can Obtain from Cards",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/maximum-points-you-can-obtain-from-cards/",
						"content": "Maximum Points You Can Obtain from Cards\n\n여러개의 카드가 한 줄로 나열되어 있다. 각각의 카드에는 점수가\n 적혀있다. 이 카드의 점수는 cardPoints 배열로 들어온다.\n\n한 번의 단계에서, 당신은 카드 줄의 제일 앞 또는 제일 뒤에서 한 장을\n 뽑을 수 있다. 이렇게 정확히 k번 카드를 뽑을 수 있다.\n\n당신의 점수는 이렇게 뽑은 카드의 점수의 합이다.\n\n이때 얻을 수 있는 최대 점수를 구하자.\n\n카드는 1~100,000개, 각 점수는 1~10,000점이다. k는 1과 카드 배열\n 길이 사이의 값이 보장된다.\n\n하라는 대로 하기\n\n그냥 하라는 대로 정직하게 구현해봤다.\n\n먼저 0부터 k까지의 합을 구한다. 즉, 카드 앞에서만 k개를 뽑았을\n 때의 점수이다. 이제 이 고정 윈도우 크기를 그대로 유지하면서 배열\n 전체를 훑으면서 각각의 합을 계산하고, 동시에 그 중 최대 값을\n 누적해가면 된다.\n\n이때 파이썬의 음수 인덱스를 활용하면 편하다. 배열의 가장 마지막\n 원소를 -1부터 시작해서 인덱스로 접근할 수 있다.\n\ndef maxScore(cardPoints, k):\n    score = sum(cardPoints[:k])\n    answer = score\n    for i in range(1, k + 1):\n        score = score - cardPoints[k - i] + cardPoints[-i]\n        answer = max(answer, score)\n\n    return answer\n\n\n\n  1부터 k까지 돌면서, 현재 점수 구간에서 먼저 가장 뒷쪽을 빼고\n(cardPoints[k-i]), 카드 배열 가장 뒷쪽을 더해준다\n(cardPoints[-i]).\n\n\n역발상하기\n\n약간 x를 0으로 만드는 최소 연산\n 횟수 문제랑 비슷한 접근을\n 해볼 수 있는데, 바로 카드 점수의 최대값을 구하는게 아니라, 점수의\n 합이 최소가 되는 카드의 연속 배열을 구하는 것이다. 그러면 전체 합에서\n 최소 점수를 빼면 된다. 참고로 이는 카드 점수가 전부 양수라서 가능한\n 테크닉이다.\n\n일단 k개를 고르는 것이 아니라 k개를 뺀 나머지를 구하는 것이기\n 때문에, 초기 점수는 n - k 까지의 합이 된다. 그러면 여기서부터\n 하나씩 고정 윈도우를 끝까지 이동하면서 이 중 최소가 되는 것을 구하고,\n 최종적으로 이를 전체 합에서 빼면 된다.\n\ndef maxScore(cardPoints, k):\n    total = sum(cardPoints)\n    n = len(cardPoints)\n    if n == k:\n        return total\n    cursum = sum(cardPoints[:n-k])\n    minsum = cursum\n    start = 0\n    for i in range(n-k, n):\n        cursum = cursum - cardPoints[start] + cardPoints[i]\n        start += 1\n        minsum = min(minsum, cursm)\n    return total - minsum\n\n\n\n  카드 점수를 앞에서부터 뺄 때 복잡하게 인덱스 연산을 할 거 없이 그냥\nstart 변수를 하나 두고 0부터 증가시키면 속편하다."
					}
					,
					"ps-leetcode-maximum-product-subarray": {
						"id": "ps-leetcode-maximum-product-subarray",
						"title": "Maximum Product Subarray",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/maximum-product-subarray/",
						"content": "Maximum Product Subarray\n\n정수 배열이 주어졌을 때, 공집합이 아닌 부분 배열의 곱이 최대가 되는\n 부분 배열을 찾고 그 곱을 구하자.\n\n모든 곱은 32비트 정수로 표현되는 것이 보장된다.\n\n부분 배열이란 배열에서 연속되는 부분 시퀀스를 뜻한다.\n\n배열의 길이는 최대 \\(2 \\times 10^4\\) 이고 각 값은 -10~10이다.\n\nO(N^2) - 타임아웃\n\n부분 배열의 최대 합랑 비슷한 문제다. 역시\n 비슷하게 Brute Force를 생각해볼 수 있는데, 역시나 타임아웃이 난다.\n\ndef maxProduct(nums):\n    maxp = float('-inf')\n    for i in range(len(nums)):\n        curp = 1\n        for j in range(i, len(nums)):\n            curp *= nums[j]\n            maxp = max(maxp, curp)\n    return maxp\n\n\n\n  합과는 다르게 곱의 초기값은 1이 되어야 정상적으로 누적되는 것만\n주의하면 된다.\n\n\nO(N) - Two Pass\n\n대관절 어떻게 하면 좋을까?? 이 문제를 처음 봤을 때에는 Brute Force\n 말고는 다른 방법이 도저히 떠오르질 않더라. 그래서 여러가지 힌트를\n 살펴보았고 접근 방법을 정리해보려고 한다.\n\n일단 부분합과는 다른 부분곱만의 특이한 점을 관찰하면 다음과 같다:\n\n  기존 방법처럼 인덱스 i 이전까지의 부분 배열로 곱을 만들려고 하면\n0이 발을 붙잡고 넘어진다. 원소가 0이면 이때까지 쌓아온 모든 값이\n초기화되기 때문이다. 곱에서 초기화란 곧 1로 초기화되는 것과\n같다. 즉, 일종의 구분자로 생각해도 된다.\n  음수의 경우도 특이하다. 음수를 홀수번 곱하면 음수이고, 짝수번\n곱하면 양수가 된다. 따라서, 합과는 다르게, 부분 배열에 음수가 몇 개\n있는지가 최대 곱에 영향을 미친다.\n\n\n좀더 구체적인 예제를 가지고 생각을 해보자.\n\n[2, 3, -4, 5]\n\n\n음수가 하나인 경우를 생각해보자. 왼쪽에서부터 누적 곱을 구해 나가면\n [2, 6, -24, -120]가 되고, 오른쪽에서부터 가면 [5, -20, -60,\n -120]가 된다. 즉, 음수 -3이 배열을 반으로 나눠버린다는 것을 알 수\n 있다. 따라서 이 중 최대값은 왼쪽에서부터 음수 직전까지를 곱한 6이\n 된다.\n\n[2, -3, -4, 5]\n\n\n이번에는 음수가 두개인 경우를 생각해보자. 앞에서 음수를 두 번 곱하면\n 양수가 된다고 했는데, 이게 어떤 영향을 미치는지 눈으로 확인할 수\n 있다. 마찬가지로 앞에서부터 곱을 누적하면 [2, -6, 24, 120]이 되고,\n 뒤에서부터 곱을 누적하면 [5, -20, 60, 120]이 되어 앞에서 곱하나\n 뒤에서 곱하나 최대 값은 120이 된다.\n\n결국 중요한 케이스는 음수가 세 개 이상이면서 홀수인 경우다. 그리고 그\n 경우에는 앞에서 곱을 누적한 것과 뒤에서 곱을 누적한 것 중에 최대값이\n 있다.\n\n이 성질을 이용해서 다음과 같이 구현할 수 있다.\n\ndef maxProduct(nums):\n    maxp = float('-inf')\n    curp = 1\n    for n in nums:\n        curp *= n\n        maxp = max(maxp, curp)\n        if n == 0:\n            curp = 1\n\n    curp = 1\n    for n in reversed(nums):\n        curp *= n\n        maxp = max(maxp, curp)\n        if n == 0:\n            curp = 1\n    return maxp\n\n\n\n  먼저 정방향으로 훑으면서 누적 곱을 계산해서 최대 값을\n갱신한다. 이때, 지금 값이 0이라면, 이후의 곱을 위해서 누적 곱을\n1로 초기화한다. 이를 통해 누적 곱 curp의 값이 인덱스 i까지의\n부분 배열 중에서 값이 0이 아닌 가장 나중의 위치부터 i까지의 누적\n곱이 담기도록 보장할 수 있다.\n  그 후 역방향으로 훑으면서 똑같이 최대 값을 갱신한다. 이렇게 두 번\n훑으면 최대 값에는 누적 곱의 최대 값이 담긴다."
					}
					,
					"ps-leetcode-maximum-size-subarray-sum-equals-k": {
						"id": "ps-leetcode-maximum-size-subarray-sum-equals-k",
						"title": "Maximum Size Subarray Sum Equals k",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/maximum-size-subarray-sum-equals-k/",
						"content": "Maximum Size Subarray Sum Equals k\n\n정수 배열 nums와 정수 값 k가 주어졌을 때, 합이 k가 되는 부분\n  배열 중 길이가 가장 긴 부분 배열의 길이를 구하자. 만약 그런 게\n  없다면 0을 리턴하자.\n\n입력 배열의 길이는 최대 \\(2 \\times 10^5\\) 이고 배열 원소의 값은 \\(-10^4 \\sim 10^4\\) 사이이다. k는 \\(-10^9 \\sim 10^9\\) 사이이다.\n\n원소가 양수였다면…!\n\n만약 원소가 전부 양수였다면, 간단한 투 포인터로 쉽게 풀 수 있는\n 문제이다. 특히 원소가 모두 양수일 때의 접근 방법은 0으로 만드는 최소\n 연산의 횟수에서도\n 쓰인다. 그 방법은 다음과 같다.\n\ndef maxSubArrayLenWithPositiveElements(nums, k):\n    n = len(nums)\n    size = 0\n    start, cur = 0, 0\n    for end in range(n):\n        cur += nums[end]\n        while cur &gt; k and start &lt;= end:\n            cur -= nums[start]\n            start += 1\n        if cur == k:\n            size = max(size, end-start+1)\n    return size\n\n\n즉, 원소가 모두 양수일 때에는 현재까지 누적한 부분 합 cur가 원하는\n 값 k보다 큰 경우, start를 전진시켜서 윈도우 사이즈를 줄이는 것이\n 가능하기 때문에 위와 같은 접근을 할 수 있었다. 하지만 이 문제에서는\n 원소가 음수일 수도 있기 때문에, 위와 같은 조건에서 start를\n 전진시키면 탐색 공간 중 일부를 놓쳐 올바른 답을 구할 수 없게 된다.\n\n\n\n음수가 포함된 경우에는, 부분 합과 해시 테이블을 모두 활용해야\n 한다. 부분 합은 말 그대로 현재 인덱스 i까지의 부분 합을\n 계산해둔다. 만약 이 부분 합이 k와 같다면, 최장 길이 후보는 i +\n 1일 것이다. 해시 테이블에는 현재 부분 합의 위치를\n 기록해둔다. 그럼 이걸 어디다 써먹냐면, 바로 부분 합 - k가 있는 첫\n 위치를 찾을 때 쓴다. 만약 이전에 부분 합을 누적해오던 중에 부분\n 합 - k와 같은 값이 있었다면, 이는 곧 지금의 부분 합에서 이 위치의\n 값을 빼면 k를 얻을 수 있다는 의미이다. 수식으로 쓴다면 지금의 부분\n 합을 cur_sum이라고 했을 때, cur_sum - (cur_sum - k) == k와\n 같다. 따라서 이 cur_sum - k가 나타났던 첫 위치를 알고\n 있다면(우리는 최장 길이를 원하기 때문에 첫 위치만을 기록한다), 지금의\n 위치 인덱스에서 cur_sum - k가 나타났던 위치를 빼면 부분 배열의\n 길이를 알 수 있다.\n\n글로만 설명하니 잘 와닿지 않는다. 예시와 함께 보자.\n\n# 입력\nnums = [-2, -1, 2, 1]\nk = 1\n\n# i = 2 에서의 부분 합 위치 해시 테이블\npartial_sum_loc = {\n    -2: 0,\n    -3: 1,\n    -1: 2,\n}\n# i = 2 에서의 partial_sum\ncur_sum = -1\n\n\n위와 같은 상황을 생각해보자. i = 2 일 때의 스냅샷이다. 이때,\n cur_sum - 1(k) == -2인데, 부분 합 위치 해시 테이블을 살펴보니 -2:\n 0이 있다. 즉, cur_sum - k가 이전에 나타난 적이 있고 그 첫 위치는\n 인덱스 0이라는 뜻이다. 이를 이용하면 우리가 원하는 부분 배열, 즉\n 합이 k가 되는 부분 배열의 시작 인덱스와 끝 인덱스를 알 수 있는데,\n 시작 인덱스는 cur_sum - k 즉 -2가 나타난 바로 다음 위치이고,\n 끝 인덱스는 현재 인덱스인 i = 2이다. 왜 cur_sum - k가 나타난\n 인덱스가 아니라 그 다음 인덱스인지는 굉장히 헷갈리는데, 이는 부분\n 합의 성질 때문이다. cur_sum - k가 나타난 위치에서의 부분 합은 그\n 위치에서의 원래 배열 원소의 값까지 더해진 값이 cur_sum - k와 같고,\n cur_sum은 현재 위치의 원소 값까지 쌓인 값과 같다. 따라서, 우리가\n 기록한 해시 테이블과 부분 합에 의해 구해지는 영역은 (w =\n partial_sum_loc[cur_sum - k] 라고 할 때) w가 아니라 w + 1부터\n i까지의 영역이다. 그림으로 나타내면 아래와 같다.\n\n i: current index\n w = partial_sum_loc[cur_sum - k]\n\n              +-----------------+\n              |/////////////////| &lt;---- cur_sum - (cur_sum - k) == k 가 되는 부분 합 구간\n    +-----+---+-------+-----+---+\n     .... | w | w + 1 | ... | i | ...\n    +-----+---+-------+-----+---+\n    ////////////////////////////|\n    ----------+-----------------+\n    //////////|               ^\n    ----------+               |\n            ^                 |\n            |                 |\n            |              cur_sum\n            |\n            |\n      (cur_sum - k)\n\n\n이 아이디어를 코드로 구현하면 다음과 같다.\n\ndef maxSubArrayLenWithPositiveElements(nums, k):\n    cur_sum = 0\n    max_len = 0\n    partial_sum_loc = {}\n\n    for i, num in enumerate(nums):\n        cur_sum += num\n        candidate = cur_sum - k\n\n        if cur_sum == k:\n            max_len = i + 1\n        if candidate in partial_sum_loc:\n            cand_len = i - partial_sum_loc[candidate]\n            max_len = max(max_len, cand_len)\n\n        # update current partial sum location\n        if cur_sum not in partial_sum_loc:\n            partial_sum_loc[cur_sum] = i\n    return max_len\n\n\n\n  최대의 길이를 구하는 것이 목적이므로 그에 맞게 최대 값을 매번\n구한다.\n  cur_sum이 k와 같을 때에는 굳이 max 연산을 할 필요가 없이 현재\n인덱스까지의 배열 길이가 곧 답이다.\n  cur_sum - k 부분합이 이전에 나타난 적이 있다면 위에서 설명한\n것처럼 부분합이 나타난 위치를 이용해서 길이를 계산한다.\n  루프 마지막에 현재 인덱스에서의 cur_sum의 위치를 기록할 때,\n이전에 기록한 적이 없을 때에만 기록한다. 왜냐하면 우리는 i가\n증가하는 방향으로 배열을 훑고 있고, 최장 길이를 구하고 싶기\n때문이다. 이전에 나타난 적 있는데 또 업데이트 하면 길이가 줄어든다."
					}
					,
					"ps-leetcode-maximum-subarray": {
						"id": "ps-leetcode-maximum-subarray",
						"title": "Maximum Subarray",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/maximum-subarray/",
						"content": "Maximum Subarray\n\n정수 배열 nums가 주어졌을 때, 합이 가장 큰 부분 배열의 합을\n 리턴하자. 부분 배열이란 배열의 연속적인 일부분이다.\n\n배열의 크기는 1~100,000 사이이고 배열의 값은 -10,000~10,000 사이이다.\n\nO(N^2) - 타임아웃\n\n이게 왜 Easy 난이도인지 모르겠네. 아무튼 가장 먼저 Brute Force부터\n 생각해보자. 그냥 모든 합을 다 구해보면서 최대 값을 업데이트 하면\n 된다. 단, 이중 루프를 돌 때 안쪽 인덱스가 바깥쪽 인덱스 이전의 값을\n 볼 필요는 없기 때문에 다음과 같이 하면 족굼 더 낫긴 하지만 여전히\n 타임아웃 난다.\n\ndef maxSubArray(nums):\n    maxsum = float('-inf')\n    for i in range(len(nums)):\n        cursum = 0\n        for j in range(i, len(nums)):\n            cursum += nums[j]\n            maxsum = max(maxsum, cursum)\n\n    return maxsum\n\n\nKadane’s Algorithm\n\n몰랐는데 이 문제를 푸는 유명한 카데인의\n 알고리즘\n 이라는 테크닉이 있다고 한다. 이 방법은 주어진 배열을 훑으면서, 인덱스\n i에 있을 때 인덱스 i로 끝나는 부분배열의 합 중 최대값을 구한다.\n\nLoop Invariant는 다음과 같다. i번째 인덱스에서, current_sum의\n 예전 값은 [0, ..., i-1] 부분 배열의 합 중에서 최대값을 담고\n 있다. 따라서, current_sum + nums[i]는 [0, ..., i] 부분 배열의\n 합이 된다. 여기서 음수가 가능하기 때문에, 실제로는 이전까지 누적 합을\n 버리고 지금 위치에서 새로 시작하는 것이 더 나을 수도 있다. 따라서\n current_sum은 nums[i]가 될 수도 있다.\n\n그리고 매번 current_sum을 업데이트할 때마다, 지금까지 계산한\n current_sum 중에서 최대 값을 업데이트하면, 이게 바로 우리가 원하는\n 값이 된다.\n\n이 아이디어를 구현하면 다음과 같다.\n\ndef maxSubArray(nums):\n    maxsum, cursum = nums[0], nums[0]\n    for n in nums[1:]:\n        cursum = max(cursum + n, n)\n        maxsum = max(maxsum, cursum)\n    return maxsum\n\n\n\n  cursum = max(cursum + n, n) 부분이 바로 위에서 길게 설명한\n부분이다. 현재 위치에서 cursum의 값은 (현재 위치 직전까지의) 이전\n누적 합 중 최대 값이지만, 이걸 버리고 지금 위치에서부터 다시\n시작하는 것이 더 괜찮은 선택일 수 있기 때문이다."
					}
					,
					"ps-leetcode-maximum-units-on-a-truck": {
						"id": "ps-leetcode-maximum-units-on-a-truck",
						"title": "Maximum Units on a Truck",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/maximum-units-on-a-truck/",
						"content": "Maximum Units on a Truck\n\n한 대의 트럭에 박스를 실으려고 한다. 박스 정보가 배열 boxTypes로\n 주어지는데, boxTypes[i] = (numberOfBoxes_i, numberOfUnitsPerBox_i)\n 이고 다음과 같다:\n\n\n  numberOfBoxes_i: i 타입 박스의 개수\n  numberOfUnitsPerBox_i: i 타입 박스 당 유닛의 개수\n\n\n트럭에 최대로 실을 수 있는 박스 개수인 truckSize도 함께\n 주어진다. 이 사이즈만 넘지않으면 어떤 박스를 넣어도 상관없다.\n\n이때, 이 트럭에 실을 수 있는 유닛의 최대 수를 구하자.\n\n박스 정보 배열 크기는 1 ~ 1,000 사이이고 각 박스 타입 원소도 1 ~\n 1,000 이다. 트럭 사이즈는 \\(1 \\sim 10^6\\) 이다.\n\n그리디하게 정렬\n\n트럭에 실을 수 있는 박스는 박스 안의 유닛과 상관없기 때문에, 여기서는\n 그리디하게 가장 많은 유닛이 들어있는 박스부터 채워넣으면 된다. 그럼\n 가장 먼저 떠올릴 수 있는 방법은 정렬하는 것이다.\n\ndef maximumUnits(boxTypes, truckSize):\n    units = 0\n    for box, unit in sorted(boxTypes, key=lambda x: -x[1]):\n        if truckSize - box &gt;= 0:\n            units += (unit * box)\n            truckSize -= box\n        else:\n            units += (unit * truckSize)\n            truckSize = 0\n        if truckSize == 0:\n            break\n    return units\n\n\n정직한 문제 정직한 구현을 했다. 정렬할 때 키 값을 음수로 줘야 가장 큰\n 유닛이 온다는 것 외에는 조심할 것이 없다. 정렬에 가장 많은 연산을 할\n 것이므로 복잡도는 O(NlogN)이다.\n\n그리디하게 힙\n\n좀더 힙한 방법은 힙을 쓰는 것이다. 가장 유닛이 많이 든 빢스부터 채워\n 넣어야 하니 여기서는 최대 힙을 유지하자.\n\nimport heapq\ndef maximumUnits(boxTypes, truckSize):\n    maxheap = [(-bt[1], bt[0]) for bt in boxTypes]\n    heapq.heapify(maxheap)\n    units = 0\n    while maxheap and truckSize:\n        unit, box = heapq.heappop(maxheap)\n        if truckSize - box &gt;= 0:\n            units += -unit * box\n            truckSize -= box\n        else:\n            units += -unit * truckSize\n            truckSize = 0\n    return units\n\n\n파이썬에는 최대 힙이 없기 때문에 키 값으로 유닛의 음수 값을\n 넘겨줬다. 따라서 힙에서 꺼냈을 때 다시 음수로 부호를 바꿔줘야 올바른\n 유닛 값이 된다. 그리고 파이썬의 힙(heapq)은 원소가 튜플일 때 첫\n 번째 원소를 가지고 우선순위를 비교하기 때문에 곧바로 heapify를 할\n 수 있다.\n\n\n\n정직하게 구현했는데 좀더 간결하게 구현할 순 없을까? 잘 살펴보면\n 다음과 같은 사실을 알 수 있다.\n\n  truckSize &gt;= box 일 때 unit * box를, truckSize &lt; box일 때\nunit * truckSize를 누적하고 있다. unit은 같고 곱하는 수만\n달라지고 있는데 잘 보면 box가 더 작을 때 box를, truckSize가\n더 작을 때 truckSize를 곱하고 있다. 따라서 이 둘 중 더 작은 값을\n곧바로 곱할 수 있다.\n  truckSize를 업데이트하는 것도 마찬가지 인데, box와 truckSize\n중 더 작은 값을 빼고 있다.\n\n\n따라서 다음과 같이 코드를 줄일 수 있다.\n\ndef maximumUnits(boxTypes, truckSize):\n    maxheap = [(-bt[1], bt[0]) for bt in boxTypes]\n    heapq.heapify(maxheap)\n    units = 0\n    while maxheap and truckSize:\n        unit, box = heapq.heappop(maxheap)\n        unit = -unit\n        units += unit * min(box, truckSize)\n        truckSize -= min(box, truckSize)\n    return units"
					}
					,
					"ps-leetcode-meeting-rooms": {
						"id": "ps-leetcode-meeting-rooms",
						"title": "Meeting Rooms",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/meeting-rooms/",
						"content": "Meeting Rooms\n\n미팅 룸의 예약 시간을 나타내는 배열 intervals가\n 들어온다. intervals[i] = [start_i, end_i]는 미팅의 시작 시간과 끝\n 시간을 나타낸다. 한 사람이 모든 미팅에 참석할 수 있는지 여부를\n 구하자.\n\n입력 배열의 길이는 1 ~ 10,000 이고 각 미팅 시간의 범위는 0 ~\n 1,000,000이다.\n\n겹치는 부분 구하기\n\n미팅을 시작 시간 (또는 끝 시간으로 해도 됨) 기준으로 정렬했을 때,\n 미팅 범위끼리 겹치는 부분이 있는지를 확인하는 문제이다. 따라서 이전\n 범위의 끝 시간을 기록해두고, 지금 범위의 시작 시간과 겹치면 곧바로\n False이다. 전체를 다 훑었다면 겹치는 부분이 없는 것이므로 참이다.\n\ndef canAttendMeetings(invertals):\n    prev_end = 0\n    for start, end in sorted(intervals, key=lambda x: x[0]):\n        if prev_end &gt; start:\n            return False\n        prev_end = end\n    return True\n\n\nMeeting Rooms II\n\n역시 미팅 룸의 예약 시간 배열 intervals가 주어진다. 이번에는, 모든\n 미팅을 진행하기 위해서 필요한 최소한의 회의실 개수를 구하자.\n\n예를 들어, intervals = [[0,30], [5,10], [15,20]]이라고 하자. 그러면\n [0, 30] 회의와 [5, 10] 회의가 겹치기 때문에 서로 다른 방에서\n 진행되어야 하므로 일단 회의실이 최소 2개는 필요하다. [15, 20]은\n 다른 두 회의가 끝나고 나서 진행할 수 있으므로 남는 회의실을 쓰면\n 된다. 따라서 답은 2이다.\n\n범위는 이전과 같다.\n\n힙\n\n갑자기 난이도가 상승했다. 일단 케이스 하나를 잡고 차근차근\n 따라가보자.\n\n미팅 시간이 [(1, 10), (2, 7), (3, 19), (8, 12), (10, 20), (11,\n 30)]으로 주어졌다고 하자. 이전과 유사하게 겹치는 부분을 알려면 어느\n 기준이든 정렬을 해야하므로, 일단 시작 시간 순으로 정렬했다. 그러면\n 다음 그림처럼 스케쥴링했을 때 회의실을 최소로 사용할 수 있다. 괄호는\n 시작 시간 기준으로 스케쥴링하는 순서이다.\n\n 시간    : 1  2  3           7  8      10  11    12               19   20                      30\n====================================================================================================&gt;\n 회의실1 : |-------------(1)------------|   |------------------------(6)------------------------|\n 회의실2 :    |-----(2)------|  |-------(4)-------|\n 회의실3 :       |----------------------(3)-----------------------|\n 회의실4 :                              |---------------(5)------------|\n\n\n일종의 시뮬레이션을 한다면, 다음과 같은 관찰을 할 수 있다.\n\n  회의실 목록을 유지한다고 하면, 현재까지 할당된 회의실 중 가장\n빨리 끝나는 회의실 정보가 필요하다.\n  괄호 안의 순서를 보면 회의실 1, 2, 3에 차례로 회의실 1, 2, 3이\n할당된 이유는, 기존 회의실 중에서 가장 빨리 끝나는 회의가 지금\n할당하려는 회의와 겹치기 때문이다. 즉, 두번째 회의 (2, 7)을\n할당하려고 할 때, 이미 진행 중인 회의 (1, 10)이 아직 끝나지\n않았으므로 (10 &gt; 2) 어쩔 수 없이 새 회의실에 할당해야 한다.\n  반면 네번째 회의인 (8, 12)가 들어왔을 때, 지금 진행 중인 회의실\n중에서 가장 빨리 끝나는 회의인 (2, 7)가 끝난 이후라서 (8 &gt; 7)\n이 회의실을 재활용할 수 있다.\n  회의실을 재활용 한다는 것은 곧 가장 빨리 끝나는 기존 회의를 지금\n회의로 바꾼다는 것이다. 즉, 가장 빨리 끝나는 회의를 빼고 지금 회의\n정보를 넣는다. 이때 이후 스케쥴링을 위해 회의실 목록은 항상 가장\n빨리 끝나는 회의를 빨리 알 수 있으면 좋겠다. 여기에 적절한\n자료구조는 최소힙이다.\n  마지막 미팅까지 끝냈을 때, 이때까지 예약된 회의실의 개수가 최소\n회의실의 개수이다.\n\n\n이 아이디어를 구현하면 다음과 같다.\n\nimport heapq\ndef minMeetingRooms(intervals):\n    sorted_itvs = sorted(intervals, key=lambda x: x[0])\n    occupied = [sorted_itvs[0][1]]\n\n    for start, end in sorted_itvs[1:]:\n        if occupied[0] &lt;= start:\n            heapq.heapreplace(occupied, end)\n        else:\n            heapq.heappush(occupied, end)\n    return len(occupied)\n\n\n\n  회의실 목록을 최소힙으로 유지한다. 이때 우리가 관심있는 것은 회의가\n끝나는 시간이므로, 시작 시간은 무시하고 그냥 끝나는 시간만 담으면\n된다.\n  파이썬에서의 최소힙은 단지 heapq 함수를 이용해서 원소의 추가와\n삭제를 해서 성질을 유지하는 것만 빼면 첫번째 원소가 최소값인\n리스트와 같다. 따라서 occupied[0]으로 곧바로 현재 회의실 중 가장\n빨리 끝나는 회의 시간을 알 수 있다.\n  회의실을 재활용한다는 것은 가장 빨리 끝나는 회의실에서 지금 회의를\n할당하는 것이다. 재활용이 안되는 경우는 항상 새 회의실을 할당해야\n하므로 곧바로 푸시한다."
					}
					,
					"wip-multicore-ocaml-memory-model": {
						"id": "wip-multicore-ocaml-memory-model",
						"title": "Memory Model",
						"version": "all",
						"categories": "",
						"url": " /wip/multicore-ocaml/memory-model/",
						"content": "OCaml 메모리 모델\nref를 읽을 때 어떻게 될까? 싱글 쓰레드 코드에서는 “뭐가 됐든 가장\n 최근에 쓴 값”을 읽는게 너무 당연하지만, 복잡한 동기화가 필요한 멀티\n 쓰레드 코드에서는 “가장 최근”에 대한 정확한 정의가 어려워진다.\n\n여기서는 이런 미묘한 부분을 어떻게 피하는지, 그리고 “가장 최근”이\n 복잡한 개념이 아닌 상황에서 직관적인 동기화 코드를 어떻게\n 작성하는지를 설명한다. 후자는 세부적인 내용을 살펴봐야 하지만,\n 대부분은 저수준의 동기화 라이브러리를 작성하거나 컴파일러를 해킹해야\n 하는 사람에게 유용한 내용이다 (만약 어플리케이션 코드를 짜는데 이런\n 저수준의 세부 사항에 의존하고 있다면, 뭔가 잘못하고 있는 거다).\n\nHappens-before\nref에서 값을 읽거나 값을 쓰는 것 같은 프로그램의 실행 흐름(trace),\n 또는 일련의 이벤트를 고려하면 실행 중인 OCaml 프로그램과 메모리\n 사이의 상호 작용을 이해할 수 있다 (여기서는 ref를 “수정 가능한\n 메모리 위치”와 같은 의미로 사용한다. 즉, 가변 레코드 필드와 가변\n 오브젝트 멤버는 전부 ref다). 각각의 이벤트는 소스 코드의 읽기와\n 쓰기 연산에 대응하지만, 소스 코드의 특정 연산은 실행할 때마다 매번\n 새로운 이벤트를 생성한다.\n\n싱글 쓰레드 프로그램이 생성하는 이벤트의 순서를 프로그램 순서라고\n 한다. 멀티 쓰레드 프로그램에서는, 여전히 프로그램 순서를 얘기하긴\n 하지만, 더 이상 total order가 아니다. 이벤트는 서로 다른 두 쓰레드가\n 생성하는데, 이 이벤트끼리는 프로그램 순서 상 서로 이전/이후라고 말할\n 수 없다.\n\n프로그램 순서는 소스 코드 안의 연산이 작성된 순서를 나타내지만,\n 반드시 그 이벤트가 발생하는 순서를 명시하지는 않는다. 이벤트는 그\n 순서가 바뀔 수 있고 (reorder), 컴파일러와 CPU에 의해서 합쳐지거나\n 최적화될 수 있다. 신뢰 가능한 순서는 happens-before라는\n relation으로 명시될 수 있다. 만약 이벤트 e1이 이벤트 e2보다\n 먼저 생긴다면(happens-before), 어떤 쓰레드도 e1 없이 e2만\n 관측할 수 없다. 이것을 e1가 e2 이후에\n 발생(happens-after)한다고 한다. 만약 서로가 각각 먼저 생길 수\n 있다면 (happens-before the other), 이들 이벤트들은 동시에\n 발생(happen concurrently)한다고 한다. Happens-before 관계는\n 추이적(transitive; e1 -&gt; e2 이고 e2 -&gt; e3 라면 e1 -&gt; e3)이고\n 비반사관계(어떤 이벤트도 스스로보다 먼저 발생하지 않는다. 즉 \\forall\n e. ~(e -&gt; e))이다.\n\n동기화를 위한 API는 일반적으로 happens-before 관계를 명시한다. 예를\n 들면, 뮤텍스는 한 쓰레드의 Lock 연산이 Unlock 연산 이전에\n 발생(happens-before)하고, Unlock 연산이 그 다음 쓰레드의 Lock\n 연산 이전에 발생(happens-before)하도록 명시한다. 여기서\n happens-before 관계는 refs와 아토믹 참조 Atomic.t로 명시된다.\n\n여기서는 채널과 같은 고수준 동기화에 대해서는 얘기하지\n 않는다. 하지만, 아토믹과 관련하여 보장되는 내용은 고수준의 동기화를\n 구현하는데 충분하다.\n\n읽기, 쓰기, 그리고 경쟁 상태\n가장 기본적인 happens-before 보장(guarantee)은 특정 ref에 대한 싱글\n 쓰레드의 접근에 관한 내용이다.\n\n\n  e1과 e2가 프로그램 순서의 이벤트이고 (즉 같은 쓰레드에 의해서\n순서대로 실행되고) 같은 ref에 접근하고 둘 다 읽기 연산이 아닐 때,\n그러면 e1이 e2에 선행(happens-before)한다.\n\n\n다음과 같은 프로그램을 생각해보자.\n\n1. let r = ref 0 in\n2. let a = !r in\n3. r := 1;\n4. let b = !r in\n5. let c = !r in\n...\n\n\n1, 2, 3 라인은 순서대로 발생한다. 메모리 모델 측면에서 보자면 라인\n 1에서는 참조를 초기화하기 때문에 “쓰기” 연산으로 취급된다. 라인 3은\n 라인 4, 5에 선행하지만, 라인 4와 5는 둘 다 읽기 연산이므로 동시에\n 발생한다.\n\n읽기 이벤트 r이 발생하면, 그 메모리 위치에 대한 어떤 쓰기 이벤트\n w에 의해 쓰여진 값을 읽는다. 초기화도 역시 쓰기 연산이다. 이때\n 어떤 쓰기 이벤트의 값인지는 다음과 같은 규칙에 의해 정해진다.\n\n\n  만약 같은 ref에 대해서 어떤 쓰기 연산 w가 어떤 읽기 연산 r에\n선행하고, 다른 모든 쓰기 연산 w'는 w에 선행하거나 r에\n후행한다면, r은 w가 쓴 값을 읽는다.\n\n\n이 규칙은 항상 적용되지는 않는다. w가 없을 수 있다: 예를 들면,\n r과 동시에 발생하는 쓰기 이벤트가 있을 수 있고, 또는 r에\n 선행하면서 동시에 발생하는 두 개의 쓰기 이벤트가 있을 수 있다. 이\n 규칙이 읽기 이벤트에 적용되지 않을 때, 우리는 이를 데이터 경쟁(data\n race)라고 한다.\n\n프로그램은 아래에서 설명할 아토믹과 같은 동기화를 통해 데이터 경쟁을\n 피해야 한다. C++ 메모리 모델과는 달리, 이 메모리 모델은 데이터 경쟁이\n 있는 상태에서도 상대적으로 강한 보장을 준다. 하지만, 프로그램은\n 여전히 경쟁을 피하기 위해서 노력해야 한다: 이 모델이 보장하는\n 내용(아래의 “Coherence and data races” 참조)은, 데이터 경쟁이\n 프로그램을 작성하는 어떤 합리적인 방법이라는 것이 아니라, 데이터\n 경쟁에 의해 발생하는 피해를 제한하기 위해 존재한다. 예를 들면, OCaml\n 메모리 모델에서, 특정 ref에 대한 데이터 경쟁은 오직 그 ref에 대한\n 미래의 읽기 이벤트들이 이상한 결과를 읽도록 할 뿐, 전체 프로그램이\n C++처럼 정의되지 않은 동작(Undefined Behaviour; UB)을 일으키도록 하는\n 것이 아니다.\n\n이 규칙은 하나의 쓰레드에 의해 사용되는 메모리 참조에 대해서 예상\n 가능한 동작을 보장하는데 충분하다. 위의 예시 프로그램에서, 라인 2의\n 읽기는 라인 1의 초기화 (쓰기)에 의해 쓰여진 값을 읽을\n 것이다. 왜냐하면, 다른 쓰기 연산(라인 3)은 라인 2(읽기)에 후행하기\n 때문이다. 비슷하게, 라인 4와 5의 읽기는 라인 3에서 쓰여진 값을 읽을\n 것인데, 다른 쓰기 연산(라인 1)이 라인 3(쓰기)에 선행하기 때문이다.\n\nAtomics\n위의 규칙이 싱글 쓰레드가 접근하는 ref에 대해서 합리적인 동작을\n 보장하는 반면, 멀티 쓰레드 환경에서는 잘 동작하지 않는다. 예를 들어,\n 아래의 관용적인 메시지 전달 코드를 보자. message는 0으로 초기화\n 된 int ref이고 flag는 false로 초기화된 bool ref 이다.\n\nthread 1:\n1. message := 42\n2. flag := true\n\nthread 2:\n3. let seen = !flag in\n4. let value = !message in\n5. if seen then print_int value\n\n\n이 프로그램에는 데이터 경쟁이 있다. 라인 3에서 flag를 읽는 부분이\n 문제다. 왜냐하면 라인 2에서 값을 쓰는 부분과 동시에 발생하기\n 때문이다. 라인 4에서 message를 읽는 부분도 비슷하게 라인 1의 쓰기\n 부분과 경쟁 상태에 있다. 만약 라인 3의 읽기 연산이 라인 2의 쓰기\n 연산을 읽고, 라인 4의 읽기 연산이 message의 초기화 결과를 읽으면,\n 이 프로그램은 0을 출력할 수도 있다.\n\n더 구체적으로, 이렇게 되는 이유는 다양하다. 예를 들어, 2번 쓰레드가\n message에 먼저 접근한다고 하자.\n\nthread 2:\nlet old = !message in\nlet seen = !flag in\nlet value = !message in\nif seen then print_int value\n\n\n컴파일러는 message를 읽는 두 번쨰 연산을 지우는 최적화를 수행할\n 수도 있다.\n\nthread 2:\nlet old = !message in\nlet seen = !flag in\nlet value = old in\nif seen then print_int value\n\n\n이제 이 프로그램은 seen = true이지만 value = 0인 상태가 될 수\n 있다.\n\n심지어 최적화 없이 실행되더라도, weakly ordered 머신인 ARM이나\n PowerPC에서 실행된다면 이 프로그램은 0을 출력할 수 있다. 이\n 머신들은 flag와 message에서 읽고 쓰는 연산의 순서를 지들 마음대로\n 바꿀 수 있다.\n\n메모리 모델의 관점에서, 이런 (0을 출력하는 것과 같은) 나쁜 동작이\n 허용되는 이유는 쓰레드 1과 쓰레드 2의 연산들 사이에 happens-before\n 관계가 없기 때문이다. 필요한 동기화를 제공하기 위해서 아토믹을\n 써야 한다. 프로그램을 다시 짜서 flag를 Atomic.t로 만들자.\n\nthread 1:\n1. message := 42\n2. Atomic.set flag true\n\nthread 2:\n3. let seen = Atomic.get flag in\n4. let value = !message in\n5. if seen then print_int value\n\n\n이 프로그램은 절대로 0을 출력할 수 없다: 아무것도 출력하지 않을\n 수는 있지만, 출력한다면 그 값은 항상 42이다. 이렇게 되는 이유는\n 아토믹과 관련한 두 가지 규칙 때문인데, 하나는 다음과 같이 싱글\n 쓰레드에서의 happens-before를 명시하는 내용이고:\n\n\n  아토믹에 선행하는 프로그램 순서의 모든 것은 아토믹에 선행하고,\n아토믹에 후행하는 프로그램 순서의 모든 것은 아토믹에 후행한다.\n\n\n다른 하나는 쓰레드 사이의 happens-before를 명시하는 내용이다:\n\n\n  같은 아토믹 참조에 대해서 둘 다 읽기가 아닌 모든 두 개의 이벤트에\n대해서, 둘 중 하나는 다른 하나에 선행한다.\n\n\n첫 번째 규칙에 의해서, 라인 1은 라인 2에 선행하고, 라인 3은 라인 4에\n 선행한다 (싱글 쓰레드). 두 번째 규칙에 의해서, 라인 2와 3 중 하나는\n 다른 하나에 선행 한다 (멀티 쓰레드). 만약 2가 3에 선행하면, 1은 4에\n 선행해야 하므로 프로그램은 42를 출력한다. 반대의 경우 (즉 3이 2에\n 선행하면), 3은 false를 읽게 되고 프로그램은 아무것도 출력하지\n 않는다.\n\n특정 아토믹 참조에 대한 이벤트는 happens-before에 의해서 전순서를\n 갖기 때문에, 아토믹에 대한 데이터 경쟁은 발생할 수 없음을 알아두자.\n\n다른 메모리 모델과의 비교\n이 모델은 데이터 경쟁이 있을 때의 동작을 명시한다. 이는 C++와는\n 다르고 자바와는 같다.\n\n이 모델의 아토믹 참조는 자바의 volatile 변수나 C++의 seq_cst\n 아토믹과 비슷하지만, OCaml 아토믹은 아토믹이 아닌 변수의 순서를\n 바꾸는 것과 관련해서 더 강한 성질을 갖고 있다. 예를 들어, 다음\n 프로그램을 보자.\n\nthread 1:\nAtomic.set x 1\nlet a = !y\n\nthread 2:\ny := 1\nlet b = Atomic.get x\n\n\nOCaml 에서는, x에 접근하는 두 아토믹 중 하나는 다른 하나에\n 선행한다. 만약 set이 먼저 발생하면 b = 1이 된다. get이 먼저\n 발생하면 y에 값을 대입하는 연산이 get에 선행하고, 이는 set에\n 선행하고, 이는 y에서 값을 읽는 연산에 선행하기 때문에, a = 1이\n 된다. 하지만, 자바와 C++ 모두에서는 a = b = 0이 가능하다.\n\n인과 (Causality)\n인과 공리 (Causality axiom)는 다음과 같다:\n\nacyclic(hb | po | rf)\n\n\n위는 herd7라는 메모리 모델\n 시뮬레이터 도구의 문법이다. 이 공리는 모든 로드-버퍼링 동작을\n 금지하여 C++와 자바가 겪는 “갑자기 튀어나온 이상한 값” 문제를\n 제거한다. hb는 happens-before 관계이고, po는 프로그램 순서이고,\n rf는 reads-from 관계(r이 w가 쓴 값을 읽으면 w rf\n r)이다. |는 합(union) 연산이다. acyclic은 관계에 대해 체크하려는\n 성질 이름으로, 여기서는 싸이클이 없어야 한다는 뜻이다.\n\nhb | po | rf에 싸이클이 없도록 요구하는 것은 C++에서 “갑자기\n 튀어나온 이상한 값(out-of-thin-air values)” 문제를 해결하기 위해서\n 제안되었지만, ARM과 PowerPC와 같은 weakly-ordered 머신에서 차후에\n 오는 쓰기(store) 연산이 이전의 읽기(load) 연산에 의존성을 갖게 되어서\n 수많은 의미없는 브랜치를 삽입해야 하기 때문에, 성능 문제로\n 거절되었다. 하지만 OCaml에서는 이런 성능과 관련한 트레이드 오프가\n 다음 두 가지 이유로 인해 받아들일 수 있는 수준이라고 보여진다.\n\n\n  OCaml에서 대부분의 읽기(load) 연산은 값이 변하지 않는\n위치(immutable locations)에 대한 것이므로, 추가적인 브랜치를 삽입할\n필요가 없다.\n  멀티코어 OCaml의 가비지 콜렉터 디자인은 이미 읽기 연산에 대한\n배리어에 대해서 브랜치를 갖고 있기 때문에, 필요한 브랜치는 대부분\n이미 (이걸로 인해) 존재한다.\n\n\nCoherence and data races\n일관 공리(Coherence axiom)는 다음과 같다:\n\nacyclic(co | rf | fr | (hb &amp; loc))\n\n\nco는 coherence order로, 주어진 모든 메모리 위치에 대한 쓰기\n 연산의 전순서이다. fr은 from-reads 관계이고 rf^(-1); co로\n 정의된다. loc는 같은 위치에 대한 이벤트이다.\n\n이 공리의 뜻은 만약 아토믹이 아닌 위치에 대해서 데이터 경쟁이\n 있더라도, 경쟁 중인 쓰기 중 하나는 반드시 경쟁을 이기게 되고 해당\n 메모리 위치의 값은 궁극적으로는 안정화된다는 뜻이다."
					}
					,
					"ps-leetcode-merge-intervals": {
						"id": "ps-leetcode-merge-intervals",
						"title": "Merge Intervals",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/merge-intervals/",
						"content": "Merge Intervals\n\n범위 interval이 (startg, end)로 정의되고 이 범위의 배열이\n 입력으로 들어올 때, 배열 안의 범위 중 서로 겹치는 모든 범위를 합쳐서\n 원래 입력의 범위를 모두 커버하면서 겹치는 부분이 없는 범위의 배열을\n 만들자.\n\n예를 들어서, [(1,3), (2,6), (8,10), (15,18)] 이 있으면 (1,3)과\n (2,6)의 범위가 겹치기 때문에 최종 출력은 [(1,6), (8,10),\n (15,18)]이 된다.\n\n범위의 범위는 0~10000이고 입력 배열의 크기는 최소 1, 최대 10000이다.\n\nO(NlogN)\n\n입력 배열이 정렬되어 있다는 말이 없기 때문에, 합칠 범위를 찾으려면\n 정렬이 필수적이다. 따라서 복잡도는 잘해봐야 O(N*logN)일 수 밖에 없다.\n\n범위의 시작 지점을 기준으로 정렬한 배열 ordered를 만든다. 그리고\n 범위를 합쳐둘 merged 배열에 ordered의 첫 번째 원소를 일단\n 넣어둔다. 문제에서 길이가 최소 1이 보장되기 때문에 특별히 널 체크는\n 하지 않아도 된다.\n\n그 후 ordered의 두 번째 원소부터 꺼내가면서 merged 배열의 제일\n 마지막 원소와 비교하면서 범위가 합쳐지는지를 확인하면서 merged를\n 업데이트 해 나간다. 이때 가능한 케이스는 크게 두 가지이다.\n\n  merged의 마지막 범위와 겹치지 않는 경우: 이 때는 그냥 범위를\n추가하면 된다.\n  merged의 마지막 범위와 겹치는 경우: 즉, 이 경우는 merged의\n마지막 범위의 끝 값과 추가하려는 범위의 시작 값이 겹치는\n경우이다. 이 때는 merged 마지막 범위의 끝 값을 확장해줘야\n하는데, 여기서도 두 가지 경우가 있다.\n    \n      merged의 끝 범위가 더 큰 경우\n      merged의 끝 범위가 더 작은 경우\n    \n  \n\n\n위의 아이디어를 구현하면 다음과 같다.\n\ndef merge(intervals):\n    ordered = sorted(intervals, key=lambda x: x[0])\n    merged = [ordered[0]]\n\n    for itv in ordered[1:]:\n        top = merged[-1]\n        if itv[0] &lt;= top[1]:  # overlapping\n            merged[-1][1] = max(itv[1], merged[-1][1])\n        else:\n            merged.append(itv)\n\n    return merged\n\n\n\n  추가할 범위가 겹칠 때, 끝 값을 업데이트 하는 방법은 두 케이스 중\n그냥 더 큰 값으로 덮어버리면 되므로 max 연산을 쓰면 된다."
					}
					,
					"ps-leetcode-merge-k-sorted-lists": {
						"id": "ps-leetcode-merge-k-sorted-lists",
						"title": "Merge k Sorted Lists",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/merge-k-sorted-lists/",
						"content": "Merge k Sorted Lists\n\nk개의 정렬된 링크드 리스트가 입력으로 들어왔을 때, 이 리스트를 전부\n 합쳐서 하나의 정렬된 링크드 리스트로 만들자.\n\nk는 0~10,000 이고 리스트의 길이는 최대 500이다. 노드의 값의 범위는\n -10,000~10,000이다.\n\nBrute Force\n가장 쉽게 떠오르는 방법은, 모든 리스트를 다 하나의 배열에다 잡아 넣은\n 다음에 정렬하는 것이다. k, n이 생각보다 작기 때문에 이 경우에\n 파이썬의 정렬은 엄청 빠르게 동작한다.\n\n\"\"\"\nclass ListNode:\n    def __init__(self, val=0, next=None):\n        self.val = val\n        self.next = next\n\"\"\"\ndef mergeKLists(lists: List[ListNode]):\n    vals = []\n    for node in lists:\n        while node:\n            vals.append(node.val)\n            node = node.next\n\n    sentinel = ListNode()\n    node = sentinel\n    for v in sorted(vals):\n        node.next = ListNode(v)\n        node = node.next\n    return sentinel.next\n\n\n\n  이론적인 복잡도는 O(nlogn)인데, 문제의 k, n이 작기 때문에 엄청\n빠르게 동작한다.\n\n\nMerge\n두 개의 정렬된 리스트를 합치는 방법을\n 그대로 적용해볼 순 없을까? 물론 가능하다. 단, k가 최대 10,000이기\n 때문에, 좋지 못한 복잡도를 얻게 된다.\n\n그래도 일단 두 개를 합치는 방법과 같은 방법으로 합쳐보자. 몇 개인진\n 모르겠지만, 아무튼 합칠려는 노드 중에서 가장 값이 작은 노드를 찾고,\n 그 값을 추가하고, 이후 반복하면 된다. 노드의 값의 범위가 -10,000 ~\n 10,000 사이 이기 때문에 이를 이용해서 최소 값의 위치를 구하면 되겠다.\n\ndef mergeKLists(lists: List[ListNode]):\n    sentinel = ListNode()\n    node = sentinel\n\n    while True:\n        min_val = float('inf')\n        min_idx = -1\n        for i, n in enumerate(lists):\n            if n and n.val &lt; min_val:\n                min_idx = i\n                min_val = n.val\n\n        if min_idx == -1:\n            break\n\n        node.next = ListNode(min_val)\n        lists[min_idx] = lists[min_idx].next\n        node = node.next\n\n    return sentinel.next\n\n\n\n  역시 리스트 문제에는 센티넬 노드를 활용해야 코드가 깔끔해진다.\n  매번 노드의 리스트를 돌면서 최소 값을 가진 노드의 위치와 값을\n찾아낸다. 그리고 해당 값으로 새 리스트에 노드를 추가하고, 노드와 새\n리스트를 모두 다음 단계로 전진한다. 이때 주의할 점은, 새 리스트를\n만드는데 쓰이는 노드 변수 node와 대상 노드 리스트 중 최소 값을\n찾기 위해 쓰이는 노드 변수 n에 같은 이름을 쓰면 안된다는\n점이다. 파이썬의 시맨틱 상 n이 for 루프 범위에서만 살아있지\n않고 루프가 끝나도 계속 살아있기 때문에, 자칫하면 node를 덮어버릴\n수 있어서 무한 루프에 빠지게 된다.\n  이론적인 복잡도는 O(nk)이지만, 문제에서 k가 생각보다 크기 때문에\n5~7초라는 어마어마한 시간이 소요된다.\n\n\nHeap\n\n좀더 빠르게 병합할 수 있는 방법은 없을까? 첫 번째 방법에서는 최소의\n 원소를 찾기 위해서 매번 k번의 반복을 돌아야 했는데, 이걸 줄일 수 있게\n 해주는 데이터 타입이 바로 힙이다. 힙의 성질을 이용하면 O(nlogk) 의\n 복잡도를 얻을 수 있다.\n\n파이썬에는 두 종류의 힙이 있는데, 하나는 collections에 있는\n heapq이고 다른 하나는 queue에 있는\n PriorityQueue이다. PriorityQueue가 내부적으로 heapq을 이용해서\n 구현되어 있다. 힙의 성질을 구현한 자료 구조는 heapq이고, 실제\n 쓰레드나 프로세스 간 메시지 패싱에 사용되는 라이브러리는\n PriorityQueue이다. 실제 사용 상에서 살짝 차이가 나는 부분이 있지만\n 거의 유사하기 때문에 여기서는 둘 다 구현해보자.\n\n방법은 O(nk)에서 최소 값을 구하는 O(k)의 로직을 힙을 이용한 O(logk)의\n 로직으로 바꾸는 것이다.\n\nimport heapq\ndef mergeKLists(lists):\n    sentinel = ListNode()\n    node = sentinel\n\n    setattr(ListNode, \"__lt__\", lambda self, other: self.val &lt; other.val)\n    heap = []\n    for n in lists:\n        if n:\n            heapq.heappush(heap, n)\n\n    while heap:\n        top = heapq.heappop(heap)\n        node.next = ListNode(top.val)\n        node = node.next\n        if top.next:\n            heapq.heappush(heap, top.next)\n\n    return sentinel.next\n\n\n\n  heapq는 따로 생성자가 있는 자료구조가 아니라, 파이썬의 리스트를\n힙으로 만들어주는 라이브러리이다.\n  힙에 넣을 오브젝트는 반드시 비교 가능해야 한다. 특히 &lt; 연산을\n지원해야 하는데, 문제의 ListNode에는 해당 어트리뷰트가 없다. 이걸\n우회하는 방법은 두 가지가 있는데, 하나는 ListNode를 상속받아서\nwrapper 클래스를 만들어서 이걸 사용하는 것이고, 다른 하나는 위의\n코드처럼 setattr 함수를 이용해서 ListNode에 직접 __lt__\n메소트 어트리뷰트를 박는 것이다. 추가로, None은 비교 가능하지\n않기 때문에, 힙에는 절대 None을 추가하면 안된다. 그래서 힙에\n추가하기 전에 널체크를 해야 한다.\n\n\nPriorityQueue로 하는 구현은 위와 살짝 다르다.\n\nfrom queue import PriorityQueue\ndef mergeKLists(lists):\n    sentinel = ListNode()\n    node = sentinel\n\n    setattr(ListNode, '__lt__', lambda self, other: self.val &lt; other.val)\n    pq = PriorityQueue()\n    for n in lists:\n        if n:\n            pq.put(n)\n\n    while not pq.empty():\n        top = pq.get()\n        node.next = ListNode(top.val)\n        node = node.next\n        if top.next:\n            pq.put(top.next)\n\n    return sentinel.next\n\n\n\n  PriorityQueue는 생성자가 있는 클래스 자료구조이다.\n  heapq의 empty check는 리스트 자체를 사용했지만, PriorityQueue는\n생성하는 순간 메모리에 올라가기 때문에 empty check을 하려면\nPriorityQueue.empty() 메소드를 호출해야 한다."
					}
					,
					"ps-leetcode-merge-two-sorted-lists": {
						"id": "ps-leetcode-merge-two-sorted-lists",
						"title": "Merge Two Sorted Lists",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/merge-two-sorted-lists/",
						"content": "Merge Two Sorted Lists\n\n두 개의 정렬된 리스트가 입력으로 들어온다. 이 두 개의 리스트를 합쳐서\n 하나의 정렬된 리스트로 만들자.\n\n노드의 개수는 둘 다 0~50이다. 두 리스트는 모두 비내림차순으로\n 정렬되어 있다. 즉 같은 수가 있을 수 있다.\n\n센티넬 + 병합\n\n병합 정렬에서 하던 것처럼 그냥 병합을 잘 구현하면 된다. 비내림차순\n 정렬이므로 같은 원소가 있을 수 있는 것에 주의하면 된다.\n\n리스트를 다룰 때의 한가지 팁은 늘 센티넬 노드를 활용하라는\n 것이다. 그러면 대부분의 리스트 코드가 깔끔해진다. 여기서도 센티넬\n 노드를 활용하면 둘 중 빈 리스트가 어떤 것인지를 특별히 확인하지\n 않아도 된다는 장점이 있다.\n\n아이디어를 코드로 구현해보자.\n\n\"\"\"\nclass ListNode:\n    def __init__(self, val=0, next=None):\n        self.val = val\n        self.next = next\n\"\"\"\ndef mergeTwoLists(l1, l2):\n    sentinel = ListNode()\n    n = sentinel\n    n1, n2 = l1, l2\n    while n1 and n2:\n        if n1.val &lt; n2.val:\n            n.next = ListNode(n1.val)\n            n1 = n1.next\n        else:\n            n.next = ListNode(n2.val)\n            n2 = n2.next\n        n = n.next\n    while n1:\n        n.next = ListNode(n1.val)\n        n, n1 = n.next, n1.next\n    while n2:\n        n.next = ListNode(n2.val)\n        n, n2 = n.next, n2.next\n    return sentinel.next\n\n\n\n  non-decreasing order 이므로 n1 &lt; n2 일 때 n1의 값을 택한다.\n  센티넬을 이용해서 새로운 리스트의 루트를 sentinel.next에 담도록\n한 덕분에 리스트가 비어있는지 확인하지 않아도 된다. 코드가\n깔끔해졌다."
					}
					,
					"ps-leetcode-middle-of-the-linked-list": {
						"id": "ps-leetcode-middle-of-the-linked-list",
						"title": "Middle of the Linked List",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/middle-of-the-linked-list/",
						"content": "Middle of the Linked List\n\n링크드 리스트의 헤드 노드가 주어졌을 때, 리스트의 중간에 있는 노드를\n 찾는 문제다. 만약 중간이 두 개라면(즉, 리스트 길이가 짝수) 두 번째\n 노드를 리턴하자. 리스트의 크기는 1~100 사이이다.\n\n배열에 저장\n\n가장 떠올리기 쉬운 방법은, 순서대로 전부 배열에다 저장한 다음에 그냥\n 배열 인덱스 계산으로 중간에 있는 것을 돌려주는 것이다. 중간에 두 개\n 있을 때 두 번째 걸 리턴하는 건 배열 길이가 짝수일 때 2로 나눈 값과\n 같으므로 trivial 하다.\n\ndef middleNode(head):\n    array = []\n    while head:\n        array.append(head)\n        head = head.next\n    return array[len(array)//2]\n\n\n투 포인터 - Fast and Slow\n\n다른 방법도 있다. 두 개의 포인터로 동시에 리스트를 훑을 건데, 하나는\n 한 칸씩 가고 다른 하나는 한번에 두 칸씩 간다. 즉, 속도가 두 배\n 차이나게 간다. 그러면 두 칸씩 가는 애가 끝에 도달했을 때 한 칸씩 가는\n 애가 있는 위치가 중간이 된다. 그림을 보면 좀더 이해가 쉽다. 한 칸씩 가는 애를 slow, 두 칸씩 가는 애를 fast라고 하면 다음과 같다.\n\n(홀수)\n  | 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5\n--+----------------------\n0 |s,f\n1 |      s    f\n2 |           s         f\n\n(짝수)\n  | 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5 -&gt; 6\n--+---------------------------\n0 |s,f\n1 |      s    f\n2 |           s         f\n3 |                s              f\n\n\n즉, fast.next가 있을 때 두 칸씩 가면 slow는 우리가 원하는 지점에\n 있게 된다.\n\ndef middleNode(head):\n    slow, fast = head, head\n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n    return slow"
					}
					,
					"ps-leetcode-minimum-deletions-to-make-character-frequencies-unique": {
						"id": "ps-leetcode-minimum-deletions-to-make-character-frequencies-unique",
						"title": "Minimum Deletions to Make Character Frequencies Unique",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/minimum-deletions-to-make-character-frequencies-unique/",
						"content": "Minimum Deletions to Make Character Frequencies Unique\n\n어떤 문자열 s의 모든 글자가 모두 다른 빈도로 나타나면\n 좋다고 정의하자.\n\n문자열이 주어졌을 때, 이 문자열을 좋게 만들기 위해서 삭제해야하는\n 글자의 최소 개수를 구하자.\n\n문자열에서 글자의 빈도란 문자열에서 글자가 나타나는 횟수를\n 뜻한다. 예를 들어 \"aab\"에서 a의 빈도는 2이고 b의 빈도는\n 1이다. 모든 글자의 빈도가 다르므로 이 문자열은 좋다.\n\n문자열의 길이는 1 ~ 100,000 사이이고 알파벳 소문자만 포함한다. 빈도가\n 0인 글자, 즉 문자열에 등장하지 않는 글자는 문자열의 좋음과 상관없다.\n\n중복이 없어질 때까지 빼기\n\n일단 문자열에서 글자의 빈도를 세는 것은 쉽다. 그 다음이\n 문제다. 빈도를 기준으로 중복을 찾아서, 중복이 없을 때까지 각각의\n 글자를 하나 씩 빼야한다. 글자가 두 개만 중복이면 쉽게 하겠지만 그런\n 조건이 없으므로, 실제로 중복되는 글자는 알파벳 소문자 수 만큼인 최대\n 26개가 가능할 것이다. 그렇다고 26개를 일일이 처리하는 것은 바보같은\n 짓이다. 뭔가 좀더 똑똑한 방법이 있을 것이다.\n\n일단 빈도를 셌으면 사실 그게 무슨 글자인지는 더 이상 알 필요가\n 없다. 빈도 값만 겹치지 않게 빼면서 유니크한 빈도 집합을 만들면\n 된다. 빈도를 쭉 훑으면서 이전에 나온 빈도를 기록해둔다고 하자. 그러면\n 어느 시점에서 이전에 나온 빈도와 같은 부분을 찾게 된다. 그 다음은?\n 빈도가 같은게 없을 때까지 계속 1씩 빼는 수밖에 없다. 그렇게 빼서\n 이전에 나온 빈도와 겹치지 않는 빈도 값을 찾았다면, 그 빈도를 빈도\n 집합에 넣으면 된다.\n\n이때 한 가지 예외는 바로 빈도가 0이 되는 경우다. 빈도가 0이면\n 문자열의 좋고 나쁨에 영향을 주지 않기 때문에 더 이상 뺄 필요가 없다.\n\n이 아이디어를 구현해보자.\n\ndef minDeletions(s):\n    deleted = 0\n    seen_freq = set()\n    for freq in Counter(s).values():\n        while freq &gt; 0 and freq in seen_freq:\n            freq -= 1\n            deleted += 1\n        seen_freq.add(freq)\n    return deleted\n\n\n시간 복잡도는 어떻게 될까? 문자열의 길이를 N, 가능한 최대의 글자\n 개수를 K라고 하면 (1 &lt;= K &lt;= 26), O(N + K^2)이 된다. 일단\n 빈도를 세는데 (Counter(s)) O(N)이 소요되고, 그 다음 각각의 빈도\n 값에 대해서 중복이 없을 때까지 1씩 빼야하는데, 최악의 경우 모든\n 글자가 전부 같은 빈도 값이면 빈도 전체에 대해서 2중 반복문을 도는\n 것과 마찬가지 이므로 K^2이 된다. 따라서 O(N + K^2)이다. 공간\n 복잡도는 빈도 기록을 위한 해시 셋만 필요하므로 O(K)이다.\n\n가장 큰 중복부터 제거하기\n\n중복을 제거하는 방법 중에 재밌는게 많아서, 여러가지를 보다가 이해하기\n 쉽고 괜찮은 것을 하나 더 가져왔다. 바로 힙을 이용하는 것이다.\n\n일단 빈도를 세서 값만 유지하는 것은 이전의 해시셋 접근과\n 같다. 여기서는 셋을 유지하지 않고 곧바로 이 빈도 목록을 최대 힙으로\n 만들어서 활용한다. 최대 힙인 이유는 우리가 가능한 연산이 빼기\n 연산이기 때문에, 가장 큰 친구부터 빼는 것이 유리하기 때문이다. 아무튼\n 이 최대 힙을 가지고 유지하고 싶은 불변식은 바로 최대 힙에서 두 번\n pop한 결과가 같지 않도록 하는 것이다. 즉, 가장 큰 두 빈도가 같으면,\n 이 중 한 친구를 1씩 빼면서 다시 힙에 넣어서 두 빈도가 같지 않을\n 때까지 반복하는 것이다. 굉장한 아이디어다. 이거는 나중에 유사한\n 문제가 나왔을 때에도 써먹을 수 있을 것 같아서 기록해둔다.\n\ndef minDeletions(s):\n    maxheap = [-f for f in Counter(s).values()]\n    heapq.heapify(maxheap)\n    deleted = 0\n    while len(maxheap) &gt;= 2:\n        top = heapq.heappop(maxheap)\n        if top != 0 and top == maxheap[0]:\n            deleted += 1\n            heapq.heappush(maxheap, top + 1)\n    return deleted\n\n\n\n  참고로 파이썬에서 힙을 만드는 가장 빠른 방법은 일일이 값을\nheapq.heapush로 넣는 것이 아니라, 일단 값을 리스트에 다\n때려박은 다음에 heapq.heapify를 호출하는 것이다. 얼핏 생각하면\n“어차피 모든 원소에 대해서 (O(N)) 힙을 하나씩 푸시하는 건\n똑같을테니(O(logN)) 복잡도는 둘다 O(NlogN)아닌가?” 라고\n생각되겠지만, 이게 생각보다 이론적인\n복잡함이\n있고 아무튼 결론은 일일이 푸시하는 것보다 리스트를 힙 성질이\n유지되도록 바꾸는 것이 더 빠르다고 한다. 정확한 복잡도 O(N)이라고\n하는데 사실 식을 유도해서 증명한 건 이해못했고 아무튼 더 빠르다\n라고만 알고 쓴다.\n  최대 힙에 원소가 최소 2개는 있어야 두 빈도가 같은지 확인할 수 있기\n때문에 루프의 조건식은 두 개 이상일 때에만 이다.\n  파이썬은 최대힙이 없기 때문에 그냥 부호를 뒤집어서 사용했다. 그래서\n실제로는 빼는 연산이지만 여기서는 더하는 연산으로 바꿨다.\n  마찬가지로 빈도가 0이 되는 케이스는 무시한다.\n\n\n이렇게하면 실제 복잡도는 O(N + K^2logK)로 해시셋보다는 약간\n 나빠지지만 logK가 별로 크지 않아서 거의 차이는 없을 것으로\n 생각된다."
					}
					,
					"ps-leetcode-minimum-difference-between-largest-and-smallest-value-in-three-moves": {
						"id": "ps-leetcode-minimum-difference-between-largest-and-smallest-value-in-three-moves",
						"title": "Minimum Difference Between Largest and Smallest Value in Three Moves",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/minimum-difference-between-largest-and-smallest-value-in-three-moves/",
						"content": "Minimum Difference Between Largest and Smallest Value in Three Moves\n\n정수 배열 nums가 주어진다. 한 번의 행동으로 아무 원소 하나를 골라서\n 아무런 값으로 바꿀 수 있다. 이때, 최대 세 번 행동한 이후에 배열에서\n 가장 큰 값과 가장 작은 값의 차이 값의 최소값을 구하자.\n\n배열의 길이는 1 ~ 100,000, 값은 \\(-10^9 \\sim 10^9\\)이다.\n\n예를 들어 [5,3,2,4]에 대해서는 [2, 2, 2, 2]로 바꾸면 최대값과\n 최소값이 같아져서 차이값은 0이 된다.\n\n단계 별로 생각하기\n\n일단 가장 작은 값과 가장 큰 값을 알아야 하니까 정렬은 필수적이다. 그\n 다음은 어떻게 접근해야 할까?\n\n처음에 든 생각은, 중위값을 기준으로 가장 큰 값과 가장 작은 값을\n 비교해가면서 더 큰 차이가 나는 쪽을 중위값으로 바꾸면 되지 않을까?\n 였는데, 곧바로 반례를 찾을 수 있었다.\n\n올바른 접근은 차근차근 단계 별로 생각하는 것이다. 문제의 조건인\n 최대 3번의 행동을 단계로 쪼개자.\n\n만약 0번의 행동, 즉 한 번도 움직일 수 없다면, 가장 큰 값과 가장 작은\n 값의 차이 값의 최소 값은 그냥 최대 값에서 최소 값을 뺀 값이다. 파이썬\n 인덱스를 이용해서 표현하면 (정렬된 배열을 기준으로) diff(0, -1)이\n 된다.\n\n만약 1번의 행동만 할 수 있다면? 딱 하나를 아무 값으로 바꿀 수\n 있으니까, 다음 중 더 작은 값일 것이다:\n\n  두 번째로 큰 값과 최소 값의 차이. 이를 파이썬 인덱스를 이용해서\ndiff(0, -2)으로 표기하자.\n  두 번째로 작은 값과 최대 값의 차이. 역시 이는 diff(1, -1)이 된다.\n\n\n즉, 정렬된 배열을 기준으로 하나, 최대값을 빼던가 아니면 최소값을\n 빼던가 했을 때의 차이 중 더 작은 것이 답이 된다. 여기서 아무 값\n 으로 바꿀 수 있기 때문에 그냥 단순히 배열에서 삭제하는 걸로 이해해도\n 무방하다.\n\n만약 2번의 행동이 가능하다면? 다음 중 최소일 것이다.\n\n  세 번째로 큰 값과 최소 값의 차이, 즉 diff(0, -3)\n  세 번째로 작은 값과 최대 값의 차이, 즉 diff(2, -1)\n  두 번째로 큰 값과 두 번째로 작은 값의 차이, 즉 diff(1, -2)\n\n\n따라서, 문제의 조건인 3번의 행동이 가능하다면, 다음 값 중 최소일\n 것이다:\n\n  네 번째로 큰 값과 최소 값의 차이, diff(0, -4)\n  세 번째로 큰 값과 두 번째로 작은 값의 차이, diff(1, -3)\n  두 번째로 큰 값과 세 번째로 작은 값의 차이, diff(2, -2)\n  최대 값과 네 번째로 작은 값의 차이, diff(3, -1)\n\n\n따라서, 위의 값 차이 중 가장 작은 값을 구하면 된다.\n\ndef minDifference(nums):\n    if len(nums) &lt;= 4:\n        return 0\n    nums = sorted(nums)\n    candidates = [\n        nums[-4] - nums[0],\n        nums[-3] - nums[1],\n        nums[-2] - nums[2],\n        nums[-1] - nums[3],\n    ]\n    return min(candidates)\n\n\n\n  정렬 후 최대 4개의 인덱스를 봐야 하기 때문에, 길이가 4보다 작은\n경우는 오버플로우가 발생할 수 있다. 만약 길이가 4보다 작거나\n같다면, 3번의 행동 안에 모든 값을 다 같게 만들 수 있으므로 답은 0이\n된다. 따라서 이 경우를 먼저 처리해줄 수 있다.\n  나머지는 차근차근 문제의 조건에 맞는 후보 값을 구해서 최소 값을\n구한다.\n\n\n\n\n여기서 좀더 파이써닉하게 풀면 다음과 같이 할 수 있다.\n\ndef minDifference(nums):\n    nums = sorted(nums)\n    return min(y - x for x, y in zip(nums[:4], nums[-4:]))\n\n\n파이썬의 zip 연산과 슬라이싱 연산을 이용한다. nums[:4]는\n nums[0]부터 nums[3]까지, nums[-4:]는 nums[-4]부터\n nums[-1]까지이다. 따라서 이들을 순서대로 zip으로 묶어버리면\n 우리가 원하는 후보자와 정확히 일치한다. 또한 슬라이싱 연산자는 배열\n 크기를 넘어버리는 경우도 알아서 처리해주기 때문에 (짤림), 이 경우에는\n 입력 배열의 길이를 미리 쳐낼 필요가 없다. 어차피 길이가 4보다 작거나\n 같은 경우는 nums[:4]도 nums[-4:]도 배열 전체가 될 것이고 그러면\n 자연스럽게 최소 차이 값인 0을 얻을 수 있다."
					}
					,
					"ps-leetcode-minimum-difficulty-of-a-job-schedule": {
						"id": "ps-leetcode-minimum-difficulty-of-a-job-schedule",
						"title": "Minimum Difficulty of a Job Schedule",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/minimum-difficulty-of-a-job-schedule/",
						"content": "Minimum Difficulty of a Job Schedule\nd 일의 기간 안에 업무 일정을 스케쥴링 하려고 한다. 업무는 서로\n 의존적이다. 즉, i 번째 업무를 하려면 모든 0 &lt;= j &lt; i 인 j\n 업무들이 완료되어야 한다.\n\n매일 하루에 최소한 하나의 업무는 끝내야 한다. 업무 스케쥴의 총\n 난이도는 d 일 동안의 난이도의 합과 같다. 하루의 난이도는 그 날\n 완료할 업무의 난이도 중 가장 높은 난이도와 같다.\n\n업무 난이도 목록 jobDifficulty랑 기간 d가 주어진다. i 번째\n 업무의 난이도는 jobDifficulty[i] 이다.\n\n가능한 업무 스케쥴링의 총 난이도 중 최소의 난이도를\n 구하자. 불가능하면 -1을 리턴한다.\n\n예를 들어 jobDifficulty = [6, 5, 4, 3, 2, 1] 이고 d = 2 라고\n 하자. 가능한 최소의 난이도는 7이 되는데, 그 이유는 첫날 (2, 3, 4,\n 5, 6) 총 다섯 작업을 완료하고 다음날 1의 작업을 하면 된다.\n\n반면 jobDifficulty = [9, 9, 9] 이고 d = 4이면, 가능한 스케쥴링이\n 없기 때문에 -1이다.\n\n다이나믹 프로그래밍\n접근 방법이 선뜻 떠오르지 않는 문제였다. 일단 예시를 보면 가장\n 간단하게 처리할 수 있는 케이스가 하나있는데, 바로 스케쥴링이 불가능한\n 경우다. 업무의 개수가 일정보다 작으면 일정마다 업무 1개를 할당할 수\n 없기 때문에 불가능하다.\n\ndef min_difficulty(jobDifficulty, d):\n    if len(jobDifficulty) &lt; d:\n        return -1\n\n\n그 다음은 어떻게 접근해야할까?\n\n이 문제는 결국 다음과 같다:\n\n\n  주어진 리스트를 d개로 나눌건데, 각 부분의 최대 값의 전체 합이\n최소가 되게 한다.\n\n\n그럼 Brute Force를 생각해보면, 가능한 모든 부분을 다 만들어본 다음에,\n 각 부분의 최대값들의 합이 최소가 되는 값을 구하면 된다. 예를 들어\n (a, b, c, d)의 업무가 있고 이걸 3일에 나눠서 스케쥴링 하는 문제를\n 생각해보자. 이는 곧, 이 4개의 업무를 3개로 나누면서 해당 조건을\n 만족하게끔 하는거다.\n\n먼저 첫째날에 가능한 경우를 생각해보자. 주어진 업무가 순서대로\n 진행되어야 하므로, 갑자기 c 를 하거나 할 순 없다. 따라서 첫째날은\n 항상 a 부터 가능한데, 이는 곧 인덱스 0부터를 뜻한다. 그럼 첫째날\n 가능한 업무의 인덱스 범위는 어디까지일까? 총 3일에 걸쳐 해야하므로\n 첫째날에 4개의 모든 업무를 해버리면 안된다. 따라서 최소 이틀에 하나\n 씩 할 양, 즉 (d - 1) 만큼의 양은 보장해줘야 한다. 즉 인덱스의\n 범위는 len(jobDifficulty) - (d - 1) - 1까지 이다.\n\n이걸 토대로 Brute Force를 구현하면 다음과 같다.\n\ndef min_difficulty(jobDifficulty, d):\n    if len(jobDifficulty) &lt; d:\n        return -1\n\n    def dfs(idx, day):\n        if day == d:\n            # no more division is possible.\n            # return the maximum among all remainings\n            return max(jobDifficulty[idx:])\n\n        min_diff = float('inf')  # accum minimum sum of each day's difficulties\n        day_diff = 0  # accum day's possible maximum difficulty\n\n        for i in range(idx, len(jobDifficulty) - d + day)):\n            day_diff = max(day_diff, jobDifficulty[i])\n            min_diff = min(min_diff, day_diff + dfs(i + 1, d + 1))\n\n        return min_diff\n\n    return dfs(0, 1)\n\n\n  idx는 지금 날짜에 배치 가능한 업무의 시작 인덱스\n이다. 여기부터 시작해서 가능한 업무의 인덱스 범위 사이 중에서 가장\n큰 난이도를 찾아야 한다. 이때 1일 차에서 시작해서 d까지\n진행하기 때문에, len(jobDifficulty) - d + day 까지의 범위가 되고\nrange를 썼기 때문에 마지막 - 1은 생략된다. 가능한 범위를\n확인하면서 최대값을 누적하고, 동시에 합의 최소값을 누적한다. 이때\n합의 최소는 현재 난이도 + 다음 날짜들의 난이도 합 중 최소가 된다.\n  day가 마지막 날이 되버리면, 남은 업무를 더 이상 쪼갤 수 없기\n때문에 이때 가능한 난이도는 현재 인덱스부터 끝까지 중에서 최대\n값이다.\n\n\n당연하지만, 이렇게 무식하게 짜면 복잡도가 엄청나다. 그렇다면 과연\n 여기에 중복되는 문제가 있을까? (a, b, c, d, e) 를 3일로 나누는\n 예시를 생각해보자.\n\n먼저 첫째날 가능한 범위는 max(a)와 max(a, b), max(a, b, c) 세\n 가지이다. 총 5개이고 첫째날이므로, 5 - 3 + 1 = 3이기 때문이다.\n\n(a, b, c, d, e)\n-&gt; max(a) -&gt; next(b, c, d, e)\n-&gt; max(a, b) -&gt; next(c, d, e)\n-&gt; max(a, b, c) -&gt; next(d, e)\n\n\n이 두 가지 경우에 대해서 다음 이틀 동안의 스케쥴을 구하는 함수를\n 퉁쳐서 next라고 하면 위 그림과 같다. 첫번째 next(b, c, d, e)는\n 이틀 동안 (b, c, d, e) 네 가지 업무를 스케쥴링하는 것이고,\n 두번째 next(c, d, e)는 이틀동안 (c, d, e) 세 가지 업무를 스케쥴링\n 하는 것이고, next(d, e)는 (d, e) 두 가지 업무를 스케쥴링 하는\n 것이다. 먼저 next(b, c, d, e)를 풀어 생각해보자.\n\n(a, b, c, d, e)\n-&gt; max(a) -&gt; max(b) -&gt; next(c, d, e) = max(c, d, e)\n-&gt; max(a) -&gt; max(b, c) -&gt; next(d, e) = max(d, e)\n-&gt; max(a) -&gt; max(b, c, d) -&gt; next(e) = max(e)\n\n\n이틀을 쪼개야 하므로 가능한 경우는 위 그림과 같다. 이때 마지막 날에는\n 남은 날짜가 하루 뿐 (즉, day가 d가 됨)이기 때문에, dfs 콜의 base\n case에 해당한다.\n\n그럼 이번에는 next(c, d, e)를 풀어 생각해보자.\n\n(a, b, c, d, e)\n-&gt; max(a, b) -&gt; max(c) -&gt; next(d, e) = max(d, e)\n-&gt; max(a, b) -&gt; max(c, d) -&gt; next(e) = max(e)\n\n\n슬슬 중복이 보이고 있음을 알 수 있다. 남은 것도 풀어 생각해보자.\n\n(a, b, c, d, e)\n-&gt; max(a, b, c) -&gt; max(d) -&gt; next(e) = max(e)\n\n\n남은 날짜가 이틀 밖에 안되기 때문에 자명하게 풀린다. 모든 케이스를\n 나열하면 다음과 같다.\n\n(a, b, c, d, e)\n-&gt; *max(a) -&gt; max(b) -&gt; next(c, d, e) = max(c, d, e)\n-&gt; *max(a) -&gt; max(b, c) -&gt; *next(d, e) = max(d, e)\n-&gt; *max(a) -&gt; max(b, c, d) -&gt; *next(e) = max(e)\n-&gt; *max(a, b) -&gt; max(c) -&gt; *next(d, e) = max(d, e)\n-&gt; *max(a, b) -&gt; max(c, d) -&gt; *next(e) = max(e)\n-&gt; max(a, b, c) -&gt; max(d) -&gt; *next(e) = max(e)\n\n\n중복되는 케이스에는 *를 찍어놨다. 이 작은 케이스에서도 중복 계산이\n 꽤 많이 발생함을 알 수 있다. 따라서, 여기서도 메모아이제이션을\n 활용하면 복잡도를 확 줄일 수 있다.\n\nfrom functools import cache\n\ndef min_difficulty(jobDifficulty, d):\n    if len(jobDifficulty) &lt; d:\n        return -1\n    @cache\n    def dfs(idx, day):\n        if day == d:\n            # no more division is possible.\n            # return the maximum among all remainings\n            return max(jobDifficulty[idx:])\n\n        min_diff = float('inf')  # accum minimum sum of each day's difficulties\n        day_diff = 0  # accum day's possible maximum difficulty\n\n        for i in range(idx, len(jobDifficulty) - d + day)):\n            day_diff = max(day_diff, jobDifficulty[i])\n            min_diff = min(min_diff, day_diff + dfs(i + 1, d + 1))\n\n        return min_diff\n\n    return dfs(0, 1)\n\n\n번외: 구간 평균의 합 중에서 가장 큰 합 구하기\nLargest Sum of Averages 를 아주 유사한 접근으로 풀 수 있다. 숫자 배열\n A를 K 개의 그룹으로 쪼갤 때, “점수”는 각 그룹의 평균의\n 합이다. 이때 가장 큰 합은 뭘까?\n\n위의 DFS 접근이 결국 인덱스마다 상태(최대값)을 구하고 이 상태로부터\n 가능한 다음 상태(난이도의 합) 중에서 최소 값을 구하는 문제였다면, 이\n 문제는 인덱스마다 상태(평균값)을 구하고 이로부터 가능한 다음\n 상태(점수의 합) 중에서 최대 값을 구하는 문제이다. 거의 유사하게 풀 수\n 있다.\n\nfrom functools import cache\nfrom statistics import mean\n\ndef largest_score(A, K):\n    if K == 1:\n        return\n\n    n = len(A)\n\n    @cache\n    def seg_mean(start, end):\n        return mean(A[start:end])\n\n    @cache\n    def dfs(idx, k):\n        if k == K:\n            return seg_mean(idx, n)\n\n        max_sum = 0\n        for i in range(idx, n - K + k):\n            max_sum = max(max_sum, seg_mean(idx, i + 1) + dfs(i + 1, k + 1))\n        return max_sum\n    return dfs(0, 1)\n\n\n  평균 값을 구하기 위해서 statistics 모듈의 mean 함수를\n활용했다. 그리고 매 구간마다 평균 값을 계속 계산할 필요는 없기\n때문에, 이 값도 메모아이즈한다.\n  여기서도 매번 최대 len(A) - K + k 까지의 범위가 가능하다. 그리고\n범위가 늘어갈 때마다 시작 인덱스는 idx 그대로인 채로 끝 구간만\n변하므로, seg_mean 함수를 십분 활용 가능하다.\n  한 가지 주의할 점은, 평균 값을 계산할 때 start은 인덱스지만\nend는 인덱스가 아니라 파이썬의 range 형식과 같이 마지막 다음\n위치를 가리키므로, 매 범위마다 seg_mean을 호출할 때 (idx, i)가\n아니라 (idx, i+1) 범위에 대해서 호출해야 한다는 점이다."
					}
					,
					"ps-leetcode-minimum-genetic-mutation": {
						"id": "ps-leetcode-minimum-genetic-mutation",
						"title": "Minimum Genetic Mutation",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/minimum-genetic-mutation/",
						"content": "Minimum Genetic Mutation\n\n유전자 스트링은 8개의 문자열로 나타낼 수 있고 각각의 글자는 A, C,\n G, T 중 하나이다.\n\n한 유전자 스트링 start에서 다른 유전자 스트링 end로 돌연변이가\n 일어날 수 있는지 확인하려고 한다. 한번의 돌연변이는 유전자 스트링에서\n 하나의 글자가 바뀌는 것을 뜻한다. 예를 들어, AACCGGTT --&gt;\n AACCGGTA는 한 번의 돌연변이이다.\n\n유전자 은행 bank도 주어진다. 여기에는 모든 유효한 유전자 돌연변이가\n 담겨있다. 어떤 유전자 스트링이 유효하려면 반드시 bank안에 들어있는\n 유전자여야 한다.\n\n두 개의 유전자 스트링 start, end와 유전자 은행 bank가 주어졌을\n 때, start가 end로 바뀌기 위해서 필요한 최소한의 돌연변이 횟수를\n 계산하자. 불가능하다면 -1을 리턴하자.\n\n참고로 start는 항상 유효한 것으로 간주되기 때문에 bank에 없을수도\n 있다.\n\n\n  start, end의 길이는 8이다.\n  bank의 크기는 0~10\n  bank에 있는 유전자의 길이는 8\n  모든 유전자 스트링은 A, C, G, T 글자만 담고 있음이\n보장된다.\n\n\n상태 공간 탐색하기\n\n\n  어떤 유전자 스트링이 가능한 모든 돌연변이 수를 생각해보자. 하나의\n글자는 A, C, G, T 중 원래 글자가 아닌 3가지의 글자로 변이가\n가능하고 유전자 스트링의 길이는 항상 8이므로 \\(3^8 = 6561\\) 개의\n다음 상태가 가능하다.\n  하지만 추가로 유효한 돌연변이가 되려면 항상 유전자 은행 안에\n속한 돌연변이로 변이해야 하므로 생각보다는 상태공간이 작다. 은행의\n크기가 최대 10이므로 가능한 돌연변이 횟수도 최대 10이다.\n  일종의 상태 공간을 탐색하는 것이므로 BFS가 적절하다. 목적지에 도달\n가능한 최소 경로를 구하는 문제와도 동치이므로 더더욱 BFS를 활용해야\n한다.\n  BFS를 위해 큐에 상태(노드)를 넣을 때, 탐색할 상태 뿐 아니라 추가로\n지금까지 탐색한 경로의 수 (= 돌연변이 횟수)도 함께 기록한다. 이것이\n곧 문제가 요구하는 최소의 돌연변이 횟수가 된다.\n  BFS이므로 방문 체크를 해야한다. 그렇지 않으면 무한루프에 빠져서\n답을 계산할 수 없는 경우가 생긴다. 한번의 돌연변이에서 가능한\n6,561개의 다음 상태 중 은행에 있는 상태로만 변이할 수 있으므로, 한\n번 방문한 상태를 또 방문하게 되면 그래프에서 루프가 생기는 것과\n동일하다. 따라서 이 경우는 애초에 불가능하다.\n\n\ndef minMutation(start, end, bank):\n    from collections import deque\n    q = deque()\n    q.append((start, 0))\n    bank_set = set(bank)\n    visited = set()\n    while q:\n        cur, turn = q.popleft()\n        if cur == end:\n            return turn\n\n        for i in range(8):\n            for c in ('A', 'C', 'G', 'T'):\n                if c == cur[i]:\n                    continue\n                cand = cur[:i] + c + cur[i+1:]\n                if cand not in visited and cand in bank_set:\n                    visited.add(cand)\n                    q.append((cand, turn + 1))\n    return -1"
					}
					,
					"ps-leetcode-minimum-moves-to-equal-array-elements-ii": {
						"id": "ps-leetcode-minimum-moves-to-equal-array-elements-ii",
						"title": "Minimum Moves to Equal Array Elements II",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/minimum-moves-to-equal-array-elements-ii/",
						"content": "Minimum Moves to Equal Array Elements II\n\n정수 배열이 주어진다. 한 단계에서 원소 하나를 1만큼 증가시키거나\n 감소시킬 수 있다. 이때, 모든 원소를 다 같이 만들기 위해서 필요한\n 단계의 최소 횟수를 구하자.\n\n모든 정답과 원소의 범위는 32비트 정수형에 담긴다.\n\n배열의 크기는 1 ~ 100,000 사이이고 원소 값의 범위는 \\(-10^9 \\sim\n 10^9\\) 이다.\n\n중위값 찾기\n\n1씩 증가 또는 감소만 할 수 있기 때문에, 처음에는 데이터에서 일종의\n 분산과 표준편차를 구하는 문제와 비슷하다고 생각했다. 그래서 각\n 원소마다 평균과의 차이를 누적하면 되지 않을까 했는데, 반례가\n 있다. 원소가 한쪽으로 많이 치우쳐 있을 때, 예를 들어 [1, 2, 10]과\n 같은 경우, 평균을 구하면 (1+2+10)/3 = 4이고 모든 원소를 이 평균으로\n 만들기 위해서 차이를 구하면 [3, 2, 6]이 되어 11이 최소 연산 수라고\n 생각할 수 있다. 하지만 실제로는 모든 원소를 2로 만드는게 가장 연산\n 수가 적은데, [1, 0, 8]이 되어 총 9번의 연산만 필요하기 때문이다.\n\n따라서 여기서 알 수 있는 것은 평균이 아니라 (정렬된) 배열의\n 중위값으로 만드는 연산이 최소 횟수라는 것이다. 그러므로 다음과\n 같이 구현할 수 있다.\n\ndef minMoves2(nums):\n    seq = sorted(nums)\n    n = len(nums)\n    median = seq[n//2] if n % 2 == 1 else ((seq[n//2-1] + seq[n//2]) // 2)\n    moves = 0\n    for num in nums:\n        moves += abs(median - num)\n    return moves\n\n\n\n\n그런데 위와 같이 정확한 방법으로 median을 구하는게 의미가 있을까?\n 예를 들면 [1, 2, 2, 10]과 같이 중위값 계산에 쓰일 두 원소가 같으면\n 당연히 이 중 아무거나 써도 되지만 [1, 2, 9, 10]과 같은 상황에서도\n 유효할까? 일일이 계산해보면 다음과 같다:\n\n\n  [1, 2, 9, 10] 에서 중위값으로 (2+9)/2 = 5를 고름: [4, 3, 4,\n5] -&gt; 합은 16\n  [1, 2, 9, 10] 에서 중위값으로 2를 고름: [1, 0, 7, 8] -&gt; 합은\n16\n  [1, 2, 9, 10] 에서 중위값으로 9를 고름: [8, 7, 0, 1] -&gt; 합은\n16\n\n\n즉 배열 크기가 짝수이더라도, 최소 횟수 계산을 위해 필요한 중위값\n 계산에는 중간의 두 원소의 평균을 내지 않아도 된다! 어떤 걸 집어도\n 똑같은 값(뒤집은)이 나오는 걸 확인할 수 있다. 따라서, 중위값을 배열\n 크기의 짝/홀수에 따라 정확히 계산하지 않아도 된다.\n\ndef minMoves2(nums):\n    seq = sorted(nums)\n    median = seq[len(nums)//2]\n    return sum(abs(median - num) for num in nums)\n\n\n\n\n번외: 왜 중위값일까?\n\n그럼 왜 “모든 원소를 같은 값으로 만들기 위한 최소의 연산”을 위해서\n 모든 원소를 중위값으로 만들어야 할까? 여기에는 수학적인 증명이\n 가능하다.\n\n먼저 다음과 같이 정의하자.\n\n  k: 모든 원소가 같아질 값\n  count_before_k: k보다 작은 원소의 수\n  count_after_k: k보다 큰 원소의 수\n  sum_before_k: k보다 작은 원소의 합\n  sum_after_k: k보다 큰 원소의 합\n\n\n그러면 모든 원소를 k로 만들기 위해서 필요한 연산의 수는 다음과 같이\n 계산할 수 있다:\n\nnumber_of_moves = (k * count_before_k) - sum_before_k + (sum_after_k - (k * count_after_k))\n\n\n즉, 아래 두 가지 경우에 대해서 case analysis를 한다고 하면:\n\n  k보다 작은 원소를 k로 만들기 위해서는, k보다 작은 원소\n수(count_before_k)를 k 만큼 곱한 값에서 k보다 작은 원소의\n합(sum_before_k)을 뺀 것만큼의 연산이 필요하다. k보다 작은\n원소의 합이 당연히 더 작을 것이기 때문에 합을 뺀다.\n  비슷하게, k보다 큰 원소를 k로 만들려면, k보다 큰 원소의\n합(sum_after_k)에서 k보다 큰 원소를 k만큼 곱한 값에서 뺀\n것만큼의 연산이 필요하다.\n\n\n이제 우리는 이 연산 수를 최소화하는 k를 찾으면 된다. 이를 위해서\n 양변을 k로 미분해보자. 그러면\n\nnumber_of_moves/dk = (k * count_before_k)/dk - sum_before_k/dk + sum_after_k/dk - (k * count_after_k)/dk\n\n                   = count_before_k - count_after_k\n\n\n가 되고, 최소가 되려면 number_of_moves/dk 미분 값이 0이어야 하므로\n 이는 곧 count_before_k == count_after_k 조건을 만족하는 k에\n 대해서 number_of_moves가 최소값을 갖는다는 의미이다. 즉 어떤 수\n k를 기준으로 k보다 작은 원소의 개수와 k보다 큰 원소의 개수가\n 같도록 하는 k를 고르면 된다. 그리고 이 성질을 만족하는 k는 바로\n 중위값이다."
					}
					,
					"ps-leetcode-minimum-operations-to-reduce-x-to-zero": {
						"id": "ps-leetcode-minimum-operations-to-reduce-x-to-zero",
						"title": "Minimum Operations to Reduce X to Zero",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/minimum-operations-to-reduce-x-to-zero/",
						"content": "Minimum Operations to Reduce X to Zero\n\n정수 배열 nums와 정수 값 x가 주어진다. 한 번의 연산에서, 가장\n 왼쪽 또는 가장 오른쪽의 원소를 nums에서 뽑은 다음 이 값을 x에서\n 뺄 수 있다. 이 연산은 nums 배열 자체를 수정한다는 것을 기억하자.\n\nx를 정확하게 0으로 만들기 위한 최소 연산 횟수를 구하자. 어떤\n 경우에도 불가능하다면 -1을 리턴하자.\n\n정수 배열의 크기는 \\(1 \\leq | nums | \\leq 10^5\\) 이고 원소의 값의\n 범위는 \\(1 \\leq nums[i] \\leq 10^4\\), \\(1 \\leq x \\leq 10^9\\)이다.\n\n백트래킹 - 타임아웃\n\n가장 직관적으로 생각해낼 수 있는 방법은, 문제에 나온 설명대로 직접\n 해보는 것이다.\n\n가장 왼쪽과 가장 오른쪽에서 하나씩 꺼내어서 합을 확인하는 것까지는\n 쉽게 구현할 수 있다. 이러면 각 단계에서 진행할 수 있는 가짓수가 2\n 가지, 즉 가장 왼쪽을 빼거나 가장 오른쪽을 빼는 두 가지 이므로,\n 복잡도는 \\(2 ^ N\\) 이 되어 터질 게 분명하다. 다만, 문제의 조건에\n 따라 모든 원소가 양수인 덕분에, 이 성질을 이용해서 조금 가지치기를 할\n 수 있다. 모든 원소가 양수이기 때문에, 재귀를 하기 전에 이미 지금까지\n 연산한 결과가 음수라면 더 이상 그 공간의 서브 트리를 살펴볼 필요가\n 없는 것이다.\n\n이 아이디어를 구현하면 다음과 같다.\n\ndef minOperations(nums, x):\n    answer = float('inf')\n\n    def find(arr, cur_x, turn):\n        nonlocal answer\n        if not arr:\n            return\n\n        # pick leftmost\n        cand_left = cur_x - arr[0]\n        if cand_left == 0:\n            answer = min(answer, turn + 1)\n            return\n\n        # pick rightmost\n        cand_right = cur_x - arr[-1]\n        if cand_right == 0:\n            answer = min(answer, turn + 1)\n            return\n\n        # pruning\n        if cand_left &gt; 0:\n            find(arr[1:], cand_left, turn + 1)\n        if cand_right &gt; 0:\n            find(arr[:len(arr)-1], cand_right, turn + 1)\n\n    find(nums, x, 0)\n    return -1 if answer == float('inf') else answer\n\n\n단, 이렇게 해도 타임아웃이 난다. 뭔가 다른 접근이 필요하다.\n\n투 포인터\n\n이 문제의 최적 알고리즘은 이 문제를 이 문제의 Dual인 합이 k가 되는\n 최장 부분 배열 문제로\n 치환해서 푸는 것이다. 즉, 양쪽 끝에서 하나씩 원소를 x에서 빼서\n 0을 만드는 게 아니라, 합이 total - x가 되는 부분 배열을 찾으면\n 된다. 그리고, 원소를 빼는 연산 횟수를 최소로 하라고 했으니, 이 말은\n 합이 total - x가 되는 가장 긴 부분 배열을 찾으면 된다. 완벽한\n Dual이다.\n\n따라서 이 아이디어를 그냥 구현하면 된다.\n\ndef minOperations(nums, x):\n    total = sum(nums)\n    tofind = total - x\n    n = len(nums)\n    maxwin = -1\n    start, cursum = 0, 0\n    for end in range(n):\n        cursum += nums[end]\n        while cursum &gt; tofind and start &lt;= end:\n            cursum -= nums[start]\n            start += 1\n        if cursum == tofind:\n            maxwin = max(maxwin, end - start + 1)\n    return (n - maxwin) if maxwin != -1 else -1\n\n\n\n  전체 합 total을 계산하고 우리가 원하는 합인 tofind = total -\nx를 계산해둬서 부분 배열의 합을 체크한다.\n  start를 줄일 수 있는 (shrink) 조건은, 여전히 start, end가\n유효한 윈도우이면서, 지금 합이 여전히 tofind보다 큰\n경우이다. 모든 원소가 양수이기 때문에, 지금 합이 tofind보다 큰\n동안 start에 있는 원소의 값을 지금 합에서 덜어내면서 start\n포인터를 이동하면 된다.\n  답을 찾은 경우, 즉 지금 합이 tofind인 경우, 우리는 이때의 최대\n윈도우 사이즈를 기록해둬야 한다. 단, 이렇게 구한 최대 윈도우\n사이즈가 곧바로 답이 되진 않는다. 우리는 원래 문제를 dual로 바꿔서\n풀고 있다는 사실을 잊지 말자. 문제의 답은, 전체 길이에서 최대\n윈도우 사이즈를 뺀 값이 된다. 이 값이 곧 최소의 연산 횟수와\n동일한 의미를 갖는다."
					}
					,
					"ps-leetcode-minimum-size-subarray-sum": {
						"id": "ps-leetcode-minimum-size-subarray-sum",
						"title": "Minimum Size Subarray Sum",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/minimum-size-subarray-sum/",
						"content": "Minimum Size Subarray Sum\n양수만 담은 배열 nums와 양수 target이 주어졌을 때, 합이\n target보다 크거나 같게 되는 연속되는 부분 배열 [nums_(l),\n nums_(l+1), ..., nums_(r)]의 최소 길이를 구하는 문제이다. 없으면\n 0을 리턴.\n\n접근\n\n  가변 길이 슬라이딩 윈도우를 활용할 수 있는 문제\n    \n      양수만 담고 있어서 가능함: 윈도우 크기를 늘리면 값이 커지고,\n윈도우 크기를 줄이면 값이 작아질 수 밖에 없음\n    \n  \n  윈도우의 시작과 끝 인덱스 (start, end)를 유지\n    \n      현재 상태가 목표(target)가 아니라면, 다음 상태는 어디로\n가야할까? -&gt; end 포인터를 움직여서 윈도우 크기를 늘림\n      현재 상태보다 더 잘 할 수 있나(Can we do better)? -&gt; 부분 배열의\n최소 길이를 구해야 하므로, start 포인터를 움직여서 윈도우\n크기를 줄임\n    \n  \n  그 외 엣지 케이스를 고려해야 함:\n    \n      길이 초기 값은 무한대(혹은 아주 큰 정수)여야 최소 길이를 구할 수\n있음\n      (start, end) 모두 인덱스이므로 길이 계산에 유의\n      start 포인터를 움직일 때 누적 합에서 값을 빼줘야 함\n      최종적으로 길이가 초기 값에서 변하지 않았다면 가능한 경우가 없는\n것임\n    \n  \n\n\ndef min_sub_array_sum(nums, target):\n    n = len(nums)\n    min_len = float('inf')\n    cur_sum = 0\n    start, end = 0, 0\n\n    for end in range(n):\n        cur_sum += nums[end]\n\n        # Can I do better?\n        while cur_sum &gt;= target:\n            min_len = min(min_len, end - start + 1)\n            cur_sum -= nums[start]\n            start += 1\n\n    return min_len if min_len != float('inf') else 0\n\n\n번외: Dual\n이 문제와 Dual이 되는 문제도 생각해볼 수 있다: “nums와 target에\n 대해서, 합이 target보다 작거나 같게되는 부분 배열의 최대 길이를\n 구하라”.\n\n이 경우는 위의 투 포인터를 조금 변형하면 다음과 같이 구현할 수 있다.\n\ndef max_sub_array_sum(nums, target):\n    n = len(nums)\n    max_len = 0\n    cur_sum = 0\n    start, end = 0, 0\n\n    for end in range(n):\n        if (cur_sum + nums[end]) &lt;= target:\n            # Can I do better?\n            cur_sum += nums[end]\n            max_len = max(max_len, end - start + 1)\n        else:\n            # Constraint not satisfied. move to the next.\n            cur_sum = cur_sum - nums[start] + nums[end]\n            start += 1\n\n    return max_len\n\n\n\n  최대 값을 구해야 하므로 최대 길이 값을 0으로 초기화 한다.\n  마찬가지로 start와 end를 이용하여 가변 길이 윈도우의 투\n포인터를 활용한다.\n  단, 이전처럼 곧바로 cur_sum을 누적하지 않는다. 예전에는 최소\n만족해야 하는 값이 target이었지만, 여기서는 아무리 커봤자\ntarget과 같아야 하므로, 루프 안에서 업데이트 하기 전에 미리\n계산하고 만족한 경우에만 업데이트 한다.\n  또한, 최대 길이를 구해야 하므로, 위 조건을 만족할 때에만\nmax_len을 업데이트 할 수 있다. 길이를 end - start + 1로 구할 수\n있는 부분은 동일하다.\n  만약 값이 target 보다 큰 경우, “그 다음”으로 진행하는 로직이 살짝\n다른데,\n    \n      최소 길이가 아니라 최대의 길이를 구하는 문제이므로, 이전처럼\nwhile 루프를 돌면 안된다. 대신, 윈도우 사이즈를 하나씩\n앞에서 부터 줄여나갈 수 있다.\n      cur_sum을 업데이트 하는 방식이 다르다. start를 하나 증가하게\n되면 당연히 cur_sum에서 nums[start]를 빼야 한다. 추가로\n여기서는 target과 비교하기 전에 nums[end]값을 cur_sum에\n누적하지 않았으므로, start를 움직이는 부분에서 이 값까지\n고려해줘야 한다.\n    \n  \n\n\n번외 2: 합이 아니라 곱이면?\n이런 문제도 생각해볼 수 있다: “합이 아니라, nums의 부분 배열의\n 곱이 target보다 작은 부분 배열의 개수는 몇개일까?”\n\n여기서 tricky한 부분은 (1) 합이 아니라 곱이고 (2) 최대/최소 길이가\n 아니라 전체 개수를 구해야 한다는 점이다.\n\n다음과 같은 경우를 생각해보자.\n\n[10, 5, 2, 6], target = 100\n\n\n이때 부분 배열의 곱이 100보다 작은 개수를, 윈도우 안에서\n 생각해보자. 만약 윈도우가 [10, 5] 라고 하면, 곱이 100보다 작은\n 부분 배열의 개수는: [10], [5], [10, 5]로 총 3개이다. 그런데 잘\n 살펴보면 이 개수는 윈도우가 [10]일 때의 개수도 포함하고 있다. 즉,\n [10, 5] 윈도우 안에서 가능한 개수만 센다면 [10, 5]와 [5]가\n 되고, 이는 곧 윈도우 크기와 일치한다.\n\n그렇다면 이전의 가변 길이 투 포인터 접근을 조금 변형해서 아래와 같이\n 구현할 수 있다.\n\ndef num_sub_array_prod(nums, target):\n    if target &lt;= 1:\n        return 0\n\n    n = len(nums)\n    count = 0\n    cur_prod = 1\n    start, end = 0, 0\n\n    for end in range(n):\n        cur_prod *= nums[end]\n\n        # find minimum window\n        while cur_prod &gt;= target:\n            cur_prod /= nums[start]\n            start += 1\n\n        count += (end - start + 1)\n\n    return count\n\n\n  Base Case를 잘 생각해야 한다. 조건이 target보다 작아야 하기\n때문에, target이 1 또는 0이면 어떤 양수를 곱해도 이 값보다\n작을 수 없기 때문에 답은 0개 이다.\n  누적 합이 아니라 누적 곱이므로 cur_prod의 초기값은 1이다.\n  최소 부분 배열과 유사하게, 조건을 만족하는 최소 크기의 윈도우를\n구한다. 그러고 나면 이때 가능한 부분 배열의 개수가 곧 윈도우의 크기\n이므로, 이를 누적하면 된다."
					}
					,
					"ps-leetcode-minimum-window-subsequence": {
						"id": "ps-leetcode-minimum-window-subsequence",
						"title": "Minimum Window Subsequence",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/minimum-window-subsequence/",
						"content": "Minimum Window Subsequence"
					}
					,
					"ps-leetcode-minimum-window-substring": {
						"id": "ps-leetcode-minimum-window-substring",
						"title": "Minimum Window Substring",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/minimum-window-substring/",
						"content": "Minimum Window Substring\n두 문자열 s랑 t가 주어졌을 때, t에 있는 모든 문자를 담은 s의\n 부분 문자열(window) 중 가장 짧은 것을 구하는 문제다. 없으면 ““를\n 리턴.\n\n최소 길이의 윈도우는 항상 1개만 존재하도록 보장된다. t에는 중복이\n 있을 수도 있기 때문에 t의 글자 수도 맞아야 한다.\n\n\n  s, t의 길이는 1~100,000\n  s, t 모두 대소문자 알파벳만 포함한다.\n\n\n슬라이딩 윈도우\n암튼 어떻게 슬라이딩 윈도우를 적용해야 할지 고민해보자. end\n 인덱스를 계속 늘려가면서 윈도우를 키운다. 윈도우가 조건인 t의 모든\n 문자를 담게 되면, 그 다음 “더 잘 할 수 있나?” 를 확인해 가면서 윈도우\n 크기를 줄여나가면 (shrink) 될 것 같다. 중간 중간 가장 작은 값을\n 누적하면 되겠지.\n\n슬라이딩 윈도우의 어려운 점은, 이렇게 말은 쉬운데 코드로 한번에 오류\n 없는 구현을 해내기가 힘든 부분인 것 같다. 차근차근 구현한 코드는\n 다음과 같다.\n\nfrom collections import Counter\n\ndef min_window(s, t):\n    # requirements\n    requirement = Counter(t)\n    required_alphas = len(requirement)\n\n    # for sliding window\n    start, end = 0, 0\n    window = {}  # contains window's alphabet count\n    formed_alphas = 0\n\n    # for answer\n    min_len = float('inf')\n    answer = \"\"\n\n    for end in range(len(s)):\n        cur = s[end]\n        window[cur] = window.get(cur, 0) + 1\n\n        if cur in requirement and window[cur] == requirement[cur]:\n            # this is the condition\n            formed_alphas += 1\n\n        # Can I do better? part\n        # shrink window while\n        # (1) it is a valid window and\n        # (2) it contains all required alphabets\n        while start &lt;= end and formed_alphas == required_alphas:\n            # update answer\n            shrinked_len = end - start + 1\n            if shrinked_len &lt; min_len:\n                min_len = shrinked_len\n                min_substring = s[start:end + 1]\n\n            # update current state\n            char = s[start]\n            window[char] -= 1\n            if char in requirement and window[char] &lt; requirement[char]:\n                formed_alphas -= 1\n\n            start += 1\n\n    return answer\n\n\n  먼저 만족해야 하는 조건인 requirement를 Counter 모듈로\n만들어둔다. 그리고 미리 조건의 알파벳 개수를 계산해둔다.\n  슬라이딩 윈도우는 start, end 정보 외에도 윈도우 안의 알파벳\n개수를 위한 window 해시 테이블과, requirement를 만족하는 알파벳\n개수를 위한 formed_alphas를 갖는다. 여기서 requirement를\n만족한다는 의미는, requirement에 있는 알파벳의 개수와 window의\n알파벳의 개수가 같다는 의미이다.\n  정답은 최소 길이 문자열 이므로 길이와 문자열을 다 갖고 있는다.\n  end를 늘려가면서 window 정보를 계속 업데이트 한다. 현재 커서가\n조건에 필요한 문자이면서, 조건과 개수까지 같을 때,\nformed_alphas를 업데이트 한다. Counter와 윈도우를 직접 비교하지\n않고 이렇게 하는 이유는, 윈도우 안에는 requirement 에 있는 알파벳\n외에 다른 알파벳이 있을 수 있기 때문이다.\n  중요한 것은 “Can I do better?” 부분이다. 최소 길이의 윈도우를\n구하는 것이 목표이기 때문에, 조건을 만족하는 동안 계속 윈도우\n크기를 줄이는 시도를 해야하므로 루프를 돈다. 이때 그 “조건”이란\n주석에도 나와있듯이,\n    \n      유효한 Window여야 하므로 start &lt;= end 이고,\n      알파벳 조건을 모두 만족해야 하므로 formed_alphas를 비교해야 한다.\n    \n  \n  그 후 루프 안에서 start를 하나씩 증가시켜야 하는데, 증가시키기\n전에 윈도우와 관련된 상태를 업데이트해줘야 한다. 일단 window 해시\n테이블 값을 업데이트하고, 만약 start에 있던 문자가 조건을\n만족시키지 못하게 한다면 이 부분도 같이 업데이트해줘야 한다.\n  여기까지 하고 나야 비로소 윈도우 크기를 줄일 수 있다."
					}
					,
					"ps-leetcode-monotonic-array": {
						"id": "ps-leetcode-monotonic-array",
						"title": "Monotonic Array",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/monotonic-array/",
						"content": "Monotonic Array\n\n어떤 배열이 단조 증가 또는 단조 감소이면 단조(monotonic)이라고 한다.\n\n모든 i &lt;= j에 대해서 nums[i] &lt;= nums[j] 이면 단조 증가, `nums[i]\n\n  = nums[j]` 이면 단조 감소이다.\n\n\n주어진 배열이 단조 배열이면 참, 아니면 거짓을 리턴하자.\n\n한 반복에 둘 다 검사하기\n\n주어진 문제를 코드로 옮기기만 하면 된다. 여기서는 반복문을 한 번만\n 써서 둘 다 체크하는 로직을 구현해보려고 한다.\n\n먼저 배열이 단조 증가인지 단조 감소인지 모르기 때문에, 처음에는 둘\n 다라고 가정한다. 그리고 모든 i &lt;= j(i+1)에 대해서 단조 증가 또는\n 단조 감소 조건을 위반하는 순간 한 쪽의 플래그를 거짓으로\n 기록한다. 최종적으로는 단조 증가 또는 단조 감소 둘 중 한 조건만\n 만족하는지를 리턴한다.\n\ndef isMonotonic(nums):\n    monotonic_increasing = True\n    monotonic_decreasing = True\n    i = 0\n    n = len(nums)\n    while i &lt; (n-1):\n        if nums[i] &gt; nums[i+1]:\n            monotonic_increasing = False\n        if nums[i] &lt; nums[i+1]:\n            monotonic_decreasing = False\n        i += 1\n    return monotonic_increasing or monotonic_decreasing\n\n\n여기서 쪼오끔 최적화를 진행할 수는 있다. 이 문제에서는 입력 배열이\n 정수 배열이지만, 조금 일반화해서 비교 연산이 값비싼 오브젝트의 배열일\n 경우, 비교 연산을 최대한 안하는 것이 좋다. 따라서 두 가지 최적화가\n 가능하다.\n\n  이미 단조 증가 또는 단조 감소가 아니라고 판단된 경우, 굳이 비교할\n필요가 없다. 파이썬에도 Short-circuit\nEvaluation이\n적용되기 때문에, 각 비교 연산 앞에 추가로 조건을 체크해주면 된다.\n  단조 증가도 단조 감소도 모두 아니라고 판단되었다면, 이후의 배열\n원소를 훑어볼 필요조차 없다.\n\n\n이 최적화를 추가하면 다음과 같다.\n\ndef isMonotonic(nums):\n    monotonic_increasing = True\n    monotonic_decreasing = True\n    i = 0\n    n = len(nums)\n    while i &lt; (n-1):\n        if monotonic_increasing and nums[i] &gt; nums[i+1]:\n            monotonic_increasing = False\n        if monotonic_decreasing and nums[i] &lt; nums[i+1]:\n            monotonic_decreasing = False\n        if not monotonic_increasing and not monotonic_decreasing:\n            break\n        i += 1\n    return monotonic_increasing or monotonic_decreasing\n\n\n제법 비결정적인 파이썬인데도 불구하고 이 최적화로 시간이 꽤 줄었다."
					}
					,
					"ps-leetcode-non-decreasing-array": {
						"id": "ps-leetcode-non-decreasing-array",
						"title": "Non-decreasing Array",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/non-decreasing-array/",
						"content": "Non-decreasing Array\n\n정수 배열 nums가 주어진다. 여기서 딱 하나의 원소만 바꿔서 배열이\n 오름차순(non-decreasing)이 되는지 확인하자.\n\n여기서의 오름차순은 모든 인덱스 i에 대해서 nums[i] &lt;= nums[i+1]이\n 성립함을 뜻한다.\n\n배열의 크기는 1~10,000 이고 배열의 값은 -100,000~100,000 사이이다.\n\n예를 들어, [4, 2, 3]의 경우 첫 번째 원소인 4를 2보다 작거나\n 같은 값으로 바꾸면 전체 배열이 되므로 참이다.\n\n스택\n\n인접한 원소 사이에서 오더를 유지할 수 있는 방법 중 내가 떠올릴 수\n 있는 가장 단순한 방법은 스택이라서, 스택으로 접근해보았다.\n\n일단 유지하려는 불변식은 스택이 오름차순이라는 것이다. 이 성질을\n 유지하면서 배열 원소를 스택에 차례로 푸시한다. 그러다가 이 성질이\n 처음으로 위겨지는 시점이 원소를 바꿔야 하는 시점(여기서는 단순히\n 제거해도 된다)이다.\n\n어떤 원소를 제거해야 오름차순이 유지되는지 보려면 다음 세 가지\n 케이스를 확인해야 한다. 일단 스택에서 꺼낸 탑을 top이라고 하자.\n\n1) 스택이 빈 경우\n인덱스 (0, 1)에서만 발생한다. nums[0] &gt; nums[1]인 경우이다. 이때는\n top(nums[0])을 버리고 지금 값(nums[1])을 취해야 한다. 따라서\n 현재 값을 스택에 푸시한다.\n\n예를 들면 입력이 아래와 같을 때:\n\n[4, 2, 3]\n\n\nstack = [4] , i = 1일때 stack[-1] &gt; nums[i] (4 &gt; 2) 라서 일단 4가\n pop 된다.  그러면 stack이 비게 되므로, 2를 stack에 푸시해야 한다.\n\n2) stack[-1] &lt;= nums[i]인 경우\ntop을 빼면 오더가 유지된다는 의미이다. 현재 값을 푸시해야 오더가\n 맞는다. 역시 현재 값을 푸시한다.\n\n예를 들어 다음과 같은 경우:\n\n[2, 5, 3, 4]\n\n\nstack = [2, 5], i = 2일때 stack[-1] &gt; nums[i] (5 &gt; 3) 라서 일단\n 5가 pop 된다. 그러면 남은 스택을 기준으로 stack[-1] &lt;= nums[i] (2\n &lt;= 3) 으로 오더가 유지되므로, pop된 5가 범인이다.\n\n3) stack[-1] &gt; nums[i]인 경우\ntop을 넣어야 오더가 유지될지도 모른다는 의미이므로, nums[i]를\n 버리고 top을 푸시해야 한다.\n\n예를 들어 다음 경우:\n\n[3, 4, 2, 3]\n\n\nstack = [3, 4], i = 2일때 stack[-1] &gt; nums[i] (4 &gt; 2) 라서 일단\n 4가 pop 된다. 그러면 남은 스택을 기준으로 stack[-1] &gt; nums[i] (3 &gt;\n 2) 이므로, nums[i]가 후보가 아니다. 이럴 경우 명백히 후보가 아닌\n nums[i]를 버리고, 이전의 후보 top을 다시 복원(스택에 푸시)해서\n 이후 범위를 살펴봐야 한다.\n\n(마지막에 3은 다시 위의 조건에 걸리기 때문에 최종적으로는\n False임을 알 수 있다.)\n\n\n\n결국 위의 아이디어를 정리하면, 꺾이는 구간을 찾고 어디서부터\n 연결해야 하는지를 살펴보는 것이다. 꺾이는 구간을 [a, b, c] (a &lt;=\n b, b &gt; c) 라고 한다면, b를 버릴지(케이스 1, 2) 아니면 c를\n 버릴지(케이스 3)을 나눠서 생각하면 되는 것이다.\n\n이 아이디어를 구현하면 다음과 같다.\n\ndef checkPossibility(nums):\n    stack = [nums[0]]\n    popcount = 0\n    for num in nums[1:]:\n        if stack[-1] &lt;= num:\n            stack.append(num)\n        else:\n            if popcount &gt; 1:\n                return False\n            top = stack.pop()\n            popcount += 1\n            if not stack or stack[-1] &lt;= num:\n                # drop top\n                stack.append(num)\n            else:\n                # drop num\n                stack.append(top)\n    return True\n\n\n이렇게 O(N)의 솔루션을 얻을 수 있다.\n\n스택없이\n\n그런데 생각해보면, 위에서 생각한대로 꺾이는 구간만 제대로\n 파악한다면, 그리고 이게 몇 번이나 나타나는지만 셀 수 있다면, 굳이\n 스택을 써서 O(N)의 공간을 낭비하지 않을 수 있을 것 같다.\n\n가능한 시나리오를 생각해보자. 먼저 nums[i-1] &gt; nums[i]가 되는 순간,\n 우리는 꺾이는 구간에 진입한 것이고, 이때 이 구간을 둘러싼 원소에\n 따라서 여러가지 케이스가 발생한다.\n\n먼저 구간의 앞 또는 뒤의 이어지는 부분이 모두 감소하는 경우, 즉\n nums[i-2] &gt; nums[i-1] &gt; nums[i] 또는 nums[i-1] &gt; nums[i] &gt;\n nums[i+1]인 경우, 우리는 이 구간을 한 번 이상 수정해야 하므로 곧바로\n 불가능하다는 것을 알 수 있다. 여기까지는 간단히 생각해낼 수 있다.\n\n좀더 복잡하게 불가능한 경우는 다음과 같다. 이건 말로 설명하기\n 어려우니 그림을 보자.\n\n|\n|        x\n|\n|  x                 x\n|              x\n|\n|\n+------------------------\n (i-2) (i-1)  (i)  (i+1)\n\n\n이때는 nums[i-1]과 nums[i]를 모두 옮겨야 가능하다.\n\n이제 좀더 복잡한 경우를 생각해보자. 일단 둘 중 하나를 움직일 수 있는\n 경우가 있다.\n\n|                    x\n|        x\n|\n|\n|              x\n|  x\n|\n+------------------------\n (i-2) (i-1)  (i)  (i+1)\n\n\n이런 상황에서, nums[i-1]을 nums[i-2]와 nums[i] 사이 값으로\n 내리거나, 아니면 nums[i]를 nums[i-1]과 nums[i+1] 사이로 올릴 수\n 있다. 즉, 한번의 수정으로 오름차순이 가능하다.\n\n다음 두 경우는 하나만을 움직일 수 있다.\n\n|                    x\n|        x\n|\n|  x\n|              x\n|\n|\n+------------------------\n (i-2) (i-1)  (i)  (i+1)\n\n\n이때는 nums[i]를 위로 올려야 한다.\n\n|\n|        x\n|\n|                    x\n|              x\n|  x\n|\n+------------------------\n (i-2) (i-1)  (i)  (i+1)\n\n\n이때는 nums[i-1]을 내려야 한다.\n\n\n\n요걸 다 정리하면 다음과 같다.\n\ndef checkPossibility(nums):\n    count = 0\n    for i in range(1, len(nums)):\n        if nums[i-1] &gt; nums[i]:\n            if count &gt; 0:\n                return False\n            if i &gt; 1 and i &lt; (len(nums)-1) and nums[i-2] &gt; nums[i] and nums[i-1] &gt; nums[i+1]:\n                return False\n            count += 1\n    return True"
					}
					,
					"ps-leetcode-non-overlapping-intervals": {
						"id": "ps-leetcode-non-overlapping-intervals",
						"title": "Non-overlapping Intervals",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/non-overlapping-intervals/",
						"content": "Non-overlapping Intervals\n\n범위 리스트가 주어졌을 때, 이중 일부 원소를 삭제하면 나머지 리스트\n 전체의 범위가 겹치지 않게 만들 수 있다. 이때, 삭제를 위해 필요한\n 최소의 범위 수를 구하자.\n\n예를 들어서 [(1,2), (2,3), (3,4), (1,3)]을 생각해보자. 이 중\n (1,3)을 삭제하면 나머지 범위가 겹치지 않으므로 답은 1이다.\n\nO(NlogN)\n\n유사한 문제인 범위 합치기에서의 방법을 여기서도\n 활용해보자. 범위 합치기에서는 시작점을 기준으로 정렬한 다음 끝점을\n 비교했는데, 범위를 합칠 때 두 끝점 중 더 큰 끝점을 새로운 끝점으로\n 생성했었다. 즉, 여기서도 시작점을 기준으로 정렬을 활용한다면, 끝점도\n 함께 봐야하는 귀찮음이 발생한다.\n\n따라서, 여기서는 끝점을 기준으로 정렬하는 방법을 생각해볼 수\n 있다. 문제에서 범위를 겹치지 않게 만들기 위해 제거해야 하는 최소의\n 범위 수를 구하라고 했기 때문에, 탐욕적인 접근을 취할 수 있다. 단,\n 이걸 거꾸로 생각해서 범위를 삭제하는 것이 아니라 (범위 합치기처럼)\n 범위를 최대한 많이 남기는 것으로 생각해보자. 이전에 확인한 범위를\n 계속 유지하면서 다음 범위를 고를 수 있다면, 즉 겹치는 부분이 없다면\n 해당 범위를 선택하고 이전 범위를 지금 범위로 업데이트\n 한다. 이런식으로 쭉 겹치지 않는 범위만 고르면 최대한 많은 겹치지 않는\n 범위를 선택할 수 있고, 삭제는 이것의 역 연산이니 전체 개수에서 빼면\n 된다.\n\n이 아이디어를 구현하면 다음과 같다.\n\ndef eraseOverlapIntervals(intervals):\n    ordered = sorted(intervals, key=lambda x: x[1])\n    prev = ordered[0]\n    picked = 1\n    for itv in ordered[1:]:\n        if prev[1] &lt;= itv[0]:\n            picked += 1\n            prev = itv\n\n    return len(intervals) - picked"
					}
					,
					"ps-leetcode-number-of-connected-components-in-an-undirected-graph": {
						"id": "ps-leetcode-number-of-connected-components-in-an-undirected-graph",
						"title": "Number of Connected Components in an Undirected Graph",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/number-of-connected-components-in-an-undirected-graph/",
						"content": "Number of Connected Components in an Undirected Graph\n\nn개의 노드를 가진 그래프가 주어진다. 그래프는 무향 그래프이고 엣지\n 정보 edges가 주어지는데 edges[i] = [ai, bi] 이고 ai와 bi 노드\n 사이에 엣지가 있다는 의미이다.\n\n그래프에서 연결된 컴포넌트의 개수를 구하자.\n\nDFS\n\n이거 사실 섬 개수 구하기와 거의 같은\n 문제이다. 그래서 DFS로 모든 노드를 방문하면서 방문 기록을 남기고,\n 방문 안한 노드를 만날 때마다 개수를 1개씩 증가하면 된다. 이때\n 그래프가 무향이므로 엣지 정보를 정방향 한번 역방향 한번 총 두 번\n 체크해줘야 한다.\n\ndef countComponents(n, edges):\n    graph = defaultdict(set)\n    for src, snk in edges:\n        graph[src].add(snk)\n        graph[snk].add(src)\n\n    visited = set()\n    def dfs(node):\n        if node in visited:\n            return\n        visited.add(node)\n\n        for neighbor in graph[node]:\n            if neighbor not in visited:\n                dfs(neighbor)\n\n    count = 0\n    for node in range(n):\n        if node not in visitied:\n            count += 1\n            dfs(node)\n    return count\n\n\nUnion Find\n\n하나의 연결된 컴포넌트에 속한 노드는 절대로 다른 컴포넌트에 속할 수\n 없다. 즉, 연결된 컴포넌트 안의 원소는 서로소 집합이다. 이 부분도 섬의\n 개수 문제와 유사하다. 따라서 서로소 집합, 또는 유니온 파인드로도 풀\n 수 있다.\n\nclass DisjointSet:\n    def __init__(self):\n        self.rep = {}\n        self.count = 0\n\n    def __len__(self):\n        return self.count\n\n    def make(self, x):\n        if x not in self.rep:\n            count += 1\n            self.rep[x] = x\n\n    def find(self, x):\n        if x != self.rep[x]:\n            self.rep[x] = self.find(self.rep[x])\n        return self.rep[x]\n\n    def union(self, x, y):\n        px, py = self.find(x), self.find(y)\n        if px != py:\n            count -= 1\n            self.rep[px] = py\n\ndef countComponents(n, edges):\n    ds = DisjointSet()\n    for i in range(n):\n        ds.make(i)\n\n    for src, snk in edges:\n        ds.union(src, snk)\n\n    return len(ds)\n\n\n\n  유니온 파인드에서는 굳이 엣지를 양방향으로 볼 필요는 없다. 어차피\n양쪽 다 대표 원소가 지정되어 있으면 합쳐질 뿐이기 때문이다."
					}
					,
					"ps-leetcode-number-of-distinct-islands": {
						"id": "ps-leetcode-number-of-distinct-islands",
						"title": "Number of Distinct Islands",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/number-of-distinct-islands/",
						"content": "Number of Distinct Islands\n\nm x n 지도가 주어진다. 0은 물이고 1은 땅이다. 4방향 1로 이뤄진 땅은\n 섬이다. 네 방향의 가장자리는 모두 물로 둘러쌓여 있다.\n\n어떤 섬의 모양을 바꾸지 않고 그대로 다른 섬에 매칭할 수 있으면, 두\n 섬은 같다고 취급한다. 즉, 90도, 180도, 270도 회전을 제외한 같은\n 모양의 섬은 모두 같은 섬이다.\n\n지도에서 고유한 섬의 개수를 구하자.\n\n접근\n\n  “고유한(distinct)”의 정의가 모든 회전을 제외한 수평이동임을\n이해하자.\n  회전이 없어서 그나마 쉬운 편에 속한다.\n  어떤 방식이든 섬의 좌표 집합을 정규화(normalize)하는 방법이\n필요하다.\n  고유한 섬의 개수를 세기 위해서 (1) 전체 지도를 탐색하는 방향과 (2)\n섬에 속한 땅을 탐색하는 방향을 항상 일정하게 유지해야\n한다.\n  그러면, 어떤 미지의 섬에 속한 첫 번째 땅을 방문하게 될 때, 항상\n같은 땅을 방문하게 되고, 그 후 거기 속한 섬의 땅은 항상 같은 순서로\n탐색됨이 보장된다. 이것이 기본 전제다.\n  문제의 조건인 고유한 섬을 구분하기 위해서 섬에 속한 땅의 좌표의\n집합을 정규화하는 접근을 적용해보자.\n  같은 모양의 섬은 항상 같은 위치의 땅부터 밟는 것이 보장되므로,\n처음으로 밟는 이 땅의 위치를 항상 원점 (0, 0)이라고 하자. 그러면\n나머지 섬의 땅을 이 원점을 기준으로 수평이동하면, 같은 모양의 섬은\n항상 같은 좌표 집합을 갖게 된다.\n  즉, BFS는 이제 섬을 방문하고 끝나는게 아니라 섬에 속한 땅의\n정규화된 좌표 집합을 리턴하는 함수가 된다. 그리고 이걸 다시\n집합으로 쌓아서 최종 개수를 세면 된다.\n\n\ndef numDistinctIslands(grid):\n    m, n = len(grid), len(grid[0])\n    visited, islands = set(), set()\n\n    def bfs(x, y):\n        visited.add((x, y))\n        lands = [(0, 0)]\n        q = deque()\n        q.append((x, y))\n        ox, oy = x, y\n        while q:\n            x, y = q.popleft()\n            for nx, ny in [(x+1,y), (x-1,y), (x,y+1), (x,y-1)]:\n                if nx &lt; 0 or ny &lt; 0 or nx &gt;= m or ny &gt;= n:\n                    continue\n                if (nx, ny) in visited or grid[nx][ny] == 0:\n                    continue\n                visited.add((nx, ny))\n                q.append((nx, ny))\n                lands.append((nx - ox, ny - oy))\n        return lands\n\n    for x in range(m):\n        for y in range(n):\n            if (x, y) not in visited and grid[x][y] == 1:\n                islands.add(tuple(bfs(x, y)))\n    return len(islands)\n\n\n접근 2\n\n  같은 모양의 섬을 정규화하는 또 다른 한 가지 방법은 바로 섬의 땅을\n탐색하는 방향의 순서를 기록하는 것이다.\n  항상 일정한 순서로 네 방향의 땅을 탐색한다고 하면, 같은 모양의 섬에\n속한 모든 땅을 방문하는 방향은 항상 같은 순서일 것이다.\n  다만 이 방법은 DFS로 밖에 안풀리는 것 같고 구현이 좀더 헷갈린다."
					}
					,
					"ps-leetcode-number-of-islands": {
						"id": "ps-leetcode-number-of-islands",
						"title": "Number of Islands I, II",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/number-of-islands/",
						"content": "Number of Islands\n\nm x n 2D 그리드가 지도로 주어진다. 1은 땅이고 0은 물일 때, 섬의\n 개수를 세는 문제다.\n\n여기서 섬은 가로/세로로 인접해서 연결된 땅이 물로 둘러 쌓여 있는\n 것을 의미하는데, 지도 바깥은 전부 물이라고 가정하면 된다.\n\nDFS\n전형적인 그래프 탐색 문제다. 파이썬으로 DFS는 특히 쉽게 구현할 수\n 있어서 여기서는 DFS로 구현해본다.\n\n전체 지도를 돌다가 땅을 만나는 순간 섬의 개수를 하나 증가하고, 곧바로\n 그 땅으로부터 DFS를 시작해서 모든 땅을 다 탐색하면 된다. 이후\n 만나는 땅 중에서 이전 땅에서 이미 탐색 된 땅은 같은 섬에 속하게\n 되고, 탐색 안된 땅은 다른 섬이기 때문에 또 DFS를 호출하게 된다.\n\ndef numIslands(grid):\n    visited = set()\n    m, n = len(grid), len(grid[0])\n    def dfs(x, y):\n        visited.add((x, y))\n\n        for nx, ny in [(x+1, y), (x-1, y), (x, y+1), (x, y-1)]:\n            if 0 &lt;= nx &lt; m and 0 &lt;= ny &lt; n:\n                if grid[nx][ny] == '1' and (nx, ny) not in visited:\n                    dfs(nx, ny)\n\n    num = 0\n    for x in range(m):\n        for y in range(n):\n            if grid[x][y] == '1' and (x, y) not in visited:\n                num += 1\n                dfs(x, y)\n\n    return num\n\n\n\n  파이썬의 튜플은 해싱 가능하기 때문에 set에 곧바로 넣을 수\n있다. 해당 좌표가 이미 탐색이 끝났는지 여부를 쉽게 체크할 수 있다.\n  범위 연산을 할 때 x &gt;= 0 and x &lt; m과 같이 &amp;&amp; 연산을 해도 되지만\n위에서 처럼 Pythonic 하게 적을 수도 있다. 더 잘 읽힌다.\n  원래 DFS 재귀 함수 안에서 다음 노드를 방문하기 전에 방문 여부\n(visited) 를 체크해주면 된다. 여기서는 바깥에서 추가로 한번 더 방문\n여부를 체크하는데 그 이유는 섬의 개수를 세기 위해서다. 어떤 섬의\n땅에 첫 발을 내딛는 순간 섬의 개수가 하나 증가하고 그 섬에 속한\n모든 땅을 방문한 것으로 기록하기 때문에, 이후 노드 중 이미 방문\n기록된 노드는 이전 DFS 에서 섬으로 카운트 된 땅이다.\n\n\nBFS\nBFS로도 구현해보았다. DFS와 마찬가지로 첫 땅을 밟는 순간 섬 개수를\n 늘리고, 인접한 모든 땅(섬)을 방문으로 기록한다.\n\ncollections 모듈에 deque가 있으니 이걸 쓰면 된다.\n\nfrom collections import deque\ndef numIslands(grid):\n    visited = set()\n    m, n = len(grid), len(grid[0])\n\n    def bfs(x, y):\n        visited.add((x, y))\n        q = deque()\n        q.append((x, y))\n\n        while q:\n            cx, cy = q.popleft()\n            for nx, ny in [(cx+1, cy), (cx-1, cy), (cx, cy+1), (cx, cy-1)]:\n                if 0 &lt;= nx &lt; m and 0 &lt;= ny &lt; n and grid[nx][ny] == '1' and (nx, ny) not in visited:\n                    visited.add((nx, ny))\n                    q.append((nx, ny))\n\n    num = 0\n    for x in range(m):\n        for y in range(n):\n            if grid[x][y] == '1' and (x, y) not in visited:\n                bfs(x, y)\n                num += 1\n\n    return num\n\n\nNumber of Islands II\n위 문제를 살짝 비튼 문제다.\n\nm x n 2D 그리드의 사이즈가 주어진다. 처음에 모든 그리드는\n 0, 즉 물이다.\n\n각 단계마다 물을 땅으로 바꾸는 조작(0 -&gt; 1)을 할 수 있다. 위치 배열\n positions가 입력으로 같이 들어오는데, positions[i] = (r_i, c_i)\n 이고 (r_i, c_i) 위치의 물을 땅으로 바꾼다. 그리고 이 작업은 i\n 번째 단계에 수행되어야 한다.\n\n이때, 각 단계마다 조작을 수행한 후의 땅의 개수를 구하자. 즉, 답은\n 땅의 개수를 담은 리스트가 될 것이다.\n\n\n  ` 1 &lt;= m, n, positions.length &lt;= 10^4`\n\n\nDisjoint Set or Union Find\n가장 단순한 방법은, 매 단계마다 땅을 추가한 다음 위에서 구현한 섬의\n 개수를 구하는 함수를 호출해서 정답 리스트에 쌓아 나가면 된다. 단,\n 이렇게하면 매 단계마다 O(n^2)의 검사가 필요하기 때문에, 아주\n 비효율적이다.\n\n여기서 서로소 집합을 떠올릴 수 있어야 한다.\n\n섬은 연결된 땅의 집합을 뜻한다. 이때, 어떤 땅이 두 개 이상의 섬에\n 속하는 것은 불가능하다. 즉, 다시 말하면 모든 섬은 공통 원소(같은\n 위치의 땅)가 없다. 이렇게 상호 배타적인 부분 집합들로 나눠진\n 원소들에 대한 정보를 저장/조작하는 자료구조가 바로 서로소 집합이다.\n\n즉, 이 문제를 풀기 위한 알고리즘을 설명하면 대략 이렇다.\n\n  섬의 정보를 저장하기 위한 서로소 집합을 만든다.\n  각 positions 마다, 땅을 추가하고, 서로소 집합에 추가한다.\n  추가된 땅의 4방향 중 땅이 있는 모든 곳은 합친다(Union).\n  그 후에 서로소 집합에 있는 모든 섬의 개수를 기록한다.\n\n\n서로소 집합만 떠올리고, 구현한다면, 생각보다 쉽게 풀리는 문제다.\n\nOptimized Disjoint Set\n서로소\n 집합이\n 필요하다는 걸 알았으니 구현해보자. 가장 단순하게 구현하는 방법은\n 다음과 같이 배열(또는 해시테이블)을 이용해서 각 서로소 집합의 대표\n 원소(부모)를 기록하는 방법이다. 일종의 트리라고 볼 수 있다.\n\nfunction MakeSet(x)\n  x.parent := x\n\nfunction Find(x)\n  if x.parent == x\n    return x\n  else\n    return Find(x.parent)\n\nfunction Union(x, y)\n  xRoot := Find(x)\n  yRoot := Find(y)\n  xRoot.parent := yRoot\n\n\n위키피디아에 있는 수도 코드를 가져왔다. MakeSet은 x 하나로\n 이루어진 서로소 집합을 만드는 연산이다. Find는 x가 속한 서로소\n 집합의 대표 원소, 즉 앞서 말한 트리의 루트 노드를 찾는\n 연산이다. Union은 x와 y를 같은 서로소 집합에 속하게 만드는\n 연산이다.\n\n근데 이렇게 나이브하게 구현하면 트리에서 Skewed Tree가 발생하는 것과\n 같은 이치로, 점점 균형이 깨질 것이다. 그러면 각 연산의 복잡도가\n O(n)에 수렴한다. 좋지 않다.\n\n이를 위해 두 가지 최적화 방법이 있는데,\n\n  Union by Rank: Rank를 기록해서, Union 연산을 할 때 항상 더 작은\n길이의 트리를 더 큰 길이의 트리에 합치는 방법이다.\n  Path Compression: Find 연산을 할 때마다, 모든 속한 원소의 부모를\n하나의 대표 원소를 가리키게 하는 방법이다.\n\n\n몇 가지 실험을 해보니까, Union by Rank는 (적어도 파이썬 구현에\n 한해서는) 크게 재미를 보지 못했다. 일단 랭크를 저장하기 위해서\n 데이터가 추가로 필요하고, 매 연산마다 랭크를 찾아서 비교해야 하기\n 때문인 것 같다. 반면 경로 압축은 엄청난 효과를 보았기 때문에 여기서는\n 경로 압축만을 적용해서 최적화된 서로소 집합을 만들 것이다.\n\n아, 그리고 그전에 한 가지 더 필요한 작업이 있다. 위의 수도 코드에서는\n Find나 Union에 파라미터로 넘어가는 원소들은 항상 그 전에\n MakeSet으로 원소 하나 짜리 집합을 만들 필요가 있었다. 그런데\n 여기서는 섬의 개수를 세는 연산을 효율적으로 하기 위해서,\n MakeSet이 호출될 때 개수를 하나 늘리고, Union 에서 서로 다른\n 서로소 집합끼리 합쳐질 때 개수를 하나 줄인다. 이렇게하면 개수를 셀\n 때마다 전체 데이터를 다 훑지 않아도(즉, Find(x) == x 검사) 된다.\n\n이제 여기까지 왔으니 서로소 집합 연산을 위한 클래스를 구현해보자.\n\nclass DisjointSet:\n    def __init__(self):\n        self._data = dict()\n        self._count = 0\n\n    def __len__(self):\n        return self._count\n\n    def make_set(self, x):\n        if x not in self._data:\n            self._data[x] = x\n            self._count += 1\n\n    def find(self, x):\n        if x != self._data[x]:\n            self._data[x] = self.find(self._data[x])\n\n        return self._data[x]\n\n    def union(self, x, y):\n        parentx, parenty = self.find(x), self.find(y)\n\n        if parentx != parenty:\n            # decrease connected counts\n            self._count -= 1\n            self._data[parentx] = parenty\n\n\n\n  개수를 캐싱하기 위해서 _count 변수도 유지한다. __len__은 단순히\n이 값을 리턴해서 O(1)을 유지한다.\n  find 연산을 경로 압축으로 최적화했다. x의 부모가 x가 아니면\nx의 루트까지 타고 올라가서 루트를 부모로 업데이트 한다.\n  union은 랭크 최적화는 진행하지 않았다. 대신 합치려는 두 서로소\n집합이 다를 때 개수도 함께 줄인다.\n\n\n그러면 이렇게 만든 서로소 집합으로 다음과 같이 문제를 풀 수 있다.\n\ndef num_islands_2(m, n, positions):\n    answer = []\n    dset = DisjointSet()\n    lands = set()\n\n    for x, y in positions:\n        dset.make_set((x, y))\n        lands.add((x, y))\n\n        for nx, ny in ((x+1, y), (x-1, y), (x, y+1), (x, y-1)):\n            if (nx, ny) in lands:\n                dset.union((x, y), (nx, ny))\n\n        answer.append(len(dset))\n\n    return answer\n\n\n  지금까지 땅으로 바뀐 위치를 기록하기 위해서 lands를\n만들어뒀다. 이게 필요한 이유는, 현재 단계에서 연산을 한 다음\n4방향을 살필 때 이게 땅인지 아닌지를 빠르게 판단하기 위해서다. m x\nn 그리드를 직접 만들어도 된다.\n  현재 단계의 위치를 땅으로 만든 후 (dset.make_set, lands.add),\n4방향의 땅 위치를 Union 한다. 이때, lands 를 기록하고 있기\n때문에 굳이 0 &lt;= nx &lt; m 또는 0 &lt;= ny &lt; n를 확인할 필요는 없다."
					}
					,
					"ps-leetcode-number-of-provinces": {
						"id": "ps-leetcode-number-of-provinces",
						"title": "Number of Provinces",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/number-of-provinces/",
						"content": "Number of Provinces\n주(Province)의 개수를 세는 문제이다. n 개의 도시가 있는데 도시끼리\n 연결되어 있기도 하고 아니기도 하다. 주는 직접/간접적으로 연결된\n 도시의 그룹이다. a랑 b가 연결되어 있으면 이건 직접적으로 연결된\n 거고, b랑 c가 연결되어 있다면 a랑 c는 간접적으로 연결된 거다.\n\nisConnected[i][j]가 주어지고 이게 1이면 i 도시랑 j 도시가 연결된\n 거다. 도시의 개수가 n개 이므로 n x n 배열이다.\n\nDFS\n전형적인 그래프 순회 문제이다. 예전 섬의 개수 구하는 거랑 비슷하게,\n 첫 방문하는 도시에 들어가자마자 주의 개수를 증가시키면서 연결된 모든\n 도시를 다 방문해버리면 된다.\n\nisConnected가 항상 n x n이 보장되기 때문에 도시의 번호를 구하기\n 쉽다. 그리고 이 정보는 무향 그래프이기 때문에 양방향을 다 고려해야\n 한다.\n\ndef numProvinces(isConnected):\n    n = len(isConnected)\n\n    visited = set()\n    def dfs(c1, c2):\n        if (c1, c2) in visited or (c2, c1) in visited:\n            return\n\n        visited.add((c1, c2))\n        visited.add((c2, c1))\n\n        for cn in range(n):\n            if isConnected[c1][cn] and (c1, cn) not in visited:\n                dfs(c1, cn)\n            if isConnected[c2][cn] and (c2, cn) not in visited:\n                dfs(c2, cn)\n\n    num = 0\n    for c1 in range(n):\n        for c2 in range(n):\n            if isConnected[c1][c2] and (c1, c2) not in visited:\n                num += 1\n                dfs(c1, c2)\n\n    return num\n\n\n\n  양방향을 모두 고려해서 (c1, c2)와 (c2, c1)을 다 세어주고 있다.\n  나머지는 섬의 개수 세는 것과 거의 유사하다."
					}
					,
					"wip-lwt-nutshell": {
						"id": "wip-lwt-nutshell",
						"title": "Lwt in 5 Minutes",
						"version": "all",
						"categories": "",
						"url": " /wip/lwt/nutshell/",
						"content": "Lwt in 5 minutes\n\n원칙\nLwt 라이브러리는 협력형 쓰레드를 구현한다. 협력형 쓰레드는 선점형\n 쓰레드에서 겪게 되는 대부분의 이슈를 해결해준다. Lwt를 이용하면\n 데드락의 위험이 거의 없고 락도 거의 필요없다. Lwt 쓰레드는 심지어\n Js_of_ocaml로 컴파일된 자바스크립트 프로그램에서도 쓰일 수\n 있다(왜냐면 Promise랑 거의 유사하기 때문에).\n\nLwt는 대부분의 프로그램이 키, 소켓에서 읽어 들일 데이터, 마우스\n 이벤트 등 입력을 기다리는데 대부분의 시간을 쓴다는 사실에\n 근거한다. 임의의 시점에 쓰레드 사이를 스위치해버리는 선점형 쓰레드와\n 달리, Lwt는 이런 기다리는 시간을 협력 포인트(cooperation points)로\n 이용한다. 즉, read 함수처럼 블로킹을 하지 않고, Lwt는 계속할 준비가\n 되어 있는 준비된 쓰레드 중 하나를 재개(resume) 시킨다. 우리가 해야 할\n 일은 각 블로킹 함수의 협력형 버전을 사용하는 것이다. 예를 들면\n Unit.sleep 대신 Lwt_unix.sleep, Unix.read 대신\n Lwt_unix.read를 호출하는 것이다. 계산 중 하나가 오랜 시간이\n 걸린다면, Lwt_main.yield를 호출해서 직접 협력 포인트를 삽입하는\n 것도 가능하다.\n\nPromises\n\nLwt는 'a Lwt.t 타입으로 프로미스를 정의한다. 예를 들어, 다음 함수\n\nval f : unit -&gt; int Lwt.t\n\n\n는 int의 프로미스를 곧바로 리턴하는데, 즉 뭔가 계산이 끝나기만\n 한다면 결국에는 하나의 정수 값을 가진다는 의미이다.\n\n다음 코드는 f ()의 계산을 (비동기적으로) 시작한다. 코드가 협력\n 포인트에 도달하면 (예를 들어 정수 값이 네트워크를 통해 요청되거나\n 하는 등), 프로그램은 계속 진행되어 print_endline \"hello\"를\n 수행하고, 데이터를 사용할 수 있을 때 이후의 협력 포인트에서 재개된다.\n\nlet g1 () =\n    let p = f () in\n    print_endline \"hello\"\n\n\nBind: 프로미스의 값을 사용하기\n\n프로미스가 완료되고 나면 함수를 사용하도록 하는 것이 가능하다. 다음\n 함수를 이용하면 된다.\n\nLwt.bind : 'a Lwt.t -&gt; ('a -&gt; 'b Lwt.t) -&gt; 'b Lwt.t\n\n\n예를 들면 Lwt.bind p h는 프로미스 p의 리턴 값을 알게 되자마자 이\n 값을 이용해서 함수 h를 호출한다. 표현식 (Lwt.bind p h) 역시\n 프로미스 타입이라서 완료하는데 시간이 걸릴 수 있다. 함수 h는 반드시\n 프로미스를 리턴해야 한다.\n\n값으로부터 완료된 프로미스를 생성하기 위해서는 Lwt.return 함수를\n 쓰면 된다.\n\nlet g2 () =\n    let p = f () in\n    Lwt.bind p (fun i -&gt; print_int i; Lwt.return ())\n\n\n위 코드에서 함수 g2는 함수 f를 호출해서 프로미스를\n 생성한다. 그러고나서 (협력적인 방식으로) 결과를 기다리고, 그 결과를\n 출력한다. g2 ()는 unit Lwt.t 타입이다.\n\n문법 확장\n\n문법 확장도 가능하다.\n\nlet%lwt i = f () in\n...\n\n\n이는 아래 코드와 동일하다.\n\nLwt.bind (f ()) (fun i -&gt; ...)\n\n\n예시\n매 초마다 “tic”를 영원히 출력하지만 프로그램의 나머지 부분은 블로킹 되지 않는 함수\n\nlet rec tic () =\n    print_endline \"tic\";\n    let%lwt () = Lwt_unix.sleep 1.0 in\n    tic ()\n\n\n여기서 Lwt_unix.sleep을 Lwt_js.sleep으로 바꾸면 브라우저에서\n 실행할 수 있다.\n\n동시성 쓰레드를 시작하고 각각의 결과를 기다리기\n\n아래 타입의 두 협력 쓰레드가 있다고 하자.\n\nval f : unit -&gt; unit Lwt.t\nval g : unit -&gt; unit Lwt.t\n\n\n다음 코드는 f ()와 g ()를 차례로 호출한다.\n\nlet%lwt () = f () in\nlet%lwt () = g () in\n...\n\n\n다음 코드는 f ()와 g ()를 동시에 시작하고, 계속하기 전에 두\n 쓰레드가 모두 종료될 때까지 기다린다.\n\nlet p1 = f () in\nlet p2 = g () in\nlet%lwt () = p1 in\nlet%lwt () = p2 in\n...\n\n\n쓰레드를 분리(detach)하려면 다음과 같이 쓰는 것을 추천한다. 그래야\n 예외를 적절히 잡을 수 있다.\n\nLwt.async (fun () -&gt; f ())\n\n\n아래와 같이 쓰지 말자.\n\nignore (f ())\n\n\n순차적인 리스트 매핑과 동시적인 리스트 매핑\n\n다음 map 함수는 모든 리스트 원소에 대해서 모든 계산을 동시에\n 진행한다.\n\nlet rec map f l =\n    match l with\n    | [] -&gt; Lwt.return []\n    | v :: r -&gt;\n        let t = f v in\n        let rt = map f r in\n        let%lwt v' = t in\n        let%lwt l' = rt in\n        Lwt.return (v' :: l')\n\n\n반면에 아래 함수는 다음번 계산을 시작하기 전에 지금 계산하고 있는\n 것이 완료될 때까지 기다려야 한다.\n\nlet rec map_serial f l =\n    match l with\n    | [] -&gt; Lwt.return []\n    | v :: r -&gt;\n        let%lwt v' = f v in\n        let%lwt l' = map_serial f r in\n        Lwt.return (v' :: l')"
					}
					,
					"ps-boj-ocaml": {
						"id": "ps-boj-ocaml",
						"title": "OCaml Problem Solving",
						"version": "all",
						"categories": "",
						"url": " /ps/boj/ocaml/",
						"content": "OCaml\n\n놀랍게도 백준에서는 OCaml 언어도 지원한다. 무려 4.11.1 버전이고\n 네이티브 컴파일러도 되는 버전이다. 하지만 C++나 파이썬만큼 문제\n 풀이에 도움이 되는 강력한 표준 라이브러리가 없고, 표준 라이브러리가\n 약간 나사빠진(?) 느낌이라 꽤나 야크 셰이빙을 해야 한다.\n\n여기서는 그나마 제정신인 라이브러리의 사용법을 정리하고, 문제 풀이에\n 반쯤 필수적인 몇몇 라이브러리 모듈을 구현해서 정리해두려고\n 한다. 심지어 지금 이 글을 쓰면서 발견한건데 표준 라이브러리 API를\n 정리해두던 공식 사이트가 v2로 올라가면서 이것마저도 살짝 나사빠진\n 구석이 있어서 문서 빌드가 에러난다(…). 아니 옛날 버전 문서가 없어?\n\n일단 문서 링크가 복원되면 그때 적기로 하자…"
					}
					,
					"ps-leetcode-optimal-partition-of-string": {
						"id": "ps-leetcode-optimal-partition-of-string",
						"title": "Optimal Partition Of String",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/optimal-partition-of-string/",
						"content": "Optimal Partition Of String\nGreedy하게 풀면 된다. 소문자만 담을 파티션 하나를 나타내는 집합을 P라고 하자.\n  문자열을 쭉 훑으면서 P에 이미 해당 알파벳이 있으면 다 초기화하고 새로 시작하면서\n  개수를 하나 늘리고, 아니면 계속 진행하면 된다.\n탐욕적 방법이 동작하는 이유를 증명하면 다음과 같다. 알파벳 a가 P에 있는 상황에서\n  쭉 훑다가 같은 알파벳 a를 만났다고 하자. 그러면 파티션 개수가 2개가 된다. 그런데\n  만약 이 탐욕적인 방법이 최소 의 해를 구하는 방법이 아니라면, 이전에 만난 a와\n  지금 만난 a가 같은 파티션에 속해야 한다. 그래야 파티션 개수가 1개가 되기\n  때문이다. 하지만 이는 파티션의 정의에 따라 불가능하기 때문에 탐욕적인 방법은\n  항상 최적의 해를 구할 수 밖에 없다.\ndef partitionString(s) -&gt; int:\n    p = set()\n    pn = 1\n    for char in s:\n        if char not in p:\n            p.add(char)\n        else:\n            p.clear()\n            p.add(char)\n            pn += 1\n    return pn"
					}
					,
					"ps-leetcode-pacific-atlantic-water-flow": {
						"id": "ps-leetcode-pacific-atlantic-water-flow",
						"title": "Pacific Atlantic Water Flow",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/pacific-atlantic-water-flow/",
						"content": "Pacific Atlantic Water Flow\n\nm x n 크기의 사각형 모양의 섬 정보가 주어진다. 섬은 태평양(Pacific\n Ocean)과 대서양(Atlantic Ocean) 모두에 둘러쌓여 있다. 태평양은 왼쪽과\n 위쪽에, 대서양은 오른쪽과 아래쪽에 있다.\n\n섬 정보는 heights 배열로 주어지는데 heights[row][col]은 섬의\n (row, col) 위치에서의 땅의 높이를 나타낸다.\n\n섬에는 비가 엄청나게 많이 오는데, 비는 현재 땅의 동서남북으로 인접한\n 땅 중에서 높이가 같거나 더 작은 곳으로 흘러내린다. 최종적으로\n 비는 태평양과 대서양으로 흘러간다.\n\n이때, 비가 양쪽 바다 모두로 흘러갈 수 있는 땅의 좌표의 리스트를\n 구하자.\n\n\\(1 \\leq m, n \\leq 200\\) 이고 높이는 \\(0 \\sim 10^5\\) 이다.\n\n예를 들어 아래 땅을 보자.\n\n\n\n그림에서 노랗게 칠해진 땅은 비가 양 쪽 바다 모두로 흘러갈 수\n 있다. 따라서 답은 이 땅들의 좌표 목록이다.\n\n그래프 탐색\n\n이거 꽤나 신박한 그래프 탐색 문제라서 재밌게 풀었다.\n\n일단 언뜻 생각하기에 가장 높은 곳을 찾아서 어찌 해야할 것 같지만, 잘\n 생각해보면 가장 높은 곳이 아니라 인접한 땅을 기준으로 가장 높은\n 곳을 찾아야 한다. 그런데 이렇게 찾을려면 전체 배열을 뒤지면서 각\n 땅마다 네 방향을 다 봐야한다. 거기다 이 높은 지점들을 찾더라도 이\n 지점들 중에서 양쪽 바다로 모두 흘러갈 수 있는 곳을 또 찾아야\n 한다. 즉, 문제의 조건을 그대로 시뮬레이션 하기에는 꽤 복잡하다.\n\n그래서 약간 발상의 전환이 필요한데, 문제를 듀얼로 생각해보는\n 것이다. 그러니까 비가 흘러서 내려가는게 아니라, 거꾸로 바다에서\n 물이 땅을 따라 올라간다고 생각해보자. 즉 바다와 인접한 모든 땅에서\n 출발해서, 네 방향 중 더 높거나 같은 높이의 땅으로 타고 올라가면서\n 땅을 적신다고 해보자. 그러면 태평양이 적실 수 있는 땅과 대서양이 적실\n 수 있는 땅의 집합이 나오는데, 이 두 집합의 교집합이 결국 우리가\n 원하는 답이 됨을 알 수 있다.\n\n바다가 적실 땅을 알아보려면 결국 그래프 탐색이 필요하다. 여기서는\n BFS로 탐색하자. 그러면 BFS의 입력으로 탐색에 쓰일 큐를 직접 받는 게\n 좋아보인다. 왜냐하면 태평양과 대서양의 출발 지점이 각각 다르기\n 때문이다. 그걸 제외하면 탐색 알고리즘은 동일하다. 탐색 결과로는\n 방문한 모든 땅의 집합을 리턴하면 된다. 그래야 최종적으로 두 바다에서\n 모두에서 방문 가능한 땅의 위치를 알 수 있다.\n\nfrom collections import deque\ndef pacificAtlantic(heights):\n    m, n = len(heights), len(heights[0])\n    def bfs(queue):\n        lands = set()\n        acc = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n        while queue:\n            cur = queue.popleft()\n            lands.add(cur)\n            for dx, dy in acc:\n                cand = (cur[0] + dx, cur[1] + dy)\n                if cand[0] &lt; 0 or cand[1] &lt; 0 or cand[0] &gt;= m or cand[1] &gt;= n:\n                    continue\n                if cand in lands:\n                    continue\n                if heights[cand[0]][cand[1]] &gt;= heights[cur[0]][cur[1]]:\n                    queue.append(cand)\n        return lands\n\n    pacific, atlantic = deque(), deque()\n    for c in range(n):\n        pacific.append((0, c))\n        atlantic.append((m - 1, c))\n    for r in range(m):\n        pacific.append((r, 0))\n        atlantic.append((r, n - 1))\n    return bfs(pacific) &amp; bfs(atlantic)"
					}
					,
					"ps-leetcode-paint-house": {
						"id": "ps-leetcode-paint-house",
						"title": "Paint House",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/paint-house/",
						"content": "Paint House\n\nn개의 집이 일렬로 서있다. 각각의 집은 빨강, 파랑, 초록 셋 중 하나의\n 색으로 칠할 수 있다. 각 집을 어떤 색으로 칠하는지에 따라서 비용이\n 다르다. 서로 인접한 두 집 끼리는 같은 색이 아니도록 모든 집을 칠하고\n 싶다.\n\n각 집을 특정 색으로 칠하는 비용 정보는 n x 3 행렬인 costs에\n 담겨있다. 예를 들어, costs[0][0]은 0번 집을 빨강으로 칠하는\n 비용이고, cost [1][2]는 1번 집을 초록으로 칠하는 비용이다.\n\n모든 집을 칠하기 위한 최소의 비용을 구하자.\n\n집의 수는 1 ~ 100, 비용의 범위는 1 ~ 20 이다.\n\n탐색 공간을 다이나믹 프로그래밍 하기\n\n순서대로 0번 집부터 칠해나아간다고 생각해보자. 그러면, 다음 두 가지\n 정보를 상태로 유지하고 진행해야 한다는 것을 깨달을 수 있다.\n\n  지금 칠해야 할 집 인덱스 cur\n  이전 집에 칠한 색깔 prev_color\n\n\n그러면 다음 관계를 알 수 있다: 이전 집 색깔 prev_color에 대해서\n 현재 집 cur를 칠하는 최소 비용 = (이전 집 색과 다른 모든 색에\n 대해서 현재 집을 칠할 비용 + 이 색에 대해서 cur + 1를 칠할 최소\n 비용) 중 최소.\n\n그리고 자연스럽게, 이 중에서 반복되는 부분 문제가 발생함을 알 수\n 있고, 이를 메모아이즈하면 풀린다.\n\nfrom functools import cache\ndef minCost(costs):\n    total = len(costs)\n\n    @cache\n    def paint(cur:int, prev_color:int) -&gt; int:\n        if cur == total:\n            return 0\n\n        min_cost = float('inf')\n        for color, cost in enumerate(costs[cur]):\n            if color == prev_color:\n                continue\n            cur_cost = cost + paint(cur + 1, color)\n            min_cost = min(min_cost, cur_cost)\n        return min_cost\n    return paint(0, -1)\n\n\n\n  재귀 함수의 베이스 케이스는 집을 끝까지 칠했을 때, 즉 마지막 집에\n도달했을 때이고, 이때의 최소 비용은 아무것도 칠하지 않아도 되므로\n0이다.\n  재귀 함수를 처음 호출할 때, 이전 집을 칠한 색깔 prev_color는\n빨강, 파랑, 초록인 0, 1, 2만 아니면 다 괜찮다. 색깔들이 costs의\n인덱스로 표현되고 있어서, 여기서는 -1을 넘겨주었다.\n\n\nPaint House II\n\n이번에는 3개의 색이 아니라 k개의 색을 칠할 수 있고 나머지 조건은\n Paint House와 같다.\n\n\\(2 \\leq k \\leq 20\\) 이라서, 그냥 위의 솔루션을 그대로 재활용할 수\n 있다.\n\nPaint House III\n\n작은 도시에 m개의 집이 일렬로 있는데 각각의 집을 반드시 n개의\n 색깔 중 하나로 칠해야 한다. 색깔은 1 부터 n까지 레이블링 되어\n 있다. 이 중 몇몇 집은 작년 여름에 이미 칠해놔서 지금 칠하지 않아도\n 된다.\n\n같은 색깔로 칠해진 집들의 연속적인 그룹을 이웃이라고 한다. 예를\n 들어, houses = [1, 2,2, 3,3, 2, 1,1]은 다섯 개의 이웃 [{1}, {2,2},\n {3,3,}, {2}, {1,1}]을 포함하고 있다.\n\n현재 집의 색깔 배열 houses와 m x n 행결 cost와 정수\n target값이 주어진다.\n\n  houses[i]는 i번째 집의 현재 색깔이다. 0이면 아직 칠해지지\n않았다.\n  cost[i][j]는 i번째 집을 j + 1색으로 칠할 때 드는 비용이다.\n\n\n이때, 아직 색이 칠해지지 않은 모든 집을 칠해서 정확히 target 개의\n 이웃이 되도록 하기 위한 최소의 비용을 구하자. 만약 불가능한 경우\n -1을 리턴하자.\n\nhouses와 costs 배열의 길이 m은 모두 같고 1 ~ 200\n 사이이다. 색깔의 종류(cost[i]의 길이)는 1 ~ 20 이다. target은 1과\n m 사이의 값이다. 각각의 비용 값은 1 ~ 10,000 사이이다.\n\n탐색 공간을 다이나믹 프로그래밍 하기\n\n이전 문제와는 달리 인접한 집끼리 반드시 서로 다른 색일 필요는 없고,\n 대신 이웃이라는 개념이 새로 추가되었다. 따라서, 추적해야 하는 상태\n 값에 하나를 더 추가해야 한다: 바로 지금까지 생성된 이웃 수이다. 즉,\n\n  지금 칠할지 말지 확인하려는 집의 인덱스 cur\n  이전에 칠한 집의 색깔 prev_color\n  지금까지 만들어진 이웃 수 neighbor\n\n\n즉, 우리가 각 단계마다 하는 결정은 바로 직전 단계의 상태(위의 세\n 가지)에 영향을 받는다.\n\nfrom functools import cache\ndef minCost(houses, cost, m, n, target):\n    @cache\n    def paint(cur, prev_color, neighbor):\n        if cur == m:\n            return 0 if neighbor == target else float('inf')\n        if neighbor &gt; target:\n            return float('inf')\n        if houses[cur] != 0:\n            neighbor = neighbor if houses[cur] == prev_color else neighbor + 1\n            return paint(cur + 1, houses[cur], neighbor)\n\n        min_cost = float('inf')\n        for color in range(1, n+1):\n            new_neighbor = neighbor if color == prev_color else neighbor + 1\n            cur_cost = cost[cur][color - 1] + paint(cur + 1, color, new_neighbor)\n            min_cost = min(min_cost, cur_cost)\n        return min_cost\n\n    answer = paint(0, 0, 0)\n    return answer if answe != float('inf') else -1\n\n\n\n  집을 끝까지 칠했다면, 즉 현재 칠할 집의 인덱스가 끝이라면, 최소\n비용을 곧바로 알 수 있다. 여기서는 한 가지 조건을 더 확인해야\n하는데, 바로 지금까지 만들어진 이웃의 수가 target과 같은지\n확인하는 것이다. 이웃 수 조건을 만족한다면 최소 비용은 0이 되고,\n그렇지 않으면 무한대가 되어야 한다.\n  문제의 조건 덕분에 현재 집을 끝까지 봤는지와는 관계 없이 탐색\n공간을 프루닝할 수 있다. 바로 지금까지 만든 이웃의 수가 target을\n넘어버린 경우이다. 이때는 집을 끝까지 칠해봐야 소용이 없기 때문에\n곧바로 무한대의 비용을 리턴하면 된다.\n  이전의 문제와 달리 이번에는 색깔이 0일 때 아직 색을 칠하지 않은\n집이다. 그리고 우리는 이런 집만을 칠해야 한다. 따라서, 현재 집의\n색깔이 0이 아니라면, 작년 여름에 이미 칠한 집이므로, 이 색깔을\n그대로 이용해서 이웃 수를 새로 계산하고 다음 집을 칠해야 한다.\n  위의 세 가지 기저 조건을 다 확인하고 나면, 이제 재귀적으로 최소\n비용을 계산할 수 있다. 색깔의 범위가 이번에는 1부터 n까지 임에\n주의하면서, 모든 색깔에 대해서 재귀적으로 확인한다. 이때 이전\n색깔과 지금 고른 색깔이 같은지 다른지에 따라 이웃의 수가 증가할 수\n있다는 것을 주의하면서 계산한다.\n  주어진 이웃의 수 조건을 만족하는 것이 불가능한 경우도 있으므로,\n최종적으로 구한 비용이 무한대인지 아닌지에 따라 -1을 리턴할 수도\n있다."
					}
					,
					"ps-leetcode-pairs-of-songs-with-total-durations-divisible-by-60": {
						"id": "ps-leetcode-pairs-of-songs-with-total-durations-divisible-by-60",
						"title": "Pairs of Songs With Total Durations Divisible by 60",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/pairs-of-songs-with-total-durations-divisible-by-60/",
						"content": "Pairs of Songs With Total Durations Divisible by 60\n노래 리스트가 주어지고 i 번째 노래의 길이는 time[i] 초다.\n\n노래 한 쌍의 전체 길이가 60으로 나누어지는 모든 쌍의 개수를\n 구하자. 좀더 정확하게는, 한 쌍의 노래 인덱스 i, j에 대해서 i &lt;\n j 이고 (time[i] + time[j]) % 60 == 0인 쌍의 개수를 구하자.\n\n대관절 이게 머선 말이냐\n이 문제를 처음 읽었을 때는 언뜻 이해가 가지 않았다. 왜냐하면 이때까지\n 풀었던 문제는 늘 정답을 한 큐에 풀 수 있는 어떤 알고리즘이 있었고,\n 대개 이 알고리즘을 적당히 변형하면 되겠거니 하는 감이 있었기 때문이다\n (e.g. DFS, Stack, …).\n\n근데 이 문제는 그런 감이 전혀 오질 않았다. 아마 내 수련이 부족한\n 탓이겠다. 이럴 땐 당황하지 말고 일단 문제가 요구하는 조건이 뭔지\n 구체적인 예제로 차근차근 파악해 나가야 한다.\n\n예시 1\ntime = [30, 20 ,150, 100, 40]이 주어졌다고 하자. 이때 답은 3이\n 되는데,\n\n  (time[0], time[2]): 합이 180초가 되고 60으로 나누어 떨어진다.\n  (time[1], time[3]): 합이 120초가 되고 이하동문.\n  (time[1], time[4]): 합이 60초가 되고 이하동문.\n\n\n뭔가 예시를 보니 감이 잡힐 것 같기도 하다.\n\nBrute Force\n일단 예시를 보니 Brute Force는 금방 떠올랐다.\n\ndef num_pairs_of_songs(time):\n    answer = 0\n    n = len(time)\n    for i in range(n):\n        for j in range(i+1, n):\n            if (time[i] + time[j]) % 60 == 0:\n                answer += 1\n\n    return answer\n\n\n  조건에 맞게 i &lt; j를 유지하기 위해서 안쪽 루프에는 range(i+1, n)\n범위를 돌아야 한다.\n\n\n이렇게 하면 대충 O(n^2) 이라는 끔찍한 복잡도가 나온다. 문제에서\n time의 크기가 최대 6 * 10^4까지 가능하기 때문에 아주 큰 입력에\n 대해서는 끔찍하게 느릴 게 분명하다.\n\n60으로 나눈 나머지를 저장해두기\n모든 쌍에 대해서 일일이 검사하지 말고, 한 큐에 “지금 나랑 쌍이 될 수\n 있는 애가 있는지?”를 알 수 있으면 복잡도를 줄일 수 있겠다.\n\n여기서 조건은 60으로 나누어 떨어지는지, 즉 모듈러 연산의 결과가\n 0인지를 판단하는 것이다. 모듈러 연산의 특징으로 인해 모든 시간에\n 모듈러를 미리 해둬도, 나중에 합해서 모듈러를 하면 똑같은 결과가\n 나온다. 이 성질을 이용하면, i 번째 노래의 모듈러 연산 결과(60으로\n 나눈 나머지)를 미리 저장해두고, “나랑 더해서 60(혹은 0) 이 되는\n 친구가 있나?”를 빠르게 살펴볼 수 있을 것 같다.\n\n좀더 구체적으로 생각해보면 다음과 같다. i &lt; j에 대해서,\n\n  time[i] % 60 == 0 이면, time[j] % 60 == 0이어야 한다.\n  time[i] % 60 &gt; 0 이면, time[j] % 60 == (60 - (time[i] % 60))\n이어야 한다.\n\n\ntime[i] % 60의 인덱스만 구해보면 다음 상황과 같다.\n\ntime: [30, 20, 150, 90, 40]\n\nremainders: {\n  20: [1],\n  30: [0, 2, 3],\n  40: [3, 4],\n}\n\n\n여기서 어떻게 우리가 원하는 답인 i&lt;j인 쌍의 개수를 구할 수\n 있을까?\n\n원소 순서대로 time을 훑으면서 time[t % 60]의 개수를 1씩\n 증가시킨다고 해보자. 그러면 위의 예시에서, i = 3 일 때의 상황은\n 다음과 같다.\n\ni:     0 , 1 , 2  , 3 , 4\ntime: [30, 20, 150, 90, 40]\nremainders: {\n  20: 1,\n  30: 2,\n  40: 0\n}\n\n\ntime[3] = 90 이므로 90 % 60 = 30 이다. 따라서, 조건에 맞는 친구는\n 나머지다 60 - 30 = 30 이어야 하고 이 개수는 remainders[30] = 2\n 이다. 이때, time을 순서대로 훑으면서 remainders를 업데이트 하고\n 있으므로, 이 시점에 담긴 remainders[30] = 2는 현재 인덱스인 3보다\n 작은 인덱스 이면서 조건을 만족하는 아이들의 개수이다. 점점 우리가\n 원하는 그림에 다가가고 있다.\n\n여기서 좀더 들어가서 그럼 이 remainders 값으로 부터 쌍의 개수를\n 어떻게 구할 수 있을지 생각해보자. 어떤 인덱스 i에 대해서 time[i] %\n 60 &gt; 0이고, time[60 - (time[i] % 60)] = f 라고 해보자. 즉, i보다\n 작은 인덱스를 가지면서 조건(쌍을 만들고 합친 다음 60으로 나누어\n 떨어질 수 있는)을 만족하는 원소의 개수가 f개이다. 그럼 이때 가능한\n 쌍의 개수는 몇 개일까? f개 각각에 대해서 현재 원소 i와 쌍을 만들\n 수 있므로 f개가 된다. 따라서, 이 값을 곧바로 누적할 수 있다.\n\n그리고 이렇게 정답 개수를 누적한 이후에, 현재 인덱스가 60으로 나눠\n 떨어지는 개수를 업데이트 하면 된다. 이를 코드로 작성하면 다음과 같다.\n\nfrom collections import defaultdict\ndef num_pairs_of_songs(time):\n    # cache modulo results\n    remainders = defaultdict(int)\n    answer = 0\n    for t in time:\n        if t % 60 == 0:\n            answer += remainders[0]\n        else:\n            answer += remainders[60 - (t % 60)]\n\n        remainders[t % 60] += 1\n\n    return answer\n\n\n\n  앞의 조건에서 처럼 t % 60 == 0인 경우와 그렇지 않은 경우를 나누어\n생각했다.\n  answer의 개수는 조건을 만족할 수 있는 remainders의 개수를\n곧바로 누적하면 된다.\n  answer를 누적한 이후에 현재 원소의 remainders를 업데이트\n해준다."
					}
					,
					"ps-leetcode-palindrome-linked-list": {
						"id": "ps-leetcode-palindrome-linked-list",
						"title": "Palindrome Linked List",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/palindrome-linked-list/",
						"content": "Palindrome Linked List\n\n싱글 링크드 리스트의 헤드 노드가 주어졌을 때, 이 리스트가\n 팰린드롬인지 아닌지를 확인하자.\n\n노드의 개수는 1~100,000 사이이고 노드의 값은 0~9사이이다.\n\n접근 1\n\n  팰린드롬은 정방향과 역방향이 같은 것\n  역방향을 구하는 가장 쉬운 방법은 스택\n  정방향을 훑어서 순서대로 스택에 쌓고, 다시 정방향을 한번 더\n훑으면서 스택을 순서대로 꺼내어 비교\n  시간, 공간 복잡도 모두 O(N)\n\n\ndef isPalindrome(head):\n    stack = []\n    node = head\n    while node:\n        stack.append(node)\n        node = node.next\n    node = head\n    while node:\n        if node.val != stack[-1].val:\n            return False\n        node = node.next\n        stack.pop()\n    return True\n\n\n접근 2\n\n  공간 복잡도를 O(1)로 할 수 있을까?\n  리스트를 직접 제자리에서 수정하는 방법 밖에 없다.\n  두 가지 아이디어가 필요하다:\n    \n      O(1) Space로 리스트의 중간을 찾는 방법\n      O(1) Space로 리스트를 뒤집는 방법\n    \n  \n  즉, 리스트를 두 개로 나눠서 앞쪽 절반과 뒤집은 뒤쪽 절반을 비교하면\n팰린드롬 여부를 확인할 수 있다.\n  O(1) 중간 지점 찾기는 토끼와 거북이 포인터를 이용하면 된다.\n  O(1) 뒤집기가 좀 까다로운데, 이전에 방문한 포인터, 현재 방문 중인\n포인터, 다음에 방문할 포인터를 적절히 유지하면서 일일이 뒤집는 수\n밖에 없다.\n  이때, 팰린드롬 여부를 구한 후에 다시 뒷쪽 절반을 뒤집어서 링크드\n리스트를 원래 모습으로 되돌리는 것도 잊지말자.\n\n\ndef half_of(node):\n    fast, slow = node, node\n    while fast.next and fast.next.next:\n        fast = fast.next.next\n        slow = slow.next\n    return slow\n\ndef reverse(node):\n    prev, cur = None, node\n    while cur:\n        to_visit = cur.next\n        cur.next = prev\n        prev = cur\n        cur = to_visit\n    return prev\n\ndef isPalindrome(head):\n    if head is None:\n        return True\n\n    half = half_of(head)\n    reversed_half = reverse(half.next)\n    result = True\n    first, second = head, reversed_half\n    while result and second:\n        if first.val != second.val:\n            result = False\n        first = first.next\n        second = second.next\n\n    half.next = reverse(reversed_half)\n    return result"
					}
					,
					"ps-theory-palindrome": {
						"id": "ps-theory-palindrome",
						"title": "Palindrome",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/palindrome/",
						"content": "팰린드롬\n\n팰린드롬이란 어떤 시퀀스가 앞으로 가나 뒤로 가나 똑같은 시퀀스를 것을\n 말한다. 예를 들면 토마토 라던가 racecar 같은 거다. 어떤 문자열이\n 팰린드롬인지 아닌지는 이 성질을 이용해서 text == text[::-1]로\n 확인할 수 있다.\n\n그럼 어떤 문자열에서 가장 긴 팰린드롬을 찾으려면 어떻게 할 수\n 있을까? 브루트 포스로는 해당 문자열의 모든 길이의 부분 문자열을\n 생성한\n 다음, 위의 성질을 이용해서 일일이 다 체크하면 된다. 이러면 복잡도가\n 터지겠지만. 따라서 조금 더 똑똑한 방법은 다음 성질을 이용한다.\n\n일단 문자열을 뒤집는 연산은 시간과 공간 복잡도 모두 O(n)이 걸리므로\n 이걸 하면 안된다. 팰린드롬인지 아닌지를 확인하는 좀더 빠른 방법은\n 다음과 같다: 어떤 인덱스를 기준으로, 앞 뒤로 동시에 포인터를\n 이동하는데, 이때 두 포인터 위치의 원소가 같을 때에만 이동한다. 즉,\n 팰린드롬의 중심이 될 것 같은 인덱스부터 앞 뒤를 동시에 보면서\n 팰린드롬 여부를 확인하는 것이다. 이때 중요한 것은 팰린드롬의 길이가\n 짝수인 경우도 고려해줘야 하기 때문에, 중심 인덱스 하나를 받는\n 것이 아니라 앞 뒤 인덱스를 다 받되 (i, i)와 (i, i+1)을 넘겨줘야\n 한다. 즉, aba와 abba를 모두 고려해야 한다.\n\ndef max_length_from_center(string, forward, backward):\n    if not string or backward &lt; forward:\n        return 0\n\n    num_of_palindrome = 0  # 모든 팰린드롬 개수를 세고 싶을 때는 여기서 셀 수 있다.\n    while forward &gt;= 0 and backward &lt; len(string) and string[forward] == string[backward]:\n        forward -= 1\n        backward += 1\n        num_of_palindrome += 1\n    return (backward - forward - 1)\n    # or, return num_of_palindrome for the number of palindromes found\n\n\nforward는 문자열의 앞쪽, 즉 0번 인덱스를 향해 감소하는\n 인덱스이고, backward는 문자열의 끝쪽, 즉 len(string)을 향해\n 증가하는 인덱스이다.\n\nwhile 루프는 유효한 팰린드롬의 조건을 만족하는 동안 계속\n 돈다. 따라서, 해당 루프를 빠져나온 순간의 forward와 backward 값은\n 가장 긴 팰린드롬의 시작과 끝 인덱스가 아니라, (시작 - 1)과\n (끝 + 1) 인덱스임에 주의하자. 따라서 가장 긴 팰린드롬의 길이를\n 구하려면, (끝 + 1) - (시작 - 1) = 끝 - 시작 + 2가 되므로 여기서 1을\n 빼주면 길이가 된다. 따라서 backward - forward - 1이 우리가 원하는\n 길이이다.\n\n이렇게 만든 함수를 이용하면 다음과 같이 짝수/홀수 길이의 팰린드롬을\n 모두 고려해서 어떤 문자열의 부분 문자열 중 가장 긴 팰린드롬을 구할 수\n 있다.\n\ndef longest_palindrome(string):\n    if not string or len(string) &lt; 1:\n        return ''\n\n    start, end = 0, 0\n    for i in range(len(string)):\n        cand = max(max_length_from_center(string, i, i),\n                   max_length_from_center(string, i, i+1))\n        if cand &gt; (end - start):\n            start = i - (cand - 1) // 2\n            end = i + cand // 2\n\n    return string[start:end+1]\n\n\n여기서 start와 end는 모두 인덱스이다. 현재 인덱스 i를 중심으로\n 하는 가장 긴 팰린드롬의 길이를 찾고나면, 이 길이로부터 팰린드롬의\n 시작과 끝 인덱스를 위와 같이 구할 수 있다. 예를 들어 길이가 홀수인\n 5라면 시작 인덱스는 i - 2, 끝 인덱스는 i + 2가 되는 것이고,\n 길이가 짝수인 6이라면 (i-2, i+3)이 된다. 즉, 현재 인덱스 i로 부터\n 가장 긴 팰린드롬을 구할 때 앞 뒤 포인터를 (i, i+1)로 설정했기\n 때문에, 길이를 구하고 나면 시작 인덱스에서 빼줄 때에 (길이 - 1) //\n 2 만큼을 빼서 인덱스를 구하는 것이다.\n\n근데 이렇게하면 사실 복잡도는 꽤 비싸다. 팰린드롬의 최대 길이가\n 문자열 길이만큼일 수 있기 때문에, 실제 복잡도는 O(n^2)이\n 된다. 앞에서 구한 팰린드롬 정보를 활용해서 동적 프로그래밍으로 이를\n 구하는 Manacher의\n 알고리즘을\n 이용하면 O(n) 복잡도를 달성할 수 있지만 아직 이건 이해하지 못했다."
					}
					,
					"ps-leetcode-palindromic-substrings": {
						"id": "ps-leetcode-palindromic-substrings",
						"title": "Palindromic Substrings",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/palindromic-substrings/",
						"content": "Palindromic Substrings\n\n주어진 문자열 안에 있는 팰린드롬인 모든 가능한 부분문자열의 개수를\n 구하자. 문자열의 길이는 최대 1000이고, 영어 소문자만 담고 있다.\n\n참고로, 같은 문자로 이루어진 팰린드롬이라도 위치가 다르면 서로 다른\n 팰린드롬으로 취급해야 한다. 예를 들어서, aaa 문자열의 경우 가능한\n 팰린드롬은 a, a, a, aa, aa, aaa의 총 6가지 인데, 이는\n 같은 문자열이라도 팰린드롬의 위치가 다르기 때문에 별개의 팰린드롬으로\n 취급하기 때문이다.\n\n팰린드롬 세기\n\n내 블로그 이전 글 중 팰린드롬을 참조하면\n 좋다.\n\n팰린드롬을 셀 때 앞이나 뒤에서 세면 좀 까다롭다. 팰린드롬의 성질을\n 이용해서 어떤 문자열의 중앙에서부터 양 옆으로 체크해 나아간다고\n 생각하면 쉽다. 대신, 팰린드롬은 길이가 짝수일 수도 있으므로, 시작점인\n 중앙을 하나의 포인트가 아니라 두 개의 포인트로 받아야 한다는 점만\n 유의하자.\n\ndef countSubstrings(s):\n    def count_palindrome_from(left, right):\n        count = 0\n        while left &gt;= 0 and right &lt; len(s) and s[left] == s[right]:\n            count += 1\n            left -= 1\n            right += 1\n        return count\n\n    if not s or len(s) &lt; 1:\n        return 0\n\n    total = 0\n    for i in range(len(s)):\n        total += count_palindrome_from(i, i)\n        total += count_palindrome_from(i, i+1)\n\n    return total\n\n\n\n  left, right가 시작할 중앙 부분이다. s[left] == s[right]인\n조건을 만족하면 팰린드롬이다. left는 빼서 왼쪽으로, right는\n더해서 오른쪽으로 가면서 개수를 센다.\n  count_palindrome_from을 호출할 때에는 앞서 말했다시피 짝수인\n케이스를 고려해야 하기 때문에 (i, i)뿐만 아니라 (i, i+1)도\n호출해줘야 한다. 함수 안에서 범위 오버플로우 체크를 해주고 있기\n때문에 그냥 곧바로 호출해도 괜찮다."
					}
					,
					"ps-leetcode-parsing-a-boolean-expression": {
						"id": "ps-leetcode-parsing-a-boolean-expression",
						"title": "Parsing a Boolean Expression",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/parsing-a-boolean-expression/",
						"content": "Parsing a Boolean Expression\n\n문자열로 주어진 불리언 표현식 expression을 평가해서 결과를 구하자.\n\n표현식은 다음으로 구성된다:\n\n  \"t\": 참\n  \"f\": 거짓\n  \"!(expr)\": 논리적 NOT. 피연산자는 1개이다.\n  \"&amp;(expr1,expr2,...)\": 논리적 AND, 괄호 안의 피연산자는 2개 이상일\n수 있다.\n  \"|(expr1,expr2,...)\": 논리적 OR, 괄호 안의 피연산자는 역시 2개\n이상이다.\n\n\n표현식의 길이 범위는 \\(1 \\sim 2 \\times 10 ^4\\) 이고 표현식은 오직\n '(', ')', ',', '!', '&amp;', '|', 't', 'f' 글자로만 구성된다. 항상\n 유효한 표현식이 입력으로 들어옴이 보장된다.\n\n폴린드 표기법, 혹은 전위 표기법 - Polish Notation, or Prefix Notation\n\n문법이 주어진 형태부터가 폴란드\n 표기법이다. 적당히\n 컴마만 무시한 다음 폴란드 표기법의 정의에 따라 스택을 이용해서 파싱과\n 동시에 평가하면 될 것 같다.\n\n먼저 표현식을 토큰 리스트로 짜르는 함수를 구현하자. 얘는 컴마를\n 무시한다.\n\ndef tokenize(expr):\n    tokens = []\n    for tok in expr:\n        if tok != ',':\n            tokens.append(tok)\n    return tokens\n\n\n이렇게 구한 토큰 배열은 이미 그 자체로 폴란드 표기법이라고 할 수\n 있다. 이제 이걸 스택을 이용해서 적당히 파싱하는 함수를 만들자.\n\ndef parse(tokens):\n    CONST = {'t': True, 'f': False}\n    OPS = {'!', '&amp;', '|'}\n    stack = []\n    for tok in tokens:\n        if tok in CONST:\n            stack.append(CONST[tok])\n        elif tok in OPS:\n            stack.append(tok)\n        elif tok == ')':\n            operands = []\n            while isinstance(stack[-1], bool):\n                operands.append(stack.pop())\n            op = stack.pop()\n            if op == '!':\n                stack.append(not operands.pop())\n            elif op == '&amp;':\n                stack.append(all(operands))\n            elif op == '|':\n                stack.append(any(operands))\n    return stack.pop()\n\n\n이전에 했던 역폴란드 표기법의 parse + eval함수와 거의 유사하지만,\n 여기서는 굳이 두 스텝을 나눌 필요가 없어서 곧바로 평가하고\n 있다. 괄호의 시작은 무시해도 되고, 만약 괄호의 끝에 도달했다면,\n 스택에서 첫번째 연산자를 만나기 전까지 추가된 모든 값(불리언)은\n 피연산자이고, 피연산자 바로 다음에 있는게 바로 연산자가 된다. 이때\n 유효한 표현식만 들어옴이 보장되므로 굳이 ! 연산자를 평가할 때\n 피연산자 개수를 체크해주지 않아도 된다. &amp;와 |의 경우 파이썬의\n all과 any를 이용해서 피연산자 전체에 대해서 빠르게 평가할 수\n 있다.\n\n그러면 실제 구현은 다음과 같다.\n\ndef parseBoolExpr(expression):\n    return parse(tokenize(expression))\n\n\n해킹\n\n그런데 위의 풀이 방법을 보면 알겠지만, 애초에 들어오는 표현식 자체가\n 항상 유효한 폴란드 표기법임이 보장되기 때문에, 다음과 같은 해킹이\n 가능하다:\n\n  !(expr) -&gt; not (expr)로 바꿈\n  &amp;(exprs) -&gt; all([exprs])로 바꿈\n  |(exprs) -&gt; any([exprs])로 바꿈\n\n\n파이썬에서도 리스트 구분자는 , 이기 때문에, 이렇게 바꾼 식은 그\n 자체로 유효한 파이썬 표현식이 되고, 곧바로 파이썬의 eval을 먹일 수\n 있다 (…). 이때 한 가지 해킹으로, !의 경우 not (expr)로 바꾸면\n 안의 expr이 복잡한 식인 경우 유효하지 않은 파이썬 표현식이 될 수\n 있으므로, not (expr) == not any([expr]) == not all([expr]) 임을\n 이용해서 not &amp; 또는 not |으로 바꾸는 해킹을 하면 된다. 또한 닫힌\n 괄호도 잘 바꿔주는 것을 잊지 말자.\n\ndef parseBoolExpr(expression):\n    hacked = expression.replace('t', 'True').replace('f', 'False').replace('!', 'not &amp;').replace('&amp;(', 'all([').replace('|(', 'any([').replace(')', '])')\n    return eval(hacked)"
					}
					,
					"ps-leetcode-partition-equal-subset-sum": {
						"id": "ps-leetcode-partition-equal-subset-sum",
						"title": "Partition Equal Subset Sum",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/partition-equal-subset-sum/",
						"content": "Partition Equal Subset Sum\n\n비어있지 않은 배열 nums에 양수만 담겨 있다. 이 배열을 각 배열의\n 합이 똑같은 두 개의 배열로 쪼갤 수 있는지 확인하자.\n\n\n  배열 크기: 1~200\n  배열 값: 1~100\n\n\nKnapsack Problem\n\n  전통적인 냅색 문제랑 비슷하다.\n  일단 전체 합이 홀수면 불가능.\n  합이 subset_sum인 크기 n인 배열 nums에서 출발. 두 배열 중\n하나만 추적. 원소 값을 하나씩 빼서 0이 되는지 보면 된다. 어떤 원소\nx에 대해서 다음 두 가지 경우가 가능함:\n    \n      x가 해당 Subset에 포함: subset_sum -= x\n      x가 포함 안됨, 따라서 subset_sum은 그대로.\n      Base case: subset_sum이 0이 되면 True, 배열의 끝까지 가거나\n(따라서 현재 원소 x를 추적하는 인덱스가 필요) subset_sum &lt; 0\n이면 불가능이므로 False\n    \n  \n  역시 부분 문제가 중복되므로 메모아이제이션 가능\n\n\nimport functools\ndef canPartition(nums):\n    n = len(nums)\n\n    @functools.cache\n    def can_reach(i, subsum):\n        if subsum == 0:\n            return True\n        if i == n or subsum &lt; 0:\n            return False\n\n        return can_reach(i+1, subsum-nums[i]) or can_reach(i+1, subsum)\n\n    total = sum(nums)\n    if total % 2 != 0:\n        return False\n\n    return can_reach(0, total // 2)"
					}
					,
					"ps-leetcode-partition-list": {
						"id": "ps-leetcode-partition-list",
						"title": "Partition List",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/partition-list/",
						"content": "Partition List\n\n싱글 링크드 리스트의 루트 노드 head와 정수 값 x가 주어질 때,\n 리스트를 나눠서 x보다 작은 모든 노드가 x보다 크거나 같은 모든\n 노드보다 앞에 오도록 하자.\n\n이때, 리스트의 원래의 상대적인 노드 순서는 보존해야 한다.\n\n예를 들어, 1 -&gt; 4 -&gt; 3 -&gt; 2 -&gt; 5 -&gt; 2와 x = 3이 주어진다면, 3을\n 기준으로 작은 모든 노드는 그 상대적인 순서를 유지하면서 1 -&gt; 2 -&gt;\n 2와 4 -&gt; 3 -&gt; 5로 나눌 수 있다. 따라서 답은 1 -&gt; 2 -&gt; 2 -&gt; 4 -&gt; 3\n -&gt; 5가 된다.\n\n노드의 개수는 0 ~ 200이고 노드의 값은 -100~100이다. x는 -200~200\n 사이의 값이다.\n\n두 개의 센티넬을 이용하기\n\n핵심은 원래의 순서를 유지하는 것이다. 따라서, 일반적인 리스트\n 탐색처럼 탐험 노드가 노드를 끝까지 쭉 밀고 나가면서, x를 기준으로\n 조건에 맞는 부분 리스트를 만들어 나가면 된다. 그러고 나면 마지막에는\n less 리스트와 geq 리스트로 나누어질텐데, 이 두 리스트를 잘\n 이어주면 된다. 이때, 주의할 점은 우리는 리스트의 탐험 노드를\n 움직이기 때문에, 리스트의 탐색이 끝나는 시점에서 이 노드들의 위치는\n less와 geq 각 리스트의 끝에 있다는 점이다. 따라서 탐험을\n 시작하기 전에 이 리스트들의 시작 위치를 기록해줘야 두 리스트를\n 올바르게 이어주고, 새로운 리스트의 루트 노드를 올바르게 돌려줄 수\n 있다.\n\ndef partition(head, x):\n    less, geq = ListNode(), ListNode()\n    lsentinel, gsentinel = less, geq\n    pioneer = head\n    while pioneer:\n        if pioneer.val &lt; x:\n            less.next = pioneer\n            less = less.next\n        else:\n            geq.next = pioneer\n            geq = geq.next\n        pioneer = pioneer.next\n\n    less.next, geq.next = gsentinel.next, None\n    return lsentinel.next\n\n\n\n  역시 여기서도 센티넬 노드를 활용했다. 이러면 리스트가 비었는지\n아닌지 확인하는 작업이 아주 쉬워진다. less, geq도 모두 센티넬\n노드이므로 이 파티션 리스트들의 시작점을 기록하기 위한\nlsentinel과 gsentinel도 역시 이름대로 센티넬이다. 따라서 두\n리스트를 연결할 때, 먼저 less의 끝 노드를 geq의 시작 노드와\n이어주고 (less -&gt; gsentinel.next), 그 후 geq의 끝 노드를 끊어서\n싸이클을 없애준다 (geq.next = None). 이러고나면 less의 시작\n노드(lsentinel.next)가 새로운 루트가 된다"
					}
					,
					"ps-leetcode-pascals-triangle": {
						"id": "ps-leetcode-pascals-triangle",
						"title": "Pascal's Triangle",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/pascals-triangle/",
						"content": "Pascal’s Triangle\n\nnumRows가 주어졌을 때 파스칼의 삼각형을 그리자.\n\n\n\n1~30 사이의 값이 들어온다.\n\n기초적인 디피\n\n아주 기초적인 디피이다. 잘 보면 다음 사실을 알 수 있다.\n\n  row 줄에는 row개의 원소가 있다. (1-indexed)\n  row 줄의 양 끝 원소는 항상 1이다.\n  (row, i) 원소는 (row - 1, i - 1) 원소와 (row - 1, i) 원소의\n합이다.\n\n\n정직하게 구현해보자.\n\ndef generate(numRows: int) -&gt; List[List[int]]:\n    pascal = []\n    for row in range(numRows):\n        line = [None] * (row + 1)\n        line[0], line[-1] = 1, 1\n        for i in range(1, len(line) - 1):\n            line[i] = pascal[row-1][i-1] + pascal[row-1][i]\n        pascal.append(line)\n    return pascal"
					}
					,
					"ps-leetcode-power-of-three": {
						"id": "ps-leetcode-power-of-three",
						"title": "Power of Three",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/power-of-three/",
						"content": "Power of Three\n\n정수가 주어졌을 때 이게 \\(n = 3^x\\)를 만족하는 수인지 확인하자.\n\nn은 32비트 정수 범위의 모든 값이다.\n\n접근 1 - 반복문\n\n  가장 쉬운 방법은 1(\\(3^0\\))부터 시작해서 n과 크거나 같아질 때까지\n계속 3을 곱한 다음 같은 값인지 보는 것\n  문제의 조건에 따라 음수는 답이 될 수 없음 (\\(3^x\\))\n\n\ndef isPowerOfThree(n):\n    if n &lt; 0:\n        return False\n    x = 1\n    while x &lt; n:\n        x *= 3\n    return x == n\n\n\n접근 2 - 반복문 없이\n\n  반복문 없이 하려면 수학적인 성질을 이용해야 함\n  지수의 역함수는 로그이니 로그를 활용\n  \n\\[n = 3^x \\iff x = log_{3}(n)\\]\n  \n  따라서 \\(log_{3}(n)\\)이 정수인지 확인하면 됨\n  주의: 로그 함수를 도입하는 순간 부동소수점의 오류를 맞이하게\n되는데, 이를 피하기 위해서는 math.log(\\(log_{2}\\)) 보다 정확도가\n높은 math.log10(\\(log_{10}\\))을 사용해야 함!\n\n\ndef isPowerOfThree(n):\n    import math\n    if n &lt;= 0:\n        return False\n    x = math.log10(n) / math.log10(3)\n    return (f - int(f)) == 0\n\n\n접근 3 - 반복문 없이 (2)\n\n  반복문 없는 또 다른 접근은, 입력의 한계를 이용하는 것\n  입력은 32비트 정수이고 문제의 조건에 따라 양의 정수만 생각하면\n되므로, 32비트 양의 정수 범위인 \\(2^{31} - 1\\) 안에서 가장 큰\n\\(3^x\\) 값을 미리 계산한 후 이 값이 n으로 나누어 떨어지는지 보면 됨\n    \n      이 값은 \\(3^{19} = 1162261467\\)\n      이 접근이 가능한 이유는 3이 소수이기 때문\n    \n  \n\n\ndef isPowerOfThree(n):\n    return n &gt; 0 and 1162261467 % n == 0"
					}
					,
					"ps-theory-powerset": {
						"id": "ps-theory-powerset",
						"title": "Powerset",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/powerset/",
						"content": "Powerset\n\ndef powerset(nums):\n    \"\"\"\n    e.g. nums = [1,2] then returns\n    [[1,2],\n     [1],\n     [2],\n     []\n    ]\n    \"\"\"\n    result = []\n    partial = []\n\n    def recurse(idx):\n        if idx == len(nums):\n            # finish\n            result.append(partial[:])  # must be copied\n            return\n\n        partial.append(nums[idx])  # pick this item\n        recurse(idx + 1)\n        partial.pop()  # not pick this item\n        recurse(idx + 1)\n\n    recurse(0)\n    return result\n\n\n\n  Simply use seq[:] to deepcopy a sequence."
					}
					,
					"ps-leetcode-powx-n": {
						"id": "ps-leetcode-powx-n",
						"title": "Pow(x, n)",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/powx-n/",
						"content": "Pow(x, n)\n\npow(x, n), 즉 \\(x ^ n\\) 을 계산하자.\n\n\\(-100.0 &lt; x &lt; 100.0\\), \\(-2^{31} \\leq n \\leq 2^{31} -1\\), \\(-10^4 \\leq x^n \\leq 10^4\\) 이다.\n\n정직한 구현 - 타임아웃\n\n정직하게 한번 구현해보자. 주의할 것은 지수가 음수인 경우이다. 이때는\n 곱하는 게 아니라 나눠줘야 한다.\n\ndef myPow(x, n):\n    if n &lt; 0:\n        x = 1 / x\n        n = -n\n    answer = 1\n    while n:\n        answer *= x\n        n -= 1\n    return answer\n\n\n당연하지만 이러면 타임아웃 난다.\n\n더 빠른 구현\n\n빠른 지수 함수를 계산하는 데에는 널리 알려진 방법이 있다. Divide and\n Conquer라고 볼 수도 있고 바이너리 서치라고 볼 수도 있는데, 아무튼\n 다음 성질을 이용하면 된다:\n\n  n이 2로 나눠 떨어질 때: \\(x ^ n = x ^ {n/2} \\times x ^ {n/2}\\)\n  Otherwise: \\(x ^ n = x \\times x ^{n-1}\\)\n\n\n여기서 n이 2의 배수일 때 \\(x ^ {n/2}\\) 라는 같은 값을 구하기\n 때문에, 이를 이용하면 된다.\n\ndef myPow(x, n):\n    def fast_power(x, n):\n        if n == 0:\n            return 1.0\n        if n % 2 == 0:\n            half = fast_power(x, n // 2)\n            return half * half\n        else:\n            return fast_power(x, n - 1) * x\n    if n &lt; 0:\n        x = 1 / x\n        n = -n\n    return fast_power(x, n)\n\n\n위의 수식을 거의 그대로 옮겨둔 재귀 함수이다. 문제를 절반 씩 나눠\n 풀고 있기 때문에 복잡도는 O(logN) 이 된다."
					}
					,
					"wip-optimization-prefetching-marking": {
						"id": "wip-optimization-prefetching-marking",
						"title": "Speed up GC by prefetching during marking",
						"version": "all",
						"categories": "",
						"url": " /wip/optimization/prefetching-marking/",
						"content": "Speed Up GC by Prefetching During Marking\n\n요 PR에서 진행된 토론을\n 정리 및 번역해본다.\n\n해당 PR은 프리페칭을 이용해서 프로세서의 메모리 병렬화를 이용하여\n 메이저 GC의 마킹 루프를 최적화한다. 이를 통해 마킹 페이즈에서\n 일어나는 거의 모든 캐시 미스를 없애서 GC 속도를 높인다.\n\n800MB 힙의 마이크로 벤치마크에서 Gc.full_major에 걸리는 시간이\n 1.8초에서 0.5초로 줄었다.\n\n물론 대부분의 프로그램은 GC에 100%의 시간을 쓰는게 아니기 때문에,\n 보통 이정도로 개선이 드라마틱하진 않다. 다른 테스트 프로그램에서는\n 마킹 시간이 1/3~2/3 정도로 줄어서 GC를 얼마나 쓰느냐에 따라서\n 전체적으로 5-20% 정도의 성능 개선이 있었다. 더 많은 벤치마킹이\n 필요하다.\n\n캐시보다 힙이 훨씬 더 큰 프로그램에서만 성능 개선이 보일 것\n 같다. 수십 메가바이트보다 적게 쓰는 프로그램은 이 패치로 개선이 크게\n 되진 않겠지만, 더 느려지지도 않을 것이다.\n\n알고리즘\n현재의 마킹 알고리즘은 순수한 DFS다. 마킹은 항상 마크 스택 위에 있는\n 오브젝트를 진행하고, 찾아낸 새로운 블록은 스택에 푸시된다. 이\n 오브젝트들은 보통 캐시에 있지 않기 때문에 GC는 대부분의 시간을 캐시\n 미스 때문에 새 오브젝트의 헤더가 로딩되는 걸 기다리는 데 쓴다\n (스톨링).\n\n이 PR의 알고리즘은 작은(현재는 256 엔트리) 원형 큐 버퍼를 마크 스택\n 앞에다 붙여서 이른바 프리페치 버퍼로 사용한다. 마킹 페이즈 동안, 그\n 다음 오브젝트는 프리페치 버퍼에서 뽑거나 (최소 Pb_min 원소 이상일\n 때), 프리페치 버퍼가 비어있거나 거의 비어있으면 마크 스택에서 팝해서\n 스캔한다. 마킹하는 동안 새로운 포인터를 발견하면, 얘네는 곧장\n 따라가는게 아니라 프리페치해서 프리페치 버퍼에 넣는다. 블록은\n 프리페치 버퍼가 오버플로우 날 때에만 마크 스택에 푸시된다.\n\n이러면 스캔할 새로운 오브젝트는 일반적으로 적어도 Pb_min 스텝\n 이전에 프리페치되고, 이 말은 곧 얘네는 캐시에 있을 확률이 아주아주\n 높아진다.\n\n마크 스택 변경 사항\n이 PR은 또한 마크 스택에 작은 구조적인 변경 사항을 포함한다. 마크\n 스택에는 이미 인터벌이 있고, 부분적으로 스캔된 오브젝트를 나타내기\n 위해 쓰이지만 이 인터벌은 (value, offset) 쌍으로 표현되고 있다. 이\n 패치는 이거를 (start, end) 쌍으로 바꾸는데, start = value +\n osffet이고 end = value + Wosize_val(value) 이다. 이러면 긴 배열의\n 뒷부분을 탐색할 때 Wosize_val(value)를 정할 때 일어나는 캐시 미스를\n 세이브할 수 있다.\n\n\n\n@stedolan\n\n프리페치는 TLB 성능에도 도움이 된다. 프리페치는 프로세서가 더 많은\n 메모리 요청을 병렬적으로 처리할 수 있게 해줘서 필요한 경우에는\n 페이지도 훑는다.\n\n페이지 사이즈가 더 커지면 TLB를 잘 활용할 수 있어서 성능을 더 많이\n 개선하겠지만, 이 PR과는 독립적인 이슈다.\n\n뭔가 오해가 있는 것 같다. 메모리 병렬성을 더 많이 얻으면 이 코드는 더\n 빨리지고 다른 파라미터 수정이 필요없다. 이유를 설명하자면 다음과\n 같다.\n\n프로세서의 메모리 서브시스템은 메모리를 읽는 요청을 받아들이는데,\n 약간의 딜레이 후에 읽은 내용물을 만든다. 이 딜레이는 3-4 싸이클(L1\n 캐시 히트 시)부터 수백 싸이클(메인 메모리 접근)까지 갈 수 있다. 아주\n 극단적인 경우에, 이것보다 길 수도 있는데, 만약 TLB 미스가 있어서 메인\n 메모리 접근 뿐만 아니라 메인 메모리의 페이지를 전부 훑어야할 수도\n 있다.\n\n메모리 서브시스템은 동시에 여러 개의 요청에 대해서 유용한 발전을 만들\n 수 있는데, 이게 바로 “메모리 레벨 병렬성” 또는 MLP 이다. 대부분의\n 모던 x86 프로세서는 최대 MLP가 약 10정도 되는데, 최신은 더 많기도\n 하다. 사실 MLP는 단순히 숫자만 가지고 보기에는 좀 복잡하다. 최대\n MLP는 어떤 캐시가 관여하는지, 코어 사이에 어떤 리소스를 공유하는지에\n 따라 다르다. 하지만 여기서는 이 숫자 하나만 봐도 충분하다.\n\n예를 들어, 만약 20개의 로드 명령어를 1-20싸이클에 걸쳐서 발행하면,\n 최대 MLP가 10이고 메인 메모리 접근까지 300 싸이클이 걸리는 머신에서는\n 모든 로드가 600싸이클 정도에 완료될 것으로 기대할 수 있다. 메모리\n 서브시스템은 첫번째 10개의 로드를 아주 빠르게 받아들여서 로드를\n 시작하지만 나머지 11-20 명령어는 큐에 쌓인다.\n\n하지만, 대부분으 피르고르매은 각 싸이클 마다 로드 명령어를 발행하지\n 않는데, 그래서 가용 MLP가 대부분 사용되지 않는다. 프로세서는 더 많은\n MLP를 사용하기 위한 다양한 트릭을 갖고 있다. 예를 들어, 브랜치를\n 투기적으로 실행해서 실제로 어떤 브랜치로 갈지 정해지기 전에 로드를\n 수행하는데, 순차적인 접근을 발견해서 미리 프로그램을\n 읽는다. 안타깝게도 이런 트릭은 전부 GC의 마킹 페이즈에 특별히\n 효과적이지 않은데, 마킹 페이즈에서는 예측 불가능한 포인터 추적이 엄청\n 많이 일어난다. 포인터 추적은 특히 MLP에 안좋다. 검사할 다음 워드의\n 주소는 이전 로드가 완료되어야만 알 수 있어서, 강제로 순차적이다.\n\n이 PR의 GC 프리페치는 다르게 작동한다. 얘는 소프트웨어 프리페치\n 명령어를 통해 곧바로 수백개 정도의 로드 명령어를 발행한다. 여기서\n “수백”은 다를 수 있다. 버퍼 사이즈는 256이지만, 이게 항상 꽉 차진\n 않고, 꽉 차 있더라도 많은 값이 포인터가 아니다. 발행된 요청 수는\n 프로세서의 가용 최대 MLP를 엄청나게 초과하는데, 그래서 대부분의 이\n 요청은 큐에 쌓인다. 이 시도는 메모리 서브시스템이 항상 최대의\n 용량(capacity)로 수행되도록 보장하기 위함이다. 로드 명령어가 데이터를\n 리턴할 때마다, 항상 준비된 그 다음 데이터가 큐에 있다.\n\n이것은 다른 프로세서에서 가용한 더 큰 MLP도 투명하게 활용할 수\n 있다. 몇 년쯤 뒤에 MLP가 수백이 되면 그때는 프리페치 버퍼 사이즈를 더\n 크게 잡는게 좋겠지만 지금은 256이면 충분해 보인다.\n\n근본적으로, 마킹 페이즈는 아주 많은 메모리 접근을 하는데, 대부분 캐시\n 미스가 난다. 건드린 메모리의 각 워드에 대해서 아주 적은 양의 계산만\n 수행하는데, 그래서 CPU가 아닌 메모리 성능에 의해서\n 제한된다. 어떤식으로든 CPU는 메모리를 기다리면서 정체된다(스톨링).\n\n스톨이 발생하면, 일반적으로 다른 오브젝트 B를 가리키는 오브젝트\n A의 필드 i를 스캐닝하면서 스톨되는데, B의 헤더는 캐시에\n 없다. 하드웨어는 계속해서 투기적으로 계산해서 스톨을 피하려고 하는데,\n 보통 A의 i+1 필드를 다음에 읽도록 예측해서 이걸 페치하려고\n 한다. 하지만, 이는 같은 오브젝트의 필드에만 제한된다. 스캔할 그 다음\n 오브젝트의 주소는 B의 헤더에 의해서 결정되는데, B의 로드가 끝나기\n 전까지는 프로세서가 알지도 못하고 추측(투기)할 시도도 못한다. 그래서,\n 스톨되는 동안, 실제 일어나는 메모리 로드는 필드 i, i+1 등 몇 개\n 안된다. 따라서 10개 정도의 메모리 로드만 일어나기 때문에 메모리\n 서브시스템이 덜 활용된다.\n\nGC 프리페치가 스톨되면, 이는 보통 로드 동안 일어나는게 아니다. 왜냐면\n 이미 프리페치가 이뤄져서 L1 캐시 히트가 일어난다. 하지만, 계속해서\n 나중에 필요할 메모리 로드 프리페치를 발행하고, 그래서 때때로 최대\n MLP에 도달한 다음 스톨된다. 이런 종류의 스톨 동안에는 가능한 한 많은\n 수의 메모리 로드가 일어나기 때문에, 메모리 서브시스템이 최대한 활용될\n 때에만 이 스톨이 발생한다.\n\n즉, 최대 MLP를 때려서 발생한 스톨은 마킹 루프를 위한 가장 이상적인\n 상태이다. 이 말은 메모리 접근이 아주 잘 스케쥴링 되어서 메모리\n 서브시스템을 최대한으로 활용하고 있다는 뜻이고, CPU가 결과를 기다리는\n 일 외에는 할 일이 없을 정도로 충분히 낮은 오버헤드가 일어난다는\n 뜻이다."
					}
					,
					"ps-leetcode-prison-cells-after-n-days": {
						"id": "ps-leetcode-prison-cells-after-n-days",
						"title": "Prison Cells After N Days",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/prison-cells-after-n-days/",
						"content": "Prison Cells After N Days\n8명을 수용할 수 있는 독방이 있다. 누가 들어가있거나(1) 비어있다(0).\n\n하루가 지날 때마다 다음 규칙이 적용된다:\n\n  어떤 방 양 옆에 두 개의 인접한 방이 있는데 이 두 개가 모두 차있거나\n비어있으면, 그 방은 누가 들어온다.\n  아니면 방이 빈다.\n\n\n참고로 독방은 1차원 배열로 들어오기 때문에 양 끝에 있는 두 방은 양\n 옆의 인접한 방이 없다.\n\nn 일 후의 독방 상태를 구해보자.\n\n문제 파악\n문제가 대체 뭔 말인지 이해하는 데에도 연습이 필요하다는 걸 깨닫게\n 해준 문제다.\n\n일단 조건에 따라 방의 상태가 바뀌기 때문에 시뮬레이션을 해야 할\n 것이다. 그런데 문제의 조건을 보면 n이 최대 10^9까지 가능하기\n 때문에, 최대 이 날짜만큼 그냥 시뮬레이션하게 되면 엄청 느리다.\n\n따라서 우리가 집중해야 하는 것은 방의 개수가 8개 밖에 안된다는\n 점이다. 거기에 누가 들어있으면 1, 비었으면 0이기 때문에 방 하나가\n 가질 수 있는 상태는 두 개밖에 안된다. 그러므로 며칠이 지나든 간에,\n 전체 독방이 가질 수 있는 상태의 개수는 2^8 = 256개 로 많지 않다.\n\n따라서, 시뮬레이션을 하긴 할 건데, 가능한 상태가 256개 밖에 안되므로\n 무조건 중복된 상태가 나오게 된다. 즉, 일단 최대 256개 만큼의\n 상태를 다 겪고 나면 그 다음부터는 반복이다. 그러므로 이 반복을 없애는\n 것이 이 문제 풀이의 핵심이다.\n\n시뮬레이션 + 빨리감기\n일단 다음 날짜로 진행하는 시뮬레이션을 구현하면 다음과 같다.\n\ndef next_day(cells):\n    ret = [0]\n    for i in range(1, len(cells) - 1):\n        ret.append(1 if cells[i-1] == cells[i+1] else 0)\n\n    ret.append(0)\n    return ret\n\n\n\n  양 옆에 방이 있고 두 방의 상태가 같아야만 누가 들어올(1) 수\n있다. 즉, 어떤 상태에서 시작하든 간에 다음 날 양 끝에 있는 방 두\n개는 항상 비게 된다(ret = [0] 부분과 마지막 ret.append(0)).\n\n\n그러면 빨리감기 없는 무식한 시뮬레이션을 다음과 같이 구현할 수 있다.\n\ndef prisonAfterNDays(cells, n):\n    while n &gt; 0:\n        n -= 1\n        cells = next_day(cells)\n    return cells\n\n\n물론 이대로 해도 작은 입력에 대해서는 잘 동작할 것이다. 하지만 앞서\n 생각했듯 상태의 개수가 256개 밖에 안되기 때문에, 큰 입력에 대해서는\n 이전에 했던 계산을 계속 중복할 것이다. 엄청난 비효율이다.\n\n그럼 날짜를 하루 씩 진행하다가, 이전에 이미 겪었던 상태를 또 겪게\n 되는 순간 빨리감기를 하면 된다.\n\n다음과 같은 상황을 생각해보자.\n\n day_(n)  -&gt;  day_(n-1)  -&gt; .... -&gt;  day_(n-p)\nstate_(i) -&gt; state_(i+1) -&gt; .... -&gt; state_(i+p)\n\n\n상태가 중복된다는 것은 결국 어떤 주기(period)가 있다는 뜻이다. 위에서\n 우리는 날짜를 n에서 하루씩 빼면서 다음 날을 시뮬레이션 하고\n 있었다. 따라서 어떤 주기 p에 대해서 위 그림과 같이 날짜와 상태가\n 진행될 것이다.\n\n따라서, 각 상태마다 날짜를 해시테이블에 기록해두면, 나중에 그 상태가\n 처음으로 또 발견되는 순간 주기를 알 수 있다. 위 그림으로 설명하면\n state_(i)에 대해서 n 값을 저장하고 있다가, 이거랑 중복되는 상태인\n state_(i+p)가 처음으로 나오면 이전의 날짜에서 이 날의 날짜를 빼주면\n 주기를 구할 수 있다. 즉, n - (n - p) = p이다.\n\n주기를 알아 내고 나면 빨리감기는 모듈러 연산으로 쉽게 가능하다. 즉\n 전체 n 일 만큼을 진행해야 하는데 주기가 p이면 p * (n//p) 만큼의\n 날짜는 일일이 시뮬레이션 해도 의미없으므로 곧 n % p 만큼만 더\n 시뮬레이션 하면 된다.\n\n여기서 날짜를 진행할 때 0일부터 시작해서 n일 까지 가는 것보다는\n n을 하루 씩 까먹는게 좋다. 왜냐하면 주기를 발견한 순간 남은 날짜를\n 모듈러 연산으로 줄여버리는 편이 더 쉽기 때문이다. 주기를 반복해서\n 목표한 n일에 가깝게 날짜를 증가시키는 계산은 생각해내기가 더\n 어렵다.\n\n아무튼 이 아이디어를 코드로 구현하면 다음과 같다.\n\ndef prisonAfterNDays(cells, n):\n    states = dict()\n    while n &gt; 0:\n        key = tuple(cells)  # key must be hashable\n        if key not in states:\n            states[key] = n  # state_(i) = day_(n)\n        else:\n            period = states[key] - n  # day_(n) - day_(n-p) = p\n            n = n % period\n\n        # if there is still some days, then proceed\n        if n &gt; 0:\n            n -= 1\n            cells = next_day(cells)\n    return cells\n\n\n  상태를 기록하기 위해서 딕셔너리(해시테이블)을 썼다. 이때 딕셔너리의\n키는 해싱 가능해야 하는데 리스트는 해싱할 수 없기 때문에, 독방을\n튜플로 바꿔서 키로 사용한다.\n  지금 상태가 이전에 한번도 만난적 없으면 현재 날짜를 기록한다. 위\n그림에서 state_(i) = day_(n)에 해당한다.\n  만약 지금 상태를 이전에도 본 적이 있다면 곧바로 주기를 계산할 수\n있다. 위 그림에서 state_(i+p) = day_(n-p)에 해당한다. 이전\n날짜에서 지금 날짜를 빼주면 주기가 된다.\n  주기를 구하고 나면 남은 주기는 하루씩 진행할 필요 없이 바로 나머지\n연산을 때려버릴 수 있다.\n  이러고 나서도 남은 날짜가 있으면 이건 하루씩 진행한다."
					}
					,
					"ps-leetcode-product-of-array-except-self": {
						"id": "ps-leetcode-product-of-array-except-self",
						"title": "Product of Array Except Self",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/product-of-array-except-self/",
						"content": "Product of Array Except Self\n\n정수 배열이 주어졌을 때, 다음 조건을 만족하는 새로운 배열을 만들자:\n\n  i 번째 원소는 i 번째 원소 자신을 제외한 모든 수의 곱과 같은 값\n\n\n모든 곱은 32비트 정수 안에 표현되는 것이 보장된다.\n\n알고리즘의 복잡도는 O(N)이어야 하고, 나누기 연산을 사용하면\n 안된다.\n\n정수 배열의 크기는 2~100,000 이고 정수의 값은 -30~30이다.\n\n접근 1 - 나누기 연산을 쓰는 버전\n\n  일단 나누기 연산을 쓰는 접근이 가장 쉽다.\n  모든 곱이 32비트 정수 안에 담길 수 있기 때문에 배열 전체를 곱해서\n누적해둔 다음 i 번째 값으로 나누기만 하면 된다.\n    \n      이때 0을 주의해야 한다.\n      0이 두 개 이상이면 어차피 뭘 곱해도 0이다.\n      0이 하나일 때는 0인 곳만 주의하면 된다.\n      0이 없을 때는 원래 방법대로 하면 된다.\n    \n  \n  즉, 두 가지 상태를 유지해야 한다:\n    \n      0의 개수\n      0을 뺀 나머지 수들의 곱\n    \n  \n\n\ndef productExceptSelf(nums):\n    all_product_except_zero = 1\n    zero_count = 0\n    for n in nums:\n        if n != 0:\n            all_product_except_zero *= n\n        else:\n            zero_count += 1\n    answer = []\n    if zero_count == 0:\n        for n in nums:\n            answer.append(all_product_except_zero // n)\n    elif zero_count == 1:\n        for n in nums:\n            if n != 0:\n                answer.append(0)\n            else:\n                answer.append(all_product_except_zero)\n    else:\n        answer = [0] * len(nums)\n    return answer\n\n\n접근 2 - 문제의 조건에 따라 나누기 안쓰는 방법\n\n  문제의 조건에 힌트가 있다: O(N)\n  배열을 정방향으로, 역방향으로 훑자.\n  누적 합과 비슷한 누적 곱의 아이디어를 적용하자.\n  정방향의 누적 곱과 역방향의 누적 곱이 있으면 인덱스 i 에서의 곱을\n구할 수 있다: i를 기준으로 왼쪽의 누적 곱과 오른쪽의 누적 곱을\n곱하면 된다.\n  즉, 정방향 누적 곱은 왼쪽의 누적 곱, 역방향 누적 곱은 오른쪽의 누적\n곱이 된다.\n  left를 만드는 방법은 straightforward하다. 0번째의 왼쪽에는 아무런\n값도 없으므로 null이 맞겠지만, 계산의 편의를 위해 1로 준다. 그러면\n그 이후 i 번째의 값은 이전의 i-1 번째의 값에 i번째 값을\n곱해서 누적해 나아가면 된다. 단, 제일 마지막 원소는 곱할 일이\n없으므로 스킵한다.\n  right는 left를 만드는 방법을 거꾸로 하면 된다. 여기서는 배열을\n뒤집어서 차례대로 누적 곱을 구한 뒤에 이것을 한번 더\n뒤집었다. 그래야 정상적으로 오른쪽에 있는 원소의 순서가 된다.\n\n\ndef productExceptSelf(nums):\n    left = [1]\n    for n in nums[:len(nums)-1]:\n        left.append(left[-1] * n)\n\n    right = [1]\n    for n in list(reversed(nums))[:len(nums)-1]:\n        right.append(right[-1] * n)\n    right = reversed(right)\n\n    answer = []\n    for l, r in zip(left, right):\n        answer.append(l * r)\n    return answer"
					}
					,
					"ps-cpp-prove": {
						"id": "ps-cpp-prove",
						"title": "Prove",
						"version": "all",
						"categories": "",
						"url": " /ps/cpp/prove/",
						"content": "Prove\nLoop Invariant\n알고리즘은 대부분 반복적인 요소를 갖기 때문에 귀납법으로 증명할 수 있다. 이때\n  반복문 불변식(Loop Invariant)를 이용하면 유용하다.\n\n  반복문 진입 때 불변식을 만족함을 보인다.\n  반복문 바디를 실행해도 불변식이 깨지지 않음을 보인다. 즉, 반복문을 매 단계\n    실행해도 계속 불변식이 성립함을 보인다.\n  반복문을 빠져나와도 불변식을 만족하면 항상 정답을 구함을 보인다.\n\n이진 탐색 증명 1\n이진 탐색 코드로 증명의 예시를 살펴보자. 종만북에서는 양 시작점이 exclusive 한\n  범위인데, 이걸 내가 자주 쓰는 half-inclusive로 바꿔서 증명하려면 아직 어떻게\n  해야하는지는 잘 모르겠다.\nint binary_search(const vector&lt;int&gt;&amp; arr, int x) {\n  // to find: return the index such that arr[i - 1] &lt; x &lt;= arr[i] (lower bound)\n  int low = -1, high = arr.size();\n  while (low + 1 &lt; high) {\n    int mid = (low + high) / 2;\n    if (arr[mid] &lt; x)\n      low = mid;\n    else:\n      high = mid;\n  }\n  return high;\n}\n\n위의 알고리즘은 두 개의 불변식을 유지한다.\n\n  low &lt; high\n  arr[low] &lt; x &lt;= arr[high]\n\n이 불변식이 반복문을 끝내고 마지막 줄에 올 때까지 계속 만족했다고 가정하자.\n  그러면 다음 두 가지 사실을 알 수 있다.\n\n  low + 1 == high: 반복문이 종료했으니 not (low + 1 &lt; high) &lt;-&gt; low + 1 &gt;= high\n    인데, 불변식 1에 따라 low &lt; high 이고 low, high 는 정수 인덱스이므로 low + 1\n    = high 일 수 밖에 없다.\n  arr[low] &lt; x &lt;= arr[high]: 가정에 따라 성립한다.\n\n찾고자 하는 인덱스 값 i 는 arr[i - 1] &lt; x &lt;= arr[i] 를 만족해야 하므로, 위의 두\n  가지 사실에 의해 i = high 임을 알 수 있다. 따라서, 반복문이 끝나도 불변식이 항상\n  만족함을 보이면 알고리즘을 증명한 것이다.\n\n  초기 조건: 초기값에 따라 불변식 1이 성립한다. arr[-1] = -oo 이고 arr[n] = oo\n    라고 가정하면 불변식 2가 성립한다.\n  유지 조건: 반복문 내부가 불변식을 깨지 않음을 보인다.\n    \n      반복문의 조건과 두 변수의 타입에 따라 low 와 high 의 차이는 항상 2\n        이상이다. 따라서 mid 값은 항상 두 값 사이에 위치한다. 따라서 mid 를 low 에\n        대입하건 high 에 대입하건 항상 불변식 1은 만족한다.\n      arr[mid] &lt; x 인 경우, 반복문을 시작할 때 x &lt;= arr[high] 이고 따라서\n        arr[mid] &lt; x &lt;= arr[high] 이므로, low 에 대입해도 불변식 2를 만족한다.\n      x &lt;= arr[mid] 인 경우, 반복문을 시작할 때 arr[low] &lt; x 이고 따라서\n        arr[low] &lt; x &lt;= arr[mid] 이므로, high 에 대입해도 불변식 2를 만족한다.\n    \n  \n\n따라서 반복문을 다 거쳐도 불변식을 모두 만족한다.\n이진 탐색 증명 2\n위의 증명을 Bisect 코드에도 해보자.\nint bisect_left(const vector&lt;int&gt;&amp; arr, int x) {\n  int low = 0, high = arr.size();\n\n  while (low &lt; high) {\n    mid = (low + high) / 2;\n    if (x &lt;= arr[mid])\n      high = mid;\n    else\n      low = mid + 1;\n  }\n  return low;\n}\n\n불변식은 다음과 같다.\n\n  low &lt;= high\n  arr[low] &lt; x &lt;= arr[high]\n\n반복문 마지막에서는 다음을 알 수 있다.\n\n  low == high: 반복문이 종료했으니 not (low &lt; high) &lt;-&gt; low &gt;= high 인데,\n    불변식 1에 따라 low &lt;= high 이고 따라서 low = high 일 수 밖에 없다.\n  arr[low] &lt; x &lt;= arr[high]: 가정에 따라 성립한다."
					}
					,
					"ps-python-tips": {
						"id": "ps-python-tips",
						"title": "Python Tips",
						"version": "all",
						"categories": "",
						"url": " /ps/python-tips/",
						"content": "sum\n\nsum(iterable, /, start=0) 타입인데, start에 iterable의 아이템을 하나씩\n 더해서 리턴하는 함수이다.\n\n그래서 start에 뭘 넘겨주느냐에 따라서 다양한 + 연산을 활용할 수 있다.\n\n예를 들면 이중 리스트를 평평하게 할 때 (flatten 연산) 리스트 컴프리헨션으로\n 헷갈리게 하는 것보다는 다음과 같이 할 수 있다:\n\narr = [[1, 2], [3, 4], [4, 5]]\nsum(arr, [])  # yields [1,2,3,4,4,5]\n\n\n이게 되는 이유는 start, 즉 accumulator로 쓸 초기값이 빈 리스트이기 때문에\n 이후 iterable의 각 원소마다 적용하는 + 연산이 리스트의 concatenation 으로\n 해석되기 때문이다.\n\n하지만 공식 문서에서는 다음과 같이\n\n\n  For some uses cases, there are good alternatives to sum()…. To concatenate\na series of iterables, consider using itertools.chain().\n\n\n즉 iterable의 시리즈를 합칠거면 sum() 쓰지 말고 itertools.chain()을\n 쓰는 것을 추천하고 있다.\n\nitertools.chain\n\n별 거 없고 아래 코드와 같다.\n\ndef chain(*iterables):\n    # chain('abc', 'def') --&gt; a b c d e f\n    for it in iterables:\n        for elt in it:\n            yield elt\n\n\nmap, filter\n적용할 함수가 먼저 온다. 어떻게 생각하면 되냐면 map(f, x) --&gt; f(x)\n 라고 생각하면 된다.\n\nmap(lambda x: x, seq)\nfilter(lambda x: return True, seq)\n\n\npow\n세 번째 파라미터 mod를 넘겨주는게 직접 계산하는 것보다 효율적임.\n\npow(base, exp, mod) == pow(base, exp) % mod\n\n\nsorted, .sort()\nsorted는 새로운 시퀀스를 만들어서 정렬하고, sort는 제자리\n 정렬이다.\n\nseq.sort()\nseq = sorted(seq)\n\n\n둘 다 정렬 비교에 쓰일 key 함수를 named parameter로 넘겨줄 수 있다.\n\nall, any\n모든 시퀀스 안의 원소를 전부 다 평가한 다음, \\(\\forall\\) 또는\n \\(\\exists\\) 를 계산한다. 문제는 모든 원소를 전부 다 평가하기 때문에\n Short-Circuit 최적화의 혜택을 받지 못해서 any는 대부분의 경우 훨씬\n 느리다. all이 필요한게 아니거나 모든 원소가 평가될 게 아니라면\n any는 되도록 쓰지말자.\n\nall([True, True]) == True\nall([]) == True\n\nany([True, False]) == True\nany([]) == False\n\n\nString\n별의 별 희한한 것까지 다 표준 라이브러리 함수로 들어있어서 구현하긴 편하다.\n\nstr.isalpha(), str.isdecimal(), str.isdigit(), str.isalnum(), str.isnumeric()\nstr.islower(), str.isupper()\nstr.lower(), str.upper(), str.swapcase()\nstr.lstrip(), str.rstrip(), str.strip()\n\"abc d asdf\".partition('d') == (\"abc \", \"q\", \" asdf\")\nstr.count(substring)\nstr.find(substring)\n\n\ncollections\n\ndefaultdict\n\nfrom collections import defaultdict\n\ndl = defaultdict(list)\ndl[0].append(1)  # not exception!\nprint(dl[1])  # also not exception! shows []\n\ndi = defaultdict(int)\ndi[0] += 1  # not exception!\nprint(di[100])  # also not exception! shows 0\n\n\nCounter\n\nfrom collections import Counter\ns = \"aabbcacaa\"\nc = Counter(s)  # Counter({'a':5, 'b':2, 'c':2})\nc.get('a')  # get count of the element, None if not exists -&gt; 5\nc.elements()  # ['a', ..., 'b', .. 'c']\nc.keys()  # ['a', 'b', 'c']\nc.values()  # [5, 2, 2]\nc.items()  # [('a', 5), ('b', 2), ('c', 2)]\nc.most_common()  # return a list of n most common elements and their counts\nc.most_common(1)  # top most common elements as list, so [('a', 5)]\n\n\nDeque\n\nfrom collections import deque\ndq = deque()\ndq.append(x)\ndq.appendleft(y)\ndq.pop()\ndq.popleft()\ndq.reverse()  # in-place reverse\ndq.rotate(n=1) == dq.appendleft(dq.pop())\ndq.count(x)\n\n\nOrderedDict\n\n\n  순서를 유지하는 딕셔너리인데, 키 값의 오더링이 아니라 아이템이 추가된\n순서를 보장한다.\n  거의 모든 메소드는 딕셔너리와 같고 다음 두 가지 연산이 추가적으로 제공된다.\n    \n      popitem(last=True): last 불리언 값에 따라서 가장 마지막에 추가된 아이템\n또는 가장 처음에 추가된 아이템을 제거한다.\n      move_to_end(key, last=True): key에 해당하는 맵핑의 순서를 last 불리언\n값에 따라 가장 마지막 또는 가장 처음으로 옮긴다.\n    \n  \n\n\n이런 성질을 이용하면 OrderedDict는 LRU 또는 LFU 캐시를 만드는데 쓰일 수 있다.\n\nHeapq\n\nimport heapq\nl = [ .... some list]\nheapq.heapify(l)  # make l as heap in-place\nheapq.heappush(l, item)\nheapq.heappop(l)\nheapq.nlargest(n, l, key=None) == sorted(l, key=None, reverse=True)[:n]\nheapq.nsmallest(n, l, key=None) == sorted(l, key=None)[:n]\n\n\nRandom\n\nimport random\n\nrandom.choice([1, 2, 3, ...])  # pick random item\nrandom.shuffle(l)  # shuffle l in-place\nrandom.uniform(a, b)  # pick random **float x** in a &lt;= x &lt;= b\n\n\nBisect\n\nimport bisect\n\nbisect.bisect_left(l, x)\nbisect.bisect_right(l, x) == bisect.bisect(l, x)\n\n\n\n\n어떤 문자열의 길이 k인 모든 부분 문자열 생성하기\n\ndef all_substrings(text: str, k: int):\n    return set(text[i:i + k] for i in range(0, len(text) - k + 1))\n\n\n\n  파이썬의 슬라이스를 이용해서 특정 인덱스 i부터 길이 k 만큼의\n부분 문자열을 str[i:i + k]로 표현할 수 있다. 인터벌 [i, i+k)를\n의미하므로 i+k 인덱스는 포함하지 않는다.\n  시작 인덱스 범위를 계산하기 위해서 range를 이용하는데 이때\nrange(start, end) 역시 [start, end) 인터벌을 의미하기 때문에\nend를 포함하지 않는다. 따라서 end를 len(text)-k+1로 해야\nlen(text) - k 까지의 인덱스를 생성해내고, 따라서 str[i:i+k]에서\nstr[len(text)-k:len(text)-k+k]가 되고 슬라이스의 end가\nlen(text)가 되어 오버플로우가 나지 않는다.\n  이렇게 생성한 부분 문자열 시퀀스를 다시 집합으로 감싸서 중복을\n제거한다."
					}
					,
					"ps-leetcode-queue-reconstruction-by-height": {
						"id": "ps-leetcode-queue-reconstruction-by-height",
						"title": "Queue Reconstruction by Height",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/queue-reconstruction-by-height/",
						"content": "Queue Reconstruction by Height\n\n사람의 정보를 담은 배열 people이 주어진다. 각 정보 people[i]는\n (h, k) 쌍인데 h는 이 사람의 키이고 k는 이 사람 앞에 이\n 사람의 키 h보다 크거나 같은 사람이 정확히 k명 있어야 한다는\n 조건을 뜻한다.\n\n이 큐를 재구성해서 이 조건에 맞게 사람들 줄을 다시 세우자.\n\n배열의 크기는 1 ~ 2,000 이고 키는 \\(0 \\sim 10^6\\), k는 0 ~\n people.length 이다. 큐는 항상 재구성할 수 있음이 보장된다.\n\n예를 들어 [[7,0], [4,4], [7,1], [5,0], [6,1], [5,2]]를\n 생각해보자. 정답은 [[5,0], [7,0], [5,2], [6,1], [4,4], [7,1]]이\n 되는데, 그 이유는:\n\n  [5,0]은 키가 5이고 앞에 자기보다 키가 크거나 같은 사람이 0명이다.\n  [7,0]은 키가 7이고 앞에 자기보다 키가 크거나 같은 사람이 0명이다.\n  [5,2]는 키가 5이고 앞에 자기보다 키가 크거나 같은 사람이 2명이다.\n  [6,1]은 키가 6이고 앞에 자기보다 키가 크거나 같은 사람이 1명이다.\n  [4,4]는 키가 4고 앞에 자기보다 키가 크거나 같은 사람이 위의 네 명\n모두이다.\n  [7,1]은 키가 7이고 앞에 자기랑 키가 크거나 같은 사람이 1명\n뿐이다.\n\n\n탐욕\n\n일단 키가 큰 친구를 먼저 배치하는 게 유리해보인다. 배열을 키의\n 내림차순으로 정렬했다고 해보자. 그러면 키 큰 순서대로 바로 배치하면\n 끝이다.\n\n키가 같은 경우에는 k가 더 작은 친구를 앞에 배치하는 것이 항상\n 유리하다. 따라서, 같은 키에 한해서는 k의 오름차순으로 정렬을 해야\n 한다. 이 경우, k가 작은 순서대로 배치하면 된다.\n\n그럼 배치는 어떻게 해야할까? 이 경우 스택처럼 뒤에 붙이는게 아니라,\n 줄을 세워야 하므로 중간에 껴 넣어야 한다. 만약 위의 조건대로, 즉\n (키가 큰 순서, 키가 같으면 k가 작은 순서)로 친구를 배치한다면,\n 친구를 곧바로 k 위치에다가 배치하고 나머지 친구를 뒤로 싹 밀면\n 된다. 예를 들어 [[7,1], [6,1], [7,0]]이 있을 때:\n\n  (키 내림차순, k 오름차순)으로 정렬하면 [[7,0], [7,1], [6,1]]이\n된다.\n  앞의 두 명을 배치하는 일은 자명하게 [[7,0], [7,1]]이 된다. 이제\n[6,1]을 배치해야 하는 경우를 잘 생각해보자. 이미 자기보다 키 큰\n친구들을 모두 배치했으므로, [6,1]은 곧바로 k 위치에\n배치하면 조건을 만족하게 된다. 즉, 자기보다 크거나 같은 친구가\n정확히 k명 있게 된다.\n\n\n정리하면,\n\n  키 기준으로 내림차순, k 기준으로 오름차순으로 정렬한다.\n  순서대로 배치하는데, 이때 k 위치에다 친구를 배치하고 나머지\n친구를 전부 뒤로 밀어버린다. 그러면 항상 조건을 만족하게 된다.\n\n\n이 놀라운 아이디어를 구현하면 다음과 같은 매우 심플한 코드가\n 완성된다.\n\ndef reconstructQueue(people):\n    queue = []\n    for p in sorted(people, key=lambda x: (-x[0], x[1])):\n        queue.insert(p[1], p)\n    return queue\n\n\n  정렬 조건으로 키 내림차순과 k 오름차순을 동시에 만족해야 하므로\nkey 함수에 튜플을 넘겨줬다.\n  파이썬에서 array.insert(index, value) 함수는 index 위치에\nvalue를 집어넣고 원래 값들을 싹 뒤로 밀어버린다. 정확히 우리가\n원하는 함수이다. p[1]이 k이고 이걸 곧바로 인덱스로 쓰면 되기\n때문에 저런 코드가 나온다. 범위가 배열보다 크면 그냥 제일 마지막에\n추가된다.\n\n\n이렇게하면 insert의 복잡도 때문에 전체 복잡도는 \\(O(N^2)\\)이 된다."
					}
					,
					"ps-leetcode-range-sum-query-2d-immutable": {
						"id": "ps-leetcode-range-sum-query-2d-immutable",
						"title": "Range Sum Query 2D Immutable",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/range-sum-query-2d-immutable/",
						"content": "Range Sum Query 2D Immutable\n\n2차원 행렬 matrix가 주어질 때, 다음 쿼리를 여러 번 수행해야\n 한다. 두 좌표 (row1, col1), (row2, col2)가 주어졌을 때, matrix\n 에서 이 두 좌표로 만들어지는 사각형 안의 원소의 합을 계산해야 한다.\n\n이때, 생성자와 쿼리 함수를 구현하자.\n\nDP\n\n부분 합의 2차원 버전이다. (0, 0)부터 (x, y)까지의 부분 합을 미리\n 계산해두면, (row1, col1)과 (row2, col2)로 만들어지는 사각형 안의\n 넓이는 다음과 같은 식을 통해서 구할 수 있다:\n\n\\[Sum_{(row_1, col_1) \\sim (row_2, col_2)} =  Partial_{(row_2, col_2)} - Partial_{(row_1 - 1, col_2)} - Partial_{(row_2, col_1 - 1)} + Partial_{(row_1 - 1, col_1 - 1)}\\]\n\n이 식을 다음 그림과 같이 살펴보면 다음과 같다.\n\n\n\n\n  D: 구하고자 하는 값 \\(Sum_{(row_1, col_1) \\sim (row_2, col_b2)}\\)\n  A + B + C + D: 캐싱해둔 부분 합 \\(Partial_{(row_2, col_2)}\\)\n  A + B: 캐싱해둔 부분 합 \\(Partial_{(row_1 - 1, col_2)}\\)\n  A + C: 캐싱해둔 부분 합 \\(Partial_{(row_2, col_1 - 1)}\\)\n  A: 캐싱해둔 부분 합 \\(Partial_{(row_1 - 1, col_1 - 1)}\\)\n\n\n즉, D의 구간 합을 구하기 위해서 A + B + C + D - (A + B) - (A +\n C) + A로 식을 바꾸고, 각각의 값을 캐싱해둔 부분 합에서 O(1) 만에\n 구해서 쿼리 속도를 높이는 방식이다.\n\n이걸로 각 쿼리의 속도는 높일 수 있다. 그러면 이 캐싱할 부분 합은\n 어떻게 구할 수 있을까? 보통 다이나믹 프로그래밍에서 메모이제이션은 탑\n 다운 방식과 바텀 업 방식의 두 종류가 있는데, 문제의 조건에 따라\n 적절한 것을 선택하면 된다. 이 문제에서, 2차원 행렬의 최대 크기는 200\n x 200이고, 쿼리는 최대 10,000 만큼 불리기 때문에, 탑 다운 방식 (온\n 디맨드)로 구하면 테스트 케이스에 따라 시간 초과가 날 수 있다. 최대\n 가능한 파라미터 수는 40,000인데 쿼리가 10,000 이기 때문이다. 따라서\n 여기서는 바텀 업 방식으로 부분 합을 초기화 함수에서 직접 구하는게 더\n 좋다.\n\n바텀 업 방식으로 부분 합을 캐싱하는 것은, 위의 식에서 row2 = row1 +\n 1, col2 = col1 + 1로 생각하여, 즉 1씩 증가하는 경우에 대해서\n 생각하면 쿼리를 구하는 방식과 거의 동일하게 쌓아나갈 수 있다. row와\n col만 가지고 이를 수식으로 적으면 다음과 같다.\n\n\\[Partial_{(row + 1, col + 1)} =  Partial_{(row + 1, col)} + Partial_{(row, col + 1)} + Matrix_{(row, col)} - Partial_{(row, col)}\\]\n\n역시 이 식을 아래 그림과 함께 보면 다음과 같다.\n\n\n\n\n  구하고자 하는 값 \\(Partial_{(row + 1, col + 1)}\\) 은 A+B+C+D의\n값이다. 이때, 한 칸씩 구하기 때문에 D는 곧 matrix[row][col] 한\n칸의 값과 같다.\n  A+C와 A+B, A의 식은 이전과 동일하다.\n  여기서는 D가 아니라 A+B+C+D를 구하는 것이 목표이기 때문에 식이\n살짝 바뀌었다. 즉, A+B+C+D = (A+C) + (A+B) + D - A가 된다.\n\n\n이 아이디어를 종합하여 코드를 완성하면 다음과 같다.\n\nclass NumMatrix:\n    def __init__(self, matrix):\n        m, n = len(matrix), len(matrix[0])\n        self.partial = [[0] * (n+1) for _ in range(m+1)]\n        for x in range(m):\n            for y in range(n):\n                self.partial[x+1][y+1] = self.partial[x+1][y] + self.partial[x][y+1] + matrix[x][y] - self.partial[x][y]\n\n    def sumRegion(self, row1, col1, row2, col2):\n        return self.partial[row2+1][col2+1] - self.partial[row1][col2+1] - self.partial[row2+1][col1] + self.partial[row1][col1]\n\n\n\n  인덱스에 주의하자. 부분 합은 아무것도 포함하지 않은 베이스 케이스\n0이 필요하기 때문에, row와 column 모두 한 칸씩 더 필요하다. 따라서\nself.partial[x][y]의 의미는 (0, 0)부터 (x-1, y-1)의 사각형\n안의 부분합이 된다. 따라서, 쿼리에서 인덱스를 주의해야 한다."
					}
					,
					"ps-leetcode-rectangle-area": {
						"id": "ps-leetcode-rectangle-area",
						"title": "Rectangle Area",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/rectangle-area/",
						"content": "Rectangle Area\n\n2차원 좌표계에서 두 개의 직사각형을 나타내는 좌표가 주어진다. 이때,\n 이 두 개의 직사각형이 만드는 넓이를 구하자.\n\n두 직사각형을 a, b라고 했을 때, 각각의 직사각형 좌표는 가장 왼쪽\n 아래의 좌표(bottom-left) (x1, y1)와 가장 오른쪽 위의\n 좌표(top-right) (x2, y2)로 주어진다. 따라서 입력은 (ax1, ay1, ax2,\n ay2)와 (bx1, by1, bx2, by2) 이다.\n\n\n  각 사각형의 좌표 x1 &lt;= x2 , y1 &lt;= y2이고 범위는 \\(-10^4 \\sim\n10^4\\) 사이이다.\n\n\nExhaustive Case Analysis\n\n  가장 무식하지만 단순하고 떠올리기 쉬운 방법은 모든 경우의 수를\n빠뜨림없이 처리하는 것이다.\n  x, y 축을 기준으로 총 6가지 경우가 있다:\n\n\n\n\n\n  Non-overlapping: 안겹치는 경우\n  Edge overlapping: 모서리가 겹치는 경우\n  X-eaten: X축으로 한쪽이 먹힌 경우\n  Y-eaten: Y축으로 한쪽이 먹힌 경우\n  Cross: 십자가를 형성하는 경우\n  Subsumed: 한쪽이 다른 한쪽에 포함되는 경우\n\n\n모든 경우에 대해서 좌표를 잘 계산해서 (…) 각각의 경우를 다 처리하면\n 다음과 같다.\n\ndef computeArea(ax1, ay1, ax2, ay2, bx1, by1, bx2, by2):\n    a_width, b_width = ax2 - ax1, bx2 - bx1\n    a_height, b_height = ay2 - ay1, by2 - by1\n    a_area = a_width * a_height\n    b_area = b_width * b_height\n    ab_area = a_area + b_area\n\n    if (ax1 &lt;= bx1 &lt;= bx2 &lt;= ax2 and ay1 &lt;= by1 &lt;= by2 &lt;= ay2) \\\n    or (bx1 &lt;= ax1 &lt;= ax2 &lt;= bx2 and by1 &lt;= ay1 &lt;= ay2 &lt;= by2):\n        # subsumed case\n        return max(a_area, b_area)\n    elif (ax1 &lt;= bx1 &lt;= bx2 &lt;= ax2 and by1 &lt;= ay1 &lt;= ay2 &lt;= by2) \\\n      or (bx1 &lt;= ax1 &lt;= ax2 &lt;= bx2 and ay1 &lt;= by1 &lt;= by2 &lt;= ay2):\n        # cross case\n        inner_area = min(a_width, b_width) * min(a_height, b_height)\n        return ab_area - inner_area\n    elif (ax1 &lt;= bx1 &lt;= bx2 &lt;= ax2 and (ay1 &lt;= by1 &lt;= ay2 or ay1 &lt;= by2 &lt;= ay2)) \\\n      or (bx1 &lt;= ax1 &lt;= ax2 &lt;= bx2 and (by1 &lt;= ay1 &lt;= by2 or by1 &lt;= ay2 &lt;= by2)):\n        # x-eaten case\n        inner_area = min(a_width, b_width) * min(by2 - ay1, ay2 - by1)\n        return ab_area - inner_area\n    elif (ay1 &lt;= by1 &lt;= by2 &lt;= ay2 and (ax1 &lt;= bx1 &lt;= ax2 or ax1 &lt;= bx2 &lt;= ax2)) \\\n      or (by1 &lt;= ay1 &lt;= ay2 &lt;= by2 and (bx1 &lt;= ax1 &lt;= bx2 or bx1 &lt;= ax2 &lt;= bx2)):\n        # y-eaten case\n        inner_area = min(ax2 - bx1, bx2 - ax1) * min(a_height, b_height)\n        return ab_area - inner_area\n    elif (ax1 &lt;= bx1 &lt;= ax2 &lt;= bx2 and (ay1 &lt;= by1 &lt;= ay2 &lt;= by2 or by1 &lt;= ay1 &lt;= by2 &lt;= ay2)) \\\n      or (bx1 &lt;= ax1 &lt;= bx2 &lt;= ax2 and (ay1 &lt;= by1 &lt;= ay2 &lt;= by2 or by1 &lt;= ay1 &lt;= by2 &lt;= ay2)):\n        # edge overlapping case\n        inner_area = min(bx2 - ax1, ax2 - bx2) * min(by2 - ay1, ay2 - by1)\n        return ab_area - inner_area\n    else:\n        # non-overlapping case\n        return ab_area\n\n\nMath\n\n  좀더 똑똑하게 하는 방법을 생각해보자.\n  1차원 X축만 생각했을 때, 두 선이 겹치는지 안겹치는지를 확인하는\n방법은 다음과 같다.\n    if min(ax2, bx2) &lt; max(ax1, bx1):\n # non-overlapping\n pass\nelse:\n # overlapping four cases!\n pass\n    \n  \n  즉, 선이 서로 안겹치면 (ax1, ax2) &lt; (bx1, bx2) 또는 (bx1, bx2) &lt;\n(ax1, ax2) 이기 때문에, x2 좌표 중 더 작은 값 (ax2 또는\nbx2)이 x1 좌표 중 더 큰 값 (bx1 또는 ax1)보다 항상 작다.\n  서로 겹치는 경우에는 min(ax2, bx2) - max(ax1, bx1) 값이 곧바로\n겹치는 부분의 길이가 된다.\n  따라서, 이걸 X축과 Y축 각각에 대해서 구한 다음에 곱하면 그게 바로\n겹치는 영역이다.\n  즉, X축과 Y축이 모두 겹치는 부분이 있어야 겹치는 영역이 있는\n것이고, 위의 수식은 겹치는 다음 네 가지 경우를 모두 포함한다:\n\n\n\n\n  겹치는 부분의 길이: ax2 - bx1 = min(ax2, bx2) - max(ax1, bx1)\n  겹치는 부분의 길이: bx2 - ax1 = min(ax2, bx2) - max(ax1, bx1)\n  겹치는 부분의 길이: ax2 - ax1 = min(ax2, bx2) - max(ax1, bx1)\n  겹치는 부분의 길이: bx2 - bx1 = min(ax2, bx2) - max(ax1, bx1)\n\n\ndef computeArea(ax1, ay1, ax2, ay2, bx1, by1, bx2, by2):\n    a_area = (ay2 - ay1) * (ax2 - ax1)\n    b_area = (by2 - by1) * (bx2 - bx1)\n\n    overlapping_width = min(ax2, bx2) - max(ax1, bx1)\n    overlapping_height = min(ay2, by2) - max(ay1, by1)\n\n    overlapping_area = 0\n    if overlapping_width &gt; 0 and overlapping_height &gt; 0:\n        overlapping_area = overlapping_width * overlapping_height\n\n    return a_area + b_area - overlapping_area"
					}
					,
					"ps-boj-recursion": {
						"id": "ps-boj-recursion",
						"title": "Recursion",
						"version": "all",
						"categories": "",
						"url": " /ps/boj/recursion/",
						"content": "Recursion\n재귀는 곧 자연수, 귀납적인 정의와 동치다.\n\n기저 조건에 대해서 반드시 종료되어야 하고, 모든 입력은 최종적으로\n 기저 조건에 수렴해야 한다.\n\n함수 파라미터로 뭘 받고, 어디까지 계산한 후 다시 재귀 호출을 할지를\n 명확하게 정해야 한다. 함수 형태를 잘 잡아야 올바른 재귀 함수를 짤 수\n 있다.\n\n모든 재귀 함수는 같은 의미의 반복문으로 바꿀 수 있다. 재귀 함수는\n 함수 호출 로드가 있기 때문에 메모리와 성능에서 약간 손해를 보지만\n 대신 코드가 아주 간결해진다.\n\n재귀 함수 호출을 두 번 이상하면 아주 비효율적일 수 있다. e.g)\n 피보나치. 그런데 만약 함수 자체가 idempotent 하다면, 나중에 DP로\n 최적화할 여지가 많다.\n\n1629번: 곱셈\n\nimport sys\na, b, c = map(int, sys.stdin.readline().rstrip().split())\n\ndef my_power(a, b, m):\n    if b == 1:\n        return a % m\n\n    val = my_power(a, b//2, m)  # val == a^(b/2)\n    val = val * val % m  # val = a^b = a^(b/2) * a(b/2)\n    if b % 2 == 0:\n        return val\n    else:\n        return val * a % m  # in case of b is an odd number\n\nprint(my_power(a, b, c))\n\n\n이건 반복문으로도 풀 수 있지만 재귀적으로 생각하는 훈련에 좋은\n 문제이기도 하다.\n\nBase Case로 a ^ 1 = a를 깔아두었다. a ^ 0 = 1을 깔아도\n 상관없다. 그러고나면 다음 식을 이용할 수 있다: a ^ b = a ^ (b/2) * a\n ^ (b/2)\n\n여기서는 이 정의에 충실하게 먼저 a ^ (b/2)인 val을 구하고 이걸 두\n 번 곱했다. 코너 케이스로 b가 홀수일 때에는 b / 2가 나누어\n 떨이지지 않기 때문에 a ^ b = a ^ (b/2) * a ^ (b/2) * a 를\n 처리해줘야 한다.\n\n거의 수학적인 정의를 그대로 써주면 되지만 따라가는 훈련을 해야한다.\n\n11729번: 하노이 탑 이동 순서\n아.. 이거 재귀 단골 문제인데 여전히 100% 이해했다고는 못하겠다.\n\n아무튼 먼저 함수 형태를 잘 생각해봐야 하는데, 단순히 지금 턴에 옮길\n 원판 개수를 입력으로 받으면 안된다. 왜냐하면 원판을 옮길 때 1 -&gt;\n 3으로 옮겨야할 때도 있고 1 -&gt; 2로 옮겨야할 때도 있어서, 즉 원판을\n 어디에서 어디로 옮길지가 매번 달라지기 때문이다. 따라서 함수의\n 원형은 hanoi(f, t, n)이 되어야 하고 f -&gt; t로 n개의 원판을\n 옮기는 함수라고 생각해야 한다.\n\n그러고나면 이제 기저 조건을 따져봐야 한다. 자명한 케이스로 원판 1개를\n 옮겨야 한다면 그냥 f -&gt; t로 곧바로 옮길 수 있다. 그럼 끝이다.\n\n그럼 이제 Inductive Case를 생각하기 위해서 k - 1개를 옮길 수 있다고\n 가정할 때 k개를 어떻게 옮길지 고민해보자. k개가 기둥 1에 있고\n 이걸 기둥 3으로 옮기려고 한다면 다음 스텝을 밟아야 한다:\n\n  기둥 1에 있는 원판 중 k - 1개를 기둥 2로 옮긴다. k - 1개를\n옮길 수 있다고 가정했으므로 (Inductive Hypothesis) 옮겨졌다고\n가정한다.\n  k번째 원판을 3번 기둥으로 옮긴다.\n  2번 기둥에 있던 k - 1개의 원판을 기둥 3으로 마저 옮긴다. 역시\nInductive Hypothesis에 의해 옮길 수 있다.\n\n\n이 과정을 거치게 되고, 우리는 k = 1일 때 옮기는 방법을 알고\n 있으므로 Inductive Definition에 따라 k = 2, 3, ..., 즉 모든 경우에\n 대해 옮길 수 있게 된다.\n\n여기까지는 뇌가 어떻게 이해할 수 있다. 그런데 이걸 막상 코드로\n 옮기려면 좀 헷갈린다.\n\n먼저 함수 원형이 hanoi(f, t, n) 이므로, k - 1개의 원판을 잠깐\n 담아두기 위한 버퍼 용도으 기둥 번호를 어떻게 구해야할지\n 고민해보자. 모든 케이스를 나열하면 다음과 같다:\n\n  기둥 1 -&gt; 3 일때: 기둥 2\n  기둥 1 -&gt; 2 일때: 기둥 3\n  기둥 3 -&gt; 1 일때: 기둥 2\n  기둥 3 -&gt; 2 일때: 기둥 1\n  기둥 2 -&gt; 3 일때: 기둥 1\n  기둥 2 -&gt; 1 일때: 기둥 3\n\n\n즉, 순서 있는 기둥 3개를 나열하는 가짓수인 3! = 6이 모든 케이스가\n 되고 이 경우는 이걸 전부 하나의 해시 테이블에 만들어놨다가 돌려줘도\n 된다. 하지만 좀더 엘레강트한 방법을 고민해보자. 잘 살펴보면, 출발\n 기둥과 도착 기둥의 번호의 합을 총 가짓수에서 빼면 버퍼로 쓸 기둥의\n 번호가 나옴을 알 수 있다. 즉, 기둥 1 -&gt; 3이면 6 - (1 + 3) = 2가\n 되고, 나머지도 모두 같은 방법으로 계산할 수 있다. 따라서, 이제 버퍼로\n 쓸 기둥의 번호도 알아냈기 때문에, 위의 스텝을 일반화 하면 다음과\n 같다:\n\n  기둥 f에 있는 k - 1개의 원판을 버퍼 기둥으로 옮긴다.\n  기둥 f에 있는 k번째 원판을 t기둥으로 옮긴다.\n  버퍼 기둥에 있던 k - 1개의 원판을 t기둥으로 옮긴다.\n\n\n이렇게 해서 하노이 탑의 옮기는 순서는 구할 수 있다.\n\n그럼 총 가짓수는 어떻게 구할까? 재귀 호출이 일어날 때마다 값을\n 누적해서 구해도 되지만, 귀납적 방법을 가지고 있기 때문에 원판의\n 개수가 주어지면 총 옮기는 횟수를 계산하는 수식을 구할 수 있다.\n\n원판 k - 1개를 이동하기 위해서 m번 이동이 필요하다고 하자. 그러면\n 위의 귀납적 방법에 의해서 원판 k개를 이동하려면 먼저 1번 스텝에\n 의해서 m번, 2번 스텝에 의해서 1번, 그리고 3번 스텝에 의해서 m번\n 이동이 필요하다. 따라서 총 2 * m + 1 번의 이동이 필요하다. 기저\n 조건에 따르면 원판 1개를 옮기는 횟수는 1회이므로, 이로부터 초항이\n 1이고 일반항은 2*k + 1인 수열의 합이 곧 원판을 옮기는 총 횟수임을\n 알 수 있고 이는 곧 2^n - 1 임을 알 수 있…는데 솔직히 유도하는\n 방법 까먹었다. 등비수열 합 공식이 뭐더라?\n\nN = int(input())\n\ndef hanoi(f, t, n):\n    if n == 1:\n        print(f, t)\n        return\n\n    buffer = 6 - f - t\n    hanoi(f, buffer, n - 1)\n    print(f, t)\n    hanoi(buffer, t, n - 1)\n\nprint(2 ** N - 1)\nhanoi(1, 3, N)\n\n\n아무튼 이게 왜 올바른 재귀함수인지를 Concrete Example을 가지고\n Reasoning 하려면 골 빠개져서 힘들다. 이럴 땐 위에서 설명한 방법처럼\n 먼저 기저 조건을 정으하고, 그 다음 k에 대해서 잘 동작하면 k + 1일\n 때에도 잘 동작하니까 나머지는 도미노 쓰러지듯이 주르륵 모든 입력에\n 대해서 잘 동작한다고 이해하고 넘어가야 한다. 익숙해지자.\n\n1074번: Z\n이거는 문제 설명 보면 재귀인건 알겠는데 대체 어떻게 함수를 짜야할지\n 한번에 떠올리기 힘들 것 같이 생겼다.\n\n일단 함수 원형은 문제 조건에 따라 z(r, c, n)으로, 2^n x 2^n\n 배열에서 (r, c)를 방문하는 순서를 계산하는 함수라고 하자.\n\n그러면 기저 조건은 아주 자명하게 n = 0 일 때 0일 것이다. n = 1\n 일 때를 기저로 가져갈 수도 있는데, 예제 입력을 보면 n = 1, r = 0, c\n = 0일 때 답이 0인걸로 봐서 r, c 그리고 방문 순서까지 전부 0부터\n 시작한다는 것을 알 수 있다. 따라서 n = 1일 때에는 [[0, 1], [2,\n 3]][r][c]로 시뮬레이션할 수 있다.\n\n그럼 이제 Inductive Case를 고려해보자. 다음과 같은 사각형일 때\n\n+---+---+\n| 1 | 2 |\n+---+---+\n| 3 | 4 |\n+---+---+\n\n\n\n  (r, c) 가 1번: z(r, c, n - 1)\n  (r, c) 가 2번: 1번 사각형 크기 + z(r, c - half, n - 1)\n  (r, c) 가 3번: 1, 2번 사각형 크기 합 + z(r - half, c, n - 1)\n  (r, c) 가 4번: 1, 2, 3번 사각형 크기 합 + z(r - half, c - half,\nn - 1)\n\n\n방문 횟수이므로 사각형 크기의 합을 구하는 건 알겠는데, half는\n 무엇이며 이걸 왜 빼주는 걸까? z(r, c, n)의 정의가 2^n x 2^n\n 배열에서 (r, c)를 방문하는 순서이므로, 위와 같이 1, 2, 3, 4번\n 사각형을 그리고 나면 이 사각형의 각 변 절반의 길이를 half = 2 ^ (n\n -1)으로 구할 수 있다. 그러면 1, 2, 3, 4번 각 사각형의 크기는\n half^2가 되고, (r, c)가 1번이 아닌 다른 사각형에 있다면\n half에서 이 값을 빼줌으로써 일종의 zoom in을 할 수 있다.\n\nimport sys\nN, R, C = map(int, sys.stdin.readline().rstrip().split())\n\ndef z(r, c, n):\n    if n == 1:\n        return [[0, 1], [2, 3]][r][c]\n    half = 2 ** (n - 1)\n    rect = half * half\n    if r &lt; half and c &lt; half:  # 1\n        return z(r, c, n-1)\n    if r &lt; half and c &gt;= half: # 2\n        return rect + z(r, c - half, n - 1)\n    if r &gt;= half and c &lt; half:  # 3\n        return 2 * rect + z(r - half, c, n - 1)\n    return 3 * rect + z(r - half, c - half, n - 1)\n\nprint(z(R,C,N))"
					}
					,
					"ps-theory-regexp": {
						"id": "ps-theory-regexp",
						"title": "Regular Expressions",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/regexp/",
						"content": "Regular Expressions\n\n정규식, 그 중에서도 파이썬의 re 패키지 사용법을 정리해둔다.\n\nre\n\n펄의 정규식 엔진과 유사한 기능이다.\n\n정규식을 쓸 때는 r로 시작하는 raw string을 사용하는 것이\n 좋다. r이 붙은 raw string에서는 \\가 이스케이프 문자로 해석되지\n 않는다. 그래서 r'\\n'은 \\과 n 두 글자로 해석되는 반면 '\\n'은\n 개행문자 한 글자로 해석된다.\n\n문법\n\n특수문자\n.\n\n개행문자를 제외한 모든 문자 한 글자랑 매치한다.\n\n^\n\n문자열의 시작 위치와 매치한다.\n\n$\n\n문자열의 끝과 매치한다. 개행문자 바로 앞이다.\n\n\\\n\n특수문자를 이스케이프하여 *나 ?를 매치할 수 있게 해주거나, 특수\n 시퀀스를 시작한다.\n\n파이썬의 문자열 리터럴에서도 \\가 이스케이프 시퀀스로 사용되기\n 때문에, raw string 패턴을 쓰지 않으면 조심해야 한다. 파이썬의 파서가\n 인식하지 않으면 결과 문자열에 포함된다.\n\n[]\n\n글자의 집합을 나타낸다.\n\n  한 글자씩 추가할 수 있다. [amk]는 a 또는 m 또는 k와\n매치한다.\n  특수문자 -와 두 개의 추가 캐릭터를 이용해서 문자의 범위를 나타낼\n수도 있다. 예를 들어 [a-z]는 영문 소문자를, [0-5][0-9]는\n00부터 59까지 매치한다. 만약 -가 [a\\-z]와 같이 이스케이프\n되거나, [-a]와 같이 집합의 가장 처음에 나타난다면 리터럴 -에\n매치한다.\n  특수문자는 집합 안에서 의미를 잃는다. 예를 들어 [(+*)]는 (,\n+, *, ) 중 하나와 매치한다.\n  \\w나 \\S같은 문자 클래스가 집합 안에 올 수 있다.\n  집합을 여집합으로 만듦(complementing the set)으로써 범위 안에 없는\n글자를 매칭하게 할 수도 있다. 집합의 시작 문자가 ^이면, 이후에\n오는 문자가 아닌 모든 글자와 매치된다. 예를 들어 [^5]는\n5빼고는 다 매치하고, [^^]는 ^빼고는 다 매치한다. ^는 집합\n안에서 첫번째에 위치하지 않으면 특수한 역할을 하지 않는다.\n  ] 리터럴을 집합 안에서 매치하고 싶다면 백슬래시로 이스케이프\n하거나 집합의 가장 처음에 위치하게 하면 된다. 예를 들어\n[()[\\]{}]와 []()[{}]는 동일한 의미로 괄호를 매치한다.\n\n\n|\n\nOR의 의미다. | 리터럴을 매치하고 싶다면 \\|처럼 이스케이프하던가\n 아니면 [|] 처럼 집합으로 표현하면 된다.\n\n(...)\n\n괄호 안의 정규식과 매치하고 그 결과를 그룹으로 묶어서 시작과 끝\n 위치를 가진다. 매치가 완료되면 매칭된 그룹 내용을 알 수 있다.\n\n괄호 자체를 매치하고 싶다면 \\(과 \\) 처럼 각각 이스케이프하거나\n [(], [)]처럼 집합으로 표현하면 된다.\n\n\\number\n\nnumber 번째 매칭된 그룹과 매치한다. 1-indexed를 사용한다. 예를\n 들어, (.+) \\1은 the the나 55 55를 매치한다.\n\n\\b\n\n빈 문자열(blank)과 매치한다. 문자의 시작이나 끝에서만\n 매치한다. r'\\bfoo\\b'는 foo, foo., (foo), bar foo baz와\n 매치하지만 foobar나 foo3과는 매치하지 않는다.\n\n\\B\n\n빈 문자열과 매치하지만, 문자의 시작이나 끝이 아닌 것만\n 매치한다. 따라서 r'py\\B'는 python, py3, py2와 매치하지만\n py, py., py!와는 매치하지 않는다. \\b의 역연산이다.\n\n\\d\n\n[0-9]\n\n\\D\n\n[^0-9]\n\n\\s\n\n유니코드 공백 문자 [ \\t\\n\\r\\f\\v]와 매치한다.\n\n\\S\n\n[^ \\t\\n\\r\\f\\v]\n\n\\w\n\n유니코드 문자열 패턴과 매치한다. [a-zA-Z0-9_]\n\n\\W\n\n[^a-zA-Z0-9_]\n\n모듈\n\nre.compile(pattern, flags=0)\n\n정규 표현식 패턴을 컴파일해서 정규 표현식 오브젝트로 만든다. 나중에\n 이 오브젝트로 match(), search() 등의 함수를 이용해서 매치할 수\n 있다.\n\nresult = re.match(pattern, string)\n\n\n위의 코드는\n\nprog = re.compile(pattern)\nresult = prog.match(string)\n\n\n과 같다. 하지만, 같은 정규식 패턴이 프로그램에서 여러 번 나타나는\n 경우, re.compile()을 이용해서 정규 표현식 오브젝트를 만들어서\n 재사용하는 것이 더 효율적이다.\n\nre.search(pattern, string, flags=0)\n\nstring을 스캔하면서 정규식 pattern과 매치하는 첫 번째 위치를 찾고\n 매치 오브젝트를 리턴한다. 더 이상 매치하는 패턴이 없으면 None을\n 리턴한다.\n\nre.match(pattern, string, flags=0)\n\nstring의 처음에서 0개 이상의 문자가 정규식 pattern과 일치하면\n 매치 오브젝트를 리턴한다.\n\nMatch Object\n\n매치 오브젝트는 조건식에서 항상 True로 평가된다.\n\nMatchObject.group(args)\n\n매치된 하나 이상의 서브 그룹을 리턴한다. 파라미터가 하나면 하나, 여러\n 개면 튜플로 리턴한다. 서브 그룹은 1-indexed이고 파라미터가 0이면\n 전체를 리턴한다.\n\nm = re.match(r\"(\\w+) (\\w+)\", \"Isaac Newton, physicist\")\nm.group(0) == 'Isaac Newton'  # entire match\nm.group(1) == 'Isaac'\nm.group(2) == 'Newton'\nm.group(1, 2) == ('Isaac', 'Newton')\n\n\n(?P&lt;name&gt;...) 정규식을 이용했다면 파라미터가 숫자가 아니라 그룹\n 이름이 될 수도 있다.\n\nm = re.match(r\"(?P&lt;first_name&gt;\\w+) (?P&lt;last_name&gt;\\w+)\", \"Steve Jobs\")\nm.group('first_name') == 'Steve'\nm.group('last_name') == 'Jobs'\n\n# can be indexed\nm.group(1) == 'Steve'\nm.group(2) == 'Jobs'\n\n\nMatchObject.groups()\n\n모든 매치된 서브 그룹을 튜플로 리턴한다.\n\nHow To\n\n\n  \n    \n      함수 이름\n      목적\n    \n  \n  \n    \n      match()\n      문자열의 시작 부분에서 정규식과 매치되는게 있는지 찾는다.\n    \n    \n      search()\n      정규식과 매치하는 위치를 찾으면서 문자열을 계속 훑어 나간다.\n    \n    \n      findall()\n      정규식과 매치하는 모든 부분 문자열을 찾아서 리스트로 리턴한다.\n    \n    \n      finditer()\n      정규식과 매치하는 모든 부분 문자열을 찾아서 이터레이터로 리턴한다.\n    \n  \n\n\n\n  match(), search()는 매치하는게 없으면 None을 리턴, 있으면\n매치 오브젝트를 리턴\n\n\n매치 오브젝트\n\n\n  \n    \n      함수 이름\n      목적\n    \n  \n  \n    \n      group()\n      정규식과 일치하는 문자열을 리턴\n    \n    \n      start()\n      매치 시작 위치\n    \n    \n      end()\n      매치 끝 위치\n    \n    \n      span()\n      매치의 (시작, 끝) 위치 튜플\n    \n  \n\n\n가장 많이 사용하는 패턴\n\np = re.compile(r'regular expression')\nm = p.match(' string to match ')\nif m:\n    print(m.group())\nelse:\n    print('no')\n\n\np = re.compile(r'\\d+')\np.findall('12 drummers drumming, 11 pipers piping, 10 lords a-leaping')\n== ['12', '11', '10']"
					}
					,
					"ps-leetcode-remove-duplicates-from-sorted-array": {
						"id": "ps-leetcode-remove-duplicates-from-sorted-array",
						"title": "Remove Duplicates from Sorted Array",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/remove-duplicates-from-sorted-array/",
						"content": "Remove Duplicates from Sorted Array\n정렬된 배열이 들어오면, 여기서 중복되는 원소를 제자리에서\n 수정하여 모든 값이 단 한번만 나오게 수정하고, 수정된 배열의 길이를\n 리턴하는 문제이다.\n\n즉, 공간 복잡도는 O(1)을 반드시 지켜야한다. 그리고 결과로 길이를\n 리턴하는 이유는, 제자리 수정된 배열의 0부터 수정된 길이까지만\n 체크하여 채점을 하기 때문이다.\n\nO(n^2)\n먼저 가장 단순하게는 왼쪽으로 땡기는 것을 생각해볼 수 있다. 두 개의\n 포인터를 이용해서 중복을 체크하다가 같은 값이 나올 때마다 왼쪽으로 한\n 칸씩 전체 배열을 땡기는 것이다. 이렇게하면 전체를 훑기 위해서 n,\n 그리고 중복이 발생될 때마다 또 전체를 훑기 위해서 n 총 O(n^2)의\n 복잡도가 소요된다. 따라서 작은 입력에 대해서는 잘 동작하지만,\n 실제로는 타임아웃이 난다.\n\n코드는 다음과 같다.\n\ndef remove_duplicate(nums) -&gt; int:\n    length = len(nums)\n    starti = 0\n\n    while starti &lt; length:\n        endi = starti + 1\n        while endi &lt; length:\n            if nums[starti] == nums[endi]:\n                # shift left\n                shifti = endi + 1\n                while shifti &lt; length:\n                    nums[shifti - 1] = nums[shifti]\n                    shifti += 1\n                # decrease length\n                length -= 1\n                # after shifting, there might be a number at nums[endi] same as nums[starti],\n                # so just leave endi as it is.\n            else:\n                # search to next\n                endi += 1\n\n        starti += 1\n    return length\n\n\n\n  왼쪽으로 땡길 때마다 (shift left) 길이가 줄어들어야 하므로\nlength를 계속 업데이트 한다.\n  starti와 endi의 값이 같아서 왼쪽으로 땡기고 나면, 원래 endi\n자리에 endi+1에 있던 값이 오게 되는데, 이 값 또한 starti와 같을\n수 있으므로 이때는 endi를 증가시키지 않는다는 것에 주의하자.\n\n\nO(n)\n타임아웃이 나지 않기 위해서는 전체 배열을 한번만 훑는 방법이 필요하다.\n\n중복을 찾았을 때 왼쪽으로 땡기는 작업은 무조건 O(n)이 소요되기\n 때문에 너무 비싸다. 이 작업을 O(1)로 줄여야 배열을 한번만 훑을 수\n 있게 된다. 그러면 생각을 뒤집어서, 중복을 찾았을 때 아무것도\n 안하려면 어떻게 해야할까? 즉, 중복이 아닌 값을 찾았을 때 뭔가를\n 해보면 좋을 것 같다. 다음 상황을 생각해보자.\n\n[1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 4]\n\n\n두 개의 포인터 starti와 endi를 이용해서 중복을\n 검사해보자. 처음에는 starti = 0, endi= 1 에서 시작한다. 앞서\n 말했듯 한번만 훑기 위해서 두 인덱스에 있는 값이 같은 경우 그냥\n 스킵하자. 그러면 처음으로 달라지는 값이 나오는 부분은 endi = 5일 때\n 1 != 2를 만나게 된다.\n\n[1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 4]\n |              |\nstarti          |\n              endi\n\n\n이 상황에서 우리가 원하는 중복없는 배열을 앞에서 부터 만들어가려면\n 어떻게 하면 될까? 잘 생각해보면 starti는 우리가 원하는 중복없는\n 값이 딱 하나 있는 위치이고, starti + 1의 위치는 그 다음 중복없는\n 값이 와야 하는 위치이다. 따라서, starti + 1 위치에, 처음으로\n 달라진 endi 위치의 값을 넣으면 다음과 같은 상황이 된다.\n\n[1, 2, 1, 1, 1, 2, 2, 2, 2, 3, 4]\n    |           |\n starti+1       |\n              endi\n\n\n이제 배열의 앞은 우리가 원하는 배열의 일부분이 되었다. 즉, 각 값이\n 정확하게 한번만 나오는 배열의 일부인 [1, 2]가 완성되었다. 그\n 다음은? 일단 starti 위치의 값과 중복되는 값은 다 스킵했으니\n starti는 다음 값으로 넘어가기만 하면 된다. 그리고 endi는 다시\n 중복값을 찾아 떠나면 된다.\n\n이렇게 endi를 배열의 끝까지 한번만 훑고나면 다음 모양이 된다.\n\n[1, 2, 3, 4, 1, 2, 2, 2, 2, 3, 4]\n          |                        |\n        starti                     |\n                              endi (out-of-index)\n\n\n따라서, 최종 배열의 길이는 starti + 1 과 같다!\n\n이를 코드로 짜면 다음과 같다.\n\ndef remove_duplicate(nums) -&gt; int:\n    if not nums: return 0\n\n    starti, endi = 0, 1\n    while endi &lt; len(nums):\n        if nums[starti] != nums[endi]:\n            starti += 1\n            nums[starti] = nums[endi]  # or, swapping is ok too\n            # [1, 1, 1, 2] (starti=0, endi=3) -&gt; starti=1 -&gt; [1, 2, 1, 2]\n        endi += 1\n    return starti + 1\n\n\n\n  starti=0, endi=1을 초기값으로 하기 때문에 베이스 케이스인 “빈\n배열”의 경우를 미리 처리해주는 것에 주의하자."
					}
					,
					"ps-theory-remove-nth-from-end": {
						"id": "ps-theory-remove-nth-from-end",
						"title": "Remove n-th Node from End of a List",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/remove-nth-from-end/",
						"content": "Remove n-th from end\n\nPioneer가 n 만큼 먼저 땅을 밝히고, 이후에 Follower와 Pioneer가\n 발맞추어 리스트의 끝까지 도달하면 된다. 이때 Pioneer를 한 칸 덜\n 보내야 Follower가 삭제할 노드 바로 직전에 위치하도록 만들 수 있다.\n\ndef remove_nth_from_end(head, n):\n    pioneer = head\n    follower = head\n\n    while n &gt; 0:\n        n -= 1\n        pioneer = pioneer.next\n\n    if pioneer is None:\n        # remove head\n        return head.next\n\n    while pioneer.next:\n        pioneer = pioneer.next\n        follower = follower.next\n\n    # now, follower is right before the node that needs be deleted\n    follower.next = follower.next.next\n\n    return head"
					}
					,
					"ps-leetcode-remove-nth-node-from-end-of-list": {
						"id": "ps-leetcode-remove-nth-node-from-end-of-list",
						"title": "Remove Nth Node from End of List",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/remove-nth-node-from-end-of-list/",
						"content": "Remove Nth Node from End of List\n\n링크드 리스트의 헤드 노드가 주어졌을 때, 끝에서 n 번째 뒤에 있는\n 노드를 삭제하자.\n\n예를 들어 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5 가 주어졌을 때, 끝에서 2번째 노드는\n 4 이므로 이를 삭제하면 1 -&gt; 2 -&gt; 3 ---&gt; 5가 된다.\n\n노드의 개수는 1~30이고, 끝에서 n번째의 n 값은 노드의 개수보다 작거나\n 같음이 보장된다.\n\nO(N) - Two Pass\n\n가장 쉬운 방법은 일단 리스트를 전체 다 훑어서 노드의 개수를 모두 센\n 다음, 여기서 n을 뺀 만큼만 한번 더 가는 것이다. 즉, 끝에서 n번째라는\n 말은 앞에서 len(list) - n 번째와 같다는 성질을 이용한다.\n\n여기서도 센티넬 노드를 활용하면 코드가 깔끔해진다. 어떤 경우냐면,\n 리스트 크기가 1일때 1번째 노드를 지우는 경우를 생각해볼 수\n 있다. 센티넬이 없으면, 삭제가 일어난 후에 리스트가 비었는지를 스페셜\n 케이스로 따로 처리해줘야 한다. 하지만 센티넬이 있으면, 알고리즘을\n 통해 sentinel.next에 올바르게 None이 들어가기 때문에 깔끔해진다.\n\n\"\"\"\nclass ListNode:\n    def __init__(self, val=0, next=None):\n        self.val = val\n        self.next = next\n\"\"\"\ndef removeNthFromEnd(head, n):\n    node, size = head, 0\n    while node:\n        node, size = node.next, size + 1\n\n    sentinel = ListNode(next=head)\n    node = sentinel\n    togo = size-n\n    while togo &gt; 0:\n        node, togo = node.next, togo - 1\n\n    node.next = node.next.next\n    return sentinel.next\n\n\n\n  리스트 사이즈를 계산한 뒤, 앞에서 부터 얼만큼 가야하는지를 togo에\n계산해서 한번 더 간다.\n  센티넬 노드는 루트 노드의 이전에 있는 가상의 노드인데, 마침\n여기서는 어떤 노드를 삭제하기 위한 이전 노드를 가리키는데 쓰기에\n최적이다. 즉, 어떤 노드를 삭제한다는 것은 그 이전 노드가 해당\n노드의 다음 노드를 가리키도록 하면 되므로, 우리는 삭제할 노드\n이전 노드를 찾으면 되는데, 센티넬을 통해서 이를 쉽게 구할 수\n있다.\n  n의 값이 항상 리스트 크기보다 작거나 같음이 보장되기 때문에, 두\n번째 반복문을 통해 삭제할 노드 이전 노드를 찾았다면, 해당 노드는\n항상 node.next가 있음이 보장된다.\n  센티넬 노드 덕분에 최종적으로 sentinel.next를 리턴하기만 하면,\n노드 삭제 후 리스트가 빈 경우도 잘 처리할 수 있다.\n\n\nO(N) - One Pass\n\n첫 번째 방법은 리스트의 크기를 계산하기 위해서 노드 전체를 한번, 그\n 후 실제 노드 삭제를 위해 한번, 리스트를 총 두 번 훑어야\n 한다. 리스트를 한번만 훑을 순 없을까?\n\n여기서 센티넬과는 다른 종류의 새로운 팁, 이른바 개척자 노드를\n 도입할 수 있다. 개척자 노드는 항상 탐색할 노드보다 일정 부분 앞서\n 나가도록 하는 노드이다. 여기서는 개척자 노드가 항상 n 만큼 앞서있다고\n 하자. 그러면, 개척자 노드가 리스트의 끝에 도달했을 시점에, 탐색\n 노드는 개척자 노드보다 n 만큼 뒤에 있게 되고, 이게 바로 우리가 원하는\n 삭제 지점이 된다. 즉, 개척자 노드를 통해 리스트를 한번만 훑게 된다.\n\n이 아이디어를 도입해서 센티넬과 개척자 노드를 모두 활용하여 한번만\n 훑는 구현은 다음과 같다.\n\ndef removeNthFromEnd(head, n):\n    sentinel = ListNode(next=head)\n    pioneer = sentinel\n    while n &gt; 0:\n        pioneer, n = pioneer.next, n - 1\n    node = sentinel\n    while pioneer.next\n        node, pioneer = node.next, pioneer.next\n    node.next = node.next.next\n    return sentinel.next\n\n\n\n  개척자 노드를 끝까지 보낼 때, 리스트의 완전 끝(None)까지 보내버리면\n탐색 노드가 삭제할 노드에 위치해버리므로 우리가 원하는 것이\n아니다. 대신, 리스트의 마지막 노드까지만 탐색하게 하면, 탐색 노드가\n삭제할 노드 바로 직전에 위치할 수 있고, 덕분에 node.next가 항상\n유효한 값을 갖고 있다."
					}
					,
					"ps-leetcode-reorder-list": {
						"id": "ps-leetcode-reorder-list",
						"title": "Reorder List",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/reorder-list/",
						"content": "Reorder List\n\n링크드 리스트가 주어졌을 때, 다음과 같이 표현할 수 있다.\n\nNode(0) -&gt; Node(1) -&gt; ... -&gt; Node(n-1) -&gt; Node(n)\n\n\n이걸 다음과 같은 형식으로 재정렬하자. 이때, 값을 바꾸면 안되고,\n 노드의 포인터만 바꿔야 한다. 리스트를 새로 만들어서도 안되고, 원래의\n 리스트를 제자리에서(in-place) 수정해야 한다.\n\nNode(0) -&gt; Node(n) -&gt; Node(1) -&gt; Node(n-1) -&gt; Node(2) -&gt; Node(n-2) -&gt; ...\n\n\n리스트를 요리조리\n\n문제를 잘 읽어야 한다. 처음에는 짝수/홀수 번째 리스트 노드를\n 교차하는 건줄 알았는데 그게 아니었다. 잘 보면 논리적으로 다음\n 스텝을 밟는다는 것을 알 수 있다:\n\n  리스트의 중간 지점을 찾는다.\n  중간부터 끝까지를 뒤집는다.\n  처음~중간까지의 리스트와 중간~끝까지 뒤집힌 리스트를 합친다.\n\n\n각각이 이미 이전에 나온 문제들이다. 따라서 이전 방법들을 조합해서 풀\n 수 있다.\n\ndef reorderList(head):\n    # find middle\n    slow, fast = head, head\n    while fast and fast.next:\n        slow, fast = slow.next, fast.next.next\n\n    # reverse from middle to end\n    stack = []\n    node = slow\n    while node:\n        stack.append(node)\n        node = node.next\n    sentinel = ListNode()\n    node = sentinel\n    while stack:\n        node.next = stack.pop()\n        node = node.next\n    reversed_list = sentinel.next\n\n    # should unlink in the middle!\n    slow.next = None\n\n    # merge them\n    n1, n2 = head, reversed_list\n    n = ListNode()\n    flag = True\n    while n1 and n2:\n        if flag:\n            n.next = n1\n            n1 = n1.next\n        else:\n            n.next = n2\n            n2 = n2.next\n        n = n.next\n        flag = flag ^ True\n\n\n\n  새로운 루트 노드를 찾는게 아니더라도 중간을 찾는거 빼고\n나머지에서는 센티넬 노드를 활용하는게 좋다.\n  주의할 점은, 중간을 찾아서 중간부터 끝까지 리스트를 뒤집고 나면\n반드시 중간 부분에서 리스트를 끊어줘야 한다는 것이다. 안그러면\n리스트에 싸이클이 생겨서 두 리스트를 병합할 때 무한 루프에 빠진다.\n  정방향 리스트와 역방향 리스트 모두 마지막 노드는 중간 노드가\n된다. 즉, 아래 그림과 같다. 따라서, 두 리스트를 합칠 때 둘 다\n남아있을 동안만 합치면 된다. 어차피 마지막은 둘다 중간 노드이기\n때문이다.\n\n\n(홀수)\n1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5\nn1: 1 -&gt; 2 -&gt; 3\nn2: 5 -&gt; 4 -&gt; 3\n\n(짝수)\n1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5 -&gt; 6\nn1: 1 -&gt; 2 -&gt; 3 -&gt; 4\nn2: 6 -&gt; 5 -&gt; 4\n\n\n\n  두 노드를 합칠 때 여기서는 특별히 값의 비교가 필요하지 않다. 대신\n어떤 노드를 합칠 것인지를 정해야하는데, 여기서는 단순한 플래그를\n둬서 참일 때에는 정방향을 합치고 거짓일 때에는 역방향을 합치도록\n했다. 플래그는 XOR의 성질을 이용해서 참과 XOR 해줘서 매번\n뒤집도록(flip) 했다."
					}
					,
					"ps-leetcode-reorder-routes-to-make-all-paths-lead-to-the-city-zero": {
						"id": "ps-leetcode-reorder-routes-to-make-all-paths-lead-to-the-city-zero",
						"title": "Reorder Routes To Make All Paths Lead To The City Zero",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/reorder-routes-to-make-all-paths-lead-to-the-city-zero/",
						"content": "Reorder Routes To Make All Paths Lead To The City Zero\n풀이가 되게 신박했다.\n그래프 탐색을 어떻게 잘 하면 되지 않을까 생각했는데, 방법은 이랬다. 일단 방향\n  그래프이므로 원본 그래프의 엣지 방향으로는 1의 가중치를 갖도록 한다. 그러고\n  동시에 그 반대 방향의 엣지에 0의 가중치 를 가지도록 한다. 그 후에 0부터 모든\n  그래프의 노드를 다 탐색하게 되면, 0에서부터 뻗어 나가는 엣지들에는 1의 가중치가,\n  0으로 들어오는 엣지들에는 0의 가중치가 매달려 있으므로, 이들을 모두 합한 값이 곧\n  리오더가 필요한 루트의 합의 최소 값이 된다. 대체 이런 생각은 어떻게 하는지 &#8230;\ndef minReorder(n: int, connections: List[List[int]]) -&gt; int:\n    graph = defaultdict(set)\n    for src, snk in connections:\n        graph[src].add((snk, 1))\n        graph[snk].add((src, 0))\n\n    count = 0\n    def dfs(node, prev):\n        nonlocal count\n        for neighbor, weight in graph[node]:\n            if neighbor == prev:\n                continue\n            count += weight\n            dfs(neighbor, node)\n    dfs(0, None)\n    return count"
					}
					,
					"ps-leetcode-reverse-linked-list": {
						"id": "ps-leetcode-reverse-linked-list",
						"title": "Reverse Linked List",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/reverse-linked-list/",
						"content": "Reverse Linked List\n\n싱글 링크드 리스트의 루트 노드 head가 입력으로 들어왔을 때, 이\n 리스트를 뒤집고 뒤집은 리스트의 루트 노드를 리턴하는 함수를 만들자.\n\nO(N) - 1\n\n루트 노드부터 끝까지 리스트를 순서대로 생각한다면, 리스트를 뒤집는\n 연산은 제일 처음 것이 제일 마지막으로 가는 것이다. 즉 처음 들어온\n 것이 가장 나중에 나간다. 이는 곧 FILO(First-In, Last-Out) 구조이므로\n 스택을 쓰면 자연스럽다.\n\n루트 노드부터 순서대로 끝까지 리스트를 스택에 푸시한다. 그 후\n 스택에서 하나씩 팝 하면서 노드를 거꾸로 연결해주기만 하면 된다. 이때,\n 빈 리스트가 들어오는 경우를 우아하게 처리하기 위해서 센티넬 노드를\n 사용하면 좋다.\n\n# class ListNode:\n#     def __init__(self, val=0, next=None):\n#        self.val = val\n#        self.next = next\ndef reverseList(head):\n    stack = []\n    while head:\n        stack.append(head)\n        head = head.next\n\n    sentinel = ListNode()\n    node = sentinel\n    while stack:\n        top = stack.pop()\n        node.next = top\n        node = node.next\n    node.next = None\n    return sentinel.next\n\n\n\n  센티넬로 바로 리스트를 순회하면 센티넬을 잃어버리기 때문에 node\n변수를 따로 만들어서 업데이트 했다.\n  while stack 반복문을 다 돌고 나면 node는 뒤집어진 리스트의 제일\n마지막 노드를 가리키게 된다. 따라서 마지막 노드가 될 수 있도록\nnode.next = None으로 업데이트 해줘야 한다.\n  최종적으로 뒤집어진 리스트의 루트 노드는 sentinel.next가\n된다. 센티넬 노드를 사용한 덕분에 입력에서 굳이 head is None 인\n경우를 처리해주지 않아도 된다.\n\n\nO(N) - 2\n\n스택을 사용한 반복문 코드는 재귀함수로도 작성할 수 있다.\n\n앞에서 센티넬 노드를 도입했던 이유는 입력으로 빈 리스트(head is\n None)이 들어올 수 있어서였다. 재귀함수로 이걸 작성하려면 prev와\n cur 두 개의 노드를 유지하면서 서로 바꿔치기 하면 된다.\n\ndef reverseList(head):\n    def reverse(prev, cur):\n        if cur is None:\n            return prev\n        _next = cur.next\n        cur.next = prev\n        return reverse(cur, _next)\n    return reverse(None, head)\n\n\n\n  재귀함수 reverse는 prev -&gt; cur 인 링크드 리스트 노드 순서를\ncur -&gt; prev로 재연결 해주는 함수다. 이때, 만약 cur가\nNone이라면 이는 곧 (1) 리스트의 끝에 도달했거나 (2) 빈 리스트가\n입력으로 들어왔거나 두 가지 경우 중 하나인데, 바로 직전 노드인\nprev가 새로운 루트 노드가 되면 된다.\n  위의 (2) 케이스에서 prev가 적절한 값을 리턴하기 위해서, reverse\n함수를 처음 호출할 때에는 prev를 None으로 준다.\n\n\nReverse Linked List II\n\n싱글 링크드 리스트의 루트 노드 head와 두 개의 정수 left,\n right가 주어지고 left &lt;= right를 항상 만족한다. 이때, left\n 위치부터 right 위치까지를 뒤집자.\n\n리스트 노드의 개수는 1~500 이고 노드의 값은 -500~500이다.\n\n예를 들어 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5가 있고 left = 2, right = 4일\n 때, 두 번째 노드부터 네 번째 노드까지를 뒤집은 결과 리스트는 1 -&gt; 4\n -&gt; 3 -&gt; 2 -&gt; 5가 된다.\n\n스택을 이용하기\n\n두 노드 prev -&gt; cur가 있다고 하자. 그러면 이 두 노드를 뒤집는 것은\n cur.next = prev면 된다. left부터 right 구간 까지를 다 뒤집어야\n 하므로, prev의 이전 노드를 또 찾아서 prev.next = prevprev와 같이\n 뒤집어 줘야 한다. 이렇게 쭉 따라가다보면 결국 원하는 구간 내의 모든\n 노드를 뒤집을 수 있다. 여기까지만 하면, 구간은 뒤집어졌지만 싸이클이\n 발생한다. 바로 prev &lt;-&gt; cur와 같은 상황이 생기는 것이다. 따라서,\n 구간 내의 노드를 다 뒤집고 나면, 두 가지를 해줘야 한다: 구간의 시작\n 위치(left)의 노드는 구간이 끝난 위치 다음 노드를 가리키도록\n 해야하고, 구간의 끝 위치(right)의 노드는 구간이 시작하기 직전\n 노드가 가리키도록 해야한다. 이를 그림으로 나타내면 다음과 같다.\n\noriginal:  .. prev.. -&gt; left -&gt; ... -&gt; right -&gt; ..remainings..\nreversed:  .. prev.. -&gt; right -&gt; ... -&gt; left -&gt; ..remainings..\n\n\n뒤집기 연산을 가장 쉽게 할 수 있는 데이터 타입은 바로\n 스택이다. 따라서, 여기서는 다음과 같은 단계를 따른다.\n\n  left, right 구간에 속한 노드를 차례로 스택에 넣는다. 이때,\n구간에 진입하기 직전 노드(prev)와, 구간이 끝난 바로 다음\n노드(remaining)도 유지한다.\n  스택에 있는 노드를 하나 씩 뒤집는다.\n  prev 노드와 remaining 노드를 구간에 알맞게 이어준다.\n\n\ndef reverseBetween(head, left, right):\n    if left == right:\n        return head\n    node, prev = head, ListNode(next=head)\n    i = 1\n    stack = []\n    while node:\n        if i == left:\n            while i &lt;= right:\n                stack.append(node)\n                node = node.next\n                i += 1\n            break\n        i += 1\n        prev, node = node, node.next\n\n    # prev -&gt; stack[:] -&gt; node\n    prev.next = stack[-1]\n    while stack:\n        top = stack.pop()\n        top.next = stack[-1] if stack else node\n    return prev.next if left == 1 else head\n\n\n\n  주의해야 할 코너케이스는 바로 left = 1인 경우이다. 이때는 prev\n노드가 head의 바로 직전을 가리키는 센티넬 노드인 채로 루프가\n끝나기 때문에, 스택의 꼭대기가 새로운 루트 노드가 되어야\n한다. 따라서 이때는 head가 prev.next와 같다."
					}
					,
					"ps-leetcode-rle-iterator": {
						"id": "ps-leetcode-rle-iterator",
						"title": "RLE Iterator",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/rle-iterator/",
						"content": "RLE Iterator\n\n정수 배열을 인코딩하는 방법 중 하나로 RLE(Run Length Encoding)이라는\n 것이 있다. RLE 인코딩 배열 encoding은 항상 짝수 길이의 배열이며\n 모든 짝수 i에 대해서 encoding[i]는 0보다 큰 정수\n encoding[i+1]이 몇 번 나타나는지를 알려준다.\n\n예를 들어서 [8,8,8,5,5] 배열의 유효한 RLE는 [3,8,2,5],\n [3,8,0,9,2,5], 또는 [2,8,1,8,2,5]등이 될 수 있다.\n\n어떤 RLE 인코딩 배열이 주어졌을 때, 디코딩된 원래 배열 위를 탐색하는\n 이터레이터를 구현하자.\n\n  RLEIterator(int[] encoded): 생성자\n  int next(int n): n개의 원래 원소를 소모하고 마지막에 소모된\n원소를 리턴한다. 소모할 원소가 더 이상 없는 경우 -1을 리턴한다.\n\n\n인코딩 배열은 항상 짝수 길이이며 2 ~ 1,000 사이의 길이이다. 각각의\n 인코딩 값은 \\(0 \\sim 10^9\\) 사이이다. 최대 1,000번의 next가\n 호출된다.\n\n복구하기 - 메모리 아웃\n\n아주 간단한 아이디어로는 인코딩 배열을 직접 복원하는 방법이\n 있다. 근데 이러면 당연하겠지만 엄청나게 큰 배열을 인코딩한 경우는\n 메모리가 터진다.\n\nclass RLEIterator:\n    def __init__(self, encoding):\n        self.restored = []\n        i = 0\n        while i &lt; len(encoding):\n            cnt, num = encoding[i], encoding[i + 1]\n            self.restored += [num] * cnt\n            i += 2\n        self.cursor = 0\n\n    def next(self, n):\n        self.cursor += n\n        if self.cursor &gt;= len(self.restored):\n            return -1\n        return self.restored[self.cursor - 1]\n\n\n인코딩한 채로 쿼리하기\n\n사실 인코딩을 굳이 풀 필요가 없다. 어차피 복잡한 인코딩도 아니고,\n 그냥 개수를 유지하고 있기 때문에, 쿼리로 들어온 정수 n을 이용해서\n 적절히 이 개수들을 소비하면 된다. 동형암호가 생각난다.\n\nclass RLEIterator:\n    def __init__(self, encoding):\n        self.encoding = encoding\n        self.cursor = 0\n\n    def next(self, n):\n        while self.cursor &lt; len(self.encoding) and self.encoding[self.cursor] &lt; n:\n            n -= self.encoding[self.cursor]\n            self.cursor += 2\n\n        if self.cursor &gt;= len(self.encoding):\n            return -1\n\n        self.encoding[self.cursor] -= n\n        return self.encoding[self.cursor + 1]\n\n\n방법은 간단하다.\n\n  일단 n보다 지금 위치의 개수가 적으면 n에서 그 개수만큼 계속\n소모하면서 커서를 이동한다.\n  위의 반복문을 빠져나온 위치가 최종 소모 위치이다. 범위를\n벗어났는지 먼저 체크한다.\n  범위 안이라면, 지금 개수를 적절히 소모해주고, 지금 위치의\n원소를 리턴한다."
					}
					,
					"ps-leetcode-roman-to-integer": {
						"id": "ps-leetcode-roman-to-integer",
						"title": "Roman to Integer",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/roman-to-integer/",
						"content": "Roman to Integer\n\n로마 숫자는 다음 일곱 개의 심볼을 가지고 표현한다:\n\n\n  \n    \n      Symbol\n      Value\n    \n  \n  \n    \n      I\n      1\n    \n    \n      V\n      5\n    \n    \n      X\n      10\n    \n    \n      L\n      50\n    \n    \n      C\n      100\n    \n    \n      D\n      500\n    \n    \n      M\n      1000\n    \n  \n\n\n예를 들어 II는 2다. 보통 왼쪽에서 오른쪽으로 큰 순서대로\n 표현된다. 하지만 아닌 경우도 있는데, 예를 들어 4의 경우 IIII가\n 아니라 IV로 표시하고 “5에서 1을 뺀 값”으로 해석한다. 이렇게 뺀\n 값으로 표시하는 것은 여섯 가지의 경우가 있다.\n\n\n  I는 V앞에 와서 4(5-1), X앞에 와서 9(10-1)\n  X는 L앞에 와서 40(50-10), C앞에 와서 90(100-10)\n  C는 D앞에 와서 400(500-100), M앞에 와서 900(1000-100)\n\n\n로마 숫자 표기가 주어졌을 때 정수로 바꾸는 함수를 구현하자.\n\n표기 길이는 1 ~ 15 사이이고 유효한 로마 숫자 심볼만 포함한다. 입력\n 표기는 1 ~ 3999 사이의 유효한 정수를 표현한 로마 숫자 표기임이\n 보장된다.\n\n접근\n\n\n  해시 테이블: 기본 심볼에서 정수로 가는 해시 테이블은 반드시 필요하다.\n  빼는 경우 처리: 주어진 6가지 경우를 일일이 처리해도 무방하다. 좀더\n일반적인 케이스를 생각해보면, 어떤 인덱스 i에서의 값과 그 다음\n인덱스 i+1의 값이 감소하는 경우에 빼는 케이스가 된다. 이 사실을\n이용하면 6가지 케이스를 다 구현하지 않아도 된다.\n\n\ndef romanToInt(s):\n    mapping = {\n        'I': 1, 'V': 5, 'X': 10, 'L': 50, 'C': 100, 'D': 500, 'M': 1000\n    }\n    res = 0\n    i = 0\n    while i &lt; len(s):\n        if (i+1) &lt; len(s) and mapping[s[i]] &lt; mapping[s[i+1]]:\n            # subtract case\n            res += (mapping[s[i+1]] - mapping[s[i]])\n            i += 2\n        else:\n            res += mapping[s[i]]\n            i += 1\n\n    return res"
					}
					,
					"ps-leetcode-rotate-image": {
						"id": "ps-leetcode-rotate-image",
						"title": "Rotate Image",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/rotate-image/",
						"content": "Rotate Image\n\nn x n 2D 매트릭스를 시계 방향으로 90도 회전할껀데,\n 제자리에서(in-place) 회전해야 한다.\n\n# input\n[[1, 2, 3],\n [4, 5, 6],\n [7, 8, 9]]\n\n# output\n[[7, 4, 1],\n [8, 5, 2],\n [9, 6, 3]]\n\n\nO(N) Space의 경우\n제자리에서 라는 제약이 없는 경우에는 어떻게 할 수 있을까? 다음 한\n 줄로 가능하다:\n\nmatrix = list(zip(*matrix[::-1]))\n\n\n\n  matrix[::-1]: 원래 2차원 배열의 순서를 뒤집는다. 즉, [[1,2,3],\n[4,5,6], [7,8,9]] 가 [[7,8,9], [4,5,6], [1,2,3]]이 된다.\n  *: 리스트를 풀어서 다른 함수에 넘길 수 있게 한다. 즉 [7,8,9],\n[4,5,6], [1,2,3] 이렇게 풀려버린다.\n  zip(): 여러개의 리스트를 같은 인덱스에 있는 것끼리 묶어준다. 즉\n(7, 4, 1), (8, 5, 2), (9, 6, 3)으로 묶이게 되고 이게 곧 90도\n회전한 결과와 같다.\n\n\nO(1) Space의 경우\n\n  O(N) 연산을 쪼개서 차근차근하면 된다.\n  matrix[::-1]는 행렬의 행(Row)을 뒤집는 연산이다. 따라서 다음과\n같이 하면 된다.\n\n\ndef reverse(matrix):\n  n = len(matrix)\n  for i in range(n // 2):\n    matrix[i], matrix[n-1-i] = matrix[n-1-i], matrix[i]\n\n\n\n  \n    중요한 건 절반만 Iterate 해야 한다는 것이다. 끝까지 다\n바꿔버리면 원래 행렬이랑 똑같다.\n  \n  zip(*) 연산은 전치 행렬(Transpose)을 구하는 연산이다.\n  대각선을 기준으로 바꾼다. (i, i) 위치가 대각선임을 기억하자.\n  그러면 i번째 Row에서는 i부터 Column을 살펴보면 된다.\n  그 외엔 단순히 (x, y)를 (y, x)로 스왑하는 연산이다.\n\n\ndef transpose(matrix):\n  n = len(matrix)\n  for i in range(n):\n    for j in range(i, n):\n      matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n\n\n\n  이 두 가지를 조합한 O(1) 공간 복잡도의 회전 연산은 다음과\n같다. 순서에 주의하자.\n\n\ndef rotate(matrix):\n  reverse(matrix)\n  transpose(matrix)"
					}
					,
					"ps-leetcode-rotting-oranges": {
						"id": "ps-leetcode-rotting-oranges",
						"title": "Rotting Oranges",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/rotting-oranges/",
						"content": "Rotting Oranges\nm x n 격자가 주어지는데 각 쎌은 세 종류의 값을 갖는다.\n\n  0: 비어 있는 쎌\n  1: 신선한 오렌지\n  2: 썩은 오렌지\n\n\n매 1분마다, 신선한 오렌지 중에서 4방향 중 한 곳이라도 썩은 오렌지랑\n 맞닿아 있는 애는 썩는다.\n\n격자의 모든 오렌지가 썩기 위해서 지나야 하는 최소 시간을\n 구하자. 불가능하면 -1을 리턴하자.\n\n예를 들면 아래와 같은 경우, 총 4분이 필요하다.\n\n2 1 1      2 2 1      2 2 2      2 2 2     2 2 2\n1 1 0  --&gt; 2 1 0  --&gt; 2 2 0  --&gt; 2 2 0 --&gt; 2 2 0 --&gt; ....\n0 1 1      0 1 1      0 1 1      0 2 1     0 2 2\n\n\nBFS With Barrier\n4방향 중 한 곳이라도 에서 BFS의 냄새가 난다. 다만, 한 번(1분)에 한\n 스텝 씩 상태가 진행되어야 한다는 점이 새로운데, 시간 사이에 배리어\n 데이터를 넣어서 구분하면 될 것 같다.\n\n일단 시작점은 썩은 오렌지이므로, 무조건 한번은 격자 전체를 다 훑어서\n 썩은 위치를 찾아내야 한다. 그리고 이 썩은 오렌지의 위치들을 큐에\n 넣어둔다. 동시에 썩혀야 할 신선한 오렌지의 전체 개수도 미리\n 계산해둔다. 격자의 모든 오렌지가 썩었다는 것은 곧 격자에 있던 신선한\n 오렌지가 하나도 없게 되는 것과 동치이기 때문이, 시간이 지나면서\n 신선한 오렌지가 썩을 때마다 신선한 오렌지 개수를 깎으면 될 것 같다.\n\n그리고 BFS를 할 껀데, 이때 큐에서 꺼낸 데이터가 배리어면, 그때마다\n 지나간 시간을 누적하면 된다. 위의 4분 예시에서는 다음과 같이 흘러갈\n 것이다.\n\nt   queue\n-----------\n0: [(0, 0), barrier]  # 시작 상태\n0: [barrier, (0, 1), (1, 0)]  # 첫 큐를 꺼내고 난 상태\n1: [(0, 1), (1, 0), barrier]  # 배리어 덕분에 시간이 흘러간 것을 알게됨\n1: [barrier, (1, 1), (0, 2)]\n2: [(1, 1), (0, 2), barrier]\n2: [barrier, (2, 0)]\n3: [(2, 0), barrier]\n3: [barrier, (2, 2)]\n4: [(2, 2), barrier]\n4: [barrier]\n4: []  # DONE\n\n\n더 이상 썩힐 신선한 오렌지가 없으면, 큐에는 배리어 하나만 남게\n 된다. 즉, 큐에서 꺼낸게 배리어인데 여전히 큐에 데이터가 남아있는\n 경우에만 시간을 진행시킬 수 있다.\n\n이 아이디어를 구현하면 다음과 같다.\n\nfrom collections import deque\ndef orange_rotting(grid):\n    q = deque()\n    fresh = 0\n    m, n = len(grid), len(grid[0])\n    # initialize rotten oranges queued, and count fresh oranges\n    for x in range(m):\n        for y in range(n):\n            if grid[x][y] == 2:\n                q.append((x, y))\n            elif grid[x][y] == 1:\n                fresh += 1\n\n    barrier = (None, None)  # used to denote elapsed time\n    q.append(barrier)\n\n    elapsed = 0\n    while q:\n        x, y = q.popleft()\n        # check if time has been elapsed\n        if (x, y) == barrier:\n            if q:\n                # if there are still some rotten oranges,\n                # it can be proceeded.\n                elapsed += 1\n                q.append(barrier)\n            continue\n\n        # proceed to next state\n        for nx, ny in ((x+1, y), (x-1, y), (x, y+1), (x, y-1)):\n            if 0 &lt;= nx &lt; m and 0 &lt;= ny &lt; n:\n                if grid[nx][ny] == 1:\n                    # rotting\n                    grid[nx][ny] = 2\n                    fresh -= 1\n                    q.append((nx, ny))\n\n    return elapsed if fresh == 0 else -1\n\n\n\n  배리어로 (None, None)을 활용했다. 큐에는 좌표값만 쌓이기 때문에\n그냥 None 하나보다는 튜플로 곧바로 받으면 편하다.\n  앞서 설명한 것처럼 BFS 진입후 꺼낸 데이터가 배리어이고, 꺼냈는데도\n큐에 여전히 데이터가 남아있을 때에만 시간이 진행된다. 그리고 동시에\n배리어를 큐에 넣어줘서, 그 다음 시간을 위한 선을 긋는다.\n  최종적으로 남아있는 신선한 오렌지 개수가 0일 때에만 흐른 시간을\n리턴한다."
					}
					,
					"ps-leetcode-same-tree": {
						"id": "ps-leetcode-same-tree",
						"title": "Same Tree",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/same-tree/",
						"content": "Same Tree\n\n주어진 두 개의 바이너리 트리가 서로 같은지 아닌지를 판단하는 함수를\n 만들어보자.\n\n두 바이너리 트리가 같다는 것은 (1) 트리의 구조가 같아야 하며 (2) 같은\n 위치의 노드는 같은 값을 가져야 한다.\n\nO(N)\n\n두 트리의 노드에 대해서 다음 경우를 판단하면 된다.\n\n\n  둘 다 null 이면 같다.\n  둘 중 하나만 null이면 다르다.\n  두 개의 값이 같으면 같다.\n  이후 양 쪽 자식 노드에 대해서 똑같은걸 계속 체크한다.\n\n\n그리고 이 모든 결과값은 and 연산으로 묶여야 한다.\n\ndef isSameTree(p, q):\n    def traverse(nodep, nodeq):\n        if not nodep and not nodeq:\n            return True\n        if not nodep or not nodeq:\n            return False\n        return (nodep.val == nodeq.val) and traverse(nodep.left, nodeq.left) and traverse(nodep.right, nodeq.right)\n\n    return traverse(p, q)"
					}
					,
					"ps-theory-scc": {
						"id": "ps-theory-scc",
						"title": "Strongly Connected Components",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/scc/",
						"content": "Strongly Connected Components\n코사라주 알고리즘 (Kosaraju&#8217;s Algorithm)\n타잔 알고리즘 (Tarjan&#8217;s Algorithm)\n칸의 알고리즘 (Kahn&#8217;s Algorithm) 활용"
					}
					,
					"ps-leetcode-search-in-rotated-sorted-array": {
						"id": "ps-leetcode-search-in-rotated-sorted-array",
						"title": "Search in Rotated Sorted Array",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/search-in-rotated-sorted-array/",
						"content": "Search in Rotated Sorted Array\n\n유니크한 값만 담긴 정렬된 정수 배열이 주어진다. 그런데 이 배열이 어떤\n 피벗 인덱스를 기준으로 회전되어 있을수 있다. 예를 들어, [0, 1, 2,\n 4, 5, 6, 7] 배열이 피벗 인덱스 3에서 회전된다면 [4, 5, 6, 7, 0, 1,\n 2]가 된다.\n\n이렇게 회전된 배열이 들어왔을 때, target 값의 인덱스를 찾자. 만약\n target이 없다면 -1을 리턴하자.\n\n알고리즘의 복잡도는 반드시 \\(O (\\log n)\\) 을 만족해야 한다.\n\n배열의 크기는 1~5,000 사이이고 배열의 값은 모두 유니크함이 보장된다.\n\n이분 탐색의 다양한 쓰임새\n\n이것과 유사한 문제로 회전 정렬된 배열에서 최소값\n 찾기가 있다. 이것과 유사한\n 방법을 사용하면 될 것 같다.\n\n일단 위의 방법으로 회전 정렬된 배열의 최소 값의 위치를 찾았다고\n 해보자. 그러면 다음과 같은 방법이 가능해보인다.\n\n  해당 인덱스가 최소라는 것은 해당 인덱스가 피벗 인덱스라는 뜻이고,\n그러면 이 피벗으로부터 다시 배열을 회전해서 정렬된 원래 배열을\n원복할 수 있다. 단, 이렇게하면 배열을 원복하는데 O(N)의 시간 및\n공간 복잡도를 소모하게 되어서 문제의 조건을 위배하긴 한다.\n  피벗 인덱스를 기준으로 왼쪽과 오른쪽이 각각 오름차순으로 정렬되어\n있다. 따라서, 피벗 왼쪽 범위에다 한번, 오른쪽 범위에다 한번 각각\n이분 탐색을 해서 값을 찾는 방법도 있다.\n  피벗을 기준으로 회전되어 있기 때문에, 모듈러 연산을 활용하면 중앙\n인덱스를 구할 수 있을 것 같기도 하다.\n\n\n그러면 일단 하나씩 해보자. 피벗을 구하는 함수는 다음과 같다.\n\ndef find_pivot(nums):\n    low, high = 0, len(nums)-1\n    while low &lt; high:\n        mid = low + (high - low) // 2\n        if nums[mid] &gt; nums[high]:\n            low = mid + 1\n        else:\n            high = mid\n    return low\n\n\n\n  중앙 원소가 끝 값보다 큰 경우, 중앙과 끝 사이 어딘가에서\n회전되었다고 생각할 수 있다. 즉, nums[low] ... nums[mid] .. pivot\n.. nums[high] 이다. 그러므로 범위 시작 값을 mid+1로 업데이트\n한다.\n  그 반대의 경우는 범위 끝 값을 mid로 땡긴다.\n\n\n\n\n이렇게 피벗은 구할 수 있고, 이제 이걸로 문제를 풀어보자.\n\n회전된 배열 복원하기\n\n피벗 위치를 알면 원래 배열을 어떻게 복원할 수 있을까? 파이썬에서는\n 슬라이스 연산을 지원하기 때문에 아주 수월하게 다음과 같이 할 수 있다.\n\nimport bisect\ndef search(nums, target):\n    pivot = find_pivot(nums)\n    orig = nums[pivot:] + nums[:pivot]\n    bi = bisect.bisect_left(orig, target)\n    if bi &lt; len(nums) and nums[bi] == target:\n        return (bi + pivot) % len(nums)\n    else:\n        return -1\n\n\n\n  피벗을 구한 뒤 원래 배열 orig를 복원해서 여기서 탐색한다. 단,\n탐색 결과의 인덱스는 원본 배열 기준이므로, 이를 다시 회전한\n배열 기준으로 돌려줘야 한다. 따라서, (bi + pivot) % len(nums)를\n계산해야 피벗을 기준으로 회전한 인덱스를 돌려줄 수 있다.\n  정렬된 배열에서 이분 탐색을 할 때에는 직접 바이너리 서치를 구현하기\n보다는 bisect.bisect_left를 활용하는 것이 좋다. 이분 탐색을 버그\n없이 제대로 구현하기가 어렵다는 것은 역사적으로도 증명된\n사실이기\n때문이다. 자세한 내용은 Upper Bound &amp; Lower\nBound에 정리해두었다.\n\n\n이분 탐색 두번하기\n\n위의 방법은 쉽긴 하지만 배열을 복원하는데 쓰이는 O(N) 때문에 복잡도를\n 만족하지 못한다.\n\n피벗 위치를 기준으로 배열을 둘로 쪼갠다면, 쪼개진 두 배열도 각각\n 정렬되어 있기 때문에, 여기다가 바로 이분 탐색을 해보는 것도 좋을 것\n 같다.\n\ndef search(nums, target):\n    pivot = find_pivot(nums)\n    left = bisect.bisect_left(nums, target, 0, pivot)\n    right = bisect.bisect_left(nums, target, pivot, len(nums))\n\n    if left &lt; pivot and nums[left] == target:\n        return left\n    elif pivot &lt;= right &lt; len(nums) and nums[right] == target:\n        return right\n    else:\n        return -1\n\n\n\n  역시 여기서도 bisect.bisect_left를 활용하는 것이 좋다. 추가적인\n입력으로 이분 탐색을 진행할 범위를 입력할 수 있는데, 이때 범위는\n[low, high)의 형태이고 피벗 인덱스는 배열의 최소값이 있는 인덱스\n이므로 위와 같이 호출하면 된다.\n\n\n똑똑하게 이분탐색 한번만 하기\n\n피벗을 구하고 나면 사실 두 번 이분 탐색할 필요 없이 찾을려는 값이\n 있는 위치의 범위를 다음과 같이 하나로 줄일 수 있다.\n\nlow, high = 0, len(nums)\nif nums[pivot] &lt;= target &lt;= nums[high-1]:\n    low = pivot\nelse:\n    high = pivot\n\n\n즉, 구하려는 값의 위치가 피벗과 배열 마지막 원소 사이에 있다면,\n 우리가 원하는 범위는 피벗의 오른쪽이다. 그게 아니라면, 우리가 원하는\n 범위는 피벗의 왼쪽이다.\n\n따라서 이렇게 범위를 좁혀놓고 나면 이분 탐색을 딱 한번만 해줘도\n 된다. 이 아이디어를 구현하면 다음과 같다.\n\ndef search(nums):\n    pivot = find_pivot(nums)\n    low, high = 0, len(nums)\n    if nums[pivot] &lt;= target &lt;= nums[high-1]:\n        low = pivot\n    else:\n        high = pivot\n\n    bi = bisect.bisect_left(nums, target, low, high)\n    if bi &lt; len(nums) and target[bi] == target:\n        return bi\n    else:\n        return -1"
					}
					,
					"ps-leetcode-search-suggestions-system": {
						"id": "ps-leetcode-search-suggestions-system",
						"title": "Search Suggestions System",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/search-suggestions-system/",
						"content": "Search Suggestions System\n\n단어 목록 products와 단어 하나 searchWord가 주어진다.\n\nsearchWord의 각 글자가 타이핑 될 때마다, products에서 최대 3개의\n 제품 목록을 추천하는 시스템을 디자인하자. 추천되는 제품은 타이핑 된\n searchWord의 부분 문자열을 접두사로 가져야 한다. 조건을 만족하는\n 제품이 세 개 이상이라면 사전순으로 3개의 제품만 리턴하자.\n\nsearchWord의 각 글자가 타이핑될 때마다 추천되는 모든 제품 목록의\n 리스트를 리턴하자.\n\nproducts는 최대 1,000개이고 각 제품 단어의 길이는 최대\n 3,000이다. 모든 제품 단어의 길이의 합은 최대 \\(2 \\times 10^4\\)를 넘지\n 않는다. 모든 제품 이름은 알파벳 소문자로만 구성되며 유니크하다. 검색\n 단어 길이는 최대 1,000이며 알파벳 소문자로만 구성된다.\n\n트라이 말고 정렬 + 필터링\n\n접두사라는 문제의 설명 때문에 무지성으로 트라이를 끼얹고 싶은 그런\n 문제이지만, 사실 이와 유사한 문제를 이미 풀어봤다. 바로 검색\n 자동완성 시스템\n 디자인하기이다. 이 문제에서는\n 처음에 트라이로 접근했지만 생각만큼 속도가 나와주지 않아서\n 정렬+필터링의 조합을 적용했었다. 여기서는 곧바로 정렬+필터링 조합을\n 적용해보자.\n\n알고리즘은 이렇다.\n\n  단어 목록에서 검색할 단어의 첫 글자와 같은 단어만 남겨둔다.\n  필터링된 단어 목록을 사전순으로 정렬한다.\n  검색할 단어를 한 글자씩 만들어 가면서 단어 목록을 계속 필터링한다:\n    \n      검색할 단어보다 길이가 긴 단어\n      지금 글자와 같은 글자를 가진 단어\n      필터링 할 때마다 최대 3개를 정답 목록에 추가한다.\n    \n  \n\n\n이게 트라이보다 훨씬 빠르고 간단하게 구현할 수 있다.\n\ndef suggestProducts(products: List[str], searchWord: str) -&gt; List[List[str]]:\n    answer = []\n    matched = [p for p in products if p[0] == searchWord[0]]\n    matched.sort()\n    answer.append(matched[:3])\n\n    i = 1\n    while 1 &lt; len(searchWord):\n        matched = [p for p in matched if len(p) &gt; i and p[i] == searchWord[i]]\n        answer.append(matched[:3])\n        i += 1\n\n    return answer\n\n\n\n  파이썬의 슬라이스 연산자로 최대 3개의 추천 목록을 쉽게 뽑아낼 수\n있다.\n  단어 길이가 항상 1보다 크기 때문에 첫 번째 matched를 필터링할 때\n예외 처리를 하지 않아도 된다.\n  두 번째 글자부터 필터링할 때, searchWord[1:]를 enumerate하면 첫\n번째 글자가 사라진 부분 문자열의 인덱스를 새로 만들기 때문에\n인덱스가 다시 0부터 시작해서 좀 까다로워진다. 그냥 클래식하게\n인덱스를 직접 이용해서 while 루프를 돌리는 게 더 편하다."
					}
					,
					"ps-leetcode-serialize-and-deserialize-binary-tree": {
						"id": "ps-leetcode-serialize-and-deserialize-binary-tree",
						"title": "Serialize and Deserialize Binary Tree",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/serialize-and-deserialize-binary-tree/",
						"content": "# [Serialize and Deserialize Binary Tree](https://leetcode.com/problems/serialize-and-deserialize-binary-tree/)\n\n 바이너리 트리를 어떤 형태로든 시리얼라이즈해서 문자열로 만들고, 이후\n 해당 문자열을 디시리얼라이즈 해서 원본 바이너리 트리를 복원하는\n 문제다.\n\n 실제 시리얼라이제이션과 디시리얼라이제이션은 바이너리로 떨어지는 것이\n 맞지만 여기서는 문제의 편의를 위해서 문자열로 제한된다.\n\n 노드의 개수는 0~10,000 이고 노드 값은 -1,000~1,000이다.\n\n## 재귀\n\n 트리를 재귀적으로 방문하면 루트로부터의 DFS와 동일하고 이는 곧 트리의\n Pre-order 순회와 같다. 이 방문 순서대로 트리를 시리얼라이즈 하면 아래\n 예시와 같다.\n\n![tree](https://assets.leetcode.com/uploads/2020/09/15/serdeser.jpg)\n\n```python\n1 -> 2 -> null -> null -> 3 -> 4 -> null -> null -> 5 -> null -> null\n```\n\n 그러면 이 순서를 다시 원래의 트리 구조로 복원하려면 어떻게 하면 될까?\n 이 역시 시리얼라이즈된 데이터를 하나씩 방문하면서 재귀적으로 트리를\n 구축해가면 된다.\n\n```python\ndef serialize(root):\n    buffer = []\n    def deconstruct(node):\n        nonlocal buffer\n        if node:\n            buffer.append(str(node.val))\n            deconstruct(node.left)\n            deconstruct(node.right)\n        else:\n            buffer.append(\"None\")\n\n    deconstruct(root)\n    return \";\".join(buffer)\n```\n\n - 노드의 값을 차례대로 버퍼에 추가한 다음 구분자로 `;`를 줘서 하나의\n   문자열로 합쳤다. 디시리얼라이즈 하는 부분에서는 이 정보를 바탕으로\n   `;`를 기준으로 데이터를 잘라내면 된다.\n - 노드가 null 일 때에는 어떤 값이든 null 임을 알려줄 수 있는 데이터로\n   시리얼라이즈하면 된다. 여기서는 그냥 `None` 문자열 자체로 주었다.\n\n```python\ndef deserialize(data):\n    raw = iter(data.split(\";\"))\n\n    def construct(value):\n        if value == \"None\":\n            return None\n        node = TreeNode(int(value))\n        node.left = construct(next(raw))\n        node.right = construct(next(raw))\n        return node\n\n    return construct(next(raw))\n```\n\n - 데이터를 `;`를 기준으로 잘라내면 원본 버퍼가 복원된다. 트리의\n   재구축은 이 원본 버퍼를 하나씩 까보면서 진행하게 되는데, 이때\n   파이썬의 `iter()`와 `next()`를 활용하면 좋다.\n - `construct`는 재귀적으로 값으로부터 트리 노드를 복구한다. 아래\n   그림을 보면 좀더 이해가 쉽다. 트리의 노드 옆 괄호 안의 숫자는\n   `construct` 함수가 재귀적으로 방문하는 순서이다.\n\n```python\n1 -> 2 -> null -> null -> 3 -> 4 -> null -> null -> 5 -> null -> null\n\n\n                    1(0)\n                     |\n          +----------+------------+\n        2(1)                    3(4)\n          |                       |\n   +------+-------+         +-----+-----------+\n null(2)       null(3)     4(5)              5(8)\n                            |                 |\n                       +----+----+      +-----+-----+\n                    null(6)   null(7) null(9)    null(10)\n```\n\n - 시리얼라이즈 함수에서 모든 null인 자식 노드들까지 전부 덤핑했기\n   때문에, 디시리얼라이즈 하는 부분에서 `next()` 함수의 호출 횟수가 딱\n   들어맞는다. 즉, `next()`를 호출하는 시점에 `StopInteration` 예외가\n   발생하지 않는다는 것이 보장된다.\n\n## BFS\n\n 트리 문제에서 리트코드 사이트의 입력 포맷을 보면 기묘한 리스트 형태로\n 되어있는 것을 볼 수 있다. 잘 살펴보면 이 형식은 트리를 루트로부터 BFS\n 한 결과와 일치한다(실제로는 trailing null을 다 삭제해도 잘 동작하도록\n 되어있다). 이 형식을 한번 시도해보자.\n\n 트리의 BFS는 결국 [레벨 오더\n 순회](../binary-tree-level-order-traversal)와 같다. 큐를 이용해서\n 구현해보자.\n\n```python\nfrom collections import deque\ndef serialize(root):\n    q = deque()\n    q.append(root)\n    buffer = []\n    while q:\n        node = q.popleft()\n        if node is None:\n            buffer.append(\"nil\")\n        else:\n            buffer.append(str(node.val))\n            q.append(node.left)\n            q.append(node.right)\n    return \",\".join(buffer)\n```\n\n - 여기서는 약간의 변주를 줘서 `None`은 `nil`로, 구분자는 `,`로\n   주었다. 나머지는 트리의 BFS와 동일하다.\n\n```python\ndef deserialize(data):\n    raw = data.split(\",\")\n    if raw[0] == \"nil\":\n        return None\n\n    nodes = iter(None if v == \"nil\" else TreeNode(int(v)) for v in raw)\n\n    root = next(nodes)\n    q = deque()\n    q.append(root)\n    while q:\n        node = q.popleft()\n        left = next(nodes)\n        if left:\n            node.left = left\n            q.append(left)\n        right = next(nodes)\n        if right:\n            node.right = right\n            q.append(right)\n\n    return root\n```\n\n - 여기서는 루트 노드가 `nil`인지를 스페셜 케이스로 처리해주는게\n   편하다. 안그러면 큐를 훑는 코드가 지저분해진다.\n - 이번에도 약간 변주를 줘서 버퍼로부터 아예 트리 노드를\n   만들었다. `nil`일 때는 `None`으로 만들어 두면 자식 노드를 연결할 때\n   아무런 문제가 없다.\n - 여기서도 `iter()`와 `next()`를 활용하고 있고, 시리얼라이즈와 짝을\n   맞추고 있기 때문에 `StopIteration` 예외가 발생하지 않음이 보장된다.\n\n BFS를 이용한 구축은 아래 그림과 같다.\n\n```python\n1 -> 2 -> 3 -> nil -> nil -> 4 -> 5 -> nil -> nil -> nil -> nil\n\n\n                    1(0)\n                     |\n          +----------+------------+\n        2(1)                    3(2)\n          |                       |\n   +------+-------+         +-----+-----------+\n nil(3)       nil(4)      4(5)               5(6)\n                            |                 |\n                       +----+----+      +-----+-----+\n                    nil(7)   nil(8)   nil(9)    nil(10)\n```"
					}
					,
					"ps-leetcode-short-encoding-of-words": {
						"id": "ps-leetcode-short-encoding-of-words",
						"title": "Short Encoding of Words",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/short-encoding-of-words/",
						"content": "# [Short Encoding of Words](https://leetcode.com/problems/short-encoding-of-words/)\n\n 단어 배열 `words`의 **유효한 인코딩**이란, 다음 조건을 만족하는 어떤\n 레퍼런스 문자열 `s`와 인덱스의 배열 `indices`를 뜻한다:\n - `words.length == indices.length`\n - 레퍼런스 문자열 `s`는 `#`로 끝난다.\n - 각각의 인덱스 `indices[i]`에 대해서, `indices[i]`에서 시작해서 `#`\n   직전에 끝나는 `s`의 **부분 문자열**은 `words[i]`와 같다.\n\n 단어 배열 `words`가 주어졌을 때, `words`에서 만들 수 있는 모든 가능한\n 유효한 인코딩 중에서 가장 짧은 레퍼런스 문자열 `s`의 길이를 구하자.\n\n 단어 배열의 길이는 1~2,000 이고, 각 단어의 길이는 1~7이다. 단어는\n 오직 알파벳 소문자로만 구성된다.\n\n 예를 들어, `words = [\"time\", \"me\", \"bell\"]` 이라고 하자. 이로부터\n 만들 수 있는 유효한 인코딩 중 가장 짧은 것은 `s = \"time#bell#\"`과\n `indices = [0, 2, 5]`, 또는 `s = \"bell#time#\"`과 `indices = [5, 7,\n 0]`이다. 둘 모두 `s`의 길이는 10이므로 답은 10이다.\n\n## 트라이 접근\n\n 예시를 보면 `time`의 중간에 `me`가 있기 때문에 `time#** 하나로 이 두\n 개의 단어를 인코딩할 수 있다. 즉, **접미사**를 공유하는 단어끼리는\n 최대한 인코딩하는 것이 바로 해결책이다.\n\n 그러면 접미사를 어떻게 구할 수 있을까? 트라이를 잘 구성하면\n 된다. 일반적으로 *접두사*를 저장하는데 트라이를 사용하는데, 단어\n 목록이 주어졌을 때 단어를 *역방향으로* 트라이를 구성하면 접미사를\n 표현할 수 있다.\n\n 그러면 주어진 단어 목록의 역방향, 즉 접미사의 트라이를 구했다면,\n 이로부터 정답인 \"가장 짧은 인코딩 문자열의 길이\"는 어떻게 구할 수\n 있을까? 먼저 우리가 관심이 있는 것은 단어의 *끝*이 아니라 단어의\n **길이**이므로, 트라이를 구성할 때 아예 단어의 길이를\n 심어두자. 그러고 나면 트라이 전체를 탐색하면서, **모든 리프 노드에\n 매달린 길이**를 합치면 우리가 원하는 답이 된다. 즉,\n\n```python\n     (root of trie)\n     /\n    /\n   e\n   |\n   m --- len: 2 (me)\n   |\n   i\n   |\n   t --- len: 4(time)\n```\n\n 위와 같은 트라이에서, 중간에 있는 길이 2가 아니라, 말단 노드에 있는\n 길이 4를 원하는 것이다. 그리고 모든 말단 노드에 있는 단어가 곧 우리가\n 원하는 인코딩에 쓰일 단어들의 목록이 된다.\n\n 이 아이디어를 구현하면 다음과 같다.\n\n```python\ndef minimumLengthEncoding(words):\n    trie = {}\n    for word in words:\n        node = trie\n        for letter in reversed(word):\n            if letter not in node:\n                node[letter] = {}\n            node = node[letter]\n        node['len'] = len(word)\n\n    def dfs(node):\n        if not node:\n            return 0\n        if 'len' in node and len(node) == 1:\n            return node['len'] + 1\n        acc = 0\n        for letter in node:\n            if letter == 'len':\n                continue\n            acc += dfs(node[letter])\n        return acc\n\n    return dfs(trie)\n```\n\n - 단어를 거꾸로 (`reversed(word)`) 해서 트라이를 만들었고, 마지막\n   리프 노드(즉, 원래 단어의 첫 글자)에는 단어의 길이를 매달아 둔다.\n - DFS로 모든 노드를 탐색하면서 답을 누적한다. 이때, 말단 노드의\n   조건은 노드에 `len` 키 **만** 있는 것이기 때문에, `len`키가 있는지\n   그리고 노드의 키 개수가 1인지를 확인하면 된다. 그러면 원하는 값은\n   `단어의 길이 + 1` 인데, 이 `1` 은 `#`을 위한 길이이다.\n\n\n## 해시 셋\n\n 트라이를 적용하는 문제를 풀다가 느낀 점이, 꼭 트라이가 아니라 적당히\n 정렬 또는 탐색 또는 해시로 풀어도 잘 풀리고 오히려 코드가 더 깔끔할\n 때도 있다는 점이다. 여기서도 트라이가 아니라 다른 접근을 고민해보자.\n\n 일단 단어를 빨리 검색하는 데에는 `O(1)`의 해시 셋이 있다. 해시 셋을\n 이용해서, 예를 들어 `time`과 `me` 이 있다면 이 단어가 서로 접미사를\n 공유하기 때문에 더 긴 단어인 `time`만 있어도 된다는 것을 확인할 수\n 있으면 된다. 즉, `time`으로 만들 수 있는 모든 접미사인 `ime`, `me`,\n `e`를 해시 셋에서 다 빼버리면 우리가 원하는 단어 목록, **같은\n 접미사**를 갖는 단어 중 가장 긴 단어만 남게 될 것이다. 이 문제에서는\n 이렇게 얻을 수 있는 유효한 인코딩의 레퍼런스 문자열의 **최소 길이**만\n 구하면 되기 때문에, 중간에 접미사(예를 들어 `me`)가 버려져도\n 괜찮다. 어차피 최종 길이만 알면 된다.\n\n 따라서 이 아이디어를 구현하면 다음과 같다.\n\n```python\ndef minimumLengthEncoding(words):\n    word_set = set(words)\n    for word in words:\n        for i in range(1, len(word)):\n            suffix = word[1:]\n            word_set.discard(suffix)\n\n    return sum(len(word) + 1 for word in word_set)\n```\n\n - 파이썬의 `set.discard`는 원소가 집합에 없어도 된다는 점만 빼면\n   `set.remove`과 같다. 즉, 없는 원소를 호출해도 익셉션이 발생하지\n   않는다. 어떤 원소가 집합에 없도록 만드는 데에 쓰기 좋다.\n - 파이썬의 슬라이싱 연산자를 이용해서 단어의 모든 접두사는 쉽게 만들\n   수 있다."
					}
					,
					"ps-leetcode-shortest-path-with-alternating-colors": {
						"id": "ps-leetcode-shortest-path-with-alternating-colors",
						"title": "Shortest Path With Alternating Colors",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/shortest-path-with-alternating-colors/",
						"content": "{% raw %} Shortest Path With Alternating Colors\n\n  red, blue 엣지를 번갈아 가야 한다.\n  최단 길이를 구해야 하므로 BFS를 쓴다.\n  멀티 소스 BFS를 변형하면 된다. 시작점은 0으로 고정되어 있지만 엣지를 번갈아\n    가야하므로 빨간 점이랑 파란 점에서 동시에 출발한다고 볼 수 있다.\ndef shortestAlternatingPaths(n: int, redEdges: List[List[int]], blueEdges: List[List[int]]) -&gt; List[int]:\n    # make both graph first\n    red, blue = defaultdict(set), defaultdict(set)\n    for src, snk in redEdges:\n        red[src].add(snk)\n    for src, snk in blueEdges:\n        blue[src].add(snk)\n\n    answer = [-1] * n\n    q = deque()\n    q.append((0, 0, -1))  # contains a pair of (node, length, color) where -1:red, 1:blue\n    q.append((0, 0, 1))\n    red_visit, blue_visit = {0}, {0}\n\n    while q:\n        node, length, color = q.popleft()\n        answer[node] = length if answer[node] &lt; 0 else min(answer[node], length)\n        graph = blue if color == 1 else red\n        visited = blue_visit if color == 1 else red_visit\n        for neighbor in graph[node]:\n            if neighbor in visited:\n                continue\n            visited.add(neighbor)\n            q.append((neighbor, length + 1, -color))\n    return answer\n\n  \n\n {% endraw %}"
					}
					,
					"ps-leetcode-shortest-unsorted-continuous-subarray": {
						"id": "ps-leetcode-shortest-unsorted-continuous-subarray",
						"title": "Shortest Unsorted Continous Subarray",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/shortest-unsorted-continuous-subarray/",
						"content": "# [Shortest Unsorted Continous Subarray](https://leetcode.com/problems/shortest-unsorted-continous-subarray/)\n\n 정수 배열이 주어진다. 이 정수 배열의 **연속되는 부분 배열**을 어떻게\n 잘 정렬하면, 배열 전체가 오름차순으로 정렬된다고 한다. 즉, 정렬이 안\n 된 연속되는 부분 배열이 존재한다.\n\n 이 부분 배열 중 가장 짧은 것의 길이를 구하자.\n\n 배열 크기는 1~10,000 이고 값은 $$ -10^5 \\sim 10^5 $$ 사이이다.\n\n 예를 들어, `[2,6,4,8,10,9,15]` 배열을 생각하자. 이 중 `[6,4,8,10,9]`\n 부분을 잘 정렬해야만 배열 전체가 오름차순으로 정렬된다. 그리고 이게\n 찾을 수 있는 부분 배열 중 가장 짧다. 따라서 정답은 5가 된다.\n\n 반면 `[1,2,3,4]` 배열은 전체가 이미 정렬되어 있기 때문에 답은 0이다.\n\n## 단순 무식한 방법\n\n 내가 문제를 이해하기로는, 적당히 정렬된 배열이 있는데 그 안에서 정렬\n 안된 연속되는 부분 중에서 제일 짧은 걸 찾는 걸로 이해했다.\n\n 가장 단순하게 떠올릴 수 있는 방법은 직접 정렬한 배열과 일대일로\n 비교해보는 것이다. 정렬 안된 부분 배열의 길이만 구하면 되므로,\n 여기서는 정렬 안된 부분을 찾는 두 개의 인덱스 `low`와 `high`를\n 유지하면서 다른 부분을 찾는다. 이때, `low`는 정렬 안된 부분의 인덱스\n 중 최소값을, `high`는 최대값을 계속 누적해 나아가면 될\n 것이다. 자연스럽게 `low`의 초기값은 마지막 인덱스가 되고 `high`의\n 초기값은 0이 된다.\n\n```python\ndef findUnsortedSubarray(nums):\n    nums_sorted = sorted(nums)\n    low, high = len(nums)-1, 0\n    for i in range(len(nums)):\n        if nums[i] != nums_sorted[i]:\n            low = min(low, i)\n            high = max(high, i)\n    return high - low + 1 if high > low else 0\n```\n\n## 스택을 이용하기\n\n 정렬을 하는 순간 `O(nlogn)`의 덫에 걸린다. 그나마 입력이 (아마도)\n 거의 정렬된 배열이고, 파이썬의 팀소트는 이런 데이터에 아주 잘\n 작동하기 때문에, 나름 괜찮은 속도가 나온다.\n\n 이론적으로 더 빠른, `O(n)`의 방법을 찾아보자. 답은 스택을 활용하는\n 것이다.\n\n 배열을 정방향으로 훑으면서, 증가하는 순서대로 스택에 넣는다. 그러다가\n 만약 스택의 꼭대기보다 작은 값이 처음으로 나온다면, 여기서부터 탐색을\n 거꾸로 해나갈 수 있다. 예시 `[2,6,4,8,10,9,15]`를 다시\n 살펴보자. 스택에 `[2,6]`을 넣고 그 다음 처음으로 작아지는 `4`를\n 만났다. 그럼 여기부터 시작해서 스택의 꼭대기 값이 `4`보다 작은 동안\n 계속 스택을 팝 하면서 부분 배열의 시작 지점을 구할 수 있다. 반대로,\n 배열을 역방향으로 훑으면서 감소하는 순서로 스택에 넣다가 스택의\n 꼭대기보다 큰 값을 만난다면, 비슷한 탐색을 통해 부분 배열의 끝 지점을\n 구할 수 있다.\n\n```python\ndef findUnsortedSubarray(nums):\n    stack = []\n    low, high = len(nums)-1, 0\n    for i in range(len(nums)):\n        while stack and nums[i] = 0:\n        while stack and nums[stack[-1]]  low else 0\n```\n\n - 스택에 직접 값을 넣는게 아니라 인덱스를 넣음으로써 부분 배열의\n   정확한 위치를 구할 수 있다.\n - `O(n)`의 시간 복잡도와 공간 복잡도를 얻었다.\n\n## 스택 없이\n\n 스택을 썼다는 것은 뭔가 순서가 거꾸로인 로직이 있다는 뜻이다. 그런데,\n 잘 생각해보면 위의 로직은 스택 없이도 구현할 수 있어 보인다. 그러면\n `O(1)`의 공간 복잡도를 추가로 얻을 수 있을 것 같다.\n\n 먼저 부분 배열의 끝 부분에 집중해보자. 배열을 정방향으로 훑으면서,\n 이때까지 만난 최대값을 기록해둔다. 그러면, 이때까지 만난 최대값보다\n **작은** 값이 있는 위치를 부분 배열의 끝으로 업데이트 한다. 이걸\n 정방향으로 한번 하고 나면, 부분 배열의 끝을 찾을 수 있을 것\n 같다. 예시 `[2,6,4,8,10,9,15]`를 다시 보자. `2,6`으로 훑어서 최대값이\n `6`인 상황에서 최대값보다 작은 `4`를 만나면, 이 값을 우선 끝 부분의\n 후보로 업데이트 한다. 그 후 `2,6,4,8,10`으로 훑으면서 최대값은 계속\n 업데이트되어 `10`이 된다. `9`를 만났을 때, 최대값인 `10`보다 작은\n 위치이므로, 또 끝 부분을 업데이트한다. 이렇게 배열 끝까지를 훑으면,\n **처음으로 값이 꺾이는 부분 중에서 제일 마지막 부분**의 위치를 알 수\n 있고, 이것이 바로 우리가 원하는 부분 배열의 끝나는 지점이다. 그리고\n 시작 지점은 이것과 정반대의 로직을 이용해, 역방향으로 훑으면 알 수\n 있다.\n\n```python\ndef findUnsortedSubarray(nums):\n    high, maxval = 0, float('-inf')\n    for i in range(len(nums)):\n        maxval = max(maxval, nums[i])\n        if nums[i] = 0:\n        minval = min(minval, nums[i])\n        if minval  low else 0\n```"
					}
					,
					"ps-leetcode-single-number": {
						"id": "ps-leetcode-single-number",
						"title": "Single Number",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/single-number/",
						"content": "# [Single Number](https://leetcode.com/problems/single-number/)\n\n 정수 배열이 주어지는데, 딱 하나의 원소만 빼고 나머지 원소는 전부\n 정확히 두 번 등장한다. 여기서 딱 한 번만 등장하는 원소 하나를 찾자.\n\n 배열의 크기는 1 ~ 30,000 사이이고 원소 값의 범위는 -30,000 ~ 30,000\n 사이이다. 문제의 조건에 부합하는 배열만 입력으로 들어온다.\n\n 선형 시간 복잡도와 상수 공간 복잡도를 구현해야 한다.\n\n## 접근 1\n - 일단 O(N) 시간만 만족하도록 해보자. 공간 복잡도도 역시 O(N)이\n   가능하다면 답은 해시 셋이다.\n - 정답 원소를 뺀 나머지는 정확히 두 번 등장하기 때문에, 첫 등장에\n   셋에 집어넣고 두 번째 등장에 셋에서 빼면 된다. 그럼 셋에 남은 원소\n   하나가 바로 답이다.\n - 이렇게하면 최악의 경우여도 O(N/2)의 공간 복잡도를 가질 것 같다.\n\n```python\ndef singleNumber(nums):\n    bucket = set()\n    for n in nums:\n        if n in bucket:\n            bucket.remove(n)\n        else:\n            bucket.add(n)\n    return bucket.pop()\n```\n\n\n## 접근 2\n - 공간 복잡도 O(1)을 만족하려면 XOR 연산의 성질을 활용해야 한다.\n - XOR 연산의 네 가지 성질: Commutative, Associative, Identity\n   Element, Self-Inverse.\n - 이 중 Identity Element가 존재해서 `X ^ 0 = X`인 것과,\n   Self-Inverse라서 `X ^ X = 0`인 것이 중요하다.\n - 즉, 어떤 정수를 비트로 표현했을 때, 이 수를 두 번 XOR 하면 XOR\n   연산의 Identity Element가 된다.\n - 따라서, 어떤 수가 됐던지 XOR을 두 번 하면 사라진다.\n - 문제의 조건에 따라 딱 하나의 원소를 빼고 나머지는 정확히 두 번\n   등장하므로, 그냥 모든 수를 XOR로 누적하면 남는 값이 정답이다.\n\n```python\ndef singleNumber(nums):\n    answer = 0\n    for n in nums:\n        answer ^= n\n    return answer\n```"
					}
					,
					"ps-leetcode-snapshot-array": {
						"id": "ps-leetcode-snapshot-array",
						"title": "Snapshot Array",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/snapshot-array/",
						"content": "# [Snapshot Array](https://leetcode.com/problems/snapshot-array/)\n\n 다음 인터페이스를 지원하는 스냅샷 배열 클래스를 구현하자.\n - `SnapshotArray(int length)`: 주어진 길이 만큼의 스냅샷 배열을\n   초기화 한다. 모든 원소의 값은 0이다.\n - `void set(int index, int val)`: `index` 위치의 원소의 값을 `val`로\n   업데이트한다.\n - `int snap()`: 지금 배열의 스냅샷을 찍고 `snap_id`를\n   리턴한다. `snap_id`는 배열이 생성되고 나서 `snap()` 함수가 호출된\n   총 횟수에서 1을 뺀 값이다.\n - `int get(int index, int snap_id)`: 주어진 `snap_id`에서의 `index`\n   위치의 원소 값을 돌려주자.\n\n\n 길이는 1 ~ 50,000 사이이고 최대 50,000번의 `set`, `snap`, `get` 함수\n 호출이 이루어진다. 모든 `index`는 $$ 0 \\leq index \\leq length $$임이\n 보장되고 `snap_id` 역시 이때까지 호출한 `snap()` 수를 넘지 않는\n 유효한 아이디임이 보장된다. 각각의 값은 0부터 $$10^9$$ 사이이다.\n\n## 해시 테이블..? 이분 탐색!\n 가장 무식하게는 스냅샷이 찍힐 때마다 배열을 통째로 복사하는 방법이\n 있지만, 당연하게도 메모리 초과 에러가 난다.\n\n 그 다음 아이디어는 스냅샷 아이디를 키 값으로 해서 거기에 스냅샷의\n 값을 매달아두는, 해시 테이블의 배열을 만들려고 했다. 파이썬 타입으로\n 치자면 `List[Dict[int, int]]`쯤 되겠다. 하지만 이렇게하면 `get()`에서\n `index`로 해시 테이블을 찾아가더라도 `snap_id`를 곧바로 찾을 수 없는\n 경우가 있다. 예를 들어 길이가 2인 경우 초기 상태는 `[{-1:0},\n {-1:0}]`일텐데, 곧바로 `snap()` 후 `get(0, 0)`을 하면 해시 테이블\n 키에 쿼리로 주어진 `snap_id` 0이 없기 때문에 O(1)만에 찾을 수\n 없다. 일일이 키 값을 거꾸로 찾아가면서 `snap_id`보다 작은 것 중에서\n 가장 큰 값을 찾아야 한다. 이렇게 하니 타임아웃이 난다.\n\n 여기서는 이분 탐색의 아이디어를 활용한다. 일단 스냅샷 배열의 타입은\n 배열의 배열로, `List[List[Tuple[int, int]]]`가 된다. 바깥 배열은\n `index`로 접근 가능하다. 안쪽 배열은 `(스냅샷 아이디, 값)`의 튜플을\n 가진 배열로, `set()`이 호출될 때마다 끝부분에 추가된다. 이렇게하면\n [이분 탐색](../../theory/bisect)의 아이디어를 빌려, 가장 최근\n 스냅샷의 가장 최근에 추가된 값은 `snap_id`를 이용해서 찾은 Upper\n Bound 바로 직전 위치에 있게 된다.\n\n 예를 들어, 길이가 5인 배열에 차례로 `set(1, 10)`, `snap()`, `set (1,\n 100)`, `set(1, 999)`, `snap()`, `snap()`, `set(1, 10)`를 했다고 하면\n 다음과 같은 상태가 된다.\n\n```python\n[\n [(-1,0)],                                     # index 0\n [(-1,0), (0,10), (1,100), (1,999), (3,10)],   # index 1\n [(-1,0)],                                     # index 2\n [(-1,0)],                                     # index 3\n [(-1,0)],                                     # index 4\n]\n```\n\n 즉, 안쪽 배열의 원소는 스냅샷 아이디를 기준으로 *증가하는 순서*로\n 정렬되어 있게 된다. 이 상태에서 `get(1, 1)`을 해보자. `(1,100)`과\n `(1,999)` 두 개중 더 뒤에 있는 것이 진짜 스냅샷이다. 즉, 스냅샷\n 아이디 1의 Upper Bound 바로 직전 위치이다. 비슷하게 `get(1, 2)`도\n 마찬가지이다. 실제로는 스냅샷 2에는 아무런 값도 추가되지 않았기\n 때문에 2보다 작은것 중에서 가장 큰 스냅샷 아이디를 찾아야 하는데,\n 이게 바로 2의 Upper Bound 바로 직전 위치가 된다.\n\n 이 아이디어를 구현하면 다음과 같다.\n\n```python\nimport bisect\nclass SnapshotArray:\n    def __init__(self, length):\n        self.snap_id = -1\n        self.array = [[(-1, 0)] for _ in range(length)]\n\n    def set(self, index, val):\n        self.array[index].append((self.snap_id, val))\n\n    def snap(self):\n        self.snap_id += 1\n        return self.snap_id\n\n    def get(self, index, snap_id):\n        snap_id = bisect.bisect_right(self.array[index], (snap_id, )) - 1\n        return self.array[index][snap_id][1]\n```\n\n - `snap_id`의 초기값은 `-1`이다. 문제의 정의에 따라 이 값은 `snap()`\n   함수가 호출된 **횟수 빼기 1**이고, 따라서 처음에는 한번도 호출되지\n   않았기 때문에 `0 - 1 = -1`이다. 따라서 `array`의 각 인덱스 배열에\n   추가되는 튜플의 `snap_id` 역시 -1로 초기화해준다.\n - `set`, `snap`은 문제 정의를 그대로 구현했다.\n\n `get`이 바로 이 구현의 핵심이다. 위에서 설명한 것처럼 `snap_id`의\n Upper Bound의 바로 직전 위치가 우리가 찾고자 하는 스냅샷의\n 위치이다. 여기에 굉장히 tricky한 부분이 있어서 추가로 설명을 하려고\n 한다. 초기에는 `snap_id`가 `-1`이다. 이 상황에서 `set(0, 5)` ->\n `snap()` -> `set(0, 6)` -> `get(0, 0)` 순으로 호출되었다고\n 하자. 그러면 인덱스 0은 다음 상태이다.\n\n```python\n[(-1,0), (-1,5), (0,6)]\n```\n\n 이때 주의할 것은 `snap()`을 호출해서 리턴하는 스냅샷의 아이디는,\n **`snap()`이 호출되기 전 스냅샷에 대한 아이디**라는 것이다. 즉, 위의\n 함수 호출에서 `snap()`은 딱 한번 호출되었으므로 `0`이 되고, 이 스냅샷\n 아이디 `0`을 갖는 값들은 `(-1, 0)`과 `(-1, 5)`이다. 따라서, 문제의\n 조건에 맞게 구현하려면 아래 두 가지 중 하나를 해야 한다:\n - 애초에 `set` 할 때 `self.snap_id + 1`을 스냅샷 아이디로 기록하기:\n   이렇게하면 초기 스냅샷 아이디가 `-1`이므로 `set()` 될 때마다 `(0,\n   value)`가 추가되고, `snap()` 하는 순간 `+1` 한 아이디인 `0`으로\n   스냅샷이 찍히므로 올바르게 된다.\n - `get` 할 때의 쿼리 `snap_id` 보다 1 작은 값을 찾기: 쿼리에 쓰이는\n   스냅샷 아이디와 저장에 쓰인 아이디가 1 차이 난다는 것을 알고 `get`\n   할 때에만 처리해주는 방식이다.\n\n 여기서는 두 번째 방법을 택했는데, 추가로 파이썬의 튜플 비교 시맨틱을\n 활용했다. 파이썬에서 파이썬의 튜플은 Element-wise 하게 비교하는데,\n 길이가 서로 다른 튜플을 비교하게 되면 **더 짧은 쪽이 항상 더\n 작다**. 즉, `(1, 100)`을 `(1, )`와 비교하게 되면 항상 `(1, ) < (1,\n 100)`이 성립한다. 즉, `(snap_id, )`라는 튜플의 위치가 항상\n `(snap_id - 1, some-value)`보다는 크지만 `(snap_id + 1,\n some-value)`보다는 작다는 것을 활용하면, `(snap_id, )`의 Upper\n Bound를 구하면 우리가 원하는 두 번째 방법을 만족한다는 것을 알 수\n 있다. 즉, `get(0, 0)`은 `[(-1,0), (-1,5), (0,6)]` 에서 `(0, )`의\n Upper Bound인 `(0,6)`의 바로 직전 위치인 `(-1,5)`를 올바르게 찾을 수\n 있다."
					}
					,
					"ps-leetcode-sort-an-array": {
						"id": "ps-leetcode-sort-an-array",
						"title": "Sort an Array",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/sort-an-array/",
						"content": "# [Sort an Array](https://leetcode.com/problems/sort-an-array/)\n\n 정수 배열을 정렬하자. 배열의 길이는 최대 $$ 5 \\times 10^4$$이고 값은\n 32비트 정수 안에 다 담긴다.\n\n## Merge Sort\n 병합 정렬을 구현해보았다.\n\n 먼저 `merge_sort`에서는 계속 배열을 절반씩 나누면서 할 일을\n 쪼갠다. 그 후 이 배열을 `merge` 함수 호출을 통해 합친다. 따라서\n `merge_sort`의 베이스 케이스는 배열이 비거나 원소가 1개만 있는\n 경우이다.\n\n `merge` 함수가 핵심이다. 여기서는 두 배열 `left`와 `right`를\n 합치는데, 핵심은 합치고 나서 남은 것 원소들은 서로 비교할 필요 없이\n 곧바로 추가하면 된다는 것이다. 이때, 두 배열을 비교하며 합치는 과정을\n 인덱스를 기준으로 반복문을 돌았다면, 반복문을 빠져나온 시점에서 두\n 배열을 순회하던 인덱스를 기준으로 남은 원소를 합쳐야\n 한다. 파이썬에서는 `extend` 함수와 슬라이스 연산을 통해서 이를 읽기\n 쉽고 오류 나지 않게 구현할 수 있다.\n\n```python\ndef sortArray(nums):\n    def merge_sort(arr):\n        if len(arr) = high:\n        return\n    pivot = partition(arr, low, high)\n    quicksort(arr, low, pivot)\n    quicksort(arr, pivot + 1, high)\n```\n\n 트리거는 `quicksort(arr, 0, len(arr) - 1)`과 같이 호출된다. `low`,\n `high` 모두 인덱스이다. 범위가 0인 경우 곧바로 리턴하고, 그렇지 않은\n 경우는 먼저 파티션 연산을 통해 피벗을 고른 다음, 이 피벗을 기준으로\n `[low, pivot]`과 `[pivot+1, high]` 두 부분 범위를 또 퀵 정렬해서 타고\n 들어가면 된다.\n\n 파티션 함수는 다음과 같다.\n\n```python\ndef partition(arr, low, high):\n    pval = arr[low]\n    while low = pval:\n            high -= 1\n        arr[low] = arr[high]\n        while low = high:\n        return\n    pi = random.randrange(low, high+1)\n    arr[pi], arr[low] = arr[low], arr[pi]\n    pivot = partition(arr, low, high)\n    quicksort(arr, low, pivot)\n    quicksort(arr, pivot+1, high)\n```\n\n 혹은, 아래와 같이 그냥 `[low, high]` 범위의 중앙값을 피벗으로 삼도록\n 해도 된다.\n\n```python\n    ...\n    pi = low + (high - low) // 2\n    ...\n```\n\n 뭘 하든 쌩으로 `low`를 피벗으로 잡는 것보다는 훨씬 좋은 효율을\n 보여주고, 둘 다 타임아웃 없이 통과한다.\n\n### 잡설\n\n 퀵 정렬은 그 유명한 토니 호어 님께서 1959년에 발명하고 1961년에\n 공개된 알고리즘이다. 호어 로직의 그 분 맞다. 호어가 모스크바 대학에서\n 교환 학생으로 갔을 때, 러시아어와 영어 단어 사이의 번역을 위해서\n 문자열을 정렬할 필요가 있었는데, 이때 가장 먼저 발명한 정렬이 바로\n 삽입 정렬이고, 그 이후에 퀵 정렬을 개발했다고 한다.\n\n 힙 정렬의 잡설 란에서 설명했듯, 퀵 정렬은 지역성을 아주 잘 활용하는\n 덕분에, (아주 잘 구현된 경우) 힙 정렬보다는 최대 2~3배 더 빠르고\n 일반적으로 병합 정렬보다도 빠르다고 한다.\n\n 아주 잘 알려진 퀵 정렬의 성질이 있다.\n - 퀵 정렬은 최악의 경우 $$O(n^2)$$의 복잡도를, 평균적으로는\n   $$\\Theta(nlogn)$$의 복잡도를 갖는다. 특히 이미 정렬되어 있거나\n   부분적으로 정렬된 배열에 대해서는 복잡도가 좋지 못하다.\n - 퀵 정렬은 피벗을 아주 잘 잡아야 한다. 쉽게 구현하려면 첫 번째 or\n   마지막 or 중간 원소를 잡아버리지만 이러면 별로 소용이 없고, 운에\n   기댄다면 랜덤한 원소를 피벗으로 잡는 방법이 있다. 피벗을 잘 잡기\n   위한 연구가 따로 있을 정도로 피벗이 퀵 정렬의 복잡도에 주는 영향은\n   지대하다."
					}
					,
					"ps-leetcode-split-linked-list-in-parts": {
						"id": "ps-leetcode-split-linked-list-in-parts",
						"title": "Split Linked List In Parts",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/split-linked-list-in-parts/",
						"content": "{% raw %} Split Linked List In Parts\n링크드 리스트 노드 head 와 정수 k 가 주어질 때 리스트를 k 개의 연속적인 부분\n  리스트로 잘라서 k 개의 노드 리스트로 반환하는 문제이다.\n이 문제는 힌트를 보고 풀었는데, 리스트의 길이를 N 이라고 하면 각각의 파트는 N/k\n  개의 원소를 가지며 N%k 개 만큼은 이거보다 하나를 더 가지게 된다.\ndef splitListToParts(head, k) -&gt; List[Optional[ListNode]]:\n    def length(node):\n        n = 0\n        while node:\n            n += 1\n            node = node.next\n        return n\n    N = length(head)\n    window = N // k\n    plus = N % k\n    sentinel = ListNode(next=head)\n    prev, cur = sentinel, head\n    nodes = [None] * k\n    for i in range(k):\n        nodes[i] = cur\n        w = window\n        while w and cur:\n            prev, cur = cur, cur.next\n            w -= 1\n        if i &lt; plus and prev and cur:\n            prev, cur = cur, cur.next\n        if prev:\n            prev.next = None\n    return nodes\n\n\n  역시 센티넬 노드를 활용한다. 센티넬 노드가 있으면 항상 prev 노드가 valid한\n    노드를 가리킬 수 있어서 유용하다.\n  cur 노드로 전체를 훑는게 아니라, range(k) 만큼 파트를 만든다고 생각한다.\n    그리고 각 i 에 대해서 window 크기 만큼 노드를 진행시켜서 prev 노드가 유효한\n    경우에만 이걸 끊어버린다.\n\n {% endraw %}"
					}
					,
					"ps-leetcode-sqrtx": {
						"id": "ps-leetcode-sqrtx",
						"title": "Sqrt(x)",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/sqrtx/",
						"content": "# [Sqrt(x)](https://leetcode.com/problems/sqrtx/)\n\n 음이 아닌 정수 `x`가 주어졌을 때, `x`의 제곱근을 구하자.\n\n 제곱근이 실수일 때 정수값만 남기고 다 짤라서 리턴하자.\n\n 당연하지만 내장함수 쓰면 안된다.\n\n $$ 0 \\leq x \\leq 2^{31} - 1 $$ 이다.\n\n## 정직하게 제곱근 구하기\n\n 제곱도 아니고 제곱근을 어떻게 구할 수 있을까? 다행히 구해야 하는\n 제곱근이 **정수**라서 다음 성질을 이용할 수 있다: 어떤 수 `x`의\n 제곱근 `y`에 대해서, $$ y ^ 2 = x $$ 이다. 너무 당연한 사실이지만\n 이를 이용해서 다음과 같이 정직한 방법으로 구할 수 있다.\n\n```python\ndef mySqrt(x):\n    y = 0\n    while y * y  x`가 되기 때문에, 실제 원하는\n 값은 `y - 1`인 것에만 주의하면 된다.\n\n 단, `x`의 범위가 32비트 양의 정수이기 때문에, 이렇게 하면 겁나\n 느리다.\n\n## 좀더 빠르게 이분 탐색\n\n 좀더 빠른 방법을 고민해보자. 먼저 $$\\sqrt{0}$$은 0, $$ \\sqrt{1} $$ 은\n 1이므로 바로 리턴할 수 있다. 2 이상의 수 `x`에 대해서 고민해보자. 2와\n `x` 의 **범위**에 $$ \\sqrt{x} $$가 있을 것이다. 따라서 이 사이의\n 범위를 이분탐색할 수 있을 것 같다. 범위 사이에서 중간값 `mid`를\n 꼽았다고 해보자. 이게 `x`의 제곱근인지 알려면, 앞의 정직한 방법에서\n 썼던 것을 그대로 쓰면 된다: `mid * mid == x` 인지 체크해보면\n 된다. 만약 더 크다면? `mid`를 기준으로 더 작은 범위를 봐야\n 한다. 반대로 `mid * mid  x:\n            high = mid\n        elif mid * mid = high`가 되므로, 아마\n   `low == high`가 되는 순간 빠져나오게 될 것이다. 즉, `[0, 0)`과 같이\n   빈 범위가 된다. 이때의 `low` (또는 `high`) 값은 우리가 원하는\n   범위를 벗어난 정수 값이므로, 이전과 마찬가지로 1을 빼줘야 원하는\n   값을 얻을수 있다."
					}
					,
					"ps-boj-stack": {
						"id": "ps-boj-stack",
						"title": "Stack",
						"version": "all",
						"categories": "",
						"url": " /ps/boj/stack/",
						"content": "# Stack\n\n 파이썬 리스트는 내부적으로는 가변 길이 배열로 되어 있고, `-1`로\n 배열을 거꾸로 인덱싱하는 기능을 제공해줘서 스택으로 활용하기 좋다.\n\n\n## 스택 응용 문제 - 괄호 쌍\n 올바른 괄호 쌍을 판단하는 문제는 스택을 응용한 아주 기초적인\n 문제이다. 우리는 스택에 *여는 괄호*를 추가하고, *닫는 괄호*를\n 만난다면 아래 세 가지 중 하나를 수행한다:\n  - 스택이 비어있는 경우: 짝이 맞지 않는 경우\n  - 스택의 꼭대기와 짝이 맞지 않는 경우: 짝이 맞지 않는 경우\n  - 스택의 꼭대기와 짝이 맞는 경우: pop\n\n 이렇게 하고 난 후 스택에 괄호가 남아있으면 짝이 맞지 않는 경우이고,\n 스택이 비어있는 경우에만 모든 괄호 쌍이 올바른 경우이다.\n\n 이 사실은 다음과 같은 예시로부터 확인할 수 있다.\n\n### 짝이 맞지 않는 경우 1\n\n```\n({)}\n\nstack: ({\n```\n\n 스택에 앞의 두 여는 괄호가 추가된 상태에서, 세 번째 원소인 `)`를\n 만나면 스택의 꼭대기인 `{`과 짝이 맞지 않으므로 틀린 경우임을 알 수\n 있다.\n\n### 짝이 맞지 않는 경우 2\n\n```\n{()\n\nstack: {\n```\n\n 처음부터 끝까지 다 훑고 나면 스택에는 `{` 하나가 남는다. 입력을 다\n 처리했는데 스택에 남는 여는 괄호랑 짝이 맞는 닫는 괄호가 없으므로\n 틀린 경우임을 알 수 있다.\n\n### 짝이 맞지 않는 경우 3\n\n```\n()}\n\nstack: (empty)\n```\n\n 앞의 두 괄호는 짝이 맞으므로 스택에 `(`가 들어갔다가 `)`를 만나\n 스택이 비어버린다. 이때 닫는 괄호 `}`를 만난다면 우리가 이때까지 만난\n 여는 괄호가 없기 때문에 틀린 경우임을 알 수 있다.\n\n---\n\n 따라서, 이런 코너 케이스를 잘 처리하면서 스택의 성질을 응용하면 된다.\n\n### [4949: 균형잡힌 세상](https://www.acmicpc.net/problem/4949)\n\n```python\nimport sys\nm = {'(': ')', '[': ']'}  # matching parentheses infor\nfor line in sys.stdin:  # fast scanner\n    line = line.rstrip()  # strip out right-most newline\n    if line == '.':\n        break\n    stack, valid = [], True\n    for char in line:  # must consider characters only!!\n        if char in m:\n            stack.append(char)\n        elif char in m.values():\n            if not stack or char != m[stack[-1]]:\n                valid = False\n                break\n            stack.pop()\n    if stack:\n        valid = False\n    print('yes' if valid else 'no')\n```\n\n\n### [10799: 쇠막대기](https://www.acmicpc.net/problem/10799)\n\n```python\nimport sys\nstack, laserable, count = [], False, 0\nfor p in sys.stdin.readline().rstrip():\n    if p == '(':\n        if not laserable:\n            laserable = True\n        stack.append(p)\n    else:\n        stack.pop()\n        count += len(stack) if laserable else 1\n        laserable = False\n\nprint(count)\n```\n\n - 레이저는 오직 `()`에서만 발사된다는 사실을 고려해야 한다.\n - 레이저가 발사되면, 그 순간 스택에 쌓여있는 `(`의 개수만큼 막대기가\n   짤린다.\n - 레이저가 발사될 수 있는 구간이 아닌데 `)`를 만나면 이는 곧 막대기\n   하나가 끝났다는 뜻으로 다르게 말해 막대기가 하나 짤렸다는 것과\n   동치이다. 따라서 이를 고려해서 카운트를 세면 된다.\n\n### [2504: 괄호의 값](https://www.acmicpc.net/problem/2504)\n\n```python\nimport sys\nstack, valid, temp, answer = [], True, 1, 0\nline = sys.stdin.readline().rstrip()\nfor i in range(len(line)):\n    p = line[i]\n    if p == '(':\n        temp *= 2\n        stack.append(p)\n    elif p == '[':\n        temp *= 3\n        stack.append(p)\n    elif p == ')':\n        if not stack or stack[-1] != '(':\n            valid = False\n            break\n        # accumulate answer iff exact previous matching\n        if i > 0 and line[i - 1] == '(':\n            answer += temp\n        # restore temp\n        stack.pop()\n        temp //= 2\n    elif p == ']':\n        if not stack or stack[-1] != '[':\n            valid = False\n            break\n        if i > 0 and line[i - 1] == '[':\n            answer += temp\n        stack.pop()\n        temp //= 3\n\nif stack:\n    valid = False\n\nprint(answer if valid else 0)\n```\n\n 전체적인 구조는 괄호 균형 체크하는 문제랑 거의 같다. 다만 점수를\n 계산하는 방법을 떠올리는 게 좀 까다로웠다.\n\n 예시를 보면 `(()[[]])`의 점수를 계산할 때 `(2 + 3*3)*2` 와 같이\n 계산했는데, 이렇게 계산하는 순서는 괄호를 제일 안쪽부터 세어나가는\n 방법과 같아서 비효율적이다. 따라서 이걸 풀어서 생각해보면 `2*2 +\n 2*3*3`이 되는데, 즉 분배법칙이 적용됨을 알 수 있다. 이 아이디어에\n 착안해서 다음과 같이 할 수 있다.\n  - 정답을 누적할 `answer`와 중간 임시값 `temp`를 유지한다.\n  - 스택에 여는 괄호를 쌓을 때, 괄호의 종류에 따라 `temp`에 `2` 또는\n    `3`을 곱한다.\n  - 닫힌 괄호를 만났을 때, **입력의 바로 직전과 짝이 맞을 때에만**\n    `answer`에 `temp`를 누적한다. 그 후 스택을 팝함과 동시에 `temp`\n    값을 원복한다.\n\n 즉, `(()[[]])`에서 처음 `((`를 지나면 `temp`는 `2*2`가 되고, 이 값은\n 제일 첫 `()`일 때에만 누적하도록 한다. 이후 `[[]]`를 만날 때에는\n `temp = 2 * 3 * 3`이 되고 제일 안쪽 `]`을 만날 때에만 이 값이\n 누적된다. 이렇게 분배법칙만을 고려하면 닫힌 괄호일 때 복잡한 점수\n 계산을 하지 않아도 된다."
					}
					,
					"ps-leetcode-step-by-step-directions-from-a-binary-tree-node-to-another": {
						"id": "ps-leetcode-step-by-step-directions-from-a-binary-tree-node-to-another",
						"title": "Step-By-Step Directions From a Binary Tree Node to Another",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/step-by-step-directions-from-a-binary-tree-node-to-another/",
						"content": "# [Step-By-Step Directions From a Binary Tree Node to Another](https://leetcode.com/problems/step-by-step-directions-from-a-binary-tree-node-to-another/)"
					}
					,
					"wip-multicore-ocaml-stock-ocaml-gc": {
						"id": "wip-multicore-ocaml-stock-ocaml-gc",
						"title": "Stock Garbage Collector",
						"version": "all",
						"categories": "",
						"url": " /wip/multicore-ocaml/stock-ocaml-gc/",
						"content": "# [가비지 콜렉터의 이해](http://dev.realworldocaml.org/garbage-collector.html)\n 프로그램을 실행하면 OCaml이 할당된 값을 주기적으로 살펴보고 더 이상\n 필요없으면 해제해줘서 변수의 라이프 싸이클을 관리해준다. 이 뜻은 결국\n 프로그램이 메모리 관리를 직접 구현할 필요가 없다는 뜻이고, 살금살금\n 기어 들어오는 메모리 관련 오류의 가능성을 엄청나게 낮춰준다는 뜻이다.\n\n OCaml 런타임은 실행 중인 OCaml 프로그램이 호출할 수 있는 루틴을\n 제공하는 C 라이브러리이다. 런타임은 운영체제로부터 획득한 메모리\n 구역의 집합인 *힙*을 관리한다. 런타임은 이 메모리를 이용해 *힙\n 블록*을 유지하여 OCaml 프로그램이 요청한 할당에 대응하여 OCaml 값을\n 채워넣는다.\n\n 이 이후에는 가비지 콜렉션, 가비지 콜렉터, GC 용어를 섞어 쓴다.\n\n\n## 마크 & 스윕 GC\n 미리 할당해놓은 힙 블록 풀만으로는 메모리가 부족할 때, 런타임\n 시스템은 GC를 부른다. OCaml 프로그램은 일을 다 하고 나서 명시적으로\n 어떤 값을 해제할 수 없다. 대신, GC가 정기적으로 어떤 값이\n *살아있고(live)* 어떤 값이 *죽었는지(dead)*, 즉 더 이상 안쓰는지를\n 판별한다. 죽은 값은 수집되고 그 값을 담던 메모리는 재사용을 위해서\n 쓰인다.\n\n GC는 어떤 값이 할당되고 사용되는지를 계속 추적하고 있지 않는다. 대신,\n 스택처럼 어플리케이션이 항상 접근할 수 있는 이른바 *루트(root)* 값의\n 집합으로부터 시작해서 정기적으로 훑어본다. GC는 힙 블록이 노드이고,\n 힙 블록 `b1`이 힙 블록 `b2`를 가리키는 포인터일 때 `b1 -> b2`로\n 엣지가 있는 방향 그래프를 유지한다.\n\n 루트에서 그래프의 엣지를 따라 닿을 수 있는 모든 블록은 사용 중이므로\n 그대로 남아있어야 한다. 닿을 수 없는 블록은 어플리케이션이 재사용할\n 수 있어야 한다. OCaml이 힙 탐색에 사용하는 알고리즘은 잘 알려진 *마크\n & 스윕* 가비지 콜렉션이다.\n\n## 세대 간 GC\n 보통의 프로그래밍 스타일은 수많은 작은 변수를 할당해서 짧은 기간\n 동안만 사용하고 다시는 접근하지 않는다. OCaml은 이 사실을 활용해서\n GC의 성능을 끌어올리는데, 이를 *세대 간(generational)* GC라고 한다.\n\n 세대 간 GC는 블록이 얼마나 살아있었는지에 따라 분리된 메모리 구역을\n 유지한다. OCaml은 두 개의 구역으로 나뉜다.\n - 작고, 고정된 크기의 *마이너 힙*. 대부분의 블록이 처음에 할당된다.\n - 더 크고, 가변 크기의 *메이저 힙*. 더 오래 살아남은 블록이 할당된다.\n\n 전형적인 함수형 프로그래밍 스타일에 따르면, 어린 블록은 일찍 죽는\n 편이며 늙은 블록은 어린 것보다 훨씬 더 오래 머무른다고 한다. 이는\n *세대 간 가설(generational hypothesis)*이라고 불리기도 한다.\n\n OCaml은 메이저와 마이너 힙에 따라 메모리 레이아웃과 GC 알고리즘을\n 다르게 쓴다.\n\n### GC 모듈과 `OCAMLRUNPARAM`\n OCaml은 런타임 시스템의 동작을 묻고 변경하는 몇 가지 메커니즘을\n 제공한다. `Gc` 모듈은 OCaml 코드 안에서 이런 기능을 제공한다.\n\n 프로그램을 시작하기 전에 `OCAMLRUNPARAM` 환경 변수를 조절해서 OCaml\n 프로그램의 동작을 조절할 수도 있다. 프로그램을 다시 컴파일 하지\n 않아도 GC 파라미터를 조절할 수 있다. 자세한 건 매뉴얼에 적혀있음.\n\n## 빠른 마이너 힙\n 마이너 힙은 단명하는 대부분의 값을 담아두는 곳이다. 하나의 연속된\n 가상 메모리 덩어리 안에 OCaml 블록의 배열이 담겨 있다. 남는 공간이\n 있으면 새 블록을 할당하는 일은 아주 빠른 상수 시간의 연산으로 고작 몇\n 개의 CPU 명령어를 필요로 한다.\n\n 마이너 힙을 GC 하기 위해서 OCaml은 *복사 수집(copying collection)*\n 이라는 방법을 쓴다. 마이너 힙에 살아있는 모든 블록을 메이저 힙으로\n 옮기는 것(이를 `oldify`라고 함)이다. 이 작업은 마이너 힙에 살아있는\n 블록의 수에 비례한 시간이 걸리는데, 세대 간 가설에 따라 보통\n 적다. 마이너 수집은 또 *중단 수집(stop-the-world)*이기도 한데, 마이너\n 수집을 하는 동안 어플리케이션이 멈춘다. 따라서, 최소한의 방해만 하기\n 위해서 빠르게 수집을 끝내고 어플리케이션을 다시 시작하는 것이 아주\n 중요하다.\n\n### 마이너 힙에 할당하기\n 마이너 힙은 보통 수 메가바이트 정도의 크기를 가져서 아주 빠르게\n 훑어볼 수 있는 가상 메모리의 연속된 덩어리다.\n\n![마이너 힙](http://dev.realworldocaml.org/images/gc/minor_heap.png)\n\n 런타임은 마이너 힙의 경계를 두 개의 포인터에 저장하는데, 이는 각각 힙\n 구역의 시작과 끝을 구분한다. 이 두 포인터는 `caml_young_start`와\n `caml_young_end`인데, 여기서는 축약을 위해서 `caml_young` 접두사를\n 뺐다. `base`(즉, `caml_young_base`)는 시스템 `malloc`이 리턴하는\n 메모리 주소이고, `start`는 OCaml 값을 더 쉽게 저장하기 위해서\n `base`로부터 다음으로 가장 가까운 워드 경계에 맞춰진다.\n\n 신선한(?) 마이너 힙에서는 `limit`가 `start`와 같고 현재 `ptr`은\n `end`와 같다. 블록이 할당되면 `ptr`은 계속 줄어들다가 `limit`에 닿는\n 순간 마이너 GC의 방아쇠를 당긴다.\n\n 마이너 힙에서 블록 하나를 할당하는 일은 그냥 `ptr`을 (헤더를 포함한)\n 블록 크기만큼 줄이고 `limit`보다 작은지를 체크하는\n 일이다. `limit`보다 작게 `ptr`을 줄여여 블록을 위한 공간을 할당할 수\n 있을 때, 마이너 GC가 시작된다. 이것은 대부분의 CPU 아키텍쳐에서\n 브랜치가 필요없는 아주 빠른 체크이다.\n\n#### 할당의 이해\n 어차피 `start`랑 같은 값인데 왜 `limit`이 필요한지 궁금할 수 있다. 그\n 이유는 바로 런타임이 마이너 힙 수집을 스케쥴링하기 위한 가장 쉬운\n 방법이 바로 `limit`을 `end`로 세팅하는 것이기 때문이다. 이러고 나면\n 그 다음 할당은 절대로 충분한 공간을 가질 수 없고 항상 GC가\n 시작된다. 이런 이른 수집에는 아직 끝나지 않은 유닉스 시그널을 다룰 때\n 쓰이거나 하는 다양한 내부 사정이 있는데, 일반적인 어플리케이션\n 코드에서는 신경쓰지 않아도 된다.\n\n#### 마이너 힙 크기 설정하기\n 마이너 힙의 기본 크기는 64비트 플랫폼에서 2 MB이지만, `Core`\n 라이브러리에서는 8 MB이다. 이 설정은 `OCAMLRUNPARAM` 환경변수에\n `s=`를 넘겨줘서 덮어쓸 수 있다. 또는 아래와 같이 `Gc.tune`\n 함수를 호출해서 설정할 수도 있다.\n\n```ocaml\nopen Core\n\nGc.tune ~minor_heap_size:(262144 * 2) ();;\n```\n\n GC 크기를 동적으로 바꾸는 순간 바로 마이너 힙 수집이\n 시작된다. `Core`가 기본 마이너 힙 크기를 표준 OCaml에 비해 상당히\n 증가시키기 때문에 메모리가 아주 제한된 환경에서는 줄이는게 좋다.\n\n## 장수하는 메이저 힙\n 메이저 힙은 오래 살고 더 큰 값의 대부분이 저장되는 곳이다. 임의의\n 수의 비연속적인 가상 메모리 덩어리로 구성되고, 각각은 여기저기\n 살아있는 블록을 담고 있다. 런타임은 시스템은 이때까지 할당한 모든\n 여유 메모리를 인덱싱하는 [*미사용\n 리스트(free-list)*](https://en.wikipedia.org/wiki/Free_list) 데이터\n 구조를 유지하는데, 이를 이용해서 OCaml 블록 할당 요청을 들어준다.\n\n 메이저 힙은 보통 마이너 힙보다 훨씬 더 크고 기가바이트 단위의 요청도\n 들어줄 수 있다. 메이저 힙에서의 수집은 마크 & 스윕 알고리즘을\n 이용하며 다음과 같은 단계를 갖는다.\n - *마크(mark)* 단계에서는 블록 그래프를 훑으면서 블록 헤더의\n   *색깔(color)* 태그 비트를 설정하여 모든 살아있는 블록을\n   표시(마크)한다.\n - *스윕(sweep)* 단계에서는 순차적으로 힙 덩어리를 훑어보고 이전에\n   마크되지 않은 죽은 블록을 식별한다.\n - *압축(compact)* 단계에서는 살아있는 블록을 새로 할당된 힙으로\n   재배치해서 미사용 리스트의 간격을 제거한다. 이는 오랫동안 동작하는\n   프로그램에서 힙 블록의 파편화(fragmentation)를 방지한다. 보통 마크\n   & 스윕 단계보다 훨씬 덜 자주 일어난다.\n\n 메이저 가비지 콜렉션 역시 GC가 힙 블록을 움직이는 것을 프로그램이\n 관찰하지 못하도록 하기 위해서 반드시 프로그램을 멈춰야\n 한다(stop-the-world). 마크 & 스윕 단계는 점진적으로(incrementally)\n 동작하는데 이 단위를 힙 조각(slices of the heap)이라고 하며,\n 어플리케이션을 장기간 멈추는 것을 피하게 해준다. 그리고 각각의 힙\n 조각을 처리하기 전에 빠른 마이너 수집을 먼저 한다. 전체 메모리를\n 한번에 건드리는 것은 압축 단계 뿐인데, 이는 상대적으로 드문 작업이다.\n\n### 메이저 힙에 할당하기\n 메이저 힙은 연속된 메모리 덩어리가 노드인 싱글 링크드 리스트로\n 구성되어 있고, 가상 메모리 주소가 증가하는 순서로 정렬되어\n 있다. 각각의 덩어리는 `malloc(3)`으로 할당된 하나의 메모리 구역이며\n 헤더와 OCaml 힙 덩어리를 담은 데이터 영역으로 구성된다. 힙 덩어리\n 헤더는 다음을 담고 있다:\n - `malloc`으로 할당된 메모리 구역의 가상 메모리 주소\n - 데이터 영역의 크기 (바이트)\n - 힙을 조각 모음하기 위해서 작은 블록을 병합하는 힙 압축 동안\n   사용되는 할당 크기 (바이트)\n - 리스트의 다음 힙 덩어리로 가는 링크(포인터)\n - 블록의 시작과 끝 범위를 가리키는 포인터. 아직 확인되지 않은 필드가\n   담겨있을 수 있어서 나중에 훑어 볼 필요가 있다. 마크 스택 오버플로우\n   이후에만 쓰인다.\n\n 각 덩어리의 데이터 영역은 페이지 범위에서 시작하고, 그 크기는 페이지\n 사이즈인 4KB의 배수이다. 여기에는 하나 또는 두 개의 4KB 페이지 정도로\n 작은 힙 블록의 연속된 배열을 담고 있지만, 보통 1MB 덩어리(또는 32비트\n 아키텍쳐에서는 512KB)에 할당되어 있다.\n\n#### 메이저 힙 성장 조절\n `Gc` 모듈은 `major_heap_increment` 값을 이용해서 메이저 힙의 성장을\n 조절한다. 이 값은 확장할 때마다 메이저 힙에 추가할 워드의 개수를\n 정의하는데, 이는 프로그램 시작 이후 OCaml 런타임으로부터 운영체제가\n 관찰하는 단 하나의 메모리 할당 작업이다.\n\n 만약 한번에 엄청 큰 OCaml 값을 할당하거나 아니면 작은 값을 굉장히\n 많이 할당할 걸로 예상되면, 힙 증가분을 더 큰 값으로 잡음으로써 할당\n 요청을 만족시키기 위해 힙 사이즈를 조절하는 횟수를 줄여 성능을\n 향상시킬 수 있다. 만약 증가분이 작으면 가상 메모리의 여러 다른 구역에\n 흩뿌려져서 작은 힙 덩어리를 엄청 많이 할당하게 되고, 이러면 OCaml\n 런타임이 이를 추적하기 위해서 더 많은 작업을 해야한다.\n\n```ocaml\nGc.tune ~major_heap_increment:(100448 * 4) ();;\n```\n\n OCaml 값을 메이저 힙에 할당하려면 먼저 값을 할당할 만한 적절한 구역이\n 있는지 미사용 리스트를 체크한다. 미사용 리스트에 충분한 공간이\n 없으면, 런타임은 충분히 큰 새로운 힙 덩어리를 할당하여 메이저 힙을\n 확장한다. 이 덩어리는 미사용 리스트에 추가되고, 그 다음 다시 한번\n 미사용 리스트를 체크한다. 이때는 분명 성공할 것이다.\n\n 대부분의 메이저 힙 할당은 마이너 힙을 통해 이뤄지며 마이너 수집\n 이후에도 여전히 프로그램이 사용하는 (살아있는) 경우에만 승격(promote;\n oldify)된다는 것을 기억하자. 단, 값의 크기가 256 워드보다 클 때, 즉\n 64비트 플랫폼에서 2KB 이상일 때에는 예외이다. 이때는 마이너 힙에\n 할당하면 어차피 곧바로 수집이 일어나서 메이저 힙으로 복사될 것이기\n 때문이다.\n\n### 메모리 할당 전략\n 메이저 힙은 메모리 할당을 최대한 효울적으로 하기 위해서 최선을\n 다하고, 메모리가 연속적이며 파편화되지 않도록 하기 위해서 힙 압축에\n 의존한다. 디폴트 할당 전략은 보통 대부분의 어플리케이션에서 잘\n 동작하지만, 다른 옵션도 있다는 걸 알아두면 좋다.\n\n 메이저 힙에 새로운 블록을 할당할 때에는 언제나 미사용 리스트를 먼저\n 확인한다. 기본적인 미사용 리스트 탐색은 *최적 할당(best-fit\n allocation)*이고, 다른 옵션으로 *다음 할당(next-fit)*과 *처음\n 할당(first-fit)*이 가능하다.\n\n#### 최적 할당\n 최적 할당은 두 전략의 조합이다. 먼저, 크기 별로\n 분리된(size-segregated) 미사용 리스트는 거의 모든 메이저 힙 할당의\n 크기가 작다는 관찰에 근거한다. 최적 할당은 대부분의 할당에 대해서\n 빠른 경로를 제공하는 최대 16 워드를 포함하는 크기에 대해 별도의\n 미사용 리스트를 유지한다. 이 크기에 대한 할당은 각 크기 별로 분리된\n 미사용 리스트에서 꺼내올 수도 있고, 아니면 리스트가 빈 경우 그 다음\n 크기의 리스트에서 꺼내올 수도 있다.\n\n 두 번째 전략은 더 큰 크기의 할당에 대한 것으로, *스플레이 트리(splay\n tree)*라는 특별한 데이터 구조를 미사용 리스트에 이용한다. 이것은 검색\n 트리의 일종으로, 최근에 접근하는 패턴에 적응한다. 즉, 가장 일반적인\n 할당 요청 크기는 가장 빠르게 접근할 수 있다는 뜻이다.\n\n 크기 별로 분리된 미사용 리스트에 더 큰 크기의 블록이 없을 때의 작은\n 크기에 대한 할당과 16 워드보다 더 큰 사이즈의 할당은 메인 미사용\n 리스트에서 꺼내온다. 미사용 리스트는 요청된 할당만큼의 크기 중에서\n 가장 작은 것을 살펴본다.\n\n 최적 할당은 할당 메커니즘의 기본값이다. 할당 비용(CPU)과 힙 파편화\n 사이에서 괜찮은 트레이드 오프를 갖고 있다.\n\n\n#### 다음 할당\n 다음 할당은 미사용 리스트에서 가장 최근의 할당 요청을 만족한 블록에\n 대한 포인터를 유지한다. 새로운 요청이 들어오면, 이 포인터로부터\n 미사용 리스트의 끝까지를 살펴보고 그 다음 다시 리스트의 시작으로\n 돌아와서 이 포인터까지를 살펴본다. 즉, 순환 큐 느낌이다.\n\n 다음 할당은 CPU 관점에서 상당히 저렴한 할당 메커니즘이다. 왜냐하면\n 같은 힙 덩어리를 다 쓸 때까지 할당 요청에서 재사용될 수 있기\n 때문이다. 이는 곧 CPU 캐시를 더 잘 사용할 수 있는 좋은 메모리\n 지역성을 갖는다는 뜻이다. 다음 할당의 가장 큰 단점은, 대부분의 할당이\n 작기 때문에 미사용 리스트의 시작 부분에 있는 큰 블록이 심하게\n 파편화된다는 점이다.\n\n\n#### 처음 할당\n 만약 프로그램이 다양한 크기의 값을 할당한다면, 아마도 미사용 리스트가\n 파편화되는 것을 목격할 수도 있다. 이런 경우, GC는 미사용 덩어리가\n 있음에도 불구하고 비싼 연산인 압축을 하게 되는데, 그 어떤 덩어리도\n 요청을 만족할 만큼 크지 않기 때문이다.\n\n 처음 할당은 메모리 파편화를 줄이는데 초점을 맞추고 있다. 즉, 압축의\n 횟수를 줄인다. 대신, 메모리 할당이 좀더 느리다. 처음 할당 전략의 모든\n 할당은 미사용 리스트를 처음부터 훑어봐서 적절한 크기의 미사용\n 덩어리를 찾아내야 한다. 다음 할당처럼 가장 최근의 힙 덩어리를\n 재사용하지 않는다.\n\n 부하가 있는데 더 많은 실시간 동작이 필요한 일부 경우, 힙 압축의\n 빈도를 감소하는 것이 추가 할당 비용보다 클 수도 있다.\n\n\n#### 힙 할당 전략 조절\n `Gc.allocation_policy` 필드를 통해 조절할 수 있다.\n\n - `0`: 다음 할당\n - `1`: 처음 할당\n - `2`: 최적 할당, 디폴트\n\n 또는, `OCAMLRUNPARAM`에서 `a=[0|1|2]`로 조절할 수도 있다.\n\n\n### 힙 마킹하고 스캔하기\n 메이저 힙 전체에 대해서 완전히 마킹 작업을 하려면 아주 오랜 시간이\n 걸릴 수 있고 동작하는 동안 프로그램을 멈춰야 한다. 따라서, 마킹\n 작업은 점진적으로 동작하며 힙을 *조각(slices***으로 나눠서\n 작업한다. 힙에 있는 각 값은 2비트의 *색깔* 필드를 헤더이 갖고 있는데\n 이걸 이용해서 해당 값의 마킹 여부를 저장하여 GC가 조각 사이를 손쉽게\n 재시작할 수 있게 해준다.\n\n - 파란색: 현재 미사용 리스트에 있으며 사용 중이 아니다.\n - 흰색 (마킹 도중): 루트에서 닿진 않았지만, 닿을 수도 있다.\n - 흰색 (스위핑 도중): 루트에서 닿을 수 없고 따라서 해제될 수 있다.\n - 검은색: 루트에서 닿을 수 있고 이 값의 모든 필드도 검사되었다.\n\n 헤더의 색깔 태그는 마킹 작업의 대부분의 상태를 저장해둬서 작업을\n 멈췄다가 나중에 다시 시작할 수 있게 해준다. 할당 시에는 모든 힙 값이\n 흰색으로 초기화되어서 루트에서 닿을 수 있지만 아직 검사되진 않았음을\n 알린다. GC와 어플리케이션은 번갈아서 메이저 힙의 조각 하나를\n 마킹하거나 프로그램을 실제로 실행한다. OCaml 런타임은 할당과 가용\n 메모리 비율에 따라 각각의 메이저 힙 조각 크기를 합리적으로 계산한다.\n\n 마킹 작업은 항상 살아있는 *루트* 값의 집합으로부터 시작한다. 예를\n 들어 루트 값에는 프로그램 스택이나 글로벌 변수가 있다. 이런 루트 값의\n 색깔은 검은색이고 *마크 스택*이라는 특별한 데이터 구조에\n 추가된다. 마킹은 이 스택에서 값을 하나 꺼내서 그 값의 필드를\n 검사하면서 진행된다. 흰색 블록을 담고 있는 모든 필드는 검은색으로\n 바뀌면서 마크 스택에 추가된다.\n\n 이 작업은 마크 스택이 비어서 더 이상 마크할 값이 없을 때까지\n 반복된다. 이 작업에는 한 가지 중요한 엣지 케이스가 있는데, 바로 마크\n 스택이 특정 크기까지만 자랄 수 있다는 것이다. 그 이후에는 GC가 값의\n 필드를 따라가는 동안 이걸 저장할 곳이 없어서 더 이상 작업할 수\n 없다. 이를 *마크 스택 오버플로우*라고 하며, 이때 *가지치기(pruning)*\n 작업이 시작된다. 가지치기는 먼저 마크 스택을 완전히 비우고, 각 블록의\n 주소를 각 힙 덩어리 헤더의 시작과 끝 범위로 요약한다.\n\n 나중에 마킹 작업에서 마크 스택이 비어있으면, 힙을 *재까맣게\n 칠해서(redarkening)* 채워넣는다. 이는 재까맣게 칠해야하는 블록, 즉\n 가지치기 도중에 마크 스택에서 제거된 블록이 있는 첫 번째 주소의 힙\n 덩어리에서 시작하고, 마크 스택의 1/4만큼이 찰 때까지 재까맣게 칠할\n 범위로부터 원소를 가져와서 추가한다. 이렇게 가지치기 도중 스택을\n 비우고 다시 재까맣게 칠해서 채워넣는 순환 작업은 재까맣게 칠할 범위가\n 남아있는 힙 덩어리가 없을 때까지 계속된다.\n\n#### 메이저 힙 수집 조절\n 조각 하나를 메이저 GC 하려면 `major_slice` 함수를 이용할 수 있다. 이\n 함수는 먼저 마이너 수집을 수행하고 그 다음 한 조각을 수집한다. 조각의\n 크기는 보통 GC가 자동으로 계산해서 적당한 값을 돌려주는데 나중에 이\n 크기를 필요한 만큼 조절할 수도 있다.\n\n```ocaml\nGc.major_slice 0;;\nGc.full_major ();;\n```\n\n `space_overhead` 값을 이용해서 조각 크기를 더 크게 조절하여 GC가 더\n 공격적으로 동작하게 할 수도 있다. 이 값은 GC가 루트에서 닿을 수 없는\n 블록을 즉시 수집하지 않아서 \"낭비\"되는 살아있는 데이터에 사용된\n 메모리의 비율을 나타낸다. `Core` 에서는 메모리가 지나치게 제한되지\n 않는 일반적인 시스템을 어우르기 위해 기본값으로 100을\n 갖는다. 메모리가 많으면 더 높게 설정해도 되고, 더 낮게 설정하면 CPU\n 시간을 더 많이 사용하는 대신 GC가 더 열심히 동작하고 블록을 더 빨리\n 수집할 수 있다.\n\n\n### 힙 압축\n 특정 횟수의 메이저 GC 주기가 완료되고 나면, 힙이 할당된 순서와 다르게\n 해제되어서 아마 파편화되기 시작할 것이다. 이러면 GC가 새로운 할당을\n 외해서 연속된 메모리 블록을 찾기 힘들어지고 불필요하게 힙을 많이 먹게\n 된다.\n\n 힙 압축은 메이저 힙에 있는 모든 값을 새로운 힙으로 옮겨서 다시\n 메모리에서 연속적으로 위치하게끔 해서 이를 피한다. 이 알고리즘을\n 무지성으로 구현하면 새로운 힙을 위해서 추가적인 메모리가\n 필요하겠지만, OCaml은 더 똑똑한 알고리즘을 통해 압축을 제자리에서\n 수행한다.\n\n#### 힙 압축 주기 조절\n `max_overhead` 값은 압축이 시작된 이후 미사용 메모리와 할당된 메모리\n 사이의 연결을 정의한다.\n\n 값이 `0`이면 모든 메이저 GC 주기가 끝날 때마다 압축을 수행하고, 최대\n 값인 `1_000_000`은 힙 압축을 완전히 꺼버린다. 특이한 할당 패턴이 아닌\n 이상 `Core`의 기본값인 `500`으로도 괜찮을 것이다.\n\n### 세대 사이의 포인터\n 세대 간 수집의 복잡한 점 중 하나는 마이너 힙 수집이 메이저 힙\n 수집보다 훨씬 더 자주 일어난다는 사실에서 발생한다. 마이너 힙에 있는\n 어떤 블록이 살아있는지를 알려면, GC는 *메이저 힙 블록이 가리키는\n 마이너 힙 블록*을 따라가야 한다. 이 정보가 없으면 각각의 마이너\n 수집은 훨씬 큰 메이저 힙을 전부 스캔해야 하는데, 이러면 메이저\n 수집이나 다를 바 없다.\n\n OCaml은 메이저 힙과 마이너 힙 사이의 의존성을 피하기 위해서 *세대\n 사이의 포인터(inter-generational pointers)* 집합을\n 관리한다. 컴파일러는 메이저 힙 블록이 마이너 힙 블록을 가리키도록\n 수정될 때마다 소위 *기억해둔 집합(remembered set)*을 수정하기 위해서\n *쓰기 배리어(write barrier)*를 도입한다.\n\n#### 가변 쓰기 배리어\n 쓰기 배리어는 코드의 구조에 엄청난 영향을 줄 수 있다. 이는 레코드를\n 직접 변경하는 것보다 불변 데이터 구조를 이용해서 약간의 변경 사항이\n 있는 새로운 복사본을 할당하는 게 더 빠를 수 있는 이유 중 하나이다.\n\n OCaml 컴파일러는 모든 가변 타입을 추적해놨다가 이 값이 변경되기 전에\n 런타임이 `caml_modify` 함수를 호출하도록 한다. 이 함수는 쓰기 작업\n 대상의 위치와 변경하려는 값을 확인해서 기억해둔 집합이 일관되도록\n 보장한다. 쓰기 배리어는 제법 효율적이긴 하지만, 경우에 따라 그냥 빠른\n 마이너 힙에 새 값을 할당하고 추가적인 마이너 수집을 하는 것보다 느릴\n 수 있다.\n\n 간단한 테스트 프로그램으로 이를 확인해볼 수 있다.\n\n```ocaml\nopen Core\nopen Core_bench\n\ntype t1 = { mutable iters1: int; mutable count1: float }\ntype t2 = { iters2: int; count2: float }\n\nlet rec test_mutable t1 =\n  match t1.iters1 with\n  | 0 -> ()\n  | _ ->\n    t1.iters1  ()\n  | n ->\n    let iters2 = n - 1 in\n    let count2 = t2.count2 +. 1.0 in\n    test_immutable { iters2; count2 }\n\nlet () =\n  let iters = 1_000_000 in\n  let tests = [\n    Bench.Test.create ~name:\"mutable\" (fun () -> test_mutable { iters1= iters; count1= 0.0 });\n    Bench.Test.create ~name:\"immutable\" (fun () -> test_immutable { iters2= iters; count2= 0.0})\n  ] in\n  Bench.make_command tests |> Command.run\n```\n\n```lisp\n(executable\n    (name barrier_bench)\n    (modules barrier_bench)\n    (libraries core core_bench))\n```\n\n```bash\ndune exec -- ./barrier_bench.exe -ascii alloc -quota 1\nEstimated testing time 2s (2 benchmarks x 1s). Change using '-quota'.\n\n  Name        Time/Run   mWd/Run   mjWd/Run   Prom/Run   Percentage\n ----------- ---------- --------- ---------- ---------- ------------\n  mutable       2.86ms    2.00Mw     20.46w     20.46w      100.00%\n  immutable     2.27ms    5.00Mw      0.15w      0.15w       79.29%\n```\n\n\n 시간/공간 트레이드 오프를 확인할 수 있다. 가변 버전은 불변 버전보다\n 더 많은 시간을 소모하지만, 더 적은 마이너 힙 워드를 할당한다\n (`mWd/Run`). OCaml의 마이너 할당은 아주 빨라서, (다른 프로그래밍\n 언어에서) 관용적으로 쓰던 가변 버전보다 불변 데이터 구조를 쓰면 더\n 좋을 때가 많다. 반면에, 값을 거의 수정하지 않는 경우라면, 그냥 쓰기\n 배리어를 건드려 가면서 할당을 전혀 하지 않는게 더 빠를 수도 있다.\n\n 어떤 패턴이 더 좋을지를 확실하게 알아보는 유일한 방법은 실제 시나리오\n 상에서 사용자 프로그램을 직접 `Core_bench` 같은걸 이용해서\n 벤치마킹하서 트레이드 오프를 실험해보는 것이다. 벤치마크 바이너리는\n GC 동작과 관련해서 여러 유용한 옵션을 제공한다.\n\n```bash\ndune exec -- ./barrier_bench.exe -help\nBenchmark for mutable, immutable\n\n  barrier_bench.exe [COLUMN ...]\n\nColumns that can be specified are:\n\ttime       - Number of nano secs taken.\n\tcycles     - Number of CPU cycles (RDTSC) taken.\n\talloc      - Allocation of major, minor and promoted words.\n\tgc         - Show major and minor collections per 1000 runs.\n\tpercentage - Relative execution time as a percentage.\n\tspeedup    - Relative execution cost as a speedup.\n\tsamples    - Number of samples collected for profiling.\n\nColumns with no significant values will not be displayed. The\nfollowing columns will be displayed by default:\n\ttime alloc percentage\n\nError Estimates\n===============\nTo display error estimates, prefix the column name (or\nregression) with a '+'. Example +time.\n\n(1) R^2 is the fraction of the variance of the responder (such as\nruntime) that is accounted for by the predictors (such as number of\nruns).  More informally, it describes how good a fit we're getting,\nwith R^2 = 1 indicating a perfect fit and R^2 = 0 indicating a\nhorrible fit. Also see:\nhttp://en.wikipedia.org/wiki/Coefficient_of_determination\n\n(2) Bootstrapping is used to compute 95% confidence intervals\nfor each estimate.\n\nBecause we expect runtime to be very highly correlated with number of\nruns, values very close to 1 are typical; an R^2 value for 'time' that\nis less than 0.99 should cause some suspicion, and a value less than\n0.9 probably indicates either a shortage of data or that the data is\nerroneous or peculiar in some way.\n\nSpecifying additional regressions\n=================================\nThe builtin in columns encode common analysis that apply to most\nfunctions. Bench allows the user to specify custom analysis to help\nunderstand relationships specific to a particular function using the\nflag \"-regression\" . It is worth noting that this feature requires\nsome understanding of both linear regression and how various quatities\nrelate to each other in the OCaml runtime.  To specify a regression\none must specify the responder variable and a command separated list\nof predictor variables.\n\nFor example: +Time:Run,mjGC,Comp\n\nwhich asks bench to estimate execution time using three predictors\nnamely the number of runs, major GCs and compaction stats and display\nerror estimates. Drop the prefix '+' to suppress error estimation. The\nvariables available for regression include:\n\tTime  - Time\n\tCycls - Cycles\n\tRun   - Runs per sampled batch\n\tmGC   - Minor Collections\n\tmjGC  - Major Collections\n\tComp  - Compactions\n\tmWd   - Minor Words\n\tmjWd  - Major Words\n\tProm  - Promoted Words\n\tOne   - Constant predictor for estimating measurement overhead\n\n=== flags ===\n\n  [-all-values]           Show all column values, including very small ones.\n  [-ascii]                Display data in simple ascii based tables.\n  [-ci-absolute]          Display 95% confidence interval in absolute numbers\n  [-clear-columns]        Don't display default columns. Only show user\n                          specified ones.\n  [-display STYLE]        Table style (short, tall, line, blank or column).\n                          Default short.\n  [-fork]                 Fork and run each benchmark in separate child-process\n  [-geometric SCALE]      Use geometric sampling. (default 1.01)\n  [-linear INCREMENT]     Use linear sampling to explore number of runs, example\n                          1.\n  [-load FILE] ...        Analyze previously saved data files and don't run\n                          tests. [-load] can be specified multiple times.\n  [-no-compactions]       Disable GC compactions.\n  [-overheads]            Show measurement overheads, when applicable.\n  [-quota x|]  Quota allowed per test. May be a number of runs (e.g.\n                          1000x or 1e6x) or a time span (e.g. 10s or 500ms).\n                          Default 10s.\n  [-reduced-bootstrap]    Reduce the number of bootstrapping iterations\n  [-regression REGR] ...  Specify additional regressions (See -? help).\n  [-save]                 Save benchmark data to .txt files.\n  [-sexp]                 Output as sexp.\n  [-stabilize-gc]         Stabilize GC between each sample capture.\n  [-thin-overhead INT]    If given, just run the test function(s) N times; skip\n                          measurements and regressions. Float lexemes like \"1e6\"\n                          are allowed.\n  [-v]                    High verbosity level.\n  [-width WIDTH]          width limit on column display (default 200).\n  [-build-info]           print info about this build and exit\n  [-version]              print the version of this build and exit\n  [-help]                 print this help text and exit\n                          (alias: -?)\n```\n\n\n `-no-compactions`와 `-stabilize-gc` 옵션을 이용하면 어플리케이션의\n 메모리가 파편화되는 상황을 강제로 만들 수 있다. 이렇게하면 성능 유닛\n 테스트에서 이런 상황을 다시 만들기 위해서 그렇게 오래 기다릴 필요\n 없이 아주 오래 동작하는 어플리케이션을 시뮬레이션할 수 있다.\n\n\n## 값에 파이널라이저 붙이기\n OCaml의 자동 메모리 관리는 GC 스위핑을 통해서든 프로그램이 끝나든\n 간에 어떤 값이 더 이상 사용되지 않으면 결국에는 해제되는 것을\n 보장한다. GC가 값을 해제하기 직전에 추가적인 코드를 실행하는 것이\n 유용할 때가 있는데, 예를 들면 파일 식별자가 닫혔는지 체크하거나, 아주\n 긴 로그 메시지가 제대로 기록됐는지를 확인하거나 하는 등이다. 이런\n 함수를 *파이널라이저(finalizer)*라고 한다.\n\n### 어떤 값에 붙일 수 있을까?\n 힙에 할당되지 않는 다양한 값은 파이널라이저를 붙일 수 없다. 이런\n 값에는 정수, 상수 생성자, 불리언, 빈 어레이, 빈 리스트, 유닛 값 등이\n 있다. 어떤 값이 힙에 할당되고 어떤 값은 힙에 할당되지 않는지는 구현에\n 따라 다른데, 그래서 `Core`는 `Heap_block` 모듈을 제공해서\n 파이널라이저를 붙이기 전에 명시적으로 이를 확인할 수 있다.\n\n 어떤 상수 값은 힙에 할당될 수 있지만 프로그램이 살아있는 동안 절대로\n 해제되지 않는데, 예를 들어 정수 상수의 리스트 등이\n 있다. `Heap_block`은 명시적으로 어떤 값이 메이저 힙에 있는지 마이너\n 힙에 있는지를 확인해주고 대부분의 상수 값에 대해서는 파이널라이저를\n 붙일 수 없다고 거절한다. 컴파일러 최적화도 역시 배열의 부동소수 값과\n 같은 몇몇 불변 값을 복제할 수 있다. 이런 값은 프로그램이 다른\n 복사본을 사용하는 동안 파이널라이즈 될 수도 있다.\n\n 이런 이유에서, (1) 힙에 할당된다는 것을 명시적으로 확인한 (2) 가변\n 값에만 파이널라이저를 붙이는게 좋다. 일반적인 사용법 중 하나는 파일\n 식별자에다가 파이널라이저를 붙여서 해제를 보장하는 것이다. 하지만,\n GC가 안쓰는 값을 수집할 때 파이널라이저를 호출하기 때문에,\n 파이널라이저로 파일 식별자를 닫는 것은 주된 방법이 아니다. 시스템이\n 바쁘면 GC가 따라잡기도 전에 파일 식별자와 같은 리소스가 쉽게 동날 수\n 있다.\n\n `Core`의 `Heap_block` 모듈을 이용해서 동적으로 특정 값에\n 파이널라이저를 붙일 수 있는지를 확인하고 나면 그 다음은 `Async`의\n `Gc.add_finalizer` 함수로 넘어가서 다른 쓰레드에 대해서 안전하게\n 파이널라이저를 호출하도록 스케쥴링된다.\n\n 다음 예시를 통해 어떤 타입이 힙에 할당되는지, 어떤 타입이 컴파일\n 시점에 상수인지, 여러 타입에 파이널라이저를 붙이는 방법 등을 살펴볼\n 수 있다.\n\n```ocaml\nopen Core\nopen Async\n\nlet attach_finalizer n v =\n  match Heap_block.create v with\n  | None -> printf \"%20s: FAIL\\n%!\" n\n  | Some hb ->\n    let final _ = printf \"%20s: OK\\n%!\" n in\n    Gc.add_finalizer hb final\n\ntype t = { foo: bool }\n\nlet main () =\n  let allocated_float = Unix.gettimeofday () in\n  let allocated_bool = Float.is_positive allocated_float in\n  let allocated_string = Bytes.create 4 in\n  attach_finalizer \"immediate int\" 1;\n  attach_finalizer \"immediate float\" 1.0;\n  attach_finalizer \"immediate variant\" (`Foo \"hello\");\n  attach_finalizer \"immediate string\" \"hello world\";\n  attach_finalizer \"immediate record\" {foo = false};\n  attach_finalizer \"allocated bool\" allocated_bool;\n  attach_finalizer \"allocated variant\" (`Foo allocated_bool);\n  attach_finalizer \"allocated string\" allocated_string;\n  attach_finalizer \"allocated record\" {foo = allocated_bool};\n  Gc.compact ();\n  return ()\n\nlet () =\n  Command.async_spec ~summary:\"Testing finalizers\"\n    Command.Spec.empty main\n  |> Command.run\n```\n\n```lisp\n(executable\n    (name finalizer)\n    (modules finalizer)\n    (libraries core async))\n```\n\n```bash\ndune exec -- ./finalizer.exe\n       immediate int: FAIL\n     immediate float: FAIL\n      allocated bool: FAIL\n    allocated record: OK\n    allocated string: OK\n   allocated variant: OK\n\n```\n\n\n GC가 파이널라이저를 호출하는 순서는 해제되는 순서와 같다. 같은 GC\n 주기 동안 몇몇 값이 루트에서 닿을 수 없다면, 파이널라이저는\n `add_finalizer`를 호출한 순서의 정반대로 호출될 것이다. 각각의\n `add_finalizer` 호출은 파이널라이저를 추가하여 그 값이 루트에서 닿을\n 수 없게 되어 수집될 때 호출된다. 원한다면 같은 힙 블록에 여러 개의\n 파이널라이저를 붙일 수도 있다.\n\n GC 수집 동안 어떤 힙 블록 `b`가 루트에서 닿을 수 없다고 판단되면,\n `b`에 붙어있는 모든 파이널라이저 함수를 제거해서 순차적으로\n 호출한다. 따라서, `b`에 붙어있던 모든 파이널라이저 함수는 딱 한번만\n 호출된다. 반면, 프로그램이 종료되면 런타임이 끝나기 전에 모든\n 파이널라이저가 호출되지는 않는다.\n\n 파이널라이저에서는 모든 OCaml 기능을 다 사용할 수 있어서, 특정 값을\n 할당해서 GC되지 않게 하거나 아니면 무한 루프를 돌 수도 있다."
					}
					,
					"ps-leetcode-stream-of-characters": {
						"id": "ps-leetcode-stream-of-characters",
						"title": "Stream of Characters",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/stream-of-characters/",
						"content": "# [Stream of Characters](https://leetcode.com/problems/stream-of-characters/)\n\n 먼저 단어 목록 `words`가 주어진다. 그 후 문자의 스트림이\n 들어온다. 이때, 문자 스트림의 접미사가 이 단어 목록 중 하나의 단어와\n 일치하는지를 판단하자.\n\n 예를 들어, 단어 목록이 `[abc, xyz]`이고 스트림이 `a, x, y, z` 라면,\n `xyz` 접미사가 단어 목록에 존재함을 알 수 있다.\n\n `StreamChecker`의 두 가지 함수를 구현해야 한다.\n - `StreamChecker(String[] words)`: 단어 목록을 가지고 초기화\n - `boolean query(char letter)`: 새로운 문자를 입력 받는다. 이전까지\n   입력받은 스트림까지 포함해서, 단어 목록 중 하나가 접미사가 된다면\n   `True`를 리턴한다.\n\n\n 각 단어의 길이는 1~2,000 이고 단어 목록의 크기는 1~2,000 이다. 단어와\n 스트림은 모두 영문 소문자만 포함한다. 최대 $$ 4 \\times 10^4 $$ 번의\n `query` 함수가 호출된다.\n\n## 트라이\n\n 접미사가 아니라 접두사라면, 이 문제는 [트라이](../../theory/trie)를\n 이용해서 쉽게 풀 수 있다. 하지만 *접미사*인 점이 까다롭다.\n\n 더 큰 문제는, 우리가 탐색해야 할 공간이 고정된 길이의 문자가 아니라\n 지속적으로 입력이 들어오는 *스트림* 이라는 점이다. 그럼 어떻게\n 해야할까?\n\n 한 가지 관찰은, 단어 목록의 **끝 문자**와 항상 매칭이 되어야 한다는\n 점이다. 즉, 우리는 **접미사**를 찾아야 한다. 이 관찰로부터, 뭔가\n 트라이와 스트림에서 **거꾸로** 연산을 적용하는 아이디어를 얻을 수\n 있다.\n\n 먼저, 트라이 사전을 만들 때, 단어를 **뒤집어서** 만들어둔다. 그러면\n 어떤 단어가 들어왔을 때, 그 단어의 끝에서부터 트라이를 매치한다면\n 단어의 접미사가 트라이 사전에 있는지 확인할 수 있을 것이다. 따라서,\n **스트림 역시 뒤집어서** 관리하면 가능해 보인다.\n\n 이 알고리즘을 구현하면 다음과 같다.\n\n```python\nclass Trie:\n    def __init__(self):\n        self.child = [None] * 26\n        self.end = False\n    def __getitem__(self, key):\n        return self.child[ord(key)-ord('a')]\n    def __setitem__(self, key, value):\n        self.child[ord(key)-ord('a')] = value\n    def __contains__(self, key):\n        return bool(self[key])\n    def done(self):\n        self.end = True\n    def is_word(self):\n        return self.end\n\nfrom collections import deque\nclass StreamChecker:\n    def __init__(self, words):\n        self.sentinel = Trie()\n        self.stream = deque()\n        for word in words:\n            self.add(word)\n\n    def add(self, word):\n        node = self.sentinel\n        for char in reversed(word):\n            if char not in node:\n                node[char] = Trie()\n            node = node[char]\n        node.done()\n\n    def query(self, letter):\n        self.stream.appendleft(letter)\n        node = self.sentinel\n\n        for char in self.stream:\n            node = node[char]\n            if node is None:\n                return False\n            if node.is_word():\n                return True\n```\n\n - `StreamChecker`에 `add()` 함수를 추가해서 단어를 하나씩 트라이\n   사전에 넣도록 했다. 이때, 단어를 뒤집어서 넣는다.\n - `query` 에서는 먼저 `letter`를 `stream`의 앞쪽에 넣는다. 즉,\n   스트림을 거꾸로 유지한다. 그 후 스트림을 훑으면서 접미사 검사를\n   거꾸로 수행한다. 중간에 하나라도 노드가 없다면 거짓이다. 중간\n   노드가 단어의 끝(즉, 뒤집은 접미사의 끝 == 올바른 접두사의\n   시작)이라면, 참이다. 스트림 문자의 체크는 무조건 이 둘 중 하나의\n   조건에 걸리기 때문에, 항상 루프 안에서 리턴된다.\n - 여기서는 스트림을 거꾸로 유지하는데 큐를 썼지만, 그냥 리스트에 때려\n   박고 거꾸로 루프를 순회해도 된다."
					}
					,
					"ps-leetcode-string-compression": {
						"id": "ps-leetcode-string-compression",
						"title": "String Compression",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/string-compression/",
						"content": "{% raw %} String Compression\n코너 케이스가 좀 까다로운 문제였다.\n일단 문자열을 제자리 압축하기 위한 인덱스 i 와 같은 글자 윈도우를 찾기 위한 left\n  , right 인덱스를 준비한다. 같은 글자인 동안 right 를 증가하면, 룹이 끝난\n  시점에서 같은 글자 수는 right - left 로 손쉽게 구할 수 있다. 이렇게 센 글자 수가\n  1개 초과일 때에는 그 숫자(의 문자열) 만큼 제자리에 채워줘야 한다.\n주의해야 할 점은 다음과 같다.\n\n  윈도우를 늘려갈 때 반드시 바운드 체크를 먼저 해줘야 한다. 그래야 Short circuit\n    evaluation에 의해서 인덱스 오버플로우가 안난다.\n  작업을 다 하고 나면 압축 문자열을 담은 부분을 뺀 나머지 배열을 날려버려야\n    한다. 이게 파이썬만 그런건진 모르겠지만 아무튼 안날리면 통과가 안된다.\n\ndef compress(chars: List[str]) -&gt; int:\n    i = 0\n    left, right = 0, 0\n    while right &lt; len(chars):\n        while right &lt; len(chars) and chars[left] == chars[right]:\n            right += 1\n        # now we have chars[left] != chars[right]\n        count = right - left\n        chars[i] = chars[left]\n        left = right\n        i += 1\n\n        if count == 1:\n            # not need to append count\n            continue\n        for digit in str(count):\n            chars[i] = digit\n            i += 1\n    # delete remainder\n    del chars[i:]\n    return i + 1\n\n {% endraw %}"
					}
					,
					"ps-leetcode-subtree-of-another-tree": {
						"id": "ps-leetcode-subtree-of-another-tree",
						"title": "Subtree of Another Tree",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/subtree-of-another-tree/",
						"content": "# [Subtree of Another Tree](https://leetcode.com/problems/subtree-of-another-tree/)\n\n 두 개의 바이너리 트리의 루트 노드 `root`와 `subRoot`가 주어졌을 때,\n `subRoot`가 `root`의 서브트리인지 아닌지를 확인하자.\n\n 어떤 트리의 서브트리는 해당 트리의 노드와 그 노드의 모든 자손을\n 포함한다. 한 트리는 그 자체로 서브트리다.\n\n `root`의 노드 수는 1~2,000, `subRoot`의 노드 수는 1~1,000이다.\n\n## 스텝 바이 스텝\n\n 문제를 쪼개야 한다. 일단 두 트리의 루트 노드가 주어졌을 때, 두 트리가\n *완전히* 동일한 트리인지 확인하는 함수 `equal`을 생각해보자.\n\n  - 두 노드 모두 null이면 같다.\n  - 두 노드 중 하나만 null이면 다르다.\n  - 두 노드의 값이 같**고**, 양쪽 자식에 대해서 똑같은 것을 확인한다.\n\n 즉, `equal`은 다음과 같이 재귀적으로 작성할 수 있다.\n\n```python\ndef equal(r1, r2):\n    if not r1 and not r2:\n        return True\n    if (not r1 and r2) or (r1 and not r2):\n        return False\n    return r1.val == r2.val and equal(r1.left, r2.left) and equal(r1.right, r2.right)\n```\n\n 복잡도는 얼마일까? `r1`, `r2` 중 더 작은 트리의 노드 수 만큼 걸릴\n 것이다. 그리고 대부분의 프로그래밍 언어에는 [Short-circuit\n evaluation](https://en.wikipedia.org/wiki/Short-circuit_evaluation)이\n 구현되어 있으므로, 마지막 `and`로 묶인 리턴은 현실 데이터에서는\n 생각보다도 빨리 끝날 것이다.\n\n---\n\n 그러면 이렇게 만든 `equal`을 가지고 다음과 같이 생각해볼 수 있다.\n\n - 일단 `root`와 `subRoot`가 같은지 확인한다.\n - 다르다면, `root`의 자식에 대해서 `subRoot`와 같은게 있는지를\n   재귀적으로 확인해 나아간다.\n\n 이를 코드로 작성하면 다음과 같다.\n\n```python\ndef isSubtree(root, subRoot):\n    return equal(root, subRoot) or (root and (isSubtree(root.left, subRoot) or isSubtree(root.right, subRoot)))\n```\n\n - `isSubtree`를 호출하기 전에 `root`에 대해서 null 체크를 해주어야\n   `root.left`나 `root.right`에 접근할 때 예외가 발생하지 않는다.\n\n 이렇게하면 복잡도는 O(`len(root)` * `len(subRoot)`)가 걸리게 되고\n 문제에서는 각각 2000, 1000 이라서 시간 초과가 나지 않는다."
					}
					,
					"tags": {
						"id": "tags",
						"title": "Tags",
						"version": "all",
						"categories": "",
						"url": " /tags/",
						"content": "clear\n{% assign tags = site.data.tags | sort %}\n\n{% for tag in tags %}\n{{tag}}\n{% endfor %}\n\n\n[]\n\n\n  {% for page in site.pages %}\n  {% if page.tags.size > 0 %}\n  \n    \n      \n          {{ page.title }}\n          {% assign crumbs = page.url | append: \"/\"  | replace: '//', '/' | split: '/' %}\n          {% if crumbs.size >= 2 %}{{ crumbs[-2] }}{% endif %}\n      \n    \n  \n  {% endif %}\n  {% endfor %}"
					}
					,
					"ps-cpp-template": {
						"id": "ps-cpp-template",
						"title": "Template",
						"version": "all",
						"categories": "",
						"url": " /ps/cpp/template/",
						"content": "{% raw %} Template\nBasic\n\n  template &lt;class T&gt; 는 template &lt;typename T&gt; 와 같지만 되도록 typename 권장\n\ntemplate &lt;typename T&gt;\nclass Vector {\n  T* data;\n  int capacity, length;\n\npublic:\n  Vector(int n = 256) : data(new T[n]), capacity(n), length(0) {  }\n  ~Vector() {\n    if (data) delete[] data;\n  }\n\n  void push_back(T s) {\n    if (capacity &lt;= length) {\n      T* temp = new T[capacity * 2];\n      for (int i = 0; i &lt; length; i++) {\n        temp[i] = data[i];\n      }\n      delete[] data;\n      data = temp;\n      capacity *= 2;\n    }\n    data[length++] = s;\n  }\n\n  T operator[](int index) { return data[index]; }\n\n  void remove(int index) {\n    for (int i = index + 1; i &lt; length; i++) {\n      data[i - 1] = data[i];\n    }\n    length--;\n  }\n\n  const int size() { return length; }\n}\n\nFunction Object, or Functor\n\n  operator () 를 오버라이딩해서 함수인 것처럼 동작하게 한다.\n\nstruct Less {\n  bool operator()(int x, int y) { return x &lt; y; }\n}\n\nVariadic Template\n\n  typename 뒤 에 붙는 ... 을 템플릿 파라미터 팩 이라고 한다. 0 개 이상의 인자를\n    뜻한다.\n  함수 인자 앞 에 붙는 ... 을 함수 파라미터 팩 이라고 하고 역시 0 개 이상의 인자를\n    뜻한다.\n  재귀함수라고 생각하면 된다. 따라서 함수 인자가 하나만 있을 때 동작할 베이스\n    케이스도 작성해줘야 한다. 이때 주의할 점은 가변인자 함수보다 베이스 케이스\n    함수가 더 먼저 정의되어야 한다.\n\nsize_t GetStringSize(const char* s) { return strlen(s); }\nsize_t GetStringSize(const std::string&amp; s) { return s.size(); }\n\ntemplate &lt;typename String, typename...Strings&gt;\nsize_t GetStringSize(const String&amp; s, Strings... strs) {\n  return GetStringSize(s) + GetStringSize(strs...);\n}\n\nvoid AppendToString(std::string* str) { }\n\ntemplate &lt;typename String, typename... Strings&gt;\nvoid AppendToString(std::string* str, const String&amp; s, Strings... strs) {\n  str-&gt;append(s);\n  AppendToString(str, strs...);\n}\n\ntemplate &lt;typename String, typename... Strings&gt;\nstd::string StrCat(const String&amp; s, Strings... strs) {\n  // calcuate the length of the concatenated string\n  size_t totalSize = GetStringSize(s, strs...);\n\n  // allocate space in advance\n  std::string res;\n  res.reverse(totalSize);\n\n  res = s; // initial string\n  AppendToString(&amp;res, strs...);\n\n  return res;\n}\n\nFold Expression\n\n  C++17에서 도입된 기능(?). 걍 OCaml 폴드다..\n\n\n  문법이름풀리는 형태\n  (E op ...)Unary Fold Right(E1 op (... op (EN-1 op EN)))\n  (... op E)Unary Fold Left(((E1 op E2) op ...) op EN)\n  (E op ... op I)Binary Fold Right(E1 op (... op (EN-1 op (EN op I))))\n  (I op ... op E)Binary Fold Left((((I op E1) op E2) op ...) op EN)\n\n {% endraw %}"
					}
					,
					"ps-leetcode-text-justification": {
						"id": "ps-leetcode-text-justification",
						"title": "Text Justification",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/text-justification/",
						"content": "# [Text Justification](https://leetcode.com/problems/text-justification/)\n (뱀발: justify 뜻 중에 \"인쇄되는 텍스트의 행 끝을 나란히 맞추다\"라는\n 뜻이 있더라...)\n\n 단어의 리스트랑 `maxWidth`가 주어졌을 때, 이 단어를 잘 나열해서 각\n 라인이 정확하게 `maxWidth` 길이 만큼이 되게끔 *완전히* (즉,\n 양방향으로) 나란히 맞추자.\n\n 여러 단어를 한 줄에 맞출 때 그리디하게 접근해야 한다. 즉, 각 줄에는\n 최대한 많은 단어를 우겨 넣어야 한다. 그리고 필요하다면 추가적인 공백\n `' '`을 추가해서 각 라인이 정확하게 `maxWidth` 길이를 갖도록 해야\n 한다.\n\n 단어 사이의 추가적인 공백은 **최대한** 균등하게 퍼져야 한다. 만약\n 단어 사이의 공백 수를 균등하게 맞출 수 없다면, 왼쪽부터 채워 나간다.\n\n 제일 마지막 줄은 왼쪽 정렬을 한다. 즉, 단어 사이의 추가적인 공백이\n 없어야 한다.\n\n - 단어에는 공백이 없다.\n - `0 = maxWidth:\n            # len(line) - 1: the minimum number of spaces required.\n            if len(line) == 1:\n                # edge case: when only a single word exists in the line\n                answer.append(line[0].ljust(maxWidth))\n            else:\n                # do round-robin, except for the last word\n                spaces = [0] * len(line)\n                for i in range(maxWidth - letters):\n                    idx = i % (len(line) - 1)  # skip the last word\n                    spaces[idx] += 1\n\n                for i in range(len(line)):\n                    line[i] += ' ' * spaces[i]\n\n                answer.append(''.join(line))\n\n            # clear\n            line = []\n            letters = 0\n\n        line.append(word)\n        letters += len(word)\n\n\n    if line:\n        # use ljust to left-justify\n        answer.append(' '.join(line).ljust(maxWidth))\n\n    return answer\n```\n\n - 현재 라인뿐만 아니라 편의를 위해서 현재 라인에 속한 단어 길이의\n   누적 합 `letters`도 유지한다.\n - \"지금 단어를 현재 라인에 추가하면 오버플로우나나요?\"를 체크하기\n   위한 로직을 잘 보자. `letters`는 앞서 말했던 현재 라인에 속한 단어\n   길이의 합이다. `len(word)`는 지금 단어의 길이다. 여기까진\n   자명하다. 그럼 `len(line) - 1`은 뭘까? 단어 사이사이에 최소한\n   공백이 1개는 필요하다는 것은 곧 현재 줄의 단어 개수에서 1개를 뺀\n   값이 필요한 공백의 최소 개수와 같다는 것을 뜻한다. 따라서, 이 세\n   값의 합이 `maxWidth`를 넘는지 확인하면, 언제 라운드 로빈을\n   시작해야할 지 알 수 있다.\n - 위의 두 번째 예시의 두 번째 줄에서 본 코너 케이스를 처리한다. 현재\n   줄에 놓을 수 있는 단어가 1개 뿐이면, 그냥 단어를 left-justification\n   하면 된다. 파이썬의 `ljust`를 이용하면 쉽게 공백을 채울 수 있다.\n - 라운드 로빈을 어떻게 하는지 생각해보자. 여기서는, 현재 줄에 있는\n   단어 중 마지막 단어를 제외한 나머지 단어의 뒤에 공백을 균등하게\n   추가하는 접근을 했다. 먼저 단어 사이의 공백 개수를 0으로\n   초기화한다. 추가할 수 있는 공백 개수는 총 `maxWidth - letters`\n   개다. 제일 마지막 단어를 제외한 나머지 단어의 뒤에 공백을 붙일\n   것이므로 총 `len(line) - 1` 개의 단어를 훑을 것이다. 이때, 왼쪽부터\n   균등하게 한다는 것은 곧 인덱스 `0`부터 순환적으로 추가하면 되므로,\n   모듈러 연산을 활용할 수 있다. 이렇게 필요한 공백의 수를 세고 나면\n   Pythonic하게 문자열 곱셈으로 공백 개수를 맞추면 된다.\n - 라인 수를 넘어서 라운드로빈을 하고 나면, 현재 라인 정보와 누적 단어\n   길이를 초기화하는 것을 잊으면 안된다.\n - 이렇게 모든 단어를 훑고 나서 `line`이 남아 있으면, 남은 단어를 모두\n   공백 1개 기준으로 합친 후에 `maxWidth` 만큼 나머지 오른쪽을\n   공백으로 채우면 된다.\n\n 안틀리고 한번에 잘 구현하기 꽤 어려운 문제다."
					}
					,
					"wip-books-the-goal": {
						"id": "wip-books-the-goal",
						"title": "The Goal",
						"version": "all",
						"categories": "",
						"url": " /wip/books/the-goal/",
						"content": "# The Goal\n\n## 한줄 요약\n - 병목자원과 비병목자원을 잘 관리해서 기업의 목표(=돈을 버는 것)를\n   달성하는 방법을 소크라테스식 접근으로 일깨워주는 고전.\n\n## 인상 깊었던 글귀들\n\n> 수치들은 분명 자네를 속이고 있을 걸세. 데이터가 모든 것을 말해주는\n> 건 아니지. 데이터를 점검해보면 잘못된 수치를 발견할 수 있을 거네.\n\n\n> 대체 생산성이 뭐지? .... 생산성이란 바로 기업의 목표 면에서 무언가를\n> 완수하는 것이지. 안 그런가? ... 생산성이란 한 회사가 그 회사의\n> 목표치에 점점 다가가는 일련의 행위라고 생각하네. 회사가 목표치에\n> 접근할 수 있도록 하는 모든 행위를 생산적이라고 한다면, 그 반대의\n> 행위는 비생산적이라고 할 수 있겠지.\n\n\n> 기업의 목표가 무엇인지 확실하게 모르면, 자넨 생산성이 어떤 의미인지\n> 이해할 수도 없어. 그건 단지 숫자놀이나 말장난에 불과한 거야.\n\n> ... 시장 점유율은 높지만 계속해서 돈을 벌어들이지 못하는 회사가 있을\n> 수 있다는 말이다. 기업이 수익을 내지 못한다면 무슨 의미가 있는가?\n> 돈. 그렇다. 제조 공장의 최대 목표는 돈을 벌어들이는\n> 것이다. ... 이제야 명확한 구도가 그려지기 시작했다. 제조 공장의\n> 목표는 오로지 돈을 버는 데 있다. ... 돈을 버는 쪽으로 연결되는 모든\n> 행위는 생산적인 것이고, 그 반대의 경우는 비생산적인 것이 된다.\n\n> '기업의 목표란 투자수익률과 현금 유동성을 높이는 동시에 순이익을\n> 늘려 돈을 벌어들이는 것!'\n\n> 첫째, 제품 판매량이 늘었는가? -> 현금 창출률이 증가했는가? 둘째,\n> 직원을 해고했는가? -> 운영비가 줄었는가? 셋째, 재고가 줄었는가?\n> ... '재고와 운영비를 줄이면서 현금 창출률을 높이는 것.'\n\n\n> ... 하지만 허비의 속도와 내 속도는 종속 관계에 있기 때문에 허비가\n> 걷고 있는 속도가 내 최고 속도가 된다. 내 속도가 바로 현금\n> 창출률이다. 따라서 실질적으로는 허비가 최대 현금 창출률을 결정하고\n> 있는 셈이다. 그 순간 머릿속이 '뻥' 뚫리는 느낌이\n> 들었다. 그랬다. 우리 대원 중 누가 얼마나 더 빨리 갈 수 있는가는\n> 중요한 문제가 아니었다. 선두에 선 대원이 평균 속도보다 빠른 속력을\n> 내고 있다 해도 그 한 사람으로 인해 전체 대열의 속도가 빨라지거나\n> 현금 창출률이 오를 순 없다. ... 바로 이 아이가 현재 우리의 현금\n> 창출률을 결정짓는 장본인이다. ... 요컨대 우리 대열에서 **가장 느린\n> 속도를 유지하는 대원이 현금 창출률을 규정하는 셈**이다.\n\n> \"병목 자원이란 생산능력이 수요와 같거나 적은 자원을 말하네. 그리고\n> 비병목 자원이란 생산능력이 수요보다 큰 자원이고 말이야.\"\n\n> \"병목 자원에서 생산 자원의 시간이 낭비되지 않도록 하는 것이 첫 번째\n> 원칙입니다. ... 두 번째 원칙은 병목 자원의 부하량을 덜어내 비병목\n> 자원으로 옮기는 겁니다.\"\n\n> 자원을 '작동(activation)'하는 것과 자원을 '가동(utilization)'은\n> 별개라는 겁니다. ... 자원을 '가동하는 것'은 시스템의 목표 달성을\n> 위해 자원을 활용하는 것을 의미하고, 자원을 '작동하는 것'은 기계의\n> 작동 스위치를 누르는 것과 같은 단순한 개념으로, 그 작업으로부터\n> 창출되는 이익과는 상관없이 현장에서 벌어지는 일상적인 활동을\n> 뜻한다. ... 특히 비병목 자원을 최대로 '작동하는 것'은 아주 어리석은\n> 행위라는 점을 강조했다."
					}
					,
					"ps-leetcode-the-most-similar-path-in-a-graph": {
						"id": "ps-leetcode-the-most-similar-path-in-a-graph",
						"title": "The Most Similar Path in a Graph",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/the-most-similar-path-in-a-graph/",
						"content": "# [The Most Similar Path in a Graph](https://leetcode.com/problems/the-most-similar-path-in-a-graph/)\n\n `n`개의 도시가 있고 `m`개의 양방향 도로 정보 `roads`가 주어져서\n `roads[i] = (ai, bi)`는 도시 `ai`와 도시 `bi`를 연결한다. 각각의\n 도시는 정확히 세 개의 대문자로 이뤄진 이름을 가지고 이 정보는\n `names`로 주어진다. 어떤 도시 `x`에서 시작해서 `x`가 아닌 어떤 도시\n `y`에도 도달할 수 있다. 즉, 도시와 도로는 무향 연결 그래프를\n 형성한다.\n\n 문자열 배열 `targetPath`가 주어진다. `targetPath`와 **같은 길이**를\n 가지면서 동시에 **최소 수정 거리**를 갖는 경로를 그래프에서 찾아야\n 한다.\n\n *최소 수정 거리를 갖는 경로의 노드 순서로* 정답을 구해야 한다. 경로는\n `targetPath`의 길이와 같아야 하고, 유효해야 한다 (즉, `ans[i]`와\n `ans[i+1]` 사이에는 곧바로 길이 있어야 함). 정답이 여러개인 경우\n 아무거나 리턴해도 된다.\n\n **수정 거리**는 다음과 같이 정의된다:\n\n```python\ndefine editDistance(targetPath, myPath) {\n    dis := 0\n    a := targetPath.length\n    b := myPath.length\n    if a != b {\n        return 10000000000000\n    }\n    for (i := 0; i < a; i += 1) {\n        if targetPath[i] != myPath[i] {\n            dis += 1\n        }\n    }\n    return dis\n}\n```\n\n - $$ 2 \\leq n \\leq 100 $$\n - `m == roads.length`\n - $$ (n-1) \\leq m \\leq (n \\times (n-1) / 2) $$\n - $$ 0 \\leq a_i, b_i \\leq n-1 $$\n - $$ a_i != b_i $$\n - 그래프는 **연결 그래프**임이 보장되고 각각의 노드는 **최대 하나**의\n   직통 도로를 갖는다.\n - `n == names.length`\n - `names[i].length == 3`\n - `names[i]`는 대문자 알파벳만 포함한다.\n - **같은 이름**을 갖는 두 개의 도시가 있을 수 있다.\n - $$ 1 \\leq | targetPath | \\leq 100 $$\n - `targetPath[i].length == 3`\n - `targetPath[i]`는 대문자 알파벳만 포함한다.\n\n 예를 들어 다음과 같은 그래프를 생각해보자\n\n![example1](https://assets.leetcode.com/uploads/2020/08/08/e1.jpg)\n\n `n = 5`이고 `roads = [(0,2), (0,3), (1,2), (1,3), (1,4), (2,4)]`,\n `names = [\"ATL\", \"PEK\", \"LAX\", \"DXB\", \"HND\"]`, `targetPath = [\"ATL\",\n \"DXB\", \"HND\", \"LAX\"]`이다. 그러면 `[0,2,4,2]`, `[0,3,0,2]`,\n `[0,3,1,2]` 세 가지가 가능한 정답이 된다. 세 경로 모두 `targetPath`와\n 수정 거리가 1이다."
					}
					,
					"ps-cpp-tips": {
						"id": "ps-cpp-tips",
						"title": "Tips",
						"version": "all",
						"categories": "",
						"url": " /ps/cpp/tips/",
						"content": "{% raw %} Tips\nComparator\nSTL로 정렬할 때, 표준 라이브러리는 비교 함수가 &lt; 연산자 (less) 와 같이\n  동작한다고 가정한다. less 의 정의는 다음과 같다.\n\n  Irreflexivity(비반사성): a &lt; a 는 항상 거짓.\n  Asymmetry(비대칭성): a &lt; b 이면 not (b &lt; a).\n  Transitivity(추이성): not (a &lt; b) 이고 not (b &lt; a) 이면 a = b 이다. a = b\n    이고 b = c 이면 a = c 이다 (transitivity of equivalence).\n\n예를 들어 정수 집합을 정렬하기 위한 다음과 같은 less가 있다고 하자.\nbool operator &lt; (const IntSet&amp; a, const IntSet&amp; b) {\n  if (isProperSubset(a, b))\n    // a가 b의 진부분집합\n    return true;\n  if (isProperSubset(b, a))\n    // 반대로 b가 a의 진부분집합\n    return false;\n  return false;\n}\n\n이 less가 동작하지 않는 이유는 위의 정의에 부합하지 않기 때문이다. 예를 들어\n  {1}, {2}, {2, 3}이 있을 때, 위의 함수는 {2} &lt; {2, 3}만 참이고 나머지는 모두\n  거짓으로 계산하는데, 추이성에 따라서 {1} = {2}, {1} = {2, 3} 의 관계가\n  되어버린다. 그러면 결과적으로 {1} = {2} = {2, 3} 이라는 요상한게 튀어나온다.\n따라서 위의 정의에 부합하게 주의해서 작성해야 한다.\nbool operator &lt; (const IntSet&amp; a, const InstSet&amp; b) {\n  if (a.size() != b.size())\n    // a와 b의 크기가 다르면 더 작은 쪽이 앞에 와야 한다\n    return a.size() &lt; b.size();\n  // 크기가 같은 경우는 사전순으로 비교한다.\n  return lexicographical_compare(a.begin(), a.end(), b.begin(), b.end());\n}\n\n크기가 작은 순으로 앞에 오도록 하고 크기가 같은 경우에만 사전 순으로 비교하면\n  모든 것이 해결된다. 또 크기가 작은 순으로 앞에 오게끔 하기 때문에 굳이\n  진부분집합 여부를 확인하지 않아도 된다.\nType Promotion\n타입의 크기가 다른 두 변수를 계산할 때 컴파일러가 임의적으로 한 쪽의 타입을\n  바꿔서 (주로 큰 쪽에 맞추기 때문에 프로모션) 같은 타입으로 만든 후에 계산을\n  한다. 주로 다음 규칙이 적용된다.\n\n  정수랑 실수일 경우 실수로 맞춘다.\n  양쪽 다 정수 또는 실수일 경우 더 큰 쪽으로 맞춘다.\n  양쪽 다 int 보다 작은 정수이면 둘다 int 로 맞춘다.\n  부호 없는 정수형과 부호 있는 정수형이 섞인 경우: 부호 없는 정수형으로 맞춘다.\n\n다음 예시를 보자.\nunsigned char a = 17;\nshort b = -18;\nint c = 2;\nunsigned int d = 0;\n\ncout &lt;&lt; (a + b) * c + d &lt;&lt; endl;\n\n결과는 (17 + (-18)) * 2 + 0 = -2 가 될 것 같지만 실행하면 엄청난 값이 나온다.\n\n  unsigned char 와 short 는 둘 다 int 보다 작은 정수형이므로 int 로 프로모션\n  int 곱하기 int 는 그대로 int\n  int 와 unsigned int 타입을 계산하므로 부호가 없는 쪽을 따라 unsigned int 가\n    최종 타입\n\n따라서 되도록이면 unsigned 를 쓰지 말고, 타입을 한 쪽으로 몰아서 생각하는 것이\n  좋다.\n입출력 최적화\n입력과 출력을 직접 처리해야 하는 경우에 할 수 있는 최적화다. C 스타일 입출력과\n  C++ 스타일의 스트림 입출력의 동기화를 끊어서 속도를 빠르게 한다. 대신, 입출력을\n  할 때 두 가지 스타일 중 하나만 사용해야 한다.\nstatic auto _ = [](){\n    // turn off sync\n    std::ios::sync_with_stdio(false);\n    // untie in/out streams\n    std::cin.tie(nullptr);\n    return 0;\n}();\n\n\n  std::ios::sync_with_stdio 는 C 표준 스트림 (stdin, stdout)과 C++ 표준 스트림\n    (std::cin, std::cout) 사이의 동기화를 끊어서 입출력을 빠르게 한다. 대신 한 쪽\n    스트림만 써야 안꼬인다.\n  std::cin.tie 는 std::cin 과 std::cout 사이의 동기화를 조절한다. 만약 동기화가\n    되어 있다면 std::cin 으로 읽기 전에 std::cout 버퍼가 항상 먼저 비워지고 이를\n    통해 입출력 순서가 유지된다. 동기화를 끄게 되면 이 순서가 보장되지 않기\n    때문에 입력과 출력의 순서가 맞아야 하는 경우에는 쓰면 안된다.\n\n설명을 보면 알겠지만 문제 풀이 수준에서는 대부분 두 동기화를 모두 꺼도 괜찮다.\n람다 인라이닝\n여러 번 쓰이는 짧은 불변식 체크 로직은 함수로 빼면 좋다. 그런데 문제에 따라서 이\n  함수가 클로저면 편한 경우가 많아서 (예를 들어 그래프 탐색에서 맵 정보나 방문\n  정보를 공유하기 편함), 람다로 몽땅 캡쳐해서 쓰면 좋다. 그런데 람다는 (일반\n  함수와 마찬가지로) 기본적으로 인라인이 안된다. 최적화 플래그를 킨다면 인라인이\n  되겠지만 최적화 플래그를 못 키는 경우에는 다음 어트리뷰트 문법을 사용하면 좋다.\nauto skip = [&amp;] (int y, int x) __attribute__((always_inline)) {\n  return !(0 &lt;= y &amp;&amp; y &lt; m) || !(0 &lt;= x &amp;&amp; x &lt; n) || visited[y][x] || map[y][x] == &#39;0&#39;;\n}\n\n__attribute__ 의 위치에 주의하자. 함수 선언이라면 리턴 타입 뒤에 와야 하지만\n  람다식의 경우 파라미터 뒤에 와야 한다.\n원형 큐 마이크로 최적화\n원형 큐가 필요한 경우 정말 복잡한 데이터가 아니라면 std::queue&lt;&gt; 를 가져다 쓰기\n  보다는 그냥 배열과 head, tail 인덱스를 유지하는게 훨씬 편하다. 이때 인덱스가\n  오버플로우났을 때 다시 0으로 만드는 방법은 세 가지가 있다.\n\n  모듈러 연산 head = (head + 1) % SIZE : 모듈러는 나누기 연산과 비슷한 비용이\n    들어가서 별로 좋지 않다.\n  매번 오버플로우 검사하기 head++; if (head == SIZE) head = 0; : 그나마 이게\n    모듈러보단 낫지만 그래도 매번 분기문이 들어가기 때문에 최적이라고 할 순 없다.\n\n그리고 마지막 세 번째 방법은 한정된 경우에서만 쓸 수 있는 트릭인데 바로 비트\n  연산을 이용하는 것이다 (사실 대부분의 마이크로 최적화는 비트 연산을 가지고\n  요리조리 하다가 나오는 것 같다). 모듈러는 아예 쳐다봐서도 안되고, 분기문도\n  되도록 피하고 싶으면 고려해보자.\n먼저 SIZE 를 적당히 늘려서 2의 배수로 만든다. 그러면 이 값은 항상 0b10000...00\n  의 비트를 갖게 된다. 우리가 하고 싶은 것은 헤드나 테일 인덱스가 이 값을 넘치는\n  순간 값을 다시 0으로 초기화 하고 싶은 것이다. 이를 조금 다르게 표현하면, SIZE\n  에서 1이 있는 곳을 제외한 나머지 오른쪽 부분을 지워버리면 된다. (참조) 따라서\n  SIZE - 1 과 And 연산을 하면 된다.\nconst int SIZE = 1 &lt;&lt; 20; // 적당히 문제 조건 보다 큰 값으로\nconst int MASK = (SIZE - 1);\n...\n\nint head = 0, tail = 0;\n\n...\n\nwhile (head != tail) {\n  ...\n  head++;\n  head &amp;= MASK;\n\n  ...\n  tail++;\n  tail &amp;= MASK;\n}\n\n {% endraw %}"
					}
					,
					"ps-leetcode-top-k-frequent-elements": {
						"id": "ps-leetcode-top-k-frequent-elements",
						"title": "Top K Frequent Elements",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/top-k-frequent-elements/",
						"content": "# [Top K Frequent Elements](https://leetcode.com/problems/top-k-frequent-elements/)\n\n 정수 배열 `nums`와 정수 `k`가 주어졌을 때, `nums`에 나타나는 수를\n 빈번한 순으로 나열했을 때 `k` 순위까지의 숫자를 리턴하자. 순서는\n 상관없다.\n\n 예를 들어 `[1,1,1,2,2,3]`이 주어지고 `k=2`일 때, 1은 3번 / 2는 2번 /\n 3번 1번 나타나므로 이 중 2순위까지의 수는 `[1,2]`이다. 순서는\n 상관없으므로 `[2,1]`도 가능하다.\n\n 배열 크기는 최대 100,000이고 `k`는 배열의 유니크 원소 수보다 작거나\n 같음이 보장된다. 그리고 정답은 유니크함이 보장된다. 즉, 동 티어에\n 같은 숫자가 여러개인 케이스는 없다.\n\n## 개수 세기\n\n 파이썬에는 카운터라는 편리한 자료구조가 있어서 그냥 이걸 바로\n 적용하면 무지성으로 풀 수 있다.\n\n```python\nfrom collections import Counter\ndef topKFrequent(nums, k):\n    c = Counter(nums)\n    return [elt[0] for elt in c.most_common(k)]\n```\n\n - `Counter.most_common()` 함수가 하는 일이 문제가 요구하는 사항과\n   완전히 일치한다. 단, 리턴값이 key가 아니라 item이기 때문에, 이\n   중에서 key 값, 즉 원본 정수 값만 가져와야 한다.\n - 내부적으로는 배열을 싹 훑어서 개수를 세고 개수를 기준으로 정렬을\n   하기 때문에, 시간 복잡도는 O(NlogN)일 것이다.\n\n## 힙\n\n 사실 이 문제의 의도는 자료구조 힙을 도입하는 것이다. 최소힙을\n 기준으로 설명하자면 힙의 탑은 항상 힙 전체 원소 중 가장 작은 값이\n 들어있음이 보장된다. 따라서 배열을 훑어서 개수를 센 다음, 개수에 맞게\n 힙을 구성하고, 힙에서 `k`번 탑을 빼내면 구하고자 하는 정답이 된다.\n\n 파이썬의 `heapq`를 이용하거나 `PriorityQueue`를 이용하면 되는데, 나는\n `heapq`를 선호하는 편이다. 어차피 개수를 세야 해서 `Counter`결과를\n 가지고 힙을 만들어서 `k`번 팝 하자.\n\n```python\nfrom collections import Counter\nimport heapq\ndef topKFrequent(nums, k):\n    c = Counter(nums)\n    heap = [(-c[1], c[0]) for c in c.items()]\n    heapq.heapify(heap)\n    answer = []\n    for _ in range(k):\n        answer.append(heapq.heappop(heap)[1])\n    return answer\n```\n\n - `heapq.heapify`는 **in-place**로 입력 리스트를 힙으로 만드는\n   함수이므로, 미리 `heap`을 리스트로 만들어놔야 한다. 이때, 원소가\n   (1) 그 자체로 비교 가능하면 그걸 쓰고, (2) 인덱싱이 가능하면 첫번째\n   값을 키 값으로 비교한다. 여기서는 원소의 개수를 **음수로 취해서**\n   키 값을 만들어야 하는데, `heapq`는 최소 힙이기 때문에 가장 많은\n   원소의 순서를 유지하기 위함이다.\n - 힙에 들어간 원소가 `(-개수, 정수)`이므로, 정답 배열에는 `정수`만\n   들어가도록 한다.\n\n---\n\n 그런데 사실 `Counter.most_common()` 함수가 바로 이 `heapq`를 이용해서\n 좀더 간결하고 Pythonic한 방식으로 구현되어 있다.\n\n```python\ndef topKFrequent(nums, k):\n    c = Counter(nums)\n    return heapq.nlargest(k, c.keys(), key=c.get)\n```\n\n `heapq.nlargest(n, l, key=None)` 함수를 이용해서, 리스트 `l`에서\n `key`값을 기준으로 가장 큰 값 `n`개를 뽑아올 수 있다. 정확히 우리가\n 원하는 함수다.\n\n 먼저 카운터로 개수를 센다. 여기까진 동일하다. 이 다음 `nlargest`\n 함수에 넘기는 파라미터들이 미묘한데, 일단 리스트가 `items`가 아니라\n 곧바로 `key`이다. 대신, 여기서 비교에 쓰일 키 값을 가져오는 함수로\n `c.get`, 즉 카운터에서 해당 원소의 개수를 가져오는 함수를\n 넘겼다. 이렇게하면 굳이 `items`를 가져와서 첫번째에 개수가 들어가도록\n 튜플을 만들고... 이런 귀찮은 짓을 하지 않아도 된다."
					}
					,
					"ps-theory-topological-ordering": {
						"id": "ps-theory-topological-ordering",
						"title": "Topological Ordering",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/topological-ordering/",
						"content": "# Topological Ordering\n\n\n 위상 정렬은 방향성 있는 비순환 그래프, 흔히 DAG(Directed Acyclic Graph)라고\n 불리는 그래프의 노드들을 선형 순서로 정렬하는 방법이다. 이 선형 순서는 모든\n 엣지의 소스와 싱크를 고려한다. 즉, 엣지 `(src, snk)`에 대해서 노드 `src`는\n 반드시 `snk`보다 앞 쪽에 위치하도록 정렬한다.\n\n 위상 정렬은 주로 *의존성*이 있는 상황에서 순서를 결정할 때 사용된다. 예를 들어\n 스케쥴링, 컴파일 시에 빌드 의존성 처리, 대학교에서 선행 과목을 고려해서\n 시간표짜기 등이 있다.\n\n 하나의 DAG에 대해서는 (노드의 선형 순서만 지켜진다면) 여러 개의 위상 정렬이\n 가능하다.\n\n 위상 정렬을 구현하는 방법은 크게 두 가지가 있다. 하나는 노드에 진입하는\n 엣지(In-degree Edge) 정보를 이용하는 방법이고, 다른 하나는 DFS를 이용하는\n 방법이다.\n\n\n## 칸의 알고리즘\n\n In-degree 엣지 정보를 이용하는 알고리즘은 칸의 알고리즘(Kahn's\n Algorithm)이라고도 한다. 노드마다 진입하는 엣지의 수를 유지하면서, 엣지 수가\n 0인 노드부터 하나 씩 그래프에서 제거하고 동시에 진입 엣지 수를 업데이트 하면서\n 남은 노드가 없을 때까지 반복하는 방법이다.\n\n 알고리즘의 순서는 다음과 같다.\n 1. in-degree가 0인 노드를 선택. 여러 개일 경우 어떤 걸 선택해도 무방하다.\n 2. 선택한 노드 선형 순서에 추가하고, 동시에 이 노드와 연결된 이웃 노드의 엣지\n    수를 업데이트한다.\n 3. 만약 업데이트한 이웃 노드의 진입 엣지 수가 0이면 큐에 추가한다.\n 4. 1~3을 반복해서 모든 노드가 삭제되면 종료한다.\n\n```python\ndef topologicalSort(nodes: List[int], edges: List[List[int]]) -> List[int]:\n    graph = defaultdict(set)\n    nodes = set(nodes)\n    indegree = Counter({c: 0 for c in nodes})\n\n    for src, snk in edges:\n        graph[src].add(snk)\n        indegree[snk] += 1\n\n    ordering = []\n    q = deque([c for c in indegree if indegree[c] == 0])\n    while q:\n        node = q.popleft()\n        ordering.append(node)\n        for neighbor in graph[node]:\n            indegree[neighbor] -= 1\n            if indegree[neighbor] == 0:\n                q.append(neighbor)\n\n    return ordering\n```\n\n 이 알고리즘의 특징은 다음과 같다.\n 1. 그래프에 싸이클이 있으면 제대로 된 위상 정렬을 해내지 못한다. 정확히 말하면\n    싸이클에 속한 모든 노드는 무슨 짓을 해도 in-degree가 0이 될 수 없으므로\n    싸이클의 노드를 **아예 만나지 못한다**. 참고로 이런 성질을 이용해서 아예\n    싸이클만 남긴 다음 SCC를 수집하는 방법도 있다.\n 2. 위상 정렬이 존재한다면, 알고리즘이 in-degree가 0인 노드부터 방문하도록\n    동작하기 때문에 항상 **위상 정렬의 순서대로** 그래프를 탐색하게 된다.\n    바꿔말하면 정렬 결과를 뒤집지 않아도 된다.\n\n\n## Toplogical Ordering with DFS\n\n DFS로도 위상 정렬을 할 수 있는데, 이때는 다음과 같은 싸이클 조건을 이용해서\n 싸이클인지 아닌지도 같이 판별할 수 있다.\n\n| | `visiting = False` | `visiting = True` |\n| --- | --- | --- |\n| `visited = False` | 아직 방문하지 않음 | **싸이클** |\n| `visited = True` | 불가능한 경우 | 탐색이 끝남 |\n\n\n DFS에서 노드에 대한 방문을 **완료** 했다는 의미는 즉 이 친구는 Topological\n Ordering 에서 제일 나중에 방문해야 한다는 뜻이다. 따라서 방문을 완료한 순서대로\n 리스트든 큐든 스택이든 차례로 넣으면 이게 곧 거꾸로 된 Topological Ordering\n 이다. 그러므로,\n  - 간선 방향을 거꾸로한 그래프 (이걸 Transposed Graph 라고 하더라) 를 따로\n    만들거나,\n  - 리턴하기 직전에 뒤집어주면 된다.\n\n``` python\nclass Graph:\n    def __init__(self, n):\n        self.node_map = defaultdict(set)\n        self.node_set = set(range(n))  # edge가 없는 노드가 있을 수 있음\n\n    def add_edge(self, src, snk):\n        self.node_set.add(src)\n        self.node_set.add(snk)\n        sef.node_map[src].add(snk)\n\n    def topological_ordering(self):\n        visiting = set()\n        visited = set()\n        order = []\n\n        def dfs(node):\n            if node in visited:  # node_set 이 entry 이므로 진입하자마자 visited 체크를 해줘야 한다.\n                return\n\n            visiting.add(node)\n            for succ in self.node_map[node]:\n                if succ in visiting:  # 정확히 싸이클 케이스\n                    raise TypeError(\"has cycle\")\n                if succ not in visited:  # 아직 방문 완료가 아닐 때에만 추가로 탐색한다\n                    dfs(succ)\n\n            # node 에 대한 방문을 완료했으므로, visiting/visited 처리를 완료하고 order에 넣는다.\n            visiting.remove(node)\n            visited.add(node)\n            order.append(node)\n\n        try:\n            for node in self.node_set:\n                dfs(node)\n        except TypeError:\n            return []\n\n        order.reverse()\n        return order\n```\n\n\n## 참고) Floyd's Cycle Finding Algorithm, or The Tortoise and The Hare Algorithm\n\n 단순히 싸이클의 유무만 판별하기 위한 유명한 알고리즘이다. 시간 복잡도는\n O(n)으로 동일하지만 공간 복잡도가 O(1)인 알고리즘이다.\n\n 플로이드의 이 알고리즘의 다른 이름은 거북이와 토끼 알고리즘이다. 속도가 두 배\n 차이나는 포인터 두 개를 이용해서 리스트를 동시에 탐색하기 때문에 이런 이름이\n 붙었다. 알고리즘은 다음과 같다. 거북이는 한번에 1개씩, 토끼는 한번에 2개씩\n 리스트를 탐색한다. 만약 싸이클이 존재한다면, 거북이와 토끼는 **반드시** 만나게\n 된다. 싸이클이 없으면 토끼가 먼저 리스트의 끝에 도달한다. 깔끔하게 구현할 수\n 있다.\n\n 여기서 궁금한 점은 싸이클이 있을 때 왜 거북이와 토끼는 항상 반드시 만날까? 하는\n 점이다. 이걸 증명해보자.\n ([참조](https://www.quora.com/How-do-I-prove-that-the-tortoise-and-hare-in-Floyd-s-cycle-detection-algorithm-definitely-meet-if-a-cycle-exists-How-do-I-determine-the-starting-point-of-a-cycle-in-a-linked-list))\n\n 싸이클이 없는 경우는 의미 없으니, 싸이클이 있는 경우만 고려하자. 거북이가\n 엉금엉금 기어서 싸이클의 시작점에 진입하게 되면, 이제 거북이는 그 싸이클을 계속\n 돌게 된다. 토끼는 이미 거북이보다 두 배 빠른 속도로 싸이클에 진입해서 뛰고\n 있다. 관건은 그래서 이 둘이 항상 만나는 지점이 있는지?, 있다면 어디서 만나는지?\n 이다.\n\n 싸이클에 진입하기 까지의 경로 길이를 `x`, 싸이클의 총 길이를 `L`이라고 하자.\n 그리고 만나는 지점이 있다고 가정하면 이 지점을 기준으로 싸이클을 쪼갤 수\n 있는데, 이를 `L = y + z`라고 하자. 그러면 거북이와 토끼가 만났을 때 거북이와\n 토끼가 각각 움직인 총 거리는 다음과 같다:\n - 거북이: `x + y + T*L` (`T`: 거북이가 싸이클을 돈 총 횟수)\n - 토끼: `x + y + H*L`(`H`: 토끼가 싸이클을 돈 총 횟수)\n\n 토끼가 거북이보다 두 배 빠르게 움직이기 때문에, 아래 등식이 성립한다:\n\n```\n      (x + y + T*L) / 2 = (x + y + H*L)\n  x + y = L *(T - 2H)\n```\n\n 이때 `(T - 2H)`를 어떤 상수 `k (>= 0)`라고 해보자. 그러면 `x + y = K*L`이\n 성립하고, 따라서 `x = K*L - y`가 된다. 이 말은 곧 거북이랑 토끼가 두 배\n 차이나는 속도로 싸이클이 있는 리스트에서 출발하면, *거북이가 딱 싸이클에 진입할\n 때* 둘이 만난다는 뜻이다."
					}
					,
					"ps-theory-treap": {
						"id": "ps-theory-treap",
						"title": "Treap",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/treap/",
						"content": "# Treap\n\n```cpp\ntypedef int KeyType;\n\nclass Node {\n    KeyType key;\n\n    int priority;\n    int size;   // of subtree\n    Node *left, *right;\n\n    Node(const KeyType& key) : key(key), priority(rand()),\n        size(1), left(nullptr), right(nullptr) { }\n\n    void setLeft(Node* left) {\n        this->left = left;\n        updateSize();\n    }\n\n    void setRight(Node* right) {\n        this->right = right;\n        updateSize();\n    }\n\n    void updateSize() {\n        size = 1;\n        if (left) size += left->size;\n        if (right) size += right->size;\n    }\n};\n\ntypedef pair NodePair;\n\n/* Split a treap into two treaps with values less than\n  key and values grater than key */\nNodePair split(Node* root, KeyType key) {\n    if (root == nullptr) {\n        return NodePair(nullptr, nullptr);\n    }\n\n    if (root->key right, key);\n        root->setRight(rs.first);\n        return NodePair(root, rs.second);\n    }\n\n    NodePair ls = split(root->left, key);\n    root->setLeft(ls.second);\n    return NodePair(ls.first, root);\n}\n\nNode* insert(Node* root, Node* node) {\n    if (root == nullptr) {\n        return node;\n    }\n\n    if (root->priority priority) {\n        NodePair splitted = split(root, node->key);\n        node->setLeft(splitted.first);\n        node->setRight(splitted.second);\n        return node;\n    }\n    else if (node->key key) {\n        root->setLeft(insert(root->left, node));\n    }\n    else {\n        root->setRight(insert(root->right, node));\n    }\n    return root;\n}\n\nNode* merge(Node* a, Node* b) {\n    if (a == nullptr) return b;\n    if (b == nullptr) return a;\n    if (a->priority priority) {\n        b->setLeft(merge(a, b->left));\n        return b;\n    }\n\n    a->setRight(merge(a->right, b));\n    return a;\n}\n\nNode* erase(Node* root, KeyType key) {\n    if (root == nullptr) return root;\n\n    if (root->key == key) {\n        Node* ret = merge(node->left, node->right);\n        delete root;\n        return ret;\n    }\n\n    if (key key) {\n        root->setLeft(erase(root->left, key));\n    }\n    else {\n        root->setRight(erase(root->right, key));\n    }\n    return root;\n}\n\nNode* kth(Node*, int k) {\n    int leftSize = 0;\n    if (root->left != nullptr) leftSize = root->left->size;\n    if (k left, k);\n    if (k == leftSize + 1) return root;\n    return kth(root->right, k - leftSize - 1);\n}\n\nint countLessThan(Node* root, KeyType key) {\n    if (root == nullptr) return 0;\n    if (root->key >= key) {\n        return countLessThan(root->left, key);\n    }\n    int ls = (root->left ? root->left->size : 0);\n    return ls + 1 + countLessThan(root->right, key);\n}\n```"
					}
					,
					"ps-leetcode-triangle": {
						"id": "ps-leetcode-triangle",
						"title": "Triangle",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/triangle/",
						"content": "# [Triangle](https://leetcode.com/problems/triangle/)\n\n 삼각형을 표현한 배열 `triangle`이 입력으로 주어졌을 때, 꼭대기에서\n 바닥까지 가는 경로 중 합이 최소가 되는 값을 구하자.\n\n 각각의 단계에서는 아래 행의 인접한 원소로 움직일 수 있다. 좀더\n 형식적으로 말하면, 현재 행의 `i` 인덱스에 있다면, 한 단계를\n 움직이려면 그 다음 행의 `i` 인덱스 또는 `i+1` 인덱스로 갈 수 있다.\n\n 삼각형의 높이(배열의 길이)는 최대 200이고, 항상 유효한 삼각형 모양이\n 입력으로 들어옴이 보장된다. 따라서 `triangle[0].length == 1` 이고\n `triangle[i].length == triangle[i-1] + 1`임이 보장된다. 삼각형 배열\n 각 원소는 정수형이고 값의 범위는 $$ -10^4 \\sim 10^4 $$ 사이이다.\n\n## 다이나믹.. 프로그래밍..\n\n 꽤 유명한 다이나믹 프로그래밍 문제 중 하나인 것 같다. [경로\n 찾기](../unique-paths)와도 비슷한 문제인데, 여기서는 맵이 격자가\n 아니라 삼각형인 점, 그리고 원소 합의 최소값을 구해야 한다는 점이\n 다르다.\n\n 그러면 다이나믹 프로그래밍을 계획해보자. 먼저 탑 다운 방식과 바텀 업\n 방식 중 어떤 것이 가능할지 가늠해보자. 꼭대기로부터 출발해서 바닥까지\n 가려면 모든 행을 적어도 한번은 다 살펴봐야 하기 때문에, 탑 다운과\n 바텀 업 모두 가능해보인다. 보통 점화식을 세우고 이것을 곧바로 코드로\n 옮기기 쉬운 것은 탑 다운 방식이기 때문에, 점화식을 고민해보자.\n\n `path(r, c)`는 `(r, c)`로부터 바닥까지 가는 경로 합의 최소라고\n 하자. 그러면 문제에 나온 \"각 단계에 움직일 수 있는 방향\"의 정의에\n 따라 다음 식이 성립한다: `path(r, c) = triangle[r][c] + min(path(r+1,\n c), path(r+1, c+1))`. 즉 `(r, c)`에서 한 칸 아래(`r+1`)로 갈 때,\n 가능한 경우는 다음 행의 `c` 인덱스 또는 `c+1` 인덱스 이고, 이 중 최소\n 값을 찾아서 경로에 누적하면 된다.\n\n 그러면 이 식을 곧바로 탑 다운 방식으로 구현하고 메모이제이션할 수\n 있다. 단, 이때 인덱스의 범위에 주의해야 한다. 삼각형의 *바닥*까지\n 간다는 뜻은 곧 다음 행 (`r+1`)이 삼각형의 높이 안인지 확인하는\n 것이다. 이 점을 조심하면서 아이디어를 구현하면 다음과 같다.\n\n```python\ndef minimumTotal(triangle):\n    from functools import cache\n\n    @cache\n    def min_path(row, col):\n        acc = triangle[row][col]\n        if (row + 1) < len(triangle):\n            p += min(min_path(row+1, col), path(row+1, col+1))\n        return p\n    return path(0, 0)\n```"
					}
					,
					"ps-boj-trie": {
						"id": "ps-boj-trie",
						"title": "Trie",
						"version": "all",
						"categories": "",
						"url": " /ps/boj/trie/",
						"content": "# Trie\n 대소문자를 구분한다면 52(26+26), 구분하지 않는다면 26 진 트리로 특정\n 문자 사전을 파싱해서 캐싱해둔 후 이후 문자를 아주 빠른 속도로 검색할\n 수 있게 해주는 자료구조이다.\n\n 편의를 위해 대소문자 구분없는 26진 트리를 만들어보자. 어떤 노드는\n `a`부터 `z`까지 총 26개의 자식 노드를 가질 수 있다. 초기값은\n `None`이다.\n\n``` python\nclass TrieNode:\n    def __init__(self, c):\n        self.c = c\n        self.children = [None] * 26\n        self.count = 0\n        self.is_word = False\n\n    def __getitem__(self, key):\n        return self.children[ord(key) - ord('a')]\n\n    def __setitem__(self, key, value):\n        self.children[ord(key) - ord('a')] = value\n```\n\n `ord` 함수는 문자의 아스키코드 값을 돌려준다. C/C++에서는 문자가\n implicit하게 정수형으로 타입 캐스팅 되어서 뺄셈을 할 수 있지만\n 파이썬에서 이러면 `unsupported operand type` 에러가 뜬다. 따라서\n `ord` 함수를 통해 정수 타입으로 바꿔준 다음 인덱스로 사용해야\n 한다. 그 후 `__getitem__`이랑 `__setitem__`을 오버라이딩해주면 마치\n 배열 인덱스처럼 트라이 노드의 자식 노드에 편하게 접근할 수 있다.\n\n``` python\ndef build_trie(root, str):\n    node = root\n    for c in str:\n        if not node[c]:\n            node[c] = TrieNode(c)\n\n        node = node[c]\n        node.count += 1\n\n    node.is_word = True\n```\n\n  그 후 사전의 문자열들을 가지고 트라이를 빌드해야 한다. 사전을 통째로\n  트라이로 만들고 나면 하나의 트리가 나오므로, 이를 유지하기 위해서\n  루트 노드 `root`는 항상 유지하고 있어야 한다.\n\n## [14425번: 문자열 집합](https://www.acmicpc.net/problem/14425)\n 사실 이 문제는 트라이로 풀면 터지기 때문에 더 간단하고 빠른 해시\n 셋으로 푸는게 좋다. 복잡도가 대충 `O(10000 x 탐색 시간)` 인데, 해시\n 셋은 탐색 시간이 대충 `O(1)`로 봐도 좋지만 트라이는 `O(500)`이고\n 실제로는 파이썬의 제네릭한 오브젝트 리스트를 왔다갔다 해야해서\n 오버헤드가 크다.\n\n 하지만 PyPy3로 제출하면 7초라는 끔찍한 시간이 걸리긴 하지만\n 통과하므로 연습삼아 풀어보았다.\n\n```python\nimport sys\n\nload = lambda: sys.stdin.readline().rstrip()\n\nclass TrieNode:\n    def __init__(self, char):\n        self.char = char\n        self.children = [None] * 26\n        self.is_word = False\n\n    def __getitem__(self, key):\n        return self.children[ord(key) - ord('a')]\n\n    def __setitem__(self, key, value):\n        self.children[ord(key) - ord('a')] = value\n\ndef build(root, string):\n    node = root\n    for char in string:\n        if not node[char]:\n            node[char] = TrieNode(char)\n\n        node = node[char]\n\n    node.is_word = True\n\n\ndef is_included(root, string) -> bool:\n    node = root\n    for char in string:\n        if not node[char]:\n            return False\n\n        node = node[char]\n\n    return node.is_word\n\nn, m = map(int, load().split())\nroot = TrieNode(None)\nfor _ in range(n):\n    build(root, load())\n\ntotal = 0\nfor _ in range(m):\n    if is_included(root, load()):\n        total += 1\n\nprint(total)\n```\n\n - 트라이를 빌드하고 트라이 위에서 검색하는 동작 모두 루트 노드가\n   필요하므로 이를 유지해준다.\n - 조금이라도 빠른 검색을 위해서 Early Return 해준다.\n - 트라이의 마지막 노드에 도달했으면 반드시 `is_word` 체크를 해줘야\n   한다.\n\n## [5052번: 전화번호 목록](https://www.acmicpc.net/problem/5052)\n 이 문제야 말로 트라이가 진가를 발휘하는 종류의 문제이다. 문제 조건에\n 따르면 (1) 쿼리는 총 10000번이 이루어지고 (2) 문자열(전화번호)의\n 길이는 최대 10자리이다. 트라이를 활용하면 `O(10000*10)`의 복잡도만에\n 각 테스트케이스를 해결할 수 있다.\n\n 조금 Tricky한 부분은, 트라이를 빌드해놓고 검색했던 이전 문제와 달리,\n 이 문제는 빌드와 검색을 동시에 진행해야 한다는 점이다. 문제의 조건에\n 따라 **기존에 기록한 전화번호 목록**에 현재 전화번호를 추가했을 때\n 일관성이 깨지느냐를 체크하는 것이 키 포인트이기 때문이다. 그리고,\n 문제의 조건에 따라, **문자열의 접두사**가 중요한 포인트이므로, 미리\n 전화번호 목록을 다 받은 뒤에 전화번호의 **길이**로 정렬해둬야\n 한다. 그래야 짧은 전화번호 순서로 트라이에 추가되고, 이후 들어오는\n 번호는 이미 트라이에 있는 전화번호들보다 길거나 같기 때문에 더 짧은\n 번호가 더 긴 번호의 접두사가 되는지를 파악할 수 있기 때문이다.\n\n 설명이 주절주절 길었는데 코드는 다음과 같다.\n\n```python\nimport sys\nload = lambda: sys.stdin.readline().rstrip()\n\nclass TrieNode:\n    def __init__(self, char):\n        self.char = char\n        self.children = [None] * 10\n        self.end = False\n\n    def __getitem__(self, key):\n        return self.children[ord(key) - ord('0')]\n\n    def __setitem__(self, key, value):\n        self.children[ord(key) - ord('0')] = value\n\ndef build_trie(root, number) -> bool:\n    node = root\n    for n in number:\n        if node[n] and node[n].end:\n            return False\n\n        if not node[n]:\n            node[n] = TrieNode(n)\n\n        node = node[n]\n\n    node.end = True\n    return True\n\nt = int(load())\nfor _ in range(t):\n    n = int(load())\n    numbers = [load() for _ in range(n)]\n    numbers.sort(key=lambda number: len(number))\n    root = TrieNode(None)\n    answer = True\n    for number in numbers:\n        if not build_trie(root, number):\n            answer = False\n            break\n    print('YES' if answer else 'NO')\n```\n\n - 전화번호가 정수형이니까 트라이의 자식 노드에 접근할 때 곧바로\n   인덱스로 활용할 수 있지 않을까? 싶지만, 잘 생각해보면 번호가\n   `0`으로 시작할 수 있으므로 그냥 이전처럼 문자열 인덱스를 `ord`를\n   이용해서 빼줘야 한다.\n - 트라이를 빌드할 때 도중에 `end` 인 자식을 만났다는 것은 곧 지금\n   번호보다 더 짧은 길이의 번호가 목록에 존재한다는 뜻이고 다시말해\n   접두사가 목록에 존재한다는 뜻이다. 따라서 이때 Early Return으로\n   실패를 알린다.\n - N개의 번호를 받은 다음 길이 순으로 정렬해야 올바른 답이 나온다."
					}
					,
					"ps-theory-trie": {
						"id": "ps-theory-trie",
						"title": "Trie",
						"version": "all",
						"categories": "",
						"url": " /ps/theory/trie/",
						"content": "# Trie\n\n 트라이 노드는 다음과 같이 구현할 수 있다.\n\n```python\nclass Trie:\n    class Node:\n        def __init__(self, char=None):\n            self.child = [None] * 26\n            self.end = False\n\n        def __getitem__(self, key):\n            return self.child[ord(key) - ord('a')]\n\n        def __setitem__(self, key, value):\n            self.child[ord(key) - ord('a')] = value\n\n        def __contains__(self, key):\n            return True if self[key] else False\n\n        def done(self):\n            self.end = True\n\n        def is_word(self):\n            return self.end\n\n    def __init__(self):\n        self.sentinel = Trie()\n\n    def add(self, word):\n        node = self.sentinel\n        for char in word:\n            if char not in node:\n                node[char] = Trie()\n            node = node[char]\n        node.done()\n\n    def startswith(self, prefix):\n        node = self.sentinel\n        for char in prefix:\n            if char not in node:\n                return False\n            node = node[char]\n        return True\n```\n\n - 알파벳 소문자만 담는 트라이다.\n - `__getitem__`, `__setitem__`을 오버라이딩 하여 `Trie[key]`와\n   `Trie[key] = value`로 사용할 수 있도록 한다.\n - `__contains__`를 오버라이딩 하여 `key in Trie`와 `key not in Trie`\n   테스트가 가능하도록 한다."
					}
					,
					"ps-leetcode-two-sum": {
						"id": "ps-leetcode-two-sum",
						"title": "Two Sum",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/two-sum/",
						"content": "# [Two Sum](https://leetcode.com/problems/two-sum/)\n 상징적인 리트코드 1번 문제다.\n\n 정수 배열 `nums`와 어떤 정수 `target`이 주어졌을 때, 정수 배열의 두\n 원소 중 합이 `target`이 되는 인덱스 두 개를 찾는 문제이다.\n\n 이때, 입력은 항상 **정확히 하나**의 해를 가지며, **같은** 원소를 두\n 번 쓸 수 없다. 인덱스 두 개의 순서는 상관없다.\n\n## 접근 1 - Brute Force\n - 모든 가능한 쌍을 탐색\n\n ```python\ndef two_sum(nums, target):\n    for i1, n1 in enumerate(nums):\n        for i2 in range(i1 + 1, len(nums)):\n            if n1 + nums[i2] == target:\n                return (i1, i2)\n```\n\n## 접근 2 - 해시 테이블\n - 문제의 조건 덕분에 가능한 접근: (1) 항상 유일한 답이 있고 (2) 같은\n   원소가 두 번 쓰이지 않음\n - 정수 `x`가 있을 때 어딘가에 반드시 `target - x`(보수)가 있어야 함\n - 따라서, 정수 -> 인덱스로 가는 해시 테이블을 이용할 수 있음\n - 문제 조건에 유의해야 함:\n   - 정답은 **인덱스**의 튜플\n   - 같은 원소가 두 번 쓰이면 안됨\n\n\n```python\ndef two_sum(nums, target):\n    comps = {}\n    for i, n in enumerate(nums):\n        comps[n] = i\n\n    for i, n in enumerate(nums):\n        comp = target - n\n        if comp in comps and i != comps[comp]:\n            return (i, comps[comp])\n```\n\n\n# [Two Sum II - Input Array Is Sorted](https://leetcode.com/problems/two-sum-ii-input-array-is-sorted/)\n\n 같은 문제인데 입력 배열이 정렬되어 있는 경우.\n\n 위의 접근 2를 그대로 활용할 수 있지만 좀더 잘 할 수 있다.\n\n\n## 접근 - O(1) 공간 복잡도\n - *정렬*되어 있는 성질을 이용하여 이분 탐색 아이디어를 활용할 수\n   있음\n   - 두 개의 포인터 `(low, high)`를 두고 양 끝에서 시작\n   - 두 값의 합이 `target`보다 작으면, 합을 더 크게 만들기 위해서는\n     `low`를 증가하는 수 밖에 없음\n   - 두 값의 합이 `target`보다 더 크면, 합을 더 작게 만들기 위해서는\n     `high`를 줄이는 수 밖에 없음\n\n\n```python\ndef twoSumII(numbers, target):\n    low, high = 0, len(numbers)-1\n    cand = 0\n    while low < high:\n        cand = numbers[low] + numbers[high]\n        if cand == target:\n            return [low+1, high+1]  # the problem is 1-indexed.\n        elif cand < target:\n            low += 1\n        else:\n            high -= 1\n\n    raise ValueError\n```\n\n\n# [Two Sum IV - Input is a BST](https://leetcode.com/problems/two-sum-iv-input-is-a-bst/)\n\n 만약 입력이 배열이 아니라 BST면 어떻게 해야할까?\n\n 역시 앞의 두 접근을 모두 사용할 수 있는데,\n  1. BST를 한번 순회하면서 보수의 해시 테이블을 만든 다음, 다시 한번\n     BST를 순회하면서 해시 테이블을 확인하는 방법과,\n  2. BST로부터 정렬된 배열을 복원한 뒤 투 포인터로 확인하는 방법\n\n 두 가지가 모두 가능하다. BST를 중위순회하면 정렬된 순서로 노드를\n 방문할 수 있다는 성질을 이용한 2번 접근을 코드로 구현하면 다음과\n 같다.\n\n```python\ndef findTarget(root, k):\n    ordered = []\n    def inorder(node):\n        if not node:\n            return\n        inorder(node.left)\n        ordered.append(node.val)\n        inorder(node.right)\n    inorder(root)\n\n    low, high = 0, len(ordered)-1\n    while low < high:\n        cand = ordered[low] + ordered[high]\n        if cand == k:\n            return True\n        elif cand < k:\n            low += 1\n        else:\n            high -= 1\n    return False\n```"
					}
					,
					"ps-leetcode-ugly-number": {
						"id": "ps-leetcode-ugly-number",
						"title": "Ugly Number",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/ugly-number/",
						"content": "# [Ugly Number](https://leetcode.com/problems/ugly-number/)\n\n **못생긴 숫자**란 소인수가 오직 2, 3, 5로 한정되는 양의 정수를\n 뜻한다.\n\n 어떤 수 `n`이 주어졌을 때 이게 못생긴 숫자인지 판단하자.\n\n 예를 들어, 6은 소인수가 2와 3 뿐이므로 못생긴 숫자이다. 1은 소인수가\n 없으므로 그 자체로 못생긴 숫자이다. 반면 14는 소인수 7을 포함하므로\n 못생긴 숫자가 아니다.\n\n 입력의 범위는 32비트 정수 전체이다.\n\n## 정직하게 구현하기\n - 문제의 조건을 잘 읽고 정직하게 잘 구현하면 되는 문제다.\n - 일단 조건에 따라 *양의 정수*이므로 0보다 작거나 같은 모든 수는\n   초장에 제외해버릴 수 있다.\n - 소인수 목록 2, 3, 5에 대해서 이제 `n`이 나누어 떨어지는 동안 계속\n   그 수로 나눠준다.\n - 최종적으로 남은 수 `n`이 1이면 2, 3, 5로만 모두 나누어떨어졌다는\n   의미이고 1이 아니면 다른 소인수가 있다는 의미이다.\n\n```python\ndef isUgly(n):\n    if n <= 0:\n        return False\n    for p in [2, 3, 5]:\n        while n % p == 0:\n            n = n // p\n    return n == 1\n```"
					}
					,
					"ps-leetcode-unique-paths": {
						"id": "ps-leetcode-unique-paths",
						"title": "Unique Paths",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/unique-paths/",
						"content": "# [Unique Paths](https://leetcode.com/problems/unique-paths/)\n `m x n` 격자판이 주어지고 왼쪽 제일 위에 로봇이 있다. 로봇은 한 번에\n 한 칸 오른쪽 또는 아래로 움직일 수 있다. 최종적으로는 오른쪽 제일\n 아래로 가려고 한다. 이때 가능한 \"유니크 경로\"의 개수는?\n\n 예를 들어, `m = 3`, `n = 2` 라고 하자. 그러면 가능한 경우는 총 세\n 가지이다.\n  1. 오른쪽 -> 아래 -> 아래\n  2. 아래 -> 아래 -> 오른쪽\n  3. 아래 -> 오른쪽 -> 아래\n\n## Brute Force\n 먼저 무식하게 풀어보자. 시작 지점을 `(1, 1)`, 도착 지점을 `(m, n)`\n 으로 모델링하자. 한 번에 아래 또는 오른쪽으로만 움직일 수 있다.\n\n 예를 들어, 다음과 같은 `3 x 2` 격자를 생각해보자. 아래 각 튜플은\n 격자의 좌표를 나타낸다.\n\n```python\n(1, 1) (1, 2)\n(2, 1) (2, 2)\n(3, 1) (3, 2)\n```\n\n `(1, 1)` 에서 출발해서 `(3, 2)`에 도착하는 게 목표다. 그럼 `(3, 2)`로\n 올 수 있는 가지 수는 몇 개일까?\n\n```python\n|   |   |\n|   | u |\n| l |l+u|\n```\n\n 한 턴에 가능한 움직임이 오른쪽과 아래쪽 밖에 없으므로, 위쪽으로 올\n 경우의 수 `u`와 왼쪽으로 올 경우의 수 `l`을 합한것 과 같다.\n\n 이런식으로 재귀적으로 거꾸로 거슬러 계산하면 구해질 것 같다. 그럼\n Base Case는 뭘까? 만약 출발 지점에서 출발하는 그림을 생각해보면,\n 아래와 같이 테두리, 즉 오른쪽으로만 or 아래로만 움직이는 경우는\n 가능한 경우가 1개 뿐이다.\n\n\n```python\n|   | 1 |\n| 1 |   |\n| 1 |   |\n```\n\n 따라서 Base Case는 둘 중 하나라도 `1`일 때, 가능한 경우의 수가\n `1`개임을 뜻한다.\n\n 이걸 코드로 구현하면 다음과 같다.\n\n```python\ndef unique_paths(m, n):\n    def pathof(x, y):\n        if x == 1 or y == 1:\n            return 1\n        return pathof(x-1, y) + pathof(x, y-1)\n    return pathof(m, n)\n```\n\n\n## 메모아이제이션\n Brute Force는 알았으니 좀더 복잡도를 줄여보자. 더 큰 격자를\n 생각해보면 중복되는 부분이 있음을 알 수 있다. 예를 들어 다음과 같이\n 큰 격자가 있을 때,\n\n```python\n|   |   |   |   |   |\n|   |   |   | p | u |\n|   |   |   | l | g |\n```\n\n 도착지점인 `g`의 값을 알아내기 위해서는 `u`, `l`을 알아야\n 한다. 그런데 가능한 움직임이 오른쪽/아래쪽 뿐이므로, `u`도 `p`위치의\n 값이 필요하고 `l`도 `p` 위치의 값이 필요하다. 즉, `p`를 위한 계산이\n 중복된다.\n\n 따라서, 아래와 같이 이전 결과를 캐싱해두면 더 빠른 결과를 얻을 수\n 있다.\n\n```python\nfrom functools import cache\n\ndef unique_paths(m, n):\n    @cache\n    def pathof(x, y):\n        if x == 1 or y == 1:\n            return 1\n        return pathof(x-1, y) + pathof(x, y-1)\n    return pathof(m, n)\n```"
					}
					,
					"ps-leetcode-valid-anagram": {
						"id": "ps-leetcode-valid-anagram",
						"title": "Valid Anagram",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/valid-anagram/",
						"content": "# [Valid Anagram](https://leetcode.com/problems/valid-anagram/)\n\n 두 문자열이 주어졌을 때, 한 쪽이 다른 한 쪽의 애너그램인지를\n 확인하자.\n\n **애너그램**이란 원래 문자열에 있는 글자를 딱 한번씩만 쓰되 순서를\n 재배치해서 다른 문자열을 만드는 것이다.\n\n 문자열의 길이는 $$ 1 \\sim 5 \\times 10^4 $$이고 소문자 알파벳만 담고\n 있다.\n\n## 걍..센다\n\n 별 거 없다. 그냥 각 문자열에 나온 글자 수를 세서 동일한지만 확인하면\n 된다. 마침 파이썬에는 카운터라는 걸출한 녀석이 있고 이걸 그대로 쓰면\n 된다.\n\n```python\nfrom collections import Counter\ndef isAnagram(s, t):\n    return Counter(s) == Counter(t)\n```\n\n---\n\n 만약 카운터를 쓰지 않고 일일이 세겠다면 말리진 않겠지만 다음과 같이\n 하면 된다.\n\n```python\nfrom collections import defaultdict\ndef isAnagram(s, t):\n    if len(s) != len(t):\n        return False\n\n    sc, tc = defaultdict(int), defaultdict(int)\n    for c in s:\n        sc[c] += 1\n    for c in t:\n        tc[c] += 1\n    for c in sc:\n        if sc[c] != tc[c]:\n            return False\n    return True\n```\n\n - 문자열의 글자 수를 일일이 세어서 비교한다. 이때, 마지막 루프문에서\n   `sc`에 없는 키 값이 `tc`에 있을 수도 있는데, 그런 경우를 미리\n   걸러내기 위해서 함수 진입 초기에 길이가 다르면 `False`를 리턴하도록\n   했다."
					}
					,
					"ps-leetcode-valid-palindrome": {
						"id": "ps-leetcode-valid-palindrome",
						"title": "Valid Palindrome",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/valid-palindrome/",
						"content": "# [Valid Palindrome](https://leetcode.com/problems/valid-palindrome/)\n\n 어떤 문장이 주어졌을 때, 모든 문장의 알파벳을 소문자로 바꾸고 알파벳\n 또는 숫자가 아닌 모든 글자를 다 지워버린 문자열이 팰린드롬일 때, 해당\n 문장은 팰린드롬이라고 정의한다.\n\n 어떤 문장이 팰린드롬인지 아닌지를 확인하자.\n\n 문장의 길이는 $$ 1 \\sim 2 \\times 10^5$$ 이고 문장은 모든 가능한\n 아스키코드 글자를 담고 있다.\n\n## 구현\n - 부분 문자열 중에서 팰린드롬의 개수를 세는 그런 복잡한 것도 아니고\n   그냥 쌩 문자열이 팰린드롬인지 아닌지 확인하면 되는데, 정방향 문자와\n   역방향 문자가 같은지 보면 된다.\n - (1) 문자열의 알파벳을 전부 소문자로, (2) 문자열에서 알파벳 또는\n   글자가 아닌 글자는 모두 지워버리는, 두 단계의 정규화가 필요하다.\n - 정규화는 복잡하게 생각하지 말고 파이썬의 `isalnum()`을\n   쓰자. 아스키코드를 확인해도 된다.\n - 정규화 -> 팰린드롬 인지 확인 하면 된다.\n\n\n```python\ndef isPalindromePhrase(s):\n    norm = [c.lower() for c in s if c.isalnum()]\n    normed = ''.join(norm)\n    return normed == normed[::-1]\n```"
					}
					,
					"ps-leetcode-valid-parentheses": {
						"id": "ps-leetcode-valid-parentheses",
						"title": "Valid Parentheses",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/valid-parentheses/",
						"content": "# [Valid Parentheses](https://leetcode.com/problems/valid-parentheses/)\n\n `(){}[]` 괄호만 담고있는 문자열이 주어졌을 때, 이 입력 문자열이\n 유효한지 검사하자.\n - 열린 괄호는 반드시 같은 종류의 닫힌 괄호와 짝이 맞아야 한다.\n - 괄호는 반드시 열린 순서대로 닫혀야 한다.\n\n 문자열의 길이는 1~10,000이다.\n\n 예를 들어, `()`는 유효하고 `{]`는 유효하지 않다.\n\n## 스택\n\n 괄호 문제는 스택과 문자열을 섞은 근본있는 문제다. 스택에는 열린\n 괄호만 추가하면서 지금 커서가 닫힌 괄호를 만났을 때 짝이 맞으면\n 제거한다. 그렇지 않으면 다음 세 가지 예외 케이스를 처리하면서\n 짝맞추기를 해나가면 된다.\n 1. 스택은 비었는데 닫힌 괄호를 만난 경우 (예: `())`)\n 2. 스택의 꼭대기에 있는 괄호랑 짝이 맞지 않는 경우 (예: `(]`)\n 3. 모든 문자열을 다 검사했는데도 스택이 비어있지 않은 경우 (예: `()(`)\n\n```python\ndef isValid(s):\n    stack = []\n    opens = set([\"(\", \"[\", \"{\"])\n    closedmap = {\"(\": \")\", \"[\": \"]\", \"{\": \"}\"}\n    for p in s:\n        if p in opens:\n            stack.append(p)\n        else:\n            if not stack or closedmap[stack[-1]] != p:\n                # handle 1 and 2\n                return False\n            else:\n                stack.pop()\n    return not stack # handle 3\n```\n\n - 조금이라도 빠르게 열린 괄호인지 확인하기 위해서 해시 셋을 썼다.\n - 스택의 꼭대기에 있는 열린 괄호와 지금 만난 닫힌 괄호가 짝이\n   맞는지를 빠르고 읽기 쉽게 확인하기 위해서 해시 테이블을 썼다.\n - 마지막 리턴 시에 스택이 비어있는지를 확인해야 하는데, 파이썬에서는\n   `not` 키워드를 붙여서 강제로 불리언으로 타입 캐스팅을 했다."
					}
					,
					"ps-leetcode-valid-word-abbreviation": {
						"id": "ps-leetcode-valid-word-abbreviation",
						"title": "Valid Word Abbreviation",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/valid-word-abbreviation/",
						"content": "# [Valid Word Abbreviation](https://leetcode.com/problems/valid-word-abbreviation/)\n\n 생각보다 함정이 많아서 문제의 조건을 꼼꼼하게 따져서 하나 씩 검사해야 한다.\n\n 1. 요약어의 숫자가 0으로 시작하면 안됨\n 2. 요약 숫자 개수만큼만 스킵해야 함\n 3. 요약어와 단어가 정확히 매칭되어야 함\n\n\n 세 가지 조건에 주의하면서 구현하면 다음과 같다.\n\n```c++\nbool validWordAbbreviation(string word, string abbr) {\n  int wi = 0, ai = 0;\n  while (wi  0 && number[0] == '0') return false;\n\n    int count = stoi(number);\n    // 2.\n    if (wi + count > word.size()) return false;\n    wi += count;\n  }\n\n  // 3.\n  return (wi == word.size() && ai == abbr.size());\n}\n```"
					}
					,
					"ps-leetcode-validate-binary-search-tree": {
						"id": "ps-leetcode-validate-binary-search-tree",
						"title": "Validate Binary Search Tree",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/validate-binary-search-tree/",
						"content": "# [Validate Binary Search Tree](https://leetcode.com/problems/validate-binary-search-tree/)\n\n BST로 추정되는 트리의 루트 노드가 주어졌을 때, 이게 진짜 BST인지\n 확인하자.\n\n BST는 다음의 Search Property를 만족해야 한다:\n - 노드의 왼쪽 서브트리는 노드의 키 값보다 작은 값만 담아야 한다.\n - 노드의 오른쪽 서브트리는 노드의 키 값보다 큰 값만 담아야 한다.\n - 왼쪽과 오른쪽 서브트리도 역시 위의 조건을 재귀적으로 만족해야 한다.\n\n 노드의 개수는 1~10,000개, 노드의 값은 32비트 정수가 포함할 수 있는\n 모든 범위에 걸쳐 있다.\n\n## 재귀적으로 범위 나누기\n\n 노드를 중심으로 범위를 나눈다고 생각해보자. 조건에 따라 왼쪽\n 서브트리의 모든 노드의 키 값은 현재 노드의 키 값보다 작아야\n 한다. 오른쪽 서브트리는 이와 반대로 커야 한다. 이걸 범위로\n 생각해보자. 초기의 범위는 $$ [-\\infty, \\infty] $$ 이다. 루트는 항상\n 이 범위 안에 들어간다. 루트를 기준으로 왼쪽 서브트리의 범위는 조건에\n 따라 $$ [-\\infty, root.val) $$이 된다. 자연스럽게 오른쪽 서브트리의\n 범위는 $$ (root.val, \\infty] $$ 임을 알 수 있다. 이런식으로\n 재귀적으로 범위를 계속 쪼개가면서, 현재 노드의 값이 이 범위 안에\n 들어가는지를 확인하면 Search Property를 만족하는지 알 수 있다.\n\n```python\ndef isValidBST(root):\n    def validate(node, low=float('-inf'), high=float('inf')):\n        if node is None:\n            return True\n        return (low  오른쪽으로 이뤄지고, 루트 노드를 언제\n 방문할 것인지에 따라 다음 세 가지가 있다.\n - Preorder: root -> left -> right\n - Inorder: left -> root -> right\n - Postorder: left -> right -> root\n\n 이때 트리가 BST라면, Inorder 순위는 자연스럽게 Search Property를\n 만족하는 정렬된 순서로 노드를 방문하게 된다. 이 성질을 이용해보자.\n\n 먼저 이전 값을 저장해둘 필요가 있다. 초기값은 $$-\\infty$$이다. 이\n 값은 항상 32비트 최소값보다 작으므로 트리에 어떤 값이 담겨 있든 중위\n 순회의 첫번째 방문 노드의 키 값보다 작을 것이다. 이후 중위 순회\n 순서대로 진행하면서, 이 이전 값보다 지금 노드 값을 비교하고\n 업데이트한다. 이렇게 끝까지 진행하면서 하나라도 순서가 이상한게\n 있는지 체크하면 된다.\n\n```python\ndef isValidBST(root):\n    prev = float('-inf')\n    def inorder(node):\n        nonlocal prev\n        if node is None:\n            return True\n\n        if not inorder(node.left):\n            return False\n\n        if not (prev < node.val):\n            return False\n\n        prev = node.val\n        return inorder(node.right)\n    return inorder(root)\n```\n\n - 파이썬은 Expression 안에 Assignment를 쓸 수 없다. 그래서 리턴\n   한줄에 조건을 우겨넣으면서 동시에 `prev` 값을 업데이트할 수\n   없다. 위 코드처럼 하나씩 차근차근 해결하자.\n - 중위 순회의 정의에 따라 왼쪽을 먼저 확인하고, 그 다음 지금 노드를\n   체크한다. 이때 반드시 `prev` 값을 업데이트해줘야 한다. 그래야\n   올바른 체크가 된다."
					}
					,
					"ps-leetcode-walking-robot-simulation": {
						"id": "ps-leetcode-walking-robot-simulation",
						"title": "Walking Robot Simulation",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/walking-robot-simulation/",
						"content": "# [Walking Robot Simulation](https://leetcode.com/problems/walking-robot-simulation/)\n\n 무한한 XY 좌표평면 공간의 (0, 0)에서 북쪽을 향하고 있는 로봇이\n 있다. 로봇은 세 종류의 `commands`가 가능하고, 이런 커맨드의 시퀀스를\n 받을 수 있다:\n - `-2`: 왼쪽으로 90도 회전\n - `-1`: 오른쪽으로 90도 회전\n - `1  동 -> 남 -> 서` 방향의 가속도 배열을 만들면, 90도\n 왼쪽 회전은 `(curdir - 1) % 4`, 90도 오른쪽 회전은 `(curdir + 1) %\n 4`로 쉽게 계산할 수 있다.\n\n```python\ndef robotSim(commands, obstacles):\n    x, y = 0, 0\n    acc = [(0,1), (1,0), (0,-1), (-1,0)]\n    curdir = 0\n    obstacles = set([(o[0], o[1]) for o in obstacles])\n    maxdis = 0\n    for cmd in commands:\n        if cmd == -2:\n            curdir = (curdir - 1) % 4\n            continue\n        if cmd == -1:\n            curdir = (curdir + 1) % 4\n            continue\n\n        for _ in range(cmd):\n            nx = x + acc[curdir][0]\n            ny = y + acc[curdir][1]\n            if (nx, ny) in obstacles:\n                break\n            x, y = nx, ny\n            maxdis = max(maxdis, x**2 + y**2)\n    return maxdis\n```\n\n - 장애물 여부를 빠르게 체크하기 위해서 해시셋을 이용했다. 파이썬에서\n   리스트는 해싱이 불가능하므로, 장애물 좌표를 튜플로 만든 후 `set()`\n   연산을 이용해 해시셋으로 바꾼다.\n - 전진 커맨드의 경우 `k` 만큼 껑충 뛰면 장애물에 부딪히는지 여부를\n   알기 힘들기 때문에, 여기서는 단순히 한 칸씩 전진하면서 매번 장애물\n   충돌 체크를 했다.\n\n---\n\n 여기서 최적화할 여지가 있는 부분은 장애물 충돌 체크 부분일\n 것이다. `k`가 최대 9이기 때문에, 로봇이 `k`만큼 전진할 수 있는 거리\n 안에 장애물이 있는지를 확인한다면 매번 for 반복문을 돌지 않고 한번에\n 껑충 뛸 수 있을 것 같다. 하지만 이건 귀찮아서 나중에..."
					}
					,
					"ps-leetcode-web-crawler": {
						"id": "ps-leetcode-web-crawler",
						"title": "Web Crawler",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/web-crawler/",
						"content": "{% raw %} Web Crawler\n문제의 요구사항 자체는 간단한 그래프 탐색 문제이다.\n만약 실제 업무에서 크롤러를 구현하게 된다면 탐색 공간이 엄청나게 커지기 때문에\n  고려해야 할 것이 많다. 예를 들어, 같은 호스트 네임을 갖는 웹 사이트마다 다른\n  속도, 링크가 무한히 이어지는 경우, 등을 고려할 수 있다. 그래서 보통은 서로 다른\n  도메인에는 DFS를 이용하고 같은 도메인에서는 BFS를 이용한다. 추가로 방문 체크를\n  위해서 해시 셋 이전에 블룸 필터 같은 것을 두기도 한다.\ndef crawl(startUrl: str, htmlParser: &#39;HtmlParser&#39;) -&gt; List[str]:\n    hostname = &#39;http://&#39; + startUrl[len(&#39;http://&#39;):].split(&#39;/&#39;, 1)[0]\n    results = [startUrl]\n\n    visited, q = set(), deque()\n    visited.add(startUrl)\n    q.append(startUrl)\n    while q:\n        url = q.popleft()\n        for follow in htmlParser.getUrls(url):\n            if follow in visited or not follow.startswith(hostname):\n                continue\n            visited.add(follow)\n            q.append(follow)\n            results.append(follow)\n    return results\n\n {% endraw %}"
					}
					,
					"wip-why-numbering-should-start-at-zero": {
						"id": "wip-why-numbering-should-start-at-zero",
						"title": "Why numbering should start at zero",
						"version": "all",
						"categories": "",
						"url": " /wip/why-numbering-should-start-at-zero/",
						"content": "# [왜 인덱스는 0에서 시작해야 하는가?](https://www.cs.utexas.edu/users/EWD/transcriptions/EWD08xx/EWD831.html)\n\n 위대하신 다익스트라님의 포스트를 번역해보았다.\n\n 자연수의 시퀀스 `2, 3, ..., 12`를 `...` 없이 표현하기 위해서, 네 가지\n 방법이 가능하다.\n\n 1. $$ 2 \\leq i  다른 종교와 마찬가지로, 이단자는 그가 틀렸을 가능성 때문이 아니라\n> 그가 옳을 가능성 때문에 추방되어야 한다.\n\n\n---\n\n 참고로 이 글은 1982년, 그러니까 대략 40년 전의 글이다. 그때는\n 다익스트라가 이런 글을 쓸 정도로, 0부터 인덱스를 세는 것이\n 메인스트림이 아니었나보다. 지금와서는 대부분의 언어가 다 0부터\n 인덱스를 세고 있고 되려 1-인덱스가 드문 편이니 참으로\n 격세지감. 찾아보니 놀랍게도 나름 최신 언어인 줄리아가 1-인덱스인 것\n 같은데, R이나 매스매티카와 비슷하게 줄리아도 계산과학에 치중한\n 언어라서 Matrix 연산을 자유롭게 표현하기 위함인 것 같다.\n\n\n 그리고 한번도 생각해본적 없었는데 0-인덱스와 하한포함-상한제외 범위를\n 쓰면 `인덱스 = 해당 원소 앞까지의 개수`가 성립한다는 점도 흥미로웠다."
					}
					,
					"ps-leetcode-wiggle-subsequence": {
						"id": "ps-leetcode-wiggle-subsequence",
						"title": "Wiggle Subsequence",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/wiggle-subsequence/",
						"content": "# [Wiggle Subsequence](https://leetcode.com/problems/wiggle-subsequence/)\n\n **흔들 배열(wiggle subsequence)**이란 배열에서 연속적인 수들 사이의\n 차이가 정확히 양수와 음수를 반복하는 배열을 뜻한다. 첫 번째 차이는\n (만약 있다면) 양수든 음수든 다 가능하다. 하나의 원소만 있는 배열과 두\n 개의 서로 다른 원소를 갖는 배열은 따라서 모두 흔들 배열이다.\n - 예를 들어, `[1, 7, 4, 9, 2, 5]` 배열은 흔들 배열이다. 원소의 차이가\n   `[6, -3, 5, -7, 3]`으로 양수와 음수를 반복하기 때문이다.\n - `[1, 4, 7, 2, 5]`와 `[1, 7, 4, 5, 5]`는 흔들 배열이 아니다.\n\n **부분열(subsequence)**은 배열에서 0개 이상의 원소를 삭제하고\n 나머지는 원래 순서 그대로 남겨서 얻을 수 있다.\n\n 정수 배열 `nums`가 주어졌을 때, 가장 긴 흔들 부분열의 길이를 구하자.\n\n 정수 배열의 크기는 1 ~ 1,000 사이이고 각 배열의 값은 0 ~ 1,000\n 사이이다.\n\n## 탐욕 접근\n\n 정답이 부분배열(subarray)가 아니라 부분열(subsequence)라서,\n 탐욕적으로 접근해도 될 것 같다. 그러니까 처음부터 시작해서 흔들리는\n 조건을 만족하지 않으면 버리고, 만족하면 취하는 방식으로 해도 될 것\n 같다.\n\n 일단 자명한 케이스부터 걸러내자. 조건에 따라 길이가 1이면 곧바로 흔들\n 배열이다. 2인 경우에는 두 원소가 서로 다른 경우에만 흔들 배열이다. 3\n 이상의 배열에 대해서는, 일단 앞의 두 원소의 차이가 양수인지\n 음수인지에 따라서 달라진다. 우리는 (중간 원소를 버려서) 부분열을\n 취하여 가장 길이가 긴 것을 만들고 싶기 때문에, 흔들리는 조건을 체크할\n 때 맨 앞의 두 원소가 양수인지 음수인지 중요하다. 왜냐하면 맨 앞의\n 원소가 흔들리는 조건을 만족하면 이 두 원소는 길이가 가장 긴 부분열에\n 반드시 포함될 것이기 때문이다.\n\n 아무튼 자명한 케이스를 걸러내고 맨 앞의 두 원소가 음수인지 양수인지를\n 알면, 그 이후는 모든 원소를 다 돌면서 이 조건을 계속 만족한다면\n 취하고, 그렇지 않으면 거르면 된다.\n\n```python\ndef wiggleMaxLength(nums):\n    if len(nums)  0 and prev = 0):\n            maxlen += 1\n            prev = diff\n    return maxlen\n```\n - 처음에 `prev`가 `0`이면 맨 앞의 두 원소가 같다는 의미이므로 이때의\n   초기값은 1이다. 즉, 원소가 같은 부분은 다 퉁쳐서 하나의 원소가 되는\n   것이다.\n - 비슷하게, 지금 확인 중인 차이(`diff`)가 음수 또는 양수라면 이전\n   차이(`prev`)는 엄밀하게 음수 또는 양수가 아니라 0이어도 된다. 예를\n   들어 `[3, 3, 3, 3, 1]` 에서 `i = 4`에서 `diff < 0`이지만 `prev =\n   0`이므로 무시되었던 부분(= 다 같은 부분 배열)을 하나의 원소(=마지막\n   원소)로 취급하여 올바른 계산을 하게 된다."
					}
					,
					"ps-leetcode-wildcard-matching": {
						"id": "ps-leetcode-wildcard-matching",
						"title": "Wildcard Matching",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/wildcard-matching/",
						"content": "# [Wildcard Matching](https://leetcode.com/problems/wildcard-matching/)\n\n 입력 단어 `s`와 패턴 `p`가 주어진다. 패턴은 다음 와일드 카드를\n 포함한다.\n - `?`는 모든 글자 하나랑 매칭된다.\n - `*`는 빈 글자를 포함한 모든 문자열과 매칭된다.\n\n 주어진 패턴이 주어진 단어 전체를 매칭할 수 있는지 체크하는 함수를\n 구현하자.\n\n 단어와 패턴의 길이는 0~2,000 사이이다. 단어는 알파벳 소문자만\n 포함한다. 패턴은 알파벳 소문자와 `?`, `*`만 포함한다.\n\n## 접근 아이디어\n 두 개의 인덱스를 가지고 패턴과 단어를 동시에 확인한다고 하자. 패턴에\n `?`가 있거나 혹은 현재 위치에서의 패턴과 단어의 글자가 같으면 계속\n 진행한다. 그러다가 처음으로 이 조건을 만족하지 않는 위치에 도달하게\n 될 것이다. 이때 가능한 경우는 네 가지이다.\n\n 1. 패턴과 단어가 매칭되지 않는 경우. 단순하게 그냥 두 위치의 글자가\n    다른 경우이다.\n 2. 패턴의 끝에 도달한 경우. 패턴에 `*`가 하나도 없는 경우이다. 패턴의\n    길이와 단어의 길이가 매칭된다.\n 3. 단어의 끝에 먼저 도달한 경우. 패턴이 아직 남아 있고, 남은 패턴에\n    `*`가 있다면 매칭될 수도 있기 때문에 살펴봐야 한다.\n 4. 패턴 위치에 `*`가 있는 경우. `*`가 몇 글자에 대응할지 알 수 없기\n    때문에, **가능한 모든 경우**를 일일이 시도해봐야 한다. 패턴\n    인덱스는 `*` 만큼 하나 진행하고, 단어 인덱스는 다시 처음부터\n    시도해봐야 한다.\n\n## 오답 노트 - 완전 탐색\n - 네 가지 케이스를 일단 다 구현해본다.\n - 당연하지만 모든 상태 공간을 다 탐색하기 때문에 타임아웃이 뜬다.\n - 캐싱할 만한 부분 최적 구조도 없다.\n\n```python\ndef isMatch(s, p):\n    pos = 0\n    while pos < len(p) and pos < len(s) and (p[pos] == '?' or p[pos] == s[pos]):\n        pos += 1\n\n    # case 2\n    if pos == len(p):\n        return pos == len(s)\n\n    if p[pos] == '*':\n        # case 3, 4\n        skip = 0\n        while pos + skip <= len(s):\n            if isMatch(s[pos+skip:], p[pos+1:]):\n                return True\n            skip += 1\n\n    return False # case 1, 3\n```\n\n## 접근 1 - 캐싱\n\n - 완전 탐색은 패턴에 `*`가 많을수록 기하 급수적으로 느려진다.\n - 완전 탐색 접근을 개선해보자.\n - 첫번째 반복에서 항상 앞부분을 확인하기 때문에 단어와 패턴은 모두\n   접미사가 된다.\n - 문제의 조건에 따라 단어와 패턴 길이가 각각 최대 2,000 이므로\n   접미사의 개수는 최대 $$ 2001 \\times 2001 = 4004001 $$ 이 되고 재귀\n   호출이 이 횟수 이상 호출되면 부분 문제가 반드시 존재한다는 뜻이다.\n - 예를 들어 패턴이 `****a` 이고 단어가 `aaaaaaaaab` 이면 접미사\n   개수에 따라 $$ 6 \\times 11 = 66$$ 번 이상 재귀 호출이 일어나면\n   반복되는 부분 문제가 있다는 것이다. 그런데 첫번째 `*`를\n   처리하는데(`skip = 0`)에만 해도 이미 같은 단어(`s[pos + 0:]`)에\n   대해서 6번의 재귀 호출을 하고 각각의 재귀는 패턴의 접미사들에\n   대해서 검사를 해야하기 때문에, 무조건 반복되는 부분 문제가 있다.\n - 서로 다른 인덱스를 가지고 재귀 호출을 타면 좀더 캐싱하기 좋다.\n - 단어와 패턴의 길이를 N이라고 하면 부분 문제의 최대 개수는 $$ N^2 $$\n   이다. 이를 캐싱해두면 한번 호출될 때마다 최대 N번 재귀 호출하므로\n   복잡도는 $$O(N^3)$$.\n\n```python\ndef isMatch(s, p):\n    @cache()\n    def match(si, pi):\n        while pi < len(p) and si < len(s) and (p[pi] == '?' or p[pi] == s[si]):\n            si += 1\n            pi += 1\n\n        if pi == len(p):\n            return si == len(si)\n\n        if p[pi] == '*':\n            skip = 0\n            while si + skip <= len(s):\n                if match(si + skip, pi + 1):\n                    return True\n                skip += 1\n        return False\n```\n\n## 접근 2 - 똑똑한 캐싱\n - 패턴에서 처음으로 `*`를 찾았을 때, 여기에 몇 글자를 매칭할지 (=\n   스킵할지) 반복으로 구하기 떄문에 추가적인 복잡도 N이 소요되고 있다.\n - 몇 글자가 매칭되던 결과는 변하지 않는다.\n - 따라서 이거도 캐싱해서 복잡도를 $$O(N^2)$$으로 낮출 수 있다.\n - 이렇게 부분 최적 구조를 활용할 때에는 재귀 함수 안에서 반복문을\n   쓰지말고 되도록 귀납적으로 계산해서 메모아이제이션을 활용하자.\n\n\n```python\ndef isMatch(s, p):\n    @cache()\n    def match(si, pi):\n        if pi < len(p) and si < len(s) and (p[pi] == '?' or p[pi] == s[si]):\n            # 스킵하지말고 결과를 모두 캐싱함\n            return match(si + 1, pi + 1)\n\n        if pi == len(p):\n            return si == len(si)\n\n        if p[pi] == '*':\n            # 여기서도 스킵하지 말고 결과를 모두 캐싱함\n            # (si, pi + 1): 매칭 안함\n            # (si + 1, pi): 글자 하나 매칭. 이후 재귀에서 또 (매칭 안함, 하나 매칭) 하므로 모든 경우가 커버됨\n            if match(si, pi + 1) or (si < len(s) and match(si + 1, pi)):\n                return True\n\n        return False\n```"
					}
					,
					"ps-leetcode-word-search": {
						"id": "ps-leetcode-word-search",
						"title": "Word Search",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/word-search/",
						"content": "# [Word Search](https://leetcode.com/problems/word-search/)\n\n `m x n` 크기의 글자 보드 `board`와 단어 `word`가 주어진다. 보드에 이\n 단어가 있는지 없는지를 확인하자.\n\n 단어는 인접한 칸에 있는 글자를 연결해서만 만들 수 있다. 인접한 칸이란\n 어떤 칸을 기준으로 위, 아래, 오른쪽, 왼쪽에 있는 이웃 칸을\n 뜻한다. 글자를 만들 때는 같은 칸을 두 번 이상 쓸 수 없다.\n\n m, n은 모두 1~6 사이의 값이고 단어의 길이는 15이다. 모두 알파벳\n 소문자로 이루어져 있다.\n\n## 백트래킹\n\n 보드를 탐색하는 백트래킹 문제이다. 어디서 글자가 완성될지 모르기\n 때문에 보드를 전부 다 훑긴 해야한다. 하지만 목표가 딱 정해져있기\n 때문에, 즉 \"단어\"를 완성하는 것이기 때문에, 많은 탐색 공간을 프루닝할\n 수 있다.\n\n 백트래킹 함수 `backtrack(row, col, wid)`에 대해서, 베이스 케이스를\n 생각해보자. `(row, col)`은 지금 상태에서 방문할 보드의 위치이고,\n `wid`는 지금까지 매칭된 단어의 인덱스이다.\n - 단어를 끝까지 다 훑었으면 당연히 `True`이다.\n - 보드 위치가 보드 사이즈를 벗어났으면 더 이상 단어를 매칭할 수\n   없다는 의미이므로 `False`이다.\n - 이제 가능한 다음 칸을 모두 재귀적으로 찾을 것인데, 도중에 단어가\n   매칭되었다면 더 이상 다른 공간을 탐색할 필요가 없다. 바로 `True`를\n   리턴하면 된다.\n\n 단, 한 가지 주의할 점은 조건에 따라 단어를 만들 때 **같은 칸을 두 번\n 이상 쓸 수 없다**는 점이다. 이것은 까다롭게 구현할 필요없이,\n 백트래킹을 시작하기 전 지금 방문한 칸의 글자를 다른 글자(`#` 같은)로\n 잠깐 수정했다가, 백트래킹이 끝나고 나면 다시 원복하는 방법이 주로\n 쓰인다.\n\n 이 방법을 구현하면 다음과 같다.\n\n```python\ndef exist(board, word):\n    n, m = len(board), len(board[0])\n\n    def backtrack(row, col, wid):\n        if wid == len(word):\n            return True\n\n        if row = n or col = m:\n            return False\n\n        if board[row][col] != word[wid]:\n            return False\n\n        board[row][col] = '#'\n        res = False\n        for dx, dy in ((1, 0), (0, 1), (-1, 0), (0, -1)):\n            res = backtrack(row + dx, col + dy, wid + 1)\n            if res:\n                break\n        board[row][col] = word[wid]\n        return res\n\n    for row in range(n):\n        for col in range(m):\n            if backtrack(row, col, 0):\n                return True\n    return False\n```\n\n---\n\n 여기서 보드가 엄청 커졌을 때 추가적인 프루닝을 할 수 있을까? 몇 가지\n 떠오르는 방법은 다음과 같은 것들이 있다:\n - 사이즈 체크. `n * m` 보다 단어 길이가 크면 불가능하기 때문에 곧바로\n   `False`이다. 그런데 이건 보드 사이즈가 커졌을 때에는 별로 소용이\n   없을 것 같다.\n - 알파벳 체크. 보드에 있는 글자 집합에 단어에 있는 글자 집합이\n   속하는지를 확인하면 곧바로 `False`인 경우를 알 수 있다. 즉, 단어에\n   있는 글자 중 일부가 보드에 속하지 않는다면, 어차피 보드를\n   탐색해봐도 소용없음을 알 수 있다.\n - 탐색하면서 알파벳 체크. 아무리 생각해도 보드가 커졌을 때 가능한\n   프루닝은 이 방법 뿐이다. 어차피 보드 전체를 한번은 탐색해야\n   한다. 그러면 보드 전체에 대해서 백트래킹을 하기 전에, 보드 전체에\n   대해서 각 칸이 가망있는 칸인지, 즉 단어에 포함되는 글자인지를 미리\n   계산해둘 수 있다. 그러면 다시 전체 보드 칸에 대해서 각각 백트래킹을\n   할 때, 다음 칸이 가망있을 때에만 가면 된다.\n\n# [Word Search II](https://leetcode.com/problems/word-search-ii/)\n\n `m x n` 크기의 글자 보드 `board`와 단어 목록 `words`가\n 주어진다. 이때, 단어 목록에 포함되면서 보드에서 만들 수 있는 모든\n 단어 목록을 구하자.\n\n 각각의 단어는 인접한 칸에 있는 글자를 연결해서만 만들 수 있다. 인접한\n 칸이란 어떤 칸을 기준으로 위, 아래, 왼쪽, 오른쪽에 있는 이웃 칸을\n 뜻한다. 같은 글자 칸은 한 단어를 만드는데 딱 한번만 쓰일 수 있다.\n\n 보드와 단어는 모두 알파벳 소문자로만 이뤄진다. 단어 목록은 최대 $$ 3\n \\times 10^4 $$개 들어 있다. 단어의 길이는 1~10 사이이다. 단어 목록\n 안의 단어는 중복이 없다.\n\n## 트라이+백트래킹\n\n 처음에 떠오른 방법은, 단어를 빨리 찾는 거니까 해시 셋을 끼얹는\n 거였다. 그런데 결국 보드를 **한 글자 씩** 탐색해야 하므로, 탐색하는\n 도중에는 결국 단어 전체보다는 단어의 **접두사**만을 보고 있는 상태가\n 훨씬 많을 것이다. 따라서 여기에 적절한 자료 구조인 트라이를 적용해야\n 한다.\n\n 그럼 트라이를 쓰는 것 까지는 알겠는데, 어떻게 보드에서 탐색할 수\n 있을까? 그냥 모든 칸에 대해서 탐색하면 복잡도가 터질 게\n 뻔하다. 하지만 우리에게는 단어 목록이 있기 때문에, 이를 잘 활용하면\n 탐색하는 도중 프루닝을 할 수 있는 지점이 보일 것이다. 이렇게 프루닝만\n 해줘도 엄청나게 도움이 것이기 때문에, 우리는 백트래킹을 할 수 있다.\n\n 일단 백트래킹 함수 `backtrack()`의 시그니쳐를 생각해보자. 보드의 어떤\n 칸의 글자를 가지고 단어를 만드는 중인지를 알아야 탐색 공간을 프루닝할\n 수 있기 때문에, 보드의 위치 `(row, col)`와 트라이의 노드가 있으면 될\n 것 같다. 그러면 전체적인 알고리즘은 이렇다.\n 1. 일단 단어 목록으로 트라이를 만든다.\n 2. 모든 칸을 다 돌면서, 그 칸으로부터 단어를 만들 수 있으면\n    백트래킹을 시작한다. 단어가 있으면 정답에 추가한다.\n\n 여기서는 백트래킹을 할 때 트라이 노드를 들고 다녀야 하고, 또 나중에\n 적용될 최적화를 위해서 [이전과 같은 방식으로 트라이를 만들기\n 보다는](../implement-trie), 가볍게 딕셔너리를 이용해서 트라이를\n 구성하는 게 좋다. 먼저 트라이를 만드는 코드를 보자.\n\n```python\ndef findWords(board, words):\n    WORD = 'word'\n    trie = {}\n    for word in words:\n        node = trie\n        for char in word:\n            if char not in node:\n                node[char] = {}\n            node = node[char]\n        node[WORD] = word\n```\n\n 즉, 노드를 오브젝트로 만들지 않고, 그냥 곧바로 딕셔너리로 만든다는\n 점만 빼면 거의 동일하다. 그리고 여기에 한 가지 최적화가 적용되어\n 있는데, 바로 한 단어의 추가가 완료되었을 때 이전 방법처럼 노드에\n `end` 같은 \"단어의 끝\"을 알리는 플래그를 두는 게 아니라, 단어를 담는\n 특별한 키 값을 이용해서 **단어 자체**를 저장하고 있다. 이렇게하면\n 백트래킹을 하면서 단어의 끝에 도달했을 때 곧바로 단어를 꺼내올 수\n 있고, 정답 목록에 단어가 중복되면 안되니까 단어를 꺼내올 때 아예\n 삭제해버림으로써 중복을 막을 수도 있다.\n\n 그러면 이 트라이를 가지고 백트래킹을 해보자.\n\n```python\ndef findWords(board, words):\n    ...\n    # build trie\n    ...\n\n    n, m = len(board), len(board[0])\n    answer = []\n    def backtrack(row, col, parent):\n        char = board[row][col]\n        node = parent[char]\n\n        if WORD in node:\n            # optimization 1) if we find a word, remove it to avoid duplicates\n            answer.append(node.pop(WORD))\n\n        # the same letter cell may not be used more than once in a word.\n        board[row][col] = '#'\n\n        for r, c in [(row+1, col), (row-1, col), (row, col+1), (row, col-1)]:\n            if r = n or c >= m:\n                continue\n            if board[r][c] in node:\n                backtrack(r, c, node)\n\n        # restore after constructing a word\n        board[row][col] = char\n```\n\n 백트래킹 자체는 따라가기 쉽다. 먼저 보드의 현재 위치 `(row, col)`에\n 있는 글자를 가져와서 이 글자가 현재 접두사의 어디에 있는지\n 가져온다. 앞서 트라이를 구축할 때 적용한 최적화를 이용해서, 만약 지금\n 노드에 단어가 매달려 있다면 (즉 `WORD` 키에 값이 있다면), 이 값이 곧\n 지금 매칭된 단어의 끝이므로 곧바로 정답 목록에 추가한다. 이때, 노드에\n 매달린 단어를 **삭제**해서, 이후 탐색에서 또 이 단어에 도달하더라도\n 단어 목록에 중복되지 않도록 한다. 나머지 부분은 문제의 조건을 그대로\n 구현한 것이다. 단어 하나를 만들 때에는 같은 칸의 글자가 여러 번 쓰일\n 수 없다고 했기 때문에, 백트래킹으로 재귀적으로 타고 들어가기 전에\n 미리 `#`으로 단어를 쓸 수 없게 만들었다가 이후에 백트래킹이 끝나고\n 나면 복원한다. 다음 위치를 찾을 때에는 먼저 4방향의 유효한 칸의\n 위치를 가져온 다음, 지금 트라이 노드의 위치에서 갈 수 있을 때에만, 즉\n 해당 글자로 이어지는 접두사가 있을 때에만 백트래킹을 이어나간다.\n\n 이렇게 만든 트라이와 백트래킹을 이용하면, 모든 보드 칸을 탐색해서\n 정답을 구할 수 있다.\n\n```python\ndef findWords(board, words):\n    ...\n    # build trie\n    # define backtracking function\n    ...\n\n    for row in range(n):\n        for col in range(m):\n            if board[row][col] in trie:\n                backtrack(row, col, trie)\n    return answer\n```\n\n### 최적화\n\n 이렇게만 하면 올바른 답을 구할 수 있지만, 생각보다 느리다. 여기서\n 최적화를 해보자.\n\n 사실 이미 위의 코드에는 세 가지 최적화가 적용되어 있다.\n 1. 백트래킹을 할 때 트라이의 현재 노드도 함께 실어간다. 이렇게하면\n    백트래킹의 각 단계에서 트라이의 *처음부터* 검색할 필요가 없다.\n 2. 단어의 마지막 트라이 노드에 단어 자체를 매달아 두었다. 플래그를\n    두면 백트래킹을 진행하면서 단어를 직접 만들어야 하는데, 그러지\n    않고 단어를 곧바로 꺼내올 수 있어서 이 수고를 덜었다.\n 3. 매칭된 단어를 정답 목록에 넣고 나서 바로 *삭제*해버렸다. 이렇게\n    하면 정답 목록에 중복을 체크하지 않아도 된다.\n\n 그러면 여기서 뭘 더 할 수 있을까? 핵심 아이디어는 단어를 검색하는\n 속도는 우리가 구성한 트라이의 크기에 영향을 받는다는 것이다. 어떤\n 단어가 끝까지 매칭되어서 정답 목록에 추가되었다면, 해당 단어를\n 삭제하는 것(3)에서 그치지 않고, 해당 단어가 있던 *노드*를 점진적으로\n 프루닝하면서 전체 트라이 사이즈를 줄인다면, 이후에 탐색할 때 공간을\n 덜 보게 되어서 성능이 좋아질 것이다. 핵심은 단어의 경로에 있는 모든\n 노드를 삭제하는 것이 아니라, **리프 노드**를 점진적으로 삭제해\n 나아가는 것이다.\n\n 예를 들어 단어 사전에 `dogs`와 `dog`가 있고 보드에 어떤 경로든\n `dogs`가 매칭된다고 해보자. 그러면 같은 접두사를 가진 두 단어가\n 차례로 매칭되다가, 더 긴 단어인 `dogs`까지 매칭이 된다. 이렇게 단어가\n 트라이 노드 **끝까지** 매칭이 되고 나면, 3에 의해서 중복없이 단어가\n 정답 목록에 추가되고, 그러면 더 이상 이 끝 노드까지 탐색할 필요가\n 없다. 즉, 트라이에서 **리프 노드**까지 탐색한 경우, (1) 단어가\n 매칭되었으면 이미 추가되었을 것이고, (2) 그렇지 않으면 단어가 없는\n 것이므로, 이 경로를 점진적으로 프루닝할 수 있다. 중요한 것은,\n 예시처럼 `dogs`가 매칭되었다고 해서 `dogs`까지 온 경로의 **모든\n 노드를 삭제하면 안된다**. 왜냐하면 `dog`가 있기 때문이다. 따라서,\n **점진적으로** 리프 노드를 삭제해 가는 전략을 써야한다. 이렇게 하면\n 안전하게 트라이 크기를 조금씩 줄여갈 수 있고 전체적으로 탐색 속도를\n 높일 수 있다.\n\n 이 최적화까지 고려한 전체 코드는 다음과 같다.\n\n```python\ndef findWords(board, words):\n    WORD = 'word'\n    trie = {}\n    for word in words:\n        node = trie\n        for char in word:\n            if char not in node:\n                node[char] = {}\n            node = node[char]\n        # optimization 2: hang whole word in the last trie node\n        node[WORD] = word\n\n    n, m = len(board), len(board[0])\n    answer = []\n\n    def backtrack(row, col, parent):\n        # optimization 1: recursion with parent trie node\n        char = board[row][col]\n        node = parent[char]\n\n        if WORD in trie:\n            # optimization 3: remove matched word to avoid duplicates\n            answer.append(node.pop(WORD))\n\n        board[row][col] = '#'\n\n        for r, c in [(row+1, col), (row-1, col), (row, col+1), (row, col-1)]:\n            if r = n or c >= m:\n                continue\n            if board[r][c] in node:\n                backtrack(r, c, node)\n\n        board[row][col] = char\n\n        # optimization 4: incrementally remove the matched leaf node\n        if not node:\n            parent.pop(char)\n\n    for row in range(n):\n        for col in range(m):\n            if board[row][col] in trie:\n                backtrack(row, col, trie)\n    return answer\n```"
					}
					,
					"wip-x86-assembly-guide": {
						"id": "wip-x86-assembly-guide",
						"title": "x86 Assembly Guide",
						"version": "all",
						"categories": "",
						"url": " /wip/x86-assembly-guide/",
						"content": "# [x86 어셈블리 가이드](http://www.cs.virginia.edu/~evans/cs216/guides/x86.html)\n 32비트 x86 어셈블리 언어의 프로그래밍 가이드이다. 전부는 아니고\n 유용한 서브셋을 다룬다. x86 머신 코드를 생성하는 어셈블리는 몇 가지\n 종류가 있는데, 여기서는 Microsoft Macro Assembler(MASM) 어셈블러를\n 다룬다. MASM은 x86 어셈블리 코드를 쓰기 위해서 인텔의 표준 문법을\n 사용한다.\n\n x86 명령어 전체 셋은 너무 크고 복잡해서 여기서는 다루지\n 않는다. 인텔의 x86 명령어 셋 매뉴얼은 2900 여 페이지에 달한다. 예를\n 들면 x86 명령어 셋의 16비트 서브셋이 있는데, 16비트 프로그래밍 모델을\n 사용하는 일은 꽤 복잡하다. 분할된 메모리 모델을 갖고 있고, 레지스터\n 사용에 좀더 제약이 많고, 등등. 그래서 여기에서는 x86 프로그래밍의\n 좀더 현대적인 측면에만 집중해서 x86 프로그래밍에 대해서 기초적인\n 부분만 다룰려고 한다.\n\n## 레지스터\n 현대적인 (즉, 386 이상) x86 프로세서는 여덟 개의 32비트 범용 목적\n 레지스터를 갖고 있다. 레지스터의 이름은 주로 역사적인 배경이\n 있다. 예를 들면, `EAX`는 *Accumulator*라고 불렸는데, 왜냐하면 여러\n 산술 연산에 쓰였기 때문이다. 그리고 `ECX`는 *Counter*라고 알려졌는데,\n 왜냐하면 주로 반복문에 쓰이는 인덱스 값을 갖고 있는데 쓰였기\n 때문이다. 레지스터의 대부분은 현대적인 명령 셋에서 원래의 특별한\n 목적을 잃어버린 반면, 관용적으로 딱 두 개의 레지스터는 특별한 목적을\n 위해 예약되어 있는데 그게 바로 스택 포인터를 위한 `ESP`와 베이스\n 포인터를 위한 `EBP`이다.\n\n `EAX`, `EBX`, `ECX`, 그리고 `EDX` 레지스터는 일부분만 사용될 수도\n 있다. 예를 들면, `EAX`의 LSB 2바이트는 16비트 레지스터 `AX`로 취급될\n 수 있다. `AX`의 LSB 1바이트는 하나의 8비트 레지스터 `AL`로, `AX`의\n MSB 1바이트는 하나의 8비트 레지스터 `AH`로 쓰일 수 있다. 이 이름들은\n 모두 같은 물리적인 레지스터를 가리킨다. 2 바이트의 데이터가 `DX`에\n 위치할 때, 이 데이터를 수정하면 `DH`, `DL`, `EDX` 모두에 영향을\n 미친다. 이런 서브-레지스터는 주로 고대의 16비트 버전 명령 셋을\n 지원하기 위해서 아직까지 유지되고 있다. 하지만, 32비트보다 작은\n 1바이트 짜리 아스키 문자를 다루거나 할 때에는 가끔 편리하기도 하다.\n\n 어셈블리 언어에서 레지스터를 참조할 때, 이름은 대소문자에 관계\n 없다. 예를 들면, `EAX`와 `eax`는 같은 레지스터를 참조한다.\n\n![x86 레지스터](http://www.cs.virginia.edu/~evans/cs216/guides/x86-registers.png)\n\n## 메모리와 어드레싱 모드\n### 정적 데이터 구역 선언하기\n x86 어셈블리에서는 특별한 어셈블러 지시자(directive)를 이용해서 마치\n 전역 변수와 비슷한 *정적 데이터 구역(static data regions)*을 선언할\n 수 있다. 데이터 선언은 `.DATA` 지시자 앞에 와야 한다. 이 지시자를\n 따라 `DB`, `DW`, 그리고 `DD` 지시자가 각각 1, 2, 4바이트의 데이터\n 위치를 선언하는데 사용될 수 있다. 선언된 위치는 나중에 참조할\n 목적으로 이름으로 레이블링 할 수 있다. 이는 변수를 이름으로 선언하는\n 것과 비슷하지만, 훨씬 더 저수준의 규칙을 따른다. 예를 들면, 차례차례\n 선언된 위치는 실제 메모리에서도 차례차례 위치하게 된다.\n\n 예시 선언을 보자.\n\n```nasm\n.DATA\nvar  DB  64         ; Declare a byte, referred to as location `var`, containing the value 64.\nvar2 DB  ?          ; Declare an uninitialized byte, referred to as location `var2`\n     DB  10         ; Declare a byte with no label, containing the value 10. Its location is `var2 + 1`\nX    DW  ?          ; Declare a 2-byte uninitialized value, referred to as location `X`\nY    DD  30000      ; Declare a 4-byte value, referred to as location `Y`, initialized to 30000.\n```\n\n 배열이 다차원을 가질 수 있고 인덱스로 접근할 수 있는 고수준의 언어와\n 다르게, x86 어셈블리 언어의 배열은 단순히 메모리에서 연속적으로\n 위치한 여러 개의 쎌이다. 배열은 예시처럼 그냥 값을 나열해서 선언할 수\n 있다. 이 외에 배열을 선언하기 위한 다른 두 개의 일반적인 방법은 `DUP`\n 지시자와 문자열 리터럴을 쓰는 것이다. `DUP` 지시자는 어셈블러가\n 주어진 횟수만큼 식을 반복하게 해준다. 예를 들면, `4 DUP(2)`는 `2, 2,\n 2, 2`와 같다.\n\n 또 다른 예시를 보자.\n\n```nasm\nZ      DD 1, 2, 3      ; Declare three 4-byte values, initialized to 1, 2, and 3. The value of location `Z + 8` will be 3.\nbytes  DB 10 DUP(?)    ; Declare 10 uninitialized bytes starting at location `bytes`\narr    DD 100 DUP(0)   ; Declare 100 4-byte words starting at location `arr`, all initialized to 0.\nstr    DB 'hello',0    ; Declare 6 bytes starting at the address `str`, initialized to the ASCII character values for `hello` and the null(0) byte.\n```\n\n### 메모리 주소 지정 (Addressing Memory)\n x86과 호환되는 현대 프로세서는 최대 `2^32` 바이트의 메모리에 대한\n 주소를 지정할 수 있다: 메모리 주소는 32비트 값이다. 레이블을 이용해서\n 메모리 구역을 참조한 앞의 예시에서, 이런 레이블은 실제로는 어셈블러에\n 의해 메모리의 주소를 가리키는 32비트 값으로 바뀐다. 레이블(즉, 상수\n 값)로 메모리 구역을 참조하는 것이 지원되는 것에 더하여, x86은 메모리\n 주소를 계산하고 참조하기 위한 유연한 방법을 제공한다. 최대 두 개의\n 32비트 레지스터와 32비트 부호있는 상수는 메모리 주소를 계산하기\n 위해서 *더해질 수 있다*. 또, 레지스터 중 하나는 미리 2, 4, 8 중\n 하나와 곱해질 수 있다. (정말 저수준이다...)\n\n 주소 지정 모드는 많은 x86 명령에 사용될 수 있다. 여기서는 `mov`\n 명령으로 레지스터와 메모리 사이에서 데이터를 옮기는 몇 가지 예시를\n 살펴본다. 이 명령은 두 개의 피연산자를 갖는데, 첫 번째는\n 목적지(destination)이고 두 번째는 출발지(source)를 명시한다.\n\n 다음은 `mov` 연산으로 주소를 계산하는 예시이다.\n\n```nasm\nmov eax, [ebx]         ; Move the 4 bytes in *memory at the address* contained in ebx into eax\nmov [var], ebx         ; Move the *contents* of ebx into the 4 bytes at memory address `var`. Note, var is a 32-bit constant.\nmov eax, [esi-4]       ; Move 4 bytes at memory address `esi + (-4)` into eax.\nmov [esi+eax], cl      ; Move the contents of CL into the byte at address `esi + eax`\nmov edx, [esi+4*ebx]   ; Move the 4 bytes of data at address esi+4*ebx into edx\n```\n\n 다음은 잘못된 주소 계산의 예시이다.\n\n```nasm\nmov eax, [ebx-ecx]     ; Can only add register values\nmov [eax+esi+edi], ebx ; At most 2 registers in adress computation\n```\n\n### 사이즈 지시자\n 일반적으로, 주어진 메모리 주소에서 데이터 아이템의 의도된 사이즈는\n 참조되는 어셈블리 코드 명령에서 추론할 수 있다. 예를 들어, 모든 위의\n 예시에서, 메모리 구역의 사이즈는 피연산 레지스터의 크기에서 추론할 수\n 있다. 32비트 레지스터를 로드할 때, 어셈블러는 참조할 메모리 구역이 4\n 바이트 크기라는 것을 추론할 수 있다. 1 바이트 레지스터에 담긴 값을\n 메모리에 저장할 때, 어셈블러는 메모리에서 1 바이트의 주소를 참조하고\n 싶다는 것을 추론할 수 있다.\n\n 하지만, 어떤 경우에는 메모리 구역을 참조하는 사이즈가 모호할 때가\n 있다. `mov [ebx], 2`를 생각해보자. 이 명령은 2라는 값을 `ebx` 주소의\n 1바이트에 옮겨야 할까? 아마 이 2라는 값은 32비트 정수 표현이라서\n `ebx` 주소의 4바이트에 옮기는 걸지 모른다. 둘 모두 유효한 해석이기\n 때문에, 어셈블러에게 반드시 명확하게 올바른 방향을 제시해줘야\n 한다. 사이즈 지시자 `BYTE PTR`, `WORD PTR`, `DWORD PTR`은 이 목적으로\n 태어났고, 각각 1, 2, 4 바이트의 크기를 알려준다.\n\n```nasm\nmov BYTE PTR [ebx], 2  ; Move 2 into the single byte at the address sotred in ebx.\nmov WORD PTR [ebx], 2  ; Move the 16-bit integer representation of 2 into the 2 bytes starting at the address in ebx.\nmov DWORD PTR [ebx], 2 ; Move the 32-bit integer representation of 2 into the 4 bytes starting at the address in ebx.\n```\n\n## 명령\n 기계 명령은 일반적으로 세 가지 카테고리로 나눠진다: 데이터 이동,\n 산술/논리, 그리고 제어 흐름이다. 여기서는 각 카테고리의 x86 명령의\n 아주 중요한 예시를 살펴본다. 여기 있는게 x86 명령의 빠뜨림 없는\n 목록은 아니고 유용한 서브셋이다. 전체가 궁금하다면 인텔의 명령 셋을\n 봐라.\n\n 다음과 같은 표기법을 사용한다.\n\n```\n     Any 32-bit register (eax, ebx, ecx, edx, esi, edi, esp, or ebp)\n     Any 16-bit register (ax, bx, cx, or dx)\n      Any 8-bit register (ah, bh, ch, dh, al, bl, cl, or dl)\n       Any register\n       A memory address (e.g. [eax], [var + 4], or dword ptr [eax+ebx])\n   Any 32-bit constant\n   Any 16-bit constant\n    Any 8-bit constant\n     Any 8-, 16-, or 32-bit constant\n```\n\n### 데이터 이동 명령\n#### `mov`\n Opcode: 88, 89, 8A, 8B, 8C, 8E, ...\n\n `mov` 명령은 두 번째 피연산자가 가리키는 데이터 아이템(즉 레지스터의\n 내용물이나 메모리 내용물, 또는 상수 값)을 첫 번째 피연산자가 가리키는\n 위치(즉 레지스터나 메모리)에 복사한다. 레지스터에서 레지스터로 값을\n 복사하는 것은 가능하지만, 메모리에서 곧바로 메모리로 복사하는 것은\n 불가능하다. 메모리 사이에서 데이터를 옮기고 싶다면, 먼저 옮기려는\n 대상 메모리 내용물을 레지스터에 로드하고 그 다음 목적지 메모리 주소로\n 복사해야 한다.\n\n```nasm\nmov , \nmov , \nmov , \nmov , \nmov , \n```\n\n```nasm\nmov eax, ebx           ; Copy the value in ebx into eax\nmov byte ptr [var], 5  ; Store the value 5 into the byte at location var\n```\n\n#### `push`\n Opcode: FF, 89, 8A, 8B, 8C, 8E, ...\n\n `push` 명령은 메모리에서 지원되는 하드웨어 스택에 피연산자를\n 푸시한다. 구체적으로는, 먼저 `esp`를 4 만큼 빼고, 그 다음 피연산자를\n 32비트 위치인 `[esp]` 주소의 내용물에 옮긴다. 스택 포인터 `esp`는\n 푸시를 통해 값이 줄어드는데, 왜냐면 x86 스택이 밑으로 자라기\n 때문이다. 즉, 높은 주소에서 낮은 주소로 자란다.\n\n```nasm\npush \npush \npush \n```\n\n```nasm\npush eax               ; Push eax onto the stack\npush [var]             ; Push the 4 bytes at address var onto the stack\n```\n\n#### `pop`\n `pop` 명령은 하드웨어가 지원하는 스택의 꼭대기에서 4 바이트 크기의\n 데이터 원소를 없애고 피연산자가 명시한 위치(즉, 레지스터 또는 메모리\n 위치)로 옮긴다. 구체적으로는 먼저 메모리 위치 `[esp]`에 위치한 4\n 바이트를 피연산 레지스터 또는 메모리 위치로 옮긴 다음, `esp`를 4만큼\n 증가시킨다.\n\n```nasm\npop \npop \n```\n\n```nasm\npop edi                ; Pop the top element of the stack into edi.\npop [ebx]              ; Pop the top element of the stack into memory at the 4-bytes starting at location ebx.\n```\n\n#### `lea` - Load Effective Address\n `lea` 명령은 두 번째 피연산자가 명시한 *주소*를 첫 번째 피연산\n 레지스터로 옮긴다. 주의할 점은 메모리 위치의 *내용물*은 로드되지\n 않고, 오직 유효 주소(effective address)만 계산해서 레지스터로\n 옮긴다는 점이다. 메모리 구역에 포인터를 얻을 때 유용한 방법이다.\n\n```nasm\nlea , \n```\n\n```nasm\nlea edi, [ebx+4*esi]   ; The quantity ebx+4*esi is placed into edi.\nlea eax, [var]         ; The value in var is placed in eax.\nlea eax, [val]         ; The value val is placed in eax.\n```\n\n### 산술과 논리 명령\n\n#### `add` - 정수 덧셈\n `add` 명령은 두 개의 피연산자를 더해서 그 결과를 첫 번째 피연산자에\n 저장한다. 즉, `add(a, b)  a += b` 라고 해석할 수 있다. 피연산자는\n 둘다 레지스터일 수 있지만, 최대 하나만 메모리 위치일 수 있다.\n\n```nasm\nadd , \nadd , \nadd , \nadd , \nadd , \n```\n\n```nasm\nadd eax, 10            ; eax += 10\nadd byte ptr [var], 10 ; Add 10 to the single byte stored at memory address var\n```\n\n#### `sub` - 정수 뺄셈\n `add`랑 같은데 뺄셈일 뿐.\n\n```nasm\nsub , \nsub , \nsub , \nsub , \nsub , \n```\n\n```nasm\nsub al, ah             ; al -= ah\nsub eax, 216           ; eax -= 216\n```\n\n\n#### `inc`, `dec`\n 피연산자의 값을 1만큼 증가시키거나(`inc`) 감소시키는(`dec`) 연산이다.\n\n```nasm\ninc \ninc \ndec \ndec \n```\n\n```nasm\ndec eax                ; Subtract one from the contents of eax.\ninc dword ptr [var]    ; Add one to the 32-bit integer stored at location var\n```\n\n#### `imul` - 정수 곱셈\n `imul` 명령은 두 개의 형태를 가지고 있다: 피연산자 두 개 짜리와 세 개\n 짜리가 있다.\n\n 피연산자 두 개 짜리 형태는 이 두 개의 피연산자를 곱해서 첫 번째\n 피연산자에 저장한다. 이때, 결과를 저장할 첫 번째 피연산자는 반드시\n 레지스터여야 한다.\n\n 피연산자 세 개 짜리 형태는 두 번째와 세 번째 피연산자를 곱해서 첫\n 번째 피연산자에 저장한다. 여기서도 결과를 저장할 첫 번째 피연산자는\n 반드시 레지스터여야 한다. 나아가, 세 번째 피연산자는 상수 값만 사용할\n 수 있다.\n\n```nasm\nimul , \nimul , \nimul , , \nimul , , \n```\n\n```nasm\nimul eax, [var]        ; Muliply the contents of eax by the 32-bit contents of the memory location var. Store the result in eax.\nimul esi, edi, 25      ; esi = edi * 25\n```\n\n#### `idiv` - 정수 나눗셈\n `idiv` 명령은 64비트 `edx:eax` (즉, `edx`가 MSB가 되고 `eax`가 LSB가\n 되는 형태) 에 담긴 정수를 지정된 연산 값(즉, 파라미터)으로\n 나눈다. 나누기 결과의 몫은 `eax`에 저장되고 나머지는 `edx`에\n 저장된다.\n\n```nasm\nidiv \nidiv \n```\n\n```nasm\nidiv ebx               ; Divide the contents of edx:eax by the contents of ebx. Place the quotient in eax and the remainder in edx.\nidiv dword ptr [var]   ; Divice the contents of edx:eax by the 32-bit value stored at memory location var. Place the quotient in eax and the remainder in edx.\n```\n\n#### `and`, `or`, `xor` - 논리적 비트 연산\n 논리적 비트 연산을 수행하고 결과를 첫 번째 피연산자에 저장한다.\n\n```nasm\nand|or|xor , \nand|or|xor , \nand|or|xor , \nand|or|xor , \nand|or|xor , \n```\n\n```nasm\nand eax, 0fH           ; Clear all but last 4 bits of eax.\nxor edx, edx           ; Set the contents of edx to zero.\n```\n\n#### `not`\n\n```nasm\nnot \nnot \n```\n\n```nasm\nnot byte ptr [var]     ; Negate all bits in the byte at the memory location var.\n```\n\n#### `neg`\n 2의 보수 연산을 수행한다.\n\n```nasm\nneg \nneg \n```\n\n```nasm\nneg eax                ; eax = -eax\n```\n\n#### `shl`, `shr` - Shift Left, Shift Right\n 이 연산은 첫 번째 피연산자의 내용물을 왼쪽 또는 오른쪽으로\n 쉬프트하고, 이로 인해 비게 되는 비트 값을 0으로 채워(padding)\n 넣는다. 피연산자는 최대 31 위치 만큼 쉬프트될 수 있다. 쉬프트할 수는\n 두 번째 피연산자로 지정되는데 8비트 상수이거나 `cl` 레지스터이다. 양\n 쪽 경우 모두 31 이상 쉬프트되는 경우는 모듈로 32 연산이 수행된다.\n\n```nasm\nshl|shr , \nshl|shr , \nshl|shr , \nshl|shr , \n```\n\n```nasm\nshl eax, 1             ; Multiply the value of eax by 2\nshr ebx, cl            ; Store in ebx the floor of result of dividing the value of ebx by 2^n where n is the value in cl.\n```\n\n### 제어 흐름 명령\n x86 프로세서는 명령 포인터(Instruction Pointer; IP) 레지스터로 지금\n 명령을 시작할 메모리의 위치가 어딘지를 나타내는 32비트 값을\n 유지한다. 보통 한 명령이 실행되고 난 이후부터 시작되는 메모리의 다음\n 명령을 가리키도록 증가된다. IP 레지스터는 직접적으로 다룰 수 없지만,\n 제어 흐름 명령을 통해 암묵적으로 업데이트할 수는 있다.\n\n `` 표기법을 이용하면 프로그램 테스트의 특정 위치에\n 레이블(딱지)를 붙일 수 있다. 레이블은 레이블 이름과 콜론만 있으면 x86\n 어셈블리 코드 텍스트의 어디든 붙일 수 있다. 예를 들어,\n\n```nasm\n       mov esi, [ebp+8]\nbegin: xor ecx, ecx\n       mov eax, [esi]\n```\n\n 이 코드에서는 둘째 줄의 명령에 `begin` 레이블이 붙어 있다. 코드의\n 다른 곳 어디에서든 `begin` 이라는 편리한 심볼 이름을 이용해서 이\n 명령이 있는 메모리의 위치를 참조할 수 있다. 즉, 실제로는 32비트 값인\n 메모리 위치를 대신하여 표현하게 해주는 편리한 방법이 바로 레이블이다.\n\n#### `jmp`\n 프로그램의 제어 흐름을 피연산자가 가리키는 메모리 위치로\n 이동한다. 간단하게 말해서 이 명령을 만나는 순간 이 명령 이후의 명령이\n 실행되는 게 아니라 피연산자로 넘겨온 레이블의 위치로 가서 명령을\n 수행한다.\n\n```nasm\njmp \n```\n\n```nasm\njmp begin              ; Jump to the instruction labeled begin.\n```\n\n#### `jcondition`\n `j-`로 시작하는 이 일련의 명령들은 조건부 점프 연산이다. 이때 조건을\n 판단하기 위해서 특별한 레지스터인 *기계 상태 워드(Machine Status\n Word)*를 이용하는데, 이 레지스터에 저장된 조건 코드 집합의 상태에\n 따라 점프한다. 기계 상태 워드의 값은 가장 마지막에 수행된 산술 연산의\n 정보를 포함한다. 예를 들면, 이 워드의 1비트는 마지막 연산의 결과가\n 0인지를 나타낸다. 마지막 연산의 결과가 음수인지를 나타내는 비트도\n 있다. 이런 조건 코드를 근거로, 여러 개의 조건부 점프 연산이 수행될 수\n 있다. 예를 들면, `jz` 명령은 마지막 산술 연산의 결과가 0일 때 주어진\n 레이블로 점프한다. 그렇지 않으면 그냥 그 다음에 오는 명령을 실행할\n 뿐이다.\n\n 여러 개의 조건부 분기 명령은 특별한 비교 명령인 `cmp`를 수행한 마지막\n 결과에 따라 직관적으로 이름 지어져 있다. 예를 들면, 조건부 분기 명령\n `jle`와 `jne`는 먼저 `cmp` 연산을 수행한 결과가 있어야 동작한다.\n\n```nasm\nje    ; jump when equal\njne   ; jump when not equal\njz    ; jump when the last result was zero\njg    ; jump when greater than\njge   ; jump when greater than or equal to\njl    ; jump when less than\njle   ; jump when less than or equal to\n```\n\n```nasm\ncmp eax, ebx\njle done\n```\n - `eax , \ncmp , \ncmp , \ncmp , \n```\n\n```nasm\ncmp dword ptr [var], 10    ; If the 4 bytes stored at location var are equal to the 4-byte integer constant 10,\njeq loop                   ; then jump to the location labeled loop.\n```\n\n#### `call`, `ret`\n 이 명령은 서브루틴 호출과 리턴을 구현한다. `call` 명령은 먼저 현재\n 코드의 위치를 메모리에 있는 하드웨어 지원 스택에 푸시하고 (위의\n `push` 명령 참조), 그 다음 피연산자 레이블로 무조건적인 점프 명령을\n 수행한다. 앞에서 봤던 단순한 점프 명령과는 달리, `call` 명령은\n 서브루틴을 완료했을 때 돌아올 위치를 저장한다.\n\n `ret` 명령은 서브루틴 리턴 메커니즘을 구현한다. 이 명령은 먼저\n 메모리에 있는 하드웨어 지원 스택을 팝해서 (위의 `pop` 명령 참조) 코드\n 위치를 꺼내오고 그 다음 이 코드 위치로 무조건적인 점프 명령을\n 수행한다.\n\n```nasm\ncall \nret\n```\n\n## 호출 규약 (Calling Convention)\n 드디어 여기까지 왔다. 사실 이거 설명하려고 이 긴 글을 번역하고 있다.\n\n 여러 명의 프로그래머가 코드를 공유하고 많은 프로그램에서 쓰일\n 라이브러리를 개발할 수 있게 하려면, 그리고 일반적으로 서브루틴의\n 사용을 최대한 간단하게 하려면, 프로그래머는 항상 일반적인 *호출\n 규약*을 따라야 한다. 호출 규약은 어떻게 서브루틴을 호출하고 어떻게\n 리턴할지에 관한 프로토콜이다. 예를 들어, 어떤 호출 규약이 주어지면,\n 프로그래머는 서브루틴에 파라미터를 어떻게 넘겨줄지 정하기 위해서\n 서브루틴의 정의를 살펴볼 필요가 없다. 게다가, 호출 규약이 주어지면,\n 고수준의 프로그래밍 언어 컴파일러는 이런 규칙을 따르도록 코드를\n 생성할 수 있고 따라서 손으로 작성한 어셈블리 언어의 서브루틴과 고수준\n 언어의 서브루틴끼리 서로 호출할 수 있게 된다.\n\n 실제로는, 많은 호출 규약이 가능하다. 여기서는 가장 널리 쓰이는 C 언어\n 호출 규약을 살펴본다. 이 규약을 따르면 어셈블리 C와 C++ 코드에서\n 안전하게 호출할 수 있는 언어 서브루틴을 작성할 수 있고, 또한 어셈블리\n 언어 코드에서 C 라이브러리 함수를 호출하는 것도 가능해진다.\n\n C 호출 규약은 하드웨어 지원 스택의 사용에 심하게 의존하고 있다. 즉,\n `push`, `pop`, `call`, `ret` 명령에 기반한다. 서브루틴 파라미터는\n 스택으로 전달된다. 레지스터는 스택에 저장되고, 서브루틴에서 사용하는\n 지역 변수는 스택 위의 메모리에 위치한다. 대부분의 프로세서 위에서\n 구현된 아주 많은 고수준 절차적 언어는 이와 유사한 호출 규약을 갖고\n 있다.\n\n 호출 규약은 두 종류의 규칙으로 나눠진다. 하나는 서브루틴을 호출하는\n 호출자(Caller)가 지켜야 하는 것이고, 다른 하나는 서브루틴을 작성하는\n 사람(피호출자; Callee)이 지켜야 하는 것이다. 이 규칙을 준수하지\n 않으면 스택이 엉망인 상태에 빠지기 때문에 프로그램에 중대한 오류가\n 빠르게 발생한다는 사실을 강조하고 싶다. 따라서, 서브루틴을 작성할\n 때에는 호출 규약을 지키기 위해서 아주 세심한 주의가 필요하다.\n\n![서브루틴 호출 도중의 스택](http://www.cs.virginia.edu/~evans/cs216/guides/stack-convention.png)\n\n 호출 규약을 시각화 하는 좋은 방법은 서브루틴이 실행되는 도중의 스택\n 영역을 직접 그리는 것이다. 위의 이미지는 세 개의 파라미터와 세 개의\n 지역 변수가 있는 서브루틴이 실행되는 도중의 스택 상태를 그린\n 것이다. 스택에 쌓인 각각의 쎌은 32 비트의 메모리 위치이고, 따라서\n 쎌의 메모리 주소는 4 바이트 씩 떨어져 있다. 첫 번째 파라미터는 베이스\n 포인터로부터 8 바이트 오프셋만큼 떨어진 곳에 있다. 스택에서\n 파라미터와 베이스 포인터 사이에는 `call` 명령이 나중에 돌아올 주소를\n 푸시해뒀고, 따라서 베이스 포인터에서 첫 번째 파라미터 사이에는\n 추가적인 4 바이트 오프셋이 존재한다. 서브루틴에서 `ret` 명령이\n 호출되면, 여기 저장된 주소로 점프하게 된다.\n\n### 호출자(콜러) 규칙\n 서브루틴을 호출하기 위해서, 호출자는 다음을 지켜야 한다:\n\n 1. 서브루틴을 호출하기 전에, 호출자는 *호출자가 저장해야\n    하는(caller-saved)* 특정한 레지스터의 값을 저장해야 한다. 호출자가\n    저장해야 하는 레지스터에는 `eax`, `ecx`, `edx`가 있다. 호출된\n    서브루틴이 이런 레지스터를 수정할 수 있기 때문에, 서브루틴이\n    리턴하고 나서 호출자가 얘네들의 값을 제대로 사용하려면 이\n    레지스터의 값을 스택에 푸시해둬야 한다. 그래야 서브루틴이 완료되고\n    나서 다시 값을 복원할 수 있다.\n 2. 서브루틴에 파라미터를 전달하기 위해서, 서브루틴을 호출하기 전에\n    파라미터로 쓰일 값들을 스택에 푸시해야 한다. 이때, 파라미터는\n    *거꾸로* 푸시되어야 한다. 즉, 마지막 파라미터를 먼저 푸시해야\n    한다. 스택이 아래로 자라기 때문에, 첫 번째 파라미터는 가장 낮은\n    주소에 푸시된다. 이렇게 파라미터가 거꾸로 저장되는 이유는\n    역사적으로 함수에 가변 갯수의 파라미터를 전달하게 하기 위함이라고\n    하는데, 정확한건 아직 잘 모르겠음.\n 3. 서브루틴을 호출하려면 `call` 명령을 써야 한다. 이 명령은 스택에서\n    파라미터 위에다 리턴 주소를 푸시하고 그 다음 서브루틴 코드로\n    점프한다. 그 이후 호출되는 서브루틴은 피호출자 규칙을 따라야 한다.\n\n 서브루틴이 리턴하고 나면, 호출자는 서브루틴의 리턴 값을 `eax`\n 레지스터에서 찾으려 할 수 있다. 기계 상태를 복원하기 위해서, 호출자는\n 또한:\n\n 1. 스택에서 파라미터를 제거해야 한다. 이를 통해 `call` 명령이\n    수행되기 전의 스택 상태를 복원한다.\n 2. 호출자가 저장해야 하는 레지스터 `eax`, `ecx`, `edx`를 스택에서\n    팝해서 값을 복원한다. 호출자는 서브루틴에 의해서 수정된 다른\n    레지스터가 없다고 가정할 수 있다.\n#### 예시\n 아래 코드는 호출자 규칙을 따르는 함수 호출을 보여준다. 호출자는 세\n 개의 정수 파라미터를 받는 `_myFunc` 함수를 호출하고 있다. 첫 번째\n 파라미터는 `eax`에 있고, 두 번째 파라미터는 상수 216이고, 세 번째\n 파라미터는 메모리 위치 `var`에 있다.\n\n```nasm\npush [var]             ; Push the last parameter first.\npush 216               ; Push the second parameter.\npush eax               ; Push the first parameter last.\n\ncall _myFunc           ; Call the function (assume C naming).\n\nadd esp, 12            ; Clean up the stack after call returns.\n```\n\n 함수가 리턴하고 나서 호출자가 `add` 명령으로 스택을 정리하고 있다는\n 점을 주목하자. 여기서는 12 바이트, 즉 각각 4 바이트 파라미터 3개를\n 스택에 쌓았고, 스택은 아래로 자란다. 따라서, 파라미터를 제거하기\n 위해서, 그냥 스택 포인터에다 12를 더하면 된다.\n\n `_myFunc` 함수의 결과는 이제 `eax` 레지스터에서 쓸 수 있다. 호출자가\n 저장해야 하는 레지스터(`ecx`, `edx`)의 값은 아마 바뀌었을 수도\n 있다. 호출자가 함수 호출 이후 이 레지스터를 쓴다면, 이 값을 스택에\n 저장해뒀다가 나중에 복원해야 할 필요가 있다.\n\n### 피호출자(콜리) 규칙\n 서브루틴의 시작 지점에서 다음과 같은 규칙을 따라야 한다.\n\n 1. 다음 명령을 따라 `ebp`의 값을 스택에 푸시하고, `esp`의 값을\n    `ebp`에 복사해야 한다.\n```nasm\npush ebp\nmov  ebp, esp\n```\n\n 이 초기화는 *베이스 포인터*, 즉 `ebp`를 유지한다. 베이스 포인터는\n 관용적으로 스택에서 파라미터와 지역 변수를 참조하기 위해서\n 사용된다. 서브루틴이 실행될 때, 베이스 포인터는 서브루틴이 실행되기\n 시작했을 때의 스택 포인터 값의 복사본을 갖고 있다. 파라미터와 지역\n 변수는 항상 어디 위치하고 있는지 알 수 있는데, 베이스 포인터 값에서\n 상수 오프셋 만큼 차이나는 곳에 위치한다. 서브루틴의 시작 지점에서\n 옛날 베이스 포인터 값을 푸시해두면 나중에 서브루틴이 리턴했을 때\n 호출자를 위한 적절한 베이스 포인터 값을 복원할 수 있다. 기억해둘\n 것은, 호루자는 서브루틴이 베이스 포인터의 값을 바꿀거라고 **예상하지\n 않는다는** 점이다. 그러고나서 스택 포인터를 `ebp`로 복사해서(`mov`)\n 파라미터와 지역 변수에 접근하기 위한 적절한 참조 지점을 얻는다.\n\n 2. 그 다음, 스택에 공간을 만들어서 지역 변수를 할당한다. 스택이\n    아래로 자라기 때문에, 스택 꼭대기에 공간을 만들려면 스택 포인터가\n    줄어야 한다는 점을 기억하자. 스택 포인터를 얼마나 줄여야 하는지는\n    필요한 지역 변수의 갯수와 크기에 달려있다. 예를 들어, 만약 각각 4\n    바이트 짜리 지역 변수 세 개가 필요하다면, 스택 포인터를 12 만큼\n    줄여서 (`sub esp, 12`)이 지역 변수를 위한 공간을 만들 수\n    있다. 파라미터와 함께, 지역 변수도 베이스 포인터로부터 상수 오프셋\n    만큼 떨어진 곳에 위치한다는 것을 알 수 있다.\n 3. 그 다음, 함수가 사용하게 될 *피호출자가 저장해야\n    하는(callee-saved)* 레지스터의 값을 저장한다. 레지스터를 저장하기\n    위해서 스택에 푸시하면 된다. 피호출자가 저장해야 하는 레지스터에는\n    `ebx`, `edi`, `esi`가 있고 `esp`와 `ebp`도 호출 규약에 따르면\n    보존되어야 하지만 이 과정에서 스택에 푸시될 필요는 없다.\n\n 이 세 가지 초기화가 수행되고 나면, 서브루틴의 본문을 수행할 수\n 있다. 서브루틴이 리턴할 때에는, 반드시 다음 단계를 따라야 한다:\n\n 1. 리턴 값은 `eax`에 둔다.\n 2. 피호출자가 저장해야 하는 레지스터(`edi`, `esi`)가 수정된 경우 이전\n    값으로 원복한다. 레지스터 값은 스택에서 팝하여 복원할 수\n    있다. 레지스터는 푸시된 순서의 반대로 팝되어야 한다.\n 3. 지역 변수를 해제한다. 가장 확실한 방법은 스택 포인터에 적절한 값을\n    더하는 것이다. 왜냐하면 스택 포인터에 적절한 값을 빼서 스택에\n    필요한 공간을 할당했기 때문이다. 실제로, 오류가 덜 나는 방법은\n    베이스 포인터의 값을 스택 포인터에다 복사하는 것이다: `mov esp,\n    ebp`. 이게 되는 이유는 베이스 포인터는 언제나 지역 변수의 할당\n    바로 직전의 스택 포인터의 값을 담고 있기 때문이다.\n 4. 리턴하기 바로 직전에, 스택에서 `ebp`를 팝해서 호출자의 베이스\n    포인터를 복원한다. 서브루틴에 진입하자마자 처음 한 일이 바로\n    베이스 포인터를 푸시해서 원래 값을 저장한 것이라는 것을 잊지말자.\n 5. 마지막으로, `ret` 명령을 실행해서 호출자의 위치로 리턴한다. 이\n    명령은 스택에서 적절한 리턴 주소를 찾아서 제거할 것이다.\n\n 피호출자의 규칙은 서로 반대되는 두 부분으로 깔끔하게 나뉜다는 사실에\n 주목하자. 첫 번째 부분은 함수의 시작 지점에 적용되고, 보통 함수의\n *도입부(Prologue)*라고 부른다. 나머지 부분은 함수의 끝 부분에\n 적용되고, 보통 *종결부(Epilogue)*라고 부른다.\n\n#### 예시\n\n```nasm\n.486\n.MODEL FLAT\n.CODE\nPUBLIC _myFunc\n_myFunc PROC\n    ; Subroutine Prologue\n    push ebp                  ; Save the old base pointer value.\n    mov ebp, esp              ; Set the new base pointer value.\n    sub esp, 4                ; Make room for one 4-byte local variable.\n    push edi                  ; Save the values of registers that the funcion will modify.\n    push esi                  ; This function uses EDI and ESI\n    ; ( no need to save EBX, EBP, or ESP )\n\n    ; Subroutine Body\n    mov eax, [ebp+8]          ; Move value of parameter 1 into eax\n    mov esi, [ebp+12]         ; Move value of parameter 2 into esi\n    mov edi, [ebp+16]         ; Move value of parameter 3 into edi\n\n    mov [ebp-4], edi          ; Move edi into the local variable\n    add [ebp-4], esi          ; Add esi into the local variable\n    add eax, [ebp-4]          ; Add the contents of the local variable into eax (final result)\n\n    ; Subroutine Epilogue\n    pop esi                   ; Recover register values\n    pop edi\n    mov esp, ebp              ; Deallocate local variables\n    pop ebp                   ; Restore the caller's base pointer value\n    ret\n_myFunc ENDP\nEND\n```\n\n\n 서브루틴의 도입부는 스택 포인터의 스냅샷을 베이스 포인터 `ebp`에\n 저장하고, 스택 포인터를 감소시켜서 지역 변수를 할당하고, 스택에\n 레지스터 값을 저장하는 일련의 표준 작업을 수행하고 있다.\n\n 서브루틴의 본문에서 베이스 포인터가 어떻게 쓰이는지 볼 수\n 있다. 파라미터와 지역 변수 둘 다 서브루틴이 실행되는 동안은 베이스\n 포인터에서 상수 오프셋만큼 떨어진 곳에 위치하고 있다. 구체적으로,\n 파라미터는 서브루틴이 호출되기 전에 스택에 쌓이기 때문에, 항상\n 스택에서 베이스 포인터의 밑에 (즉, 더 높은 주소에)\n 위치한다. 서브루틴의 첫 번째 파라미터 항상 메모리 위치 `ebp + 8`에\n 위치하고, 두 번째는 `ebp + 12`, 세 번째는 `ebp + 16`에\n 위치한다. 비슷하게, 지역 변수는 베이스 포인터가 설정되고 난 이후에\n 할당되기 때문에, 항상 스택에서 베이스 포인터의 위에 (즉, 더 낮은\n 주소에) 위치한다. 구체적으로, 첫 번째 지역 변수는 항상 `ebp - 4`에\n 위치하고, 두 번째 지역 변수는 `ebp - 8`에, 등등이다. 이렇게 베이스\n 포인터를 사용하는 관습은 함수 본문 안에서 지역 변수와 파라미터에\n 빠르게 접근할 수 있게 해준다.\n\n 서브루틴의 종결부는 기본적으로 도입부의 듀얼이다. 호출자의 레지스터\n 값을 스택에서 복원하고, 스택 포인터를 다시 세팅해서 지역 변수를\n 해제하고, 호출자의 베이스 포인터 값을 복원하고, `ret` 명령을 이용해서\n 호출자의 적절한 코드 위치로 되돌아간다."
					}
					,
					"ps-leetcode-zigzag-conversion": {
						"id": "ps-leetcode-zigzag-conversion",
						"title": "Zigzag Conversion",
						"version": "all",
						"categories": "",
						"url": " /ps/leetcode/zigzag-conversion/",
						"content": "{% raw %} Zigzag Conversion\n지그재그 모양에 현혹되면 안된다. 핵심은 numRows 만큼 문자열을 정방향 -&gt; 역방향\n  -&gt; 정방향 -&gt; &#8230; 으로 번갈아가며 (alternate) 훑는 것이다.\n번갈아가며 배열에 쌓는 방식\n번갈아가며 탐색한 결과를 배열에 쌓아서 최종 문자열을 만들 수 있다. 이때 현재\n  방향의 탐색이 끝나서 (= 범위를 벗어나서) 방향을 바꿀 때, 반대 방향으로 두 번\n  가야 한다는 점에 주의하자. 벗어남 -&gt; 역방향으로 한칸 (가장 최근에 추가한 위치)\n  -&gt; 역방향으로 한번 더 가야 그 다음 탐색할 위치가 된다.\ndef convert(s: str, numRows: int) -&gt; str:\n    if numRows == 1:\n        return s\n    rows = [[] for _ in range(numRows)]\n    i, d = 0, 1\n    for char in s:\n        rows[i].append(char)\n        i += d\n        if not (0 &lt;= i &lt; numRows):\n            d = -d\n            i += 2*d\n    rows = [&#39;&#39;.join(row) for row in rows]\n    return &#39;&#39;.join(rows)\n\n번갈아가며 문자열을 쌓는 방식\n별 건 없고 위의 방식에서 각 행의 탐색을 배열이 아니라 문자열로 쌓는 방식이다.\n  이러면 마지막에 &#39;&#39;.join() 을 한 번만 해줘도 된다.\ndef convert(s: str, numRows: int) -&gt; str:\n    rows = [&#39;&#39;] * numRows\n    i, d = 0, 1\n    for char in s:\n        rows[i] += char\n        i += d\n        if not (0 &lt;= i &lt; numRows):\n            d = -d\n            i += 2*d\n    return &#39;&#39;.join(rows)\n\n {% endraw %}"
					}
	};
</script>
<script src="/book/assets/js/lunr.min.js"></script>
<script src="/book/assets/js/search.js"></script>
              <br/>
          </div>
         </main>
       </div>
     </div>
     <footer class="bg-dark py-5 row d-print-none">
 <div class="container-fluid mx-sm-5">
   <div class="row">
     <div class="col-6 col-sm-4 text-xs-center order-sm-2">
       <ul class="list-inline mb-0">  
       </ul>
     </div>
     <div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
       <ul class="list-inline mb-0">  
         <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="" aria-label="GitHub" data-original-title="GitHub">
            <a class="text-white" target="_blank" href="https://github.com/sangwoo-joh/book">
              <i class="fab fa-github"></i>
            </a>
       </ul>
     </div>
     <div class="col-12 col-sm-4 text-center py-2 order-sm-2">
        <small class="text-white">© 2024 Sangwoo Joh All Rights Reserved</small>
     </div>
     <div class="col-12 text-center">
        <small class="text-white">Icons & favicons by <a href="https://icons8.com">icons8.com</a></small>
     </div>
   </div>
 </div>
</footer>
   </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
<script src="/book/assets/js/main.js"></script>
  
